{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30ff24b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "from official.nlp import optimization  # to create AdamW optmizer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "import math\n",
    "import numpy as np\n",
    "import sklearn.metrics as sk \n",
    "import pickle\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.spatial import distance\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from scipy.stats import entropy\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a45b44a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('20news-18828'):\n",
    "  shutil.rmtree('20news-18828')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b5f0849",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://qwone.com/~jason/20Newsgroups/20news-18828.tar.gz'\n",
    "\n",
    "dataset = tf.keras.utils.get_file('20news-18828.tar.gz', url,\n",
    "                                  untar=True, cache_dir='.',\n",
    "                                  cache_subdir='')\n",
    "\n",
    "dataset_dir = os.path.join(os.path.dirname(dataset), '20news')\n",
    "train_dir = os.path.join(dataset_dir, 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f37797a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'comp.sys.mac.hardware',\n",
       " 1: 'comp.os.ms-windows.misc',\n",
       " 2: 'rec.motorcycles',\n",
       " 3: 'talk.politics.misc',\n",
       " 4: 'comp.graphics',\n",
       " 5: 'talk.politics.mideast',\n",
       " 6: 'sci.med',\n",
       " 7: 'rec.sport.baseball',\n",
       " 8: 'talk.religion.misc',\n",
       " 9: 'sci.electronics',\n",
       " 10: 'comp.windows.x',\n",
       " 11: 'sci.crypt',\n",
       " 12: 'talk.politics.guns',\n",
       " 13: 'rec.sport.hockey',\n",
       " 14: 'rec.autos',\n",
       " 15: 'sci.space',\n",
       " 16: 'comp.sys.ibm.pc.hardware',\n",
       " 17: 'soc.religion.christian',\n",
       " 18: 'misc.forsale',\n",
       " 19: 'alt.atheism'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rootPath = '20news-18828'\n",
    "files = os.listdir(rootPath)\n",
    "\n",
    "all_classes = {}\n",
    "for ind in range(len(files)):\n",
    "  all_classes[ind] = files[ind]\n",
    "\n",
    "all_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ae037ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# models_path = \"outputs/\"\n",
    "# pickle_file_name = models_path + 'all_classes'\n",
    "# out_file = open(pickle_file_name,\"wb\")\n",
    "# pickle.dump(all_classes, out_file)\n",
    "# out_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752e57ba",
   "metadata": {},
   "source": [
    "# Set the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8e9f5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_path = \"outputs/\"\n",
    "pickle_file_name = models_path + 'all_classes'\n",
    "out_file = open(pickle_file_name,\"rb\")\n",
    "all_classes = pickle.load(out_file)\n",
    "out_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f806bda1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'comp.sys.mac.hardware',\n",
       " 1: 'comp.os.ms-windows.misc',\n",
       " 2: 'rec.motorcycles',\n",
       " 3: 'talk.politics.misc',\n",
       " 4: 'comp.graphics',\n",
       " 5: 'talk.politics.mideast',\n",
       " 6: 'sci.med',\n",
       " 7: 'rec.sport.baseball',\n",
       " 8: 'talk.religion.misc',\n",
       " 9: 'sci.electronics',\n",
       " 10: 'comp.windows.x',\n",
       " 11: 'sci.crypt',\n",
       " 12: 'talk.politics.guns',\n",
       " 13: 'rec.sport.hockey',\n",
       " 14: 'rec.autos',\n",
       " 15: 'sci.space',\n",
       " 16: 'comp.sys.ibm.pc.hardware',\n",
       " 17: 'soc.religion.christian',\n",
       " 18: 'misc.forsale',\n",
       " 19: 'alt.atheism'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "614acbed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first_10_classes_dict\n",
      "{   0: 'comp.sys.mac.hardware',\n",
      "    1: 'comp.os.ms-windows.misc',\n",
      "    2: 'rec.motorcycles',\n",
      "    3: 'talk.politics.misc',\n",
      "    4: 'comp.graphics',\n",
      "    5: 'talk.politics.mideast',\n",
      "    6: 'sci.med',\n",
      "    7: 'rec.sport.baseball',\n",
      "    8: 'talk.religion.misc',\n",
      "    9: 'sci.electronics'}\n",
      "id_classes_dict\n",
      "{   0: 'comp.sys.mac.hardware',\n",
      "    1: 'comp.os.ms-windows.misc',\n",
      "    2: 'rec.motorcycles',\n",
      "    3: 'talk.politics.misc',\n",
      "    4: 'comp.graphics',\n",
      "    5: 'talk.politics.mideast',\n",
      "    6: 'sci.med',\n",
      "    7: 'rec.sport.baseball',\n",
      "    8: 'talk.religion.misc'}\n",
      "anom_classes_dict\n",
      "{9: 'sci.electronics'}\n",
      "\n",
      "ID Classes\n",
      "------------\n",
      "[   'comp.sys.mac.hardware',\n",
      "    'comp.os.ms-windows.misc',\n",
      "    'rec.motorcycles',\n",
      "    'talk.politics.misc',\n",
      "    'comp.graphics',\n",
      "    'talk.politics.mideast',\n",
      "    'sci.med',\n",
      "    'rec.sport.baseball',\n",
      "    'talk.religion.misc']\n",
      "Anomalous Classes\n",
      "------------\n",
      "['sci.electronics']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'anom_9'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_10_classes_dict = {}\n",
    "for ind in all_classes:\n",
    "  if ind <= 9:\n",
    "    first_10_classes_dict[ind] = all_classes[ind]\n",
    "\n",
    "id_classes_ind = [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
    "anom_classes_ind = [9]\n",
    "\n",
    "id_classes_dict = {}\n",
    "for ind in all_classes:\n",
    "  if ind in id_classes_ind:\n",
    "    id_classes_dict[ind] = first_10_classes_dict[ind]\n",
    "\n",
    "anom_classes_dict = {}\n",
    "for ind in all_classes:\n",
    "  if ind in anom_classes_ind:\n",
    "    anom_classes_dict[ind] = first_10_classes_dict[ind]\n",
    "\n",
    "print(\"first_10_classes_dict\")\n",
    "pp.pprint(first_10_classes_dict)\n",
    "print(\"id_classes_dict\")\n",
    "pp.pprint(id_classes_dict)\n",
    "print(\"anom_classes_dict\")\n",
    "pp.pprint(anom_classes_dict)\n",
    "\n",
    "id_classes_whole = list(id_classes_dict.values())\n",
    "anom_classes = list(anom_classes_dict.values())\n",
    "\n",
    "print(\"\\nID Classes\\n------------\")\n",
    "pp.pprint(id_classes_whole)\n",
    "print(\"Anomalous Classes\\n------------\")\n",
    "pp.pprint(anom_classes)\n",
    "\n",
    "anom_class_name_for_path = \"anom_%d\" % (anom_classes_ind[0])\n",
    "anom_class_name_for_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16b68cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comp.sys.mac.hardware 961 192\n",
      "comp.os.ms-windows.misc 985 197\n",
      "rec.motorcycles 994 198\n",
      "talk.politics.misc 775 155\n",
      "comp.graphics 973 194\n",
      "talk.politics.mideast 940 188\n",
      "sci.med 990 198\n",
      "rec.sport.baseball 994 198\n",
      "talk.religion.misc 628 125\n"
     ]
    }
   ],
   "source": [
    "# Test has all class labels 0 - 9. Further separated by Test_OOD\n",
    "testPath = rootPath + \"/test\"\n",
    "if os.path.exists(testPath):\n",
    "  shutil.rmtree(testPath)\n",
    "os.mkdir(testPath)\n",
    "\n",
    "for className in files:\n",
    "  if className in first_10_classes_dict.values() and className not in anom_classes:\n",
    "    path = os.path.join(rootPath, className)\n",
    "    classTestPath = testPath+\"/\"+className\n",
    "    os.mkdir(classTestPath)\n",
    "    idFiles = os.listdir(path)\n",
    "    lenIdFiles = len(idFiles)\n",
    "    testLen = math.floor(0.2 * lenIdFiles)\n",
    "    print(className, lenIdFiles, testLen)\n",
    "    for ind, idFile in enumerate(idFiles):\n",
    "      if ind <= testLen:\n",
    "        shutil.move(os.path.join(rootPath, className, idFile), classTestPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eff4669b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comp.sys.mac.hardware 768 153\n",
      "comp.os.ms-windows.misc 787 157\n",
      "rec.motorcycles 795 159\n",
      "talk.politics.misc 619 123\n",
      "comp.graphics 778 155\n",
      "talk.politics.mideast 751 150\n",
      "sci.med 791 158\n",
      "rec.sport.baseball 795 159\n",
      "talk.religion.misc 502 100\n"
     ]
    }
   ],
   "source": [
    "# Validation has all class labels except for anomalous class \n",
    "# Here, 0 - 8\n",
    "testPath = rootPath + \"/val\"\n",
    "if os.path.exists(testPath):\n",
    "  shutil.rmtree(testPath)\n",
    "os.mkdir(testPath)\n",
    "\n",
    "for className in files:\n",
    "  if className in id_classes_whole:\n",
    "    path = os.path.join(rootPath, className)\n",
    "    classTestPath = testPath+\"/\"+className\n",
    "    os.mkdir(classTestPath)\n",
    "    idFiles = os.listdir(path)\n",
    "    lenIdFiles = len(idFiles)\n",
    "    testLen = math.floor(0.2 * lenIdFiles)\n",
    "    print(className, lenIdFiles, testLen)\n",
    "    for ind, idFile in enumerate(idFiles):\n",
    "      if ind <= testLen:\n",
    "        shutil.move(os.path.join(rootPath, className, idFile), classTestPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b18e1696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comp.sys.mac.hardware 614\n",
      "comp.os.ms-windows.misc 629\n",
      "rec.motorcycles 635\n",
      "talk.politics.misc 495\n",
      "comp.graphics 622\n",
      "talk.politics.mideast 600\n",
      "sci.med 632\n",
      "rec.sport.baseball 635\n",
      "talk.religion.misc 401\n"
     ]
    }
   ],
   "source": [
    "# Train has all class labels except for anomalous class \n",
    "# Here, 0 - 8\n",
    "testPath = rootPath + \"/train\"\n",
    "if os.path.exists(testPath):\n",
    "  shutil.rmtree(testPath)\n",
    "os.mkdir(testPath)\n",
    "\n",
    "for className in files:\n",
    "  if className in id_classes_whole:\n",
    "    path = os.path.join(rootPath, className)\n",
    "    classTestPath = testPath+\"/\"+className\n",
    "    os.mkdir(classTestPath)\n",
    "    idFiles = os.listdir(path)\n",
    "    lenIdFiles = len(idFiles)\n",
    "    # testLen = math.floor(0.2 * lenIdFiles)\n",
    "    print(className, lenIdFiles)\n",
    "    for idFile in idFiles:\n",
    "      shutil.move(os.path.join(rootPath, className, idFile), classTestPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "13d63488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test_OOD separates anomalous classes in the test.\n",
    "# Test contains 0 - 8\n",
    "# Test_OOD contains 9\n",
    "# files = os.listdir(rootPath + \"/test\")\n",
    "\n",
    "testPath = rootPath + \"/test_ood\"\n",
    "if os.path.exists(testPath):\n",
    "  shutil.rmtree(testPath)\n",
    "os.mkdir(testPath)\n",
    "\n",
    "for className in files:\n",
    "  if className in anom_classes:\n",
    "    path = os.path.join(rootPath, className)\n",
    "    classTestPath = testPath+\"/\"+className\n",
    "    os.mkdir(classTestPath)\n",
    "    idFiles = os.listdir(path)\n",
    "    lenIdFiles = len(idFiles)\n",
    "    # testLen = math.floor(0.2 * lenIdFiles)\n",
    "    # print(className, lenIdFiles, testLen)\n",
    "    for idFile in idFiles:\n",
    "      shutil.move(os.path.join(rootPath, className, idFile), classTestPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "30c98645",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_files_to_txt(id_ood_path):\n",
    "  print(\"Files in folder '%s' are renamed as .txt\" % id_ood_path)\n",
    "  files = os.listdir(id_ood_path)\n",
    "  \n",
    "  for i in files:\n",
    "    path = os.path.join(id_ood_path, i)\n",
    "    files = os.listdir(path)  \n",
    "    for index, file in enumerate(files):\n",
    "      os.rename(os.path.join(path, file), os.path.join(path, ''.join([str(index), '.txt'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "91f3c285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in folder '20news-18828/test' are renamed as .txt\n",
      "Files in folder '20news-18828/test_ood' are renamed as .txt\n",
      "Files in folder '20news-18828/val' are renamed as .txt\n",
      "Files in folder '20news-18828/train' are renamed as .txt\n"
     ]
    }
   ],
   "source": [
    "update_files_to_txt('20news-18828/test')\n",
    "update_files_to_txt('20news-18828/test_ood')\n",
    "update_files_to_txt('20news-18828/val')\n",
    "update_files_to_txt('20news-18828/train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a702ea9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1654 files belonging to 9 classes.\n"
     ]
    }
   ],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "batch_size = 32\n",
    "seed = 42\n",
    "\n",
    "test_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
    "    '20news-18828/test',\n",
    "    batch_size=batch_size)\n",
    "\n",
    "test_class_names = test_ds.class_names\n",
    "test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "130e5c92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'sci.med',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.religion.misc']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0f76b596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 981 files belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "batch_size = 32\n",
    "seed = 42\n",
    "\n",
    "test_ood_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
    "    '20news-18828/test_ood',\n",
    "    batch_size=batch_size)\n",
    "\n",
    "test_ood_class_names = test_ood_ds.class_names\n",
    "test_ood_ds = test_ood_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2ddd74ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sci.electronics']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ood_class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "37c80bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5263 files belonging to 9 classes.\n"
     ]
    }
   ],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "batch_size = 32\n",
    "seed = 42\n",
    "\n",
    "train_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
    "    '20news-18828/train',\n",
    "    batch_size=batch_size)\n",
    "\n",
    "train_class_names = train_ds.class_names\n",
    "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e042833a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'sci.med',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.religion.misc']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b5dc4649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1323 files belonging to 9 classes.\n"
     ]
    }
   ],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "batch_size = 32\n",
    "seed = 42\n",
    "\n",
    "val_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
    "    '20news-18828/val',\n",
    "    batch_size=batch_size)\n",
    "\n",
    "val_class_names = val_ds.class_names\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7c9332e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'sci.med',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.religion.misc']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8d630364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train labels {0, 1, 2, 3, 4, 5, 6, 7, 8}\n",
      "Val labels {0, 1, 2, 3, 4, 5, 6, 7, 8}\n",
      "Test ID labels {0, 1, 2, 3, 4, 5, 6, 7, 8}\n",
      "Test OOD labels {0}\n"
     ]
    }
   ],
   "source": [
    "# Checking for class labels\n",
    "def get_set_labels(ds):\n",
    "  labels = []\n",
    "  for _, label in ds:\n",
    "    labels.extend(label.numpy())\n",
    "  return set(labels)\n",
    "\n",
    "print(\"Train labels\", get_set_labels(train_ds))\n",
    "print(\"Val labels\", get_set_labels(val_ds))\n",
    "print(\"Test ID labels\", get_set_labels(test_ds))\n",
    "print(\"Test OOD labels\", get_set_labels(test_ood_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5c21ec56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train class names\n",
      "0 comp.graphics\n",
      "1 comp.os.ms-windows.misc\n",
      "2 comp.sys.mac.hardware\n",
      "3 rec.motorcycles\n",
      "4 rec.sport.baseball\n",
      "5 sci.med\n",
      "6 talk.politics.mideast\n",
      "7 talk.politics.misc\n",
      "8 talk.religion.misc\n",
      "\n",
      "Val class names\n",
      "0 comp.graphics\n",
      "1 comp.os.ms-windows.misc\n",
      "2 comp.sys.mac.hardware\n",
      "3 rec.motorcycles\n",
      "4 rec.sport.baseball\n",
      "5 sci.med\n",
      "6 talk.politics.mideast\n",
      "7 talk.politics.misc\n",
      "8 talk.religion.misc\n",
      "\n",
      "Test ID class names\n",
      "0 comp.graphics\n",
      "1 comp.os.ms-windows.misc\n",
      "2 comp.sys.mac.hardware\n",
      "3 rec.motorcycles\n",
      "4 rec.sport.baseball\n",
      "5 sci.med\n",
      "6 talk.politics.mideast\n",
      "7 talk.politics.misc\n",
      "8 talk.religion.misc\n",
      "\n",
      "Test OOD class names\n",
      "0 sci.electronics\n"
     ]
    }
   ],
   "source": [
    "# Class labels and class names\n",
    "def get_class_names(class_names):\n",
    "  for ind, name in enumerate(class_names):\n",
    "    print(ind, name)\n",
    "\n",
    "print(\"Train class names\")\n",
    "get_class_names(train_class_names)\n",
    "print(\"\\nVal class names\")\n",
    "get_class_names(val_class_names)\n",
    "print(\"\\nTest ID class names\")\n",
    "get_class_names(test_class_names)\n",
    "print(\"\\nTest OOD class names\")\n",
    "get_class_names(test_ood_class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "90c9e440",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_test_class_names = test_class_names + test_ood_class_names\n",
    "\n",
    "models_path = \"outputs/\" + anom_class_name_for_path + \"/\"\n",
    "\n",
    "try:\n",
    "  os.mkdir(models_path)\n",
    "except:\n",
    "  print(models_path, \"is already present.\")\n",
    "  pass\n",
    "\n",
    "pickle_file_name = models_path + 'all_test_class_names'\n",
    "out_file = open(pickle_file_name,\"wb\")\n",
    "pickle.dump(all_test_class_names, out_file)\n",
    "out_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eeb8cccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InOutData:\n",
    "  def __init__(self, leave_out_ind, id_classes_whole): \n",
    "    self.leave_out_class = id_classes_whole[leave_out_ind]\n",
    "    self.id_classes_whole = id_classes_whole\n",
    "    self.id_classes, self.ood_classes = self.get_id_ood_classes()\n",
    "\n",
    "    # do the steps for train ds\n",
    "    self.root_path = '20news-18828/train'\n",
    "    self.reset_id_ood_folders()\n",
    "    self.divide_id_ood_folders()\n",
    "    self.id_path = self.root_path + '/id_classes'\n",
    "    # self.ood_path = self.root_path + '/ood_classes'\n",
    "    self.update_files_to_txt(self.id_path)\n",
    "    # self.update_files_to_txt(self.ood_path)\n",
    "    self.train_ds, self.train_class_names = self.get_ds(self.id_path)\n",
    "\n",
    "    # do the steps for val ds\n",
    "    self.root_path = '20news-18828/val'\n",
    "    self.reset_id_ood_folders()\n",
    "    self.divide_id_ood_folders()\n",
    "    self.id_path = self.root_path + '/id_classes'\n",
    "    self.ood_path = self.root_path + '/ood_classes'\n",
    "    self.update_files_to_txt(self.id_path)\n",
    "    self.update_files_to_txt(self.ood_path)\n",
    "    self.val_ds, self.val_class_names = self.get_ds(self.id_path)\n",
    "    self.ood_ds, self.ood_class_names = self.get_ds(self.ood_path)\n",
    "\n",
    "  def get_id_ood_classes(self):\n",
    "    print(\"Fetching ID and OOD classes\")\n",
    "    id_classes, ood_classes = [], []\n",
    "    for i in self.id_classes_whole:\n",
    "      if i not in self.leave_out_class:\n",
    "        id_classes.append(i)\n",
    "      else:\n",
    "        ood_classes.append(i)\n",
    "    print(\"ID Classes\")\n",
    "    for name in id_classes:\n",
    "      ind = id_classes_whole.index(name)\n",
    "      print(ind, name)\n",
    "    print(\"OOD Classes\")\n",
    "    for name in ood_classes:\n",
    "      ind = id_classes_whole.index(name)\n",
    "      print(ind, name)\n",
    "    return id_classes, ood_classes\n",
    "\n",
    "  def reset_id_ood_folders(self):\n",
    "    print(\"Resetting ID and OOD folders\")\n",
    "    if os.path.exists(self.root_path + \"/id_classes\"):\n",
    "      shutil.rmtree(self.root_path + \"/id_classes\")\n",
    "\n",
    "    if os.path.exists(self.root_path + \"/ood_classes\"):\n",
    "      shutil.rmtree(self.root_path + \"/ood_classes\")\n",
    "      \n",
    "    os.mkdir(self.root_path + \"/id_classes\")\n",
    "    os.mkdir(self.root_path + \"/ood_classes\")\n",
    "  \n",
    "  def divide_id_ood_folders(self):\n",
    "    print(\"Dividing dataset as ID and OOD\")\n",
    "    files = os.listdir(self.root_path)\n",
    "\n",
    "    id_ood_str = \"\"\n",
    "\n",
    "    for i in files:\n",
    "      if i not in [\"id_classes\", \"ood_classes\"]:\n",
    "        if i in self.id_classes:\n",
    "          id_ood_str = \"id_classes\"\n",
    "        elif i in self.ood_classes:\n",
    "          id_ood_str = \"ood_classes\"\n",
    "        else:\n",
    "          id_ood_str = \"\"\n",
    "        path = os.path.join(self.root_path, id_ood_str, i)\n",
    "\n",
    "      if id_ood_str != \"\":\n",
    "        try:\n",
    "          os.mkdir(path)\n",
    "        except:\n",
    "          pass\n",
    "\n",
    "      orPath = os.path.join(self.root_path, i)\n",
    "\n",
    "      files_ = os.listdir(orPath)\n",
    "      for i in files_:\n",
    "        try:\n",
    "          shutil.copy(os.path.join(orPath, i), path)\n",
    "        except:\n",
    "          pass\n",
    "\n",
    "  def update_files_to_txt(self, id_ood_path):\n",
    "      print(\"Files in folder '%s' are renamed as .txt\" % id_ood_path)\n",
    "      files = os.listdir(id_ood_path)\n",
    "\n",
    "      for i in files:\n",
    "        path = os.path.join(id_ood_path, i)\n",
    "        files = os.listdir(path)  \n",
    "        for index, file in enumerate(files):\n",
    "          os.rename(os.path.join(path, file), os.path.join(path, ''.join([str(index), '.txt'])))\n",
    "\n",
    "  def get_ds(self, path):\n",
    "    AUTOTUNE = tf.data.AUTOTUNE\n",
    "    batch_size = 32\n",
    "    seed = 42\n",
    "\n",
    "    ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
    "        path,\n",
    "        batch_size=batch_size)\n",
    "\n",
    "    class_names = ds.class_names\n",
    "    ds = ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "    return ds, class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "32ad003c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTModel:\n",
    "  def __init__(self, train_ds):\n",
    "    self.tfhub_handle_encoder = 'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3'\n",
    "    self.tfhub_handle_preprocess = 'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3'\n",
    "    self.bert_preprocess_model = hub.KerasLayer(self.tfhub_handle_preprocess)\n",
    "    self.bert_model = hub.KerasLayer(self.tfhub_handle_encoder)\n",
    "    self.train_ds = train_ds\n",
    "    \n",
    "    self.num_of_classes = 8 # after leaving out one class, only 8 classes left\n",
    "    self.classifier_model = self.build_classifier_model()\n",
    "\n",
    "    self.loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "    self.metrics = tf.metrics.SparseCategoricalAccuracy()\n",
    "    self.optimizer = self.build_optimizer()\n",
    "\n",
    "    self.classifier_model.compile(\n",
    "        optimizer=self.optimizer,\n",
    "        loss=self.loss,\n",
    "        metrics=self.metrics,\n",
    "      )\n",
    "\n",
    "\n",
    "  def build_classifier_model(self):\n",
    "    text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
    "    preprocessing_layer = hub.KerasLayer(self.tfhub_handle_preprocess, name='preprocessing')\n",
    "    encoder_inputs = preprocessing_layer(text_input)\n",
    "    encoder = hub.KerasLayer(self.tfhub_handle_encoder, trainable=True, name='BERT_encoder')\n",
    "    outputs = encoder(encoder_inputs)\n",
    "    net = outputs['pooled_output']\n",
    "    net = tf.keras.layers.Dropout(0.1)(net)\n",
    "    net = tf.keras.layers.Dense(self.num_of_classes, activation=None, name='classifier')(net)\n",
    "    return tf.keras.Model(text_input, net)\n",
    "\n",
    "  def build_optimizer(self):\n",
    "    epochs = 10\n",
    "    steps_per_epoch = tf.data.experimental.cardinality(self.train_ds).numpy()\n",
    "    num_train_steps = steps_per_epoch * epochs\n",
    "    num_warmup_steps = int(0.1*num_train_steps)\n",
    "    # print(num_train_steps)\n",
    "    init_lr = 3e-5\n",
    "    optimizer = optimization.create_optimizer(init_lr=init_lr,\n",
    "                                              num_train_steps=num_train_steps,\n",
    "                                              num_warmup_steps=num_warmup_steps,\n",
    "                                              optimizer_type='adamw')\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6d72c8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getScores(class_ind, model, classifier_name):\n",
    "  def get_labels_and_logits(ds):\n",
    "    y = []\n",
    "    logits = []\n",
    "    for text_batch, label_batch in ds:\n",
    "      label = label_batch.numpy()\n",
    "      for lbl in label:\n",
    "        y.append(lbl)\n",
    "      text_test = text_batch\n",
    "      bert_raw_result = model(text_test)\n",
    "      for batch in bert_raw_result:\n",
    "        logits.append(batch)\n",
    "    return y, logits\n",
    "\n",
    "\n",
    "  y_val, logits_val = get_labels_and_logits(class_ind.val_ds)\n",
    "  y_ood, logits_ood = get_labels_and_logits(class_ind.ood_ds)\n",
    "  y_test, logits_test = get_labels_and_logits(test_ds)\n",
    "  y_anom, logits_anom = get_labels_and_logits(test_ood_ds)\n",
    "\n",
    "  out = {\n",
    "      'y_val': y_val,\n",
    "      'y_ood': y_ood,\n",
    "      'y_test': y_test,\n",
    "      'y_anom': y_anom,\n",
    "      'logits_val': logits_val,\n",
    "      'logits_ood': logits_ood,\n",
    "      'logits_test': logits_test,\n",
    "      'logits_anom': logits_anom,\n",
    "      'train_class_names': class_ind.train_class_names,\n",
    "      'val_class_names': class_ind.val_class_names,\n",
    "      'ood_class_names': class_ind.ood_class_names\n",
    "  }\n",
    "  \n",
    "  models_path = \"outputs/\" + anom_class_name_for_path + \"/\"\n",
    "  #if os.path.exists(models_path):\n",
    "  #  shutil.rmtree(models_path)\n",
    "  #os.mkdir(models_path)\n",
    "  \n",
    "  pickle_file_name = models_path + '%s_out' % classifier_name\n",
    "  out_file = open(pickle_file_name,\"wb\")\n",
    "  pickle.dump(out, out_file)\n",
    "  out_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "61f6af08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(classifier_name, leave_out_ind):\n",
    "  # Fetch dataset\n",
    "  class_ind = InOutData(leave_out_ind=leave_out_ind, id_classes_whole=id_classes_whole)\n",
    "  # Build and plot model\n",
    "  classifier_ind = BERTModel(class_ind.train_ds)\n",
    "\n",
    "  # Train model\n",
    "  classifier_ind.classifier_model.fit(x=class_ind.train_ds,\n",
    "                                      batch_size=32,\n",
    "                                      validation_data=class_ind.val_ds,\n",
    "                                      epochs=10, \n",
    "                                      verbose=1)\n",
    "\n",
    "  # Save model\n",
    "  # models_path = '/content/drive/MyDrive/Uni Projects/Anomaly Detection using Ensembles/Experiments/Text Dataset/models/'\n",
    "  # dataset_name = '%s_model' % classifier_name\n",
    "  # saved_model_path = models_path+'{}'.format(dataset_name.replace('/', '_'))\n",
    "  # classifier_ind.classifier_model.save(saved_model_path, include_optimizer=True)\n",
    "  getScores(class_ind, classifier_ind.classifier_model, classifier_name)\n",
    "\n",
    "  return classifier_ind.classifier_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bedaa69f",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5a7a1399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching ID and OOD classes\n",
      "ID Classes\n",
      "1 comp.os.ms-windows.misc\n",
      "2 rec.motorcycles\n",
      "3 talk.politics.misc\n",
      "4 comp.graphics\n",
      "5 talk.politics.mideast\n",
      "6 sci.med\n",
      "7 rec.sport.baseball\n",
      "8 talk.religion.misc\n",
      "OOD Classes\n",
      "0 comp.sys.mac.hardware\n",
      "Resetting ID and OOD folders\n",
      "Dividing dataset as ID and OOD\n",
      "Files in folder '20news-18828/train/id_classes' are renamed as .txt\n",
      "Found 2324 files belonging to 8 classes.\n",
      "Resetting ID and OOD folders\n",
      "Dividing dataset as ID and OOD\n",
      "Files in folder '20news-18828/val/id_classes' are renamed as .txt\n",
      "Files in folder '20news-18828/val/ood_classes' are renamed as .txt\n",
      "Found 607 files belonging to 8 classes.\n",
      "Found 79 files belonging to 1 classes.\n",
      "Epoch 1/10\n",
      "73/73 [==============================] - 48s 501ms/step - loss: 2.1585 - sparse_categorical_accuracy: 0.1827 - val_loss: 0.5886 - val_sparse_categorical_accuracy: 0.8171\n",
      "Epoch 2/10\n",
      "73/73 [==============================] - 36s 490ms/step - loss: 0.4845 - sparse_categorical_accuracy: 0.8506 - val_loss: 0.3257 - val_sparse_categorical_accuracy: 0.8896\n",
      "Epoch 3/10\n",
      "73/73 [==============================] - 36s 490ms/step - loss: 0.2141 - sparse_categorical_accuracy: 0.9364 - val_loss: 0.2435 - val_sparse_categorical_accuracy: 0.9176\n",
      "Epoch 4/10\n",
      "73/73 [==============================] - 36s 491ms/step - loss: 0.1146 - sparse_categorical_accuracy: 0.9657 - val_loss: 0.2781 - val_sparse_categorical_accuracy: 0.9226\n",
      "Epoch 5/10\n",
      "73/73 [==============================] - 36s 493ms/step - loss: 0.0441 - sparse_categorical_accuracy: 0.9892 - val_loss: 0.2971 - val_sparse_categorical_accuracy: 0.9275\n",
      "Epoch 6/10\n",
      "73/73 [==============================] - 36s 494ms/step - loss: 0.0230 - sparse_categorical_accuracy: 0.9965 - val_loss: 0.2666 - val_sparse_categorical_accuracy: 0.9275\n",
      "Epoch 7/10\n",
      "73/73 [==============================] - 36s 490ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9985 - val_loss: 0.2777 - val_sparse_categorical_accuracy: 0.9226\n",
      "Epoch 8/10\n",
      "73/73 [==============================] - 36s 491ms/step - loss: 0.0040 - sparse_categorical_accuracy: 0.9989 - val_loss: 0.2746 - val_sparse_categorical_accuracy: 0.9275\n",
      "Epoch 9/10\n",
      "73/73 [==============================] - 36s 491ms/step - loss: 0.0019 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.2939 - val_sparse_categorical_accuracy: 0.9259\n",
      "Epoch 10/10\n",
      "73/73 [==============================] - 36s 489ms/step - loss: 9.1948e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.2926 - val_sparse_categorical_accuracy: 0.9275\n"
     ]
    }
   ],
   "source": [
    "model0 = train_model(classifier_name=\"class_0\", leave_out_ind=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7764ba8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching ID and OOD classes\n",
      "ID Classes\n",
      "0 comp.sys.mac.hardware\n",
      "2 rec.motorcycles\n",
      "3 talk.politics.misc\n",
      "4 comp.graphics\n",
      "5 talk.politics.mideast\n",
      "6 sci.med\n",
      "7 rec.sport.baseball\n",
      "8 talk.religion.misc\n",
      "OOD Classes\n",
      "1 comp.os.ms-windows.misc\n",
      "Resetting ID and OOD folders\n",
      "Dividing dataset as ID and OOD\n",
      "Files in folder '20news-18828/train/id_classes' are renamed as .txt\n",
      "Found 2313 files belonging to 8 classes.\n",
      "Resetting ID and OOD folders\n",
      "Dividing dataset as ID and OOD\n",
      "Files in folder '20news-18828/val/id_classes' are renamed as .txt\n",
      "Files in folder '20news-18828/val/ood_classes' are renamed as .txt\n",
      "Found 605 files belonging to 8 classes.\n",
      "Found 81 files belonging to 1 classes.\n",
      "Epoch 1/10\n",
      "73/73 [==============================] - 46s 486ms/step - loss: 2.1875 - sparse_categorical_accuracy: 0.2001 - val_loss: 0.7087 - val_sparse_categorical_accuracy: 0.8364\n",
      "Epoch 2/10\n",
      "73/73 [==============================] - 35s 478ms/step - loss: 0.4735 - sparse_categorical_accuracy: 0.8795 - val_loss: 0.2305 - val_sparse_categorical_accuracy: 0.9240\n",
      "Epoch 3/10\n",
      "73/73 [==============================] - 35s 477ms/step - loss: 0.1191 - sparse_categorical_accuracy: 0.9613 - val_loss: 0.2101 - val_sparse_categorical_accuracy: 0.9339\n",
      "Epoch 4/10\n",
      "73/73 [==============================] - 35s 480ms/step - loss: 0.0374 - sparse_categorical_accuracy: 0.9885 - val_loss: 0.3004 - val_sparse_categorical_accuracy: 0.9289\n",
      "Epoch 5/10\n",
      "73/73 [==============================] - 35s 479ms/step - loss: 0.0244 - sparse_categorical_accuracy: 0.9922 - val_loss: 0.2614 - val_sparse_categorical_accuracy: 0.9388\n",
      "Epoch 6/10\n",
      "73/73 [==============================] - 35s 480ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9991 - val_loss: 0.2239 - val_sparse_categorical_accuracy: 0.9504\n",
      "Epoch 7/10\n",
      "73/73 [==============================] - 35s 478ms/step - loss: 0.0011 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.2368 - val_sparse_categorical_accuracy: 0.9504\n",
      "Epoch 8/10\n",
      "73/73 [==============================] - 35s 478ms/step - loss: 5.3238e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.2325 - val_sparse_categorical_accuracy: 0.9488\n",
      "Epoch 9/10\n",
      "73/73 [==============================] - 35s 477ms/step - loss: 5.5119e-04 - sparse_categorical_accuracy: 0.9999 - val_loss: 0.2252 - val_sparse_categorical_accuracy: 0.9521\n",
      "Epoch 10/10\n",
      "73/73 [==============================] - 35s 480ms/step - loss: 4.6742e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.2251 - val_sparse_categorical_accuracy: 0.9471\n"
     ]
    }
   ],
   "source": [
    "model1 = train_model(classifier_name=\"class_1\", leave_out_ind=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "673e9095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching ID and OOD classes\n",
      "ID Classes\n",
      "0 comp.sys.mac.hardware\n",
      "1 comp.os.ms-windows.misc\n",
      "3 talk.politics.misc\n",
      "4 comp.graphics\n",
      "5 talk.politics.mideast\n",
      "6 sci.med\n",
      "7 rec.sport.baseball\n",
      "8 talk.religion.misc\n",
      "OOD Classes\n",
      "2 rec.motorcycles\n",
      "Resetting ID and OOD folders\n",
      "Dividing dataset as ID and OOD\n",
      "Files in folder '20news-18828/train/id_classes' are renamed as .txt\n",
      "Found 2310 files belonging to 8 classes.\n",
      "Resetting ID and OOD folders\n",
      "Dividing dataset as ID and OOD\n",
      "Files in folder '20news-18828/val/id_classes' are renamed as .txt\n",
      "Files in folder '20news-18828/val/ood_classes' are renamed as .txt\n",
      "Found 604 files belonging to 8 classes.\n",
      "Found 82 files belonging to 1 classes.\n",
      "Epoch 1/10\n",
      "73/73 [==============================] - 48s 498ms/step - loss: 2.1138 - sparse_categorical_accuracy: 0.1779 - val_loss: 0.6914 - val_sparse_categorical_accuracy: 0.8030\n",
      "Epoch 2/10\n",
      "73/73 [==============================] - 36s 488ms/step - loss: 0.5642 - sparse_categorical_accuracy: 0.8314 - val_loss: 0.3006 - val_sparse_categorical_accuracy: 0.9023\n",
      "Epoch 3/10\n",
      "73/73 [==============================] - 36s 491ms/step - loss: 0.1732 - sparse_categorical_accuracy: 0.9483 - val_loss: 0.3096 - val_sparse_categorical_accuracy: 0.9156\n",
      "Epoch 4/10\n",
      "73/73 [==============================] - 36s 487ms/step - loss: 0.0751 - sparse_categorical_accuracy: 0.9806 - val_loss: 0.3407 - val_sparse_categorical_accuracy: 0.9123\n",
      "Epoch 5/10\n",
      "73/73 [==============================] - 36s 490ms/step - loss: 0.0411 - sparse_categorical_accuracy: 0.9891 - val_loss: 0.2990 - val_sparse_categorical_accuracy: 0.9321\n",
      "Epoch 6/10\n",
      "73/73 [==============================] - 36s 490ms/step - loss: 0.0220 - sparse_categorical_accuracy: 0.9930 - val_loss: 0.2657 - val_sparse_categorical_accuracy: 0.9454\n",
      "Epoch 7/10\n",
      "73/73 [==============================] - 36s 490ms/step - loss: 0.0062 - sparse_categorical_accuracy: 0.9985 - val_loss: 0.2639 - val_sparse_categorical_accuracy: 0.9454\n",
      "Epoch 8/10\n",
      "73/73 [==============================] - 36s 489ms/step - loss: 0.0019 - sparse_categorical_accuracy: 0.9997 - val_loss: 0.2651 - val_sparse_categorical_accuracy: 0.9421\n",
      "Epoch 9/10\n",
      "73/73 [==============================] - 36s 490ms/step - loss: 0.0010 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.2667 - val_sparse_categorical_accuracy: 0.9454\n",
      "Epoch 10/10\n",
      "73/73 [==============================] - 36s 489ms/step - loss: 6.7568e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.2702 - val_sparse_categorical_accuracy: 0.9454\n"
     ]
    }
   ],
   "source": [
    "model2 = train_model(classifier_name=\"class_2\", leave_out_ind=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0aed53bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching ID and OOD classes\n",
      "ID Classes\n",
      "0 comp.sys.mac.hardware\n",
      "1 comp.os.ms-windows.misc\n",
      "2 rec.motorcycles\n",
      "4 comp.graphics\n",
      "5 talk.politics.mideast\n",
      "6 sci.med\n",
      "7 rec.sport.baseball\n",
      "8 talk.religion.misc\n",
      "OOD Classes\n",
      "3 talk.politics.misc\n",
      "Resetting ID and OOD folders\n",
      "Dividing dataset as ID and OOD\n",
      "Files in folder '20news-18828/train/id_classes' are renamed as .txt\n",
      "Found 2372 files belonging to 8 classes.\n",
      "Resetting ID and OOD folders\n",
      "Dividing dataset as ID and OOD\n",
      "Files in folder '20news-18828/val/id_classes' are renamed as .txt\n",
      "Files in folder '20news-18828/val/ood_classes' are renamed as .txt\n",
      "Found 617 files belonging to 8 classes.\n",
      "Found 69 files belonging to 1 classes.\n",
      "Epoch 1/10\n",
      "75/75 [==============================] - 51s 496ms/step - loss: 1.9809 - sparse_categorical_accuracy: 0.2428 - val_loss: 0.5032 - val_sparse_categorical_accuracy: 0.8622\n",
      "Epoch 2/10\n",
      "75/75 [==============================] - 37s 489ms/step - loss: 0.3836 - sparse_categorical_accuracy: 0.8793 - val_loss: 0.2412 - val_sparse_categorical_accuracy: 0.9303\n",
      "Epoch 3/10\n",
      "75/75 [==============================] - 37s 488ms/step - loss: 0.1222 - sparse_categorical_accuracy: 0.9662 - val_loss: 0.2356 - val_sparse_categorical_accuracy: 0.9319\n",
      "Epoch 4/10\n",
      "75/75 [==============================] - 36s 487ms/step - loss: 0.0471 - sparse_categorical_accuracy: 0.9875 - val_loss: 0.2310 - val_sparse_categorical_accuracy: 0.9384\n",
      "Epoch 5/10\n",
      "75/75 [==============================] - 37s 487ms/step - loss: 0.0113 - sparse_categorical_accuracy: 0.9973 - val_loss: 0.2633 - val_sparse_categorical_accuracy: 0.9352\n",
      "Epoch 6/10\n",
      "75/75 [==============================] - 37s 488ms/step - loss: 0.0041 - sparse_categorical_accuracy: 0.9994 - val_loss: 0.2552 - val_sparse_categorical_accuracy: 0.9465\n",
      "Epoch 7/10\n",
      "75/75 [==============================] - 36s 487ms/step - loss: 0.0014 - sparse_categorical_accuracy: 0.9999 - val_loss: 0.2545 - val_sparse_categorical_accuracy: 0.9546\n",
      "Epoch 8/10\n",
      "75/75 [==============================] - 36s 486ms/step - loss: 0.0015 - sparse_categorical_accuracy: 0.9995 - val_loss: 0.2490 - val_sparse_categorical_accuracy: 0.9498\n",
      "Epoch 9/10\n",
      "75/75 [==============================] - 37s 489ms/step - loss: 7.1775e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.2580 - val_sparse_categorical_accuracy: 0.9481\n",
      "Epoch 10/10\n",
      "75/75 [==============================] - 37s 488ms/step - loss: 6.4730e-04 - sparse_categorical_accuracy: 0.9999 - val_loss: 0.2583 - val_sparse_categorical_accuracy: 0.9481\n"
     ]
    }
   ],
   "source": [
    "model3 = train_model(classifier_name=\"class_3\", leave_out_ind=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2c0fce7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching ID and OOD classes\n",
      "ID Classes\n",
      "0 comp.sys.mac.hardware\n",
      "1 comp.os.ms-windows.misc\n",
      "2 rec.motorcycles\n",
      "3 talk.politics.misc\n",
      "5 talk.politics.mideast\n",
      "6 sci.med\n",
      "7 rec.sport.baseball\n",
      "8 talk.religion.misc\n",
      "OOD Classes\n",
      "4 comp.graphics\n",
      "Resetting ID and OOD folders\n",
      "Dividing dataset as ID and OOD\n",
      "Files in folder '20news-18828/train/id_classes' are renamed as .txt\n",
      "Found 2318 files belonging to 8 classes.\n",
      "Resetting ID and OOD folders\n",
      "Dividing dataset as ID and OOD\n",
      "Files in folder '20news-18828/val/id_classes' are renamed as .txt\n",
      "Files in folder '20news-18828/val/ood_classes' are renamed as .txt\n",
      "Found 607 files belonging to 8 classes.\n",
      "Found 79 files belonging to 1 classes.\n",
      "Epoch 1/10\n",
      "73/73 [==============================] - 47s 495ms/step - loss: 2.0510 - sparse_categorical_accuracy: 0.2120 - val_loss: 0.4566 - val_sparse_categorical_accuracy: 0.8748\n",
      "Epoch 2/10\n",
      "73/73 [==============================] - 36s 487ms/step - loss: 0.4021 - sparse_categorical_accuracy: 0.8819 - val_loss: 0.2104 - val_sparse_categorical_accuracy: 0.9390\n",
      "Epoch 3/10\n",
      "73/73 [==============================] - 36s 489ms/step - loss: 0.1236 - sparse_categorical_accuracy: 0.9648 - val_loss: 0.2088 - val_sparse_categorical_accuracy: 0.9473\n",
      "Epoch 4/10\n",
      "73/73 [==============================] - 36s 488ms/step - loss: 0.0405 - sparse_categorical_accuracy: 0.9916 - val_loss: 0.2471 - val_sparse_categorical_accuracy: 0.9423\n",
      "Epoch 5/10\n",
      "73/73 [==============================] - 36s 488ms/step - loss: 0.0173 - sparse_categorical_accuracy: 0.9955 - val_loss: 0.2683 - val_sparse_categorical_accuracy: 0.9473\n",
      "Epoch 6/10\n",
      "73/73 [==============================] - 36s 489ms/step - loss: 0.0021 - sparse_categorical_accuracy: 0.9995 - val_loss: 0.2406 - val_sparse_categorical_accuracy: 0.9506\n",
      "Epoch 7/10\n",
      "73/73 [==============================] - 36s 489ms/step - loss: 0.0014 - sparse_categorical_accuracy: 0.9994 - val_loss: 0.2390 - val_sparse_categorical_accuracy: 0.9522\n",
      "Epoch 8/10\n",
      "73/73 [==============================] - 36s 489ms/step - loss: 9.3754e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.2352 - val_sparse_categorical_accuracy: 0.9539\n",
      "Epoch 9/10\n",
      "73/73 [==============================] - 36s 489ms/step - loss: 5.5320e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.2488 - val_sparse_categorical_accuracy: 0.9506\n",
      "Epoch 10/10\n",
      "73/73 [==============================] - 36s 488ms/step - loss: 5.0136e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.2489 - val_sparse_categorical_accuracy: 0.9506\n"
     ]
    }
   ],
   "source": [
    "model4 = train_model(classifier_name=\"class_4\", leave_out_ind=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "20ec114a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching ID and OOD classes\n",
      "ID Classes\n",
      "0 comp.sys.mac.hardware\n",
      "1 comp.os.ms-windows.misc\n",
      "2 rec.motorcycles\n",
      "3 talk.politics.misc\n",
      "4 comp.graphics\n",
      "6 sci.med\n",
      "7 rec.sport.baseball\n",
      "8 talk.religion.misc\n",
      "OOD Classes\n",
      "5 talk.politics.mideast\n",
      "Resetting ID and OOD folders\n",
      "Dividing dataset as ID and OOD\n",
      "Files in folder '20news-18828/train/id_classes' are renamed as .txt\n",
      "Found 2331 files belonging to 8 classes.\n",
      "Resetting ID and OOD folders\n",
      "Dividing dataset as ID and OOD\n",
      "Files in folder '20news-18828/val/id_classes' are renamed as .txt\n",
      "Files in folder '20news-18828/val/ood_classes' are renamed as .txt\n",
      "Found 606 files belonging to 8 classes.\n",
      "Found 80 files belonging to 1 classes.\n",
      "Epoch 1/10\n",
      "73/73 [==============================] - 47s 499ms/step - loss: 2.1796 - sparse_categorical_accuracy: 0.1776 - val_loss: 0.6203 - val_sparse_categorical_accuracy: 0.8317\n",
      "Epoch 2/10\n",
      "73/73 [==============================] - 36s 490ms/step - loss: 0.5467 - sparse_categorical_accuracy: 0.8404 - val_loss: 0.2940 - val_sparse_categorical_accuracy: 0.9125\n",
      "Epoch 3/10\n",
      "73/73 [==============================] - 36s 490ms/step - loss: 0.1890 - sparse_categorical_accuracy: 0.9497 - val_loss: 0.2468 - val_sparse_categorical_accuracy: 0.9340\n",
      "Epoch 4/10\n",
      "73/73 [==============================] - 36s 490ms/step - loss: 0.0723 - sparse_categorical_accuracy: 0.9776 - val_loss: 0.2325 - val_sparse_categorical_accuracy: 0.9340\n",
      "Epoch 5/10\n",
      "73/73 [==============================] - 36s 489ms/step - loss: 0.0243 - sparse_categorical_accuracy: 0.9939 - val_loss: 0.2636 - val_sparse_categorical_accuracy: 0.9340\n",
      "Epoch 6/10\n",
      "73/73 [==============================] - 36s 490ms/step - loss: 0.0095 - sparse_categorical_accuracy: 0.9960 - val_loss: 0.2722 - val_sparse_categorical_accuracy: 0.9323\n",
      "Epoch 7/10\n",
      "73/73 [==============================] - 36s 490ms/step - loss: 0.0064 - sparse_categorical_accuracy: 0.9989 - val_loss: 0.2841 - val_sparse_categorical_accuracy: 0.9356\n",
      "Epoch 8/10\n",
      "73/73 [==============================] - 36s 492ms/step - loss: 0.0052 - sparse_categorical_accuracy: 0.9993 - val_loss: 0.2815 - val_sparse_categorical_accuracy: 0.9389\n",
      "Epoch 9/10\n",
      "73/73 [==============================] - 36s 490ms/step - loss: 9.3854e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.2884 - val_sparse_categorical_accuracy: 0.9389\n",
      "Epoch 10/10\n",
      "73/73 [==============================] - 36s 490ms/step - loss: 9.6478e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.2855 - val_sparse_categorical_accuracy: 0.9406\n"
     ]
    }
   ],
   "source": [
    "model5 = train_model(classifier_name=\"class_5\", leave_out_ind=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dfdf6c0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching ID and OOD classes\n",
      "ID Classes\n",
      "0 comp.sys.mac.hardware\n",
      "1 comp.os.ms-windows.misc\n",
      "2 rec.motorcycles\n",
      "3 talk.politics.misc\n",
      "4 comp.graphics\n",
      "5 talk.politics.mideast\n",
      "7 rec.sport.baseball\n",
      "8 talk.religion.misc\n",
      "OOD Classes\n",
      "6 sci.med\n",
      "Resetting ID and OOD folders\n",
      "Dividing dataset as ID and OOD\n",
      "Files in folder '20news-18828/train/id_classes' are renamed as .txt\n",
      "Found 2310 files belonging to 8 classes.\n",
      "Resetting ID and OOD folders\n",
      "Dividing dataset as ID and OOD\n",
      "Files in folder '20news-18828/val/id_classes' are renamed as .txt\n",
      "Files in folder '20news-18828/val/ood_classes' are renamed as .txt\n",
      "Found 604 files belonging to 8 classes.\n",
      "Found 82 files belonging to 1 classes.\n",
      "Epoch 1/10\n",
      "73/73 [==============================] - 47s 498ms/step - loss: 2.1830 - sparse_categorical_accuracy: 0.1654 - val_loss: 0.6621 - val_sparse_categorical_accuracy: 0.8262\n",
      "Epoch 2/10\n",
      "73/73 [==============================] - 36s 488ms/step - loss: 0.5667 - sparse_categorical_accuracy: 0.8243 - val_loss: 0.3411 - val_sparse_categorical_accuracy: 0.8957\n",
      "Epoch 3/10\n",
      "73/73 [==============================] - 36s 490ms/step - loss: 0.2076 - sparse_categorical_accuracy: 0.9365 - val_loss: 0.2243 - val_sparse_categorical_accuracy: 0.9222\n",
      "Epoch 4/10\n",
      "73/73 [==============================] - 36s 491ms/step - loss: 0.0746 - sparse_categorical_accuracy: 0.9753 - val_loss: 0.2633 - val_sparse_categorical_accuracy: 0.9305\n",
      "Epoch 5/10\n",
      "73/73 [==============================] - 36s 490ms/step - loss: 0.0320 - sparse_categorical_accuracy: 0.9904 - val_loss: 0.2679 - val_sparse_categorical_accuracy: 0.9321\n",
      "Epoch 6/10\n",
      "73/73 [==============================] - 36s 490ms/step - loss: 0.0106 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.3118 - val_sparse_categorical_accuracy: 0.9222\n",
      "Epoch 7/10\n",
      "73/73 [==============================] - 36s 491ms/step - loss: 0.0112 - sparse_categorical_accuracy: 0.9973 - val_loss: 0.3001 - val_sparse_categorical_accuracy: 0.9288\n",
      "Epoch 8/10\n",
      "73/73 [==============================] - 36s 491ms/step - loss: 0.0041 - sparse_categorical_accuracy: 0.9992 - val_loss: 0.2417 - val_sparse_categorical_accuracy: 0.9454\n",
      "Epoch 9/10\n",
      "73/73 [==============================] - 36s 490ms/step - loss: 0.0015 - sparse_categorical_accuracy: 0.9992 - val_loss: 0.2376 - val_sparse_categorical_accuracy: 0.9421\n",
      "Epoch 10/10\n",
      "73/73 [==============================] - 36s 490ms/step - loss: 7.7026e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.2383 - val_sparse_categorical_accuracy: 0.9421\n"
     ]
    }
   ],
   "source": [
    "model6 = train_model(classifier_name=\"class_6\", leave_out_ind=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3c4a9f85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching ID and OOD classes\n",
      "ID Classes\n",
      "0 comp.sys.mac.hardware\n",
      "1 comp.os.ms-windows.misc\n",
      "2 rec.motorcycles\n",
      "3 talk.politics.misc\n",
      "4 comp.graphics\n",
      "5 talk.politics.mideast\n",
      "6 sci.med\n",
      "8 talk.religion.misc\n",
      "OOD Classes\n",
      "7 rec.sport.baseball\n",
      "Resetting ID and OOD folders\n",
      "Dividing dataset as ID and OOD\n",
      "Files in folder '20news-18828/train/id_classes' are renamed as .txt\n",
      "Found 2310 files belonging to 8 classes.\n",
      "Resetting ID and OOD folders\n",
      "Dividing dataset as ID and OOD\n",
      "Files in folder '20news-18828/val/id_classes' are renamed as .txt\n",
      "Files in folder '20news-18828/val/ood_classes' are renamed as .txt\n",
      "Found 604 files belonging to 8 classes.\n",
      "Found 82 files belonging to 1 classes.\n",
      "Epoch 1/10\n",
      "73/73 [==============================] - 47s 496ms/step - loss: 2.0731 - sparse_categorical_accuracy: 0.1862 - val_loss: 0.7588 - val_sparse_categorical_accuracy: 0.7980\n",
      "Epoch 2/10\n",
      "73/73 [==============================] - 36s 487ms/step - loss: 0.5826 - sparse_categorical_accuracy: 0.8325 - val_loss: 0.2929 - val_sparse_categorical_accuracy: 0.8974\n",
      "Epoch 3/10\n",
      "73/73 [==============================] - 36s 489ms/step - loss: 0.1898 - sparse_categorical_accuracy: 0.9419 - val_loss: 0.2810 - val_sparse_categorical_accuracy: 0.9272\n",
      "Epoch 4/10\n",
      "73/73 [==============================] - 36s 489ms/step - loss: 0.0776 - sparse_categorical_accuracy: 0.9779 - val_loss: 0.3144 - val_sparse_categorical_accuracy: 0.9222\n",
      "Epoch 5/10\n",
      "73/73 [==============================] - 36s 488ms/step - loss: 0.0402 - sparse_categorical_accuracy: 0.9895 - val_loss: 0.3192 - val_sparse_categorical_accuracy: 0.9272\n",
      "Epoch 6/10\n",
      "73/73 [==============================] - 36s 489ms/step - loss: 0.0195 - sparse_categorical_accuracy: 0.9954 - val_loss: 0.2829 - val_sparse_categorical_accuracy: 0.9305\n",
      "Epoch 7/10\n",
      "73/73 [==============================] - 36s 487ms/step - loss: 0.0056 - sparse_categorical_accuracy: 0.9992 - val_loss: 0.2925 - val_sparse_categorical_accuracy: 0.9354\n",
      "Epoch 8/10\n",
      "73/73 [==============================] - 36s 490ms/step - loss: 0.0015 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3003 - val_sparse_categorical_accuracy: 0.9371\n",
      "Epoch 9/10\n",
      "73/73 [==============================] - 36s 489ms/step - loss: 0.0023 - sparse_categorical_accuracy: 0.9994 - val_loss: 0.2990 - val_sparse_categorical_accuracy: 0.9404\n",
      "Epoch 10/10\n",
      "73/73 [==============================] - 36s 488ms/step - loss: 9.7862e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3003 - val_sparse_categorical_accuracy: 0.9387\n"
     ]
    }
   ],
   "source": [
    "model7 = train_model(classifier_name=\"class_7\", leave_out_ind=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c28e8cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching ID and OOD classes\n",
      "ID Classes\n",
      "0 comp.sys.mac.hardware\n",
      "1 comp.os.ms-windows.misc\n",
      "2 rec.motorcycles\n",
      "3 talk.politics.misc\n",
      "4 comp.graphics\n",
      "5 talk.politics.mideast\n",
      "6 sci.med\n",
      "7 rec.sport.baseball\n",
      "OOD Classes\n",
      "8 talk.religion.misc\n",
      "Resetting ID and OOD folders\n",
      "Dividing dataset as ID and OOD\n",
      "Files in folder '20news-18828/train/id_classes' are renamed as .txt\n",
      "Found 2428 files belonging to 8 classes.\n",
      "Resetting ID and OOD folders\n",
      "Dividing dataset as ID and OOD\n",
      "Files in folder '20news-18828/val/id_classes' are renamed as .txt\n",
      "Files in folder '20news-18828/val/ood_classes' are renamed as .txt\n",
      "Found 634 files belonging to 8 classes.\n",
      "Found 52 files belonging to 1 classes.\n",
      "Epoch 1/10\n",
      "76/76 [==============================] - 49s 501ms/step - loss: 2.0377 - sparse_categorical_accuracy: 0.2063 - val_loss: 0.6044 - val_sparse_categorical_accuracy: 0.8328\n",
      "Epoch 2/10\n",
      "76/76 [==============================] - 37s 490ms/step - loss: 0.4926 - sparse_categorical_accuracy: 0.8523 - val_loss: 0.2698 - val_sparse_categorical_accuracy: 0.9196\n",
      "Epoch 3/10\n",
      "76/76 [==============================] - 37s 489ms/step - loss: 0.1957 - sparse_categorical_accuracy: 0.9407 - val_loss: 0.2509 - val_sparse_categorical_accuracy: 0.9243\n",
      "Epoch 4/10\n",
      "76/76 [==============================] - 37s 491ms/step - loss: 0.0867 - sparse_categorical_accuracy: 0.9731 - val_loss: 0.2565 - val_sparse_categorical_accuracy: 0.9290\n",
      "Epoch 5/10\n",
      "76/76 [==============================] - 37s 492ms/step - loss: 0.0468 - sparse_categorical_accuracy: 0.9828 - val_loss: 0.2319 - val_sparse_categorical_accuracy: 0.9432\n",
      "Epoch 6/10\n",
      "76/76 [==============================] - 37s 491ms/step - loss: 0.0093 - sparse_categorical_accuracy: 0.9973 - val_loss: 0.2616 - val_sparse_categorical_accuracy: 0.9448\n",
      "Epoch 7/10\n",
      "76/76 [==============================] - 37s 490ms/step - loss: 0.0032 - sparse_categorical_accuracy: 0.9992 - val_loss: 0.2728 - val_sparse_categorical_accuracy: 0.9416\n",
      "Epoch 8/10\n",
      "76/76 [==============================] - 37s 491ms/step - loss: 0.0016 - sparse_categorical_accuracy: 0.9995 - val_loss: 0.2760 - val_sparse_categorical_accuracy: 0.9401\n",
      "Epoch 9/10\n",
      "76/76 [==============================] - 37s 492ms/step - loss: 8.8550e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.2755 - val_sparse_categorical_accuracy: 0.9416\n",
      "Epoch 10/10\n",
      "76/76 [==============================] - 37s 492ms/step - loss: 0.0012 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.2737 - val_sparse_categorical_accuracy: 0.9416\n"
     ]
    }
   ],
   "source": [
    "model8 = train_model(classifier_name=\"class_8\", leave_out_ind=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776a2f73",
   "metadata": {},
   "source": [
    "# Reload logits from pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f9ac6f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "anom_class_name_for_path = 'anom_9'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "187fa7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_path = \"outputs/\" + anom_class_name_for_path + \"/\"\n",
    "pickle_file_name = models_path + 'all_test_class_names'\n",
    "out_file = open(pickle_file_name,\"rb\")\n",
    "all_test_class_names = pickle.load(out_file)\n",
    "out_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a6cd4688",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLogits(classifier_name):\n",
    "  pickle_file_name = models_path + '%s_out' % classifier_name\n",
    "  out_file = open(pickle_file_name,\"rb\")\n",
    "  model_out = pickle.load(out_file)\n",
    "  out_file.close()\n",
    "\n",
    "  return model_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "17b3a16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "output0 = getLogits(\"class_0\")\n",
    "output1 = getLogits(\"class_1\")\n",
    "output2 = getLogits(\"class_2\")\n",
    "output3 = getLogits(\"class_3\")\n",
    "output4 = getLogits(\"class_4\")\n",
    "output5 = getLogits(\"class_5\")\n",
    "output6 = getLogits(\"class_6\")\n",
    "output7 = getLogits(\"class_7\")\n",
    "output8 = getLogits(\"class_8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "85f6269b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "dict_keys(['y_val', 'y_ood', 'y_test', 'y_anom', 'logits_val', 'logits_ood', 'logits_test', 'logits_anom', 'train_class_names', 'val_class_names', 'ood_class_names'])\n"
     ]
    }
   ],
   "source": [
    "outputs = [\n",
    "          output0,\n",
    "          output1,\n",
    "          output2,\n",
    "          output3,\n",
    "          output4,\n",
    "          output5,\n",
    "          output6,\n",
    "          output7,\n",
    "          output8\n",
    "          ]\n",
    "print(len(outputs))\n",
    "print(outputs[0].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5d45df",
   "metadata": {},
   "source": [
    "# Temperature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cc31d32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def temp_cal(y_pred, y):\n",
    "\n",
    "  temp = tf.Variable(initial_value=1.0, trainable=True, dtype=tf.float32) \n",
    "\n",
    "  def compute_loss():\n",
    "      y_pred_model_w_temp = tf.math.divide(y_pred, temp)\n",
    "      loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\\\n",
    "                                  tf.convert_to_tensor(keras.utils.to_categorical(np.asarray(y))), y_pred_model_w_temp))\n",
    "      return loss\n",
    "\n",
    "  optimizer = tf.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "  print('Temperature Initial value: {}'.format(temp.numpy()))\n",
    "\n",
    "  for i in range(300):\n",
    "      opts = optimizer.minimize(compute_loss, var_list=[temp])\n",
    "\n",
    "\n",
    "  print('Temperature Final value: {}'.format(temp.numpy()))\n",
    "\n",
    "  return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1598ae7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temperature Initial value: 1.0\n",
      "Temperature Final value: 1.695942759513855\n",
      "Temperature Initial value: 1.0\n",
      "Temperature Final value: 1.6615626811981201\n",
      "Temperature Initial value: 1.0\n",
      "Temperature Final value: 1.7107561826705933\n",
      "Temperature Initial value: 1.0\n",
      "Temperature Final value: 1.7225301265716553\n",
      "Temperature Initial value: 1.0\n",
      "Temperature Final value: 1.7363266944885254\n",
      "Temperature Initial value: 1.0\n",
      "Temperature Final value: 1.7249693870544434\n",
      "Temperature Initial value: 1.0\n",
      "Temperature Final value: 1.6090620756149292\n",
      "Temperature Initial value: 1.0\n",
      "Temperature Final value: 1.7317672967910767\n",
      "Temperature Initial value: 1.0\n",
      "Temperature Final value: 1.7360734939575195\n"
     ]
    }
   ],
   "source": [
    "temp_list = []\n",
    "\n",
    "for output in outputs:\n",
    "  temp = temp_cal(output['logits_val'], #+output['logits_ood'], \n",
    "                  output['y_val']) #+output['y_ood'])\n",
    "  temp_list.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "50b5bdad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def temp_scaling(y_pred, temp):\n",
    "  return tf.math.divide(y_pred, temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ed62bfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax_list = []\n",
    "\n",
    "for output in outputs:\n",
    "    softmax = tf.nn.softmax(output['logits_val'])\n",
    "    softmax_list.append(softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8836e29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ood_softmax_list = []\n",
    "\n",
    "for output in outputs:\n",
    "    ood_softmax = tf.nn.softmax(output['logits_ood'])\n",
    "    ood_softmax_list.append(ood_softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9793a596",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_logits_list = []\n",
    "new_softmax_list = []\n",
    "\n",
    "for temp, output in zip(temp_list, outputs):\n",
    "  new_logits = temp_scaling(output['logits_val'], temp)\n",
    "  new_logits_list.append(new_logits)\n",
    "\n",
    "  new_softmax = tf.nn.softmax(new_logits)\n",
    "  new_softmax_list.append(new_softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c2ea96d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_logits_ood_list = []\n",
    "new_ood_softmax_list = []\n",
    "\n",
    "for temp, output in zip(temp_list, outputs):\n",
    "  new_logits_ood = temp_scaling(output['logits_ood'], temp)\n",
    "  new_logits_ood_list.append(new_logits_ood)\n",
    "\n",
    "  new_ood_softmax = tf.nn.softmax(new_logits_ood)\n",
    "  new_ood_softmax_list.append(new_ood_softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5ac3cbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_softmax_list = []\n",
    "for temp, output in zip(temp_list, outputs):\n",
    "  test_softmax = tf.nn.softmax(temp_scaling(output['logits_test'], temp))\n",
    "  test_softmax_list.append(test_softmax)\n",
    "\n",
    "anom_softmax_list = []\n",
    "for temp, output in zip(temp_list, outputs):\n",
    "  anom_softmax = tf.nn.softmax(temp_scaling(output['logits_anom'], temp))\n",
    "  anom_softmax_list.append(anom_softmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66298fe0",
   "metadata": {},
   "source": [
    "# Compute reference vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8efd146b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.947583729220183,\n",
       " 0.9578432826956441,\n",
       " 0.9542997828777263,\n",
       " 0.9565142840630039,\n",
       " 0.9615651853198471,\n",
       " 0.9516753924168376,\n",
       " 0.9489715546369553,\n",
       " 0.9494689795749867,\n",
       " 0.9532428966711748]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding ref vector for ID - with temp scaling\n",
    "ref_vector_ID_with_tmp = []\n",
    "\n",
    "for new_softmax in new_softmax_list:\n",
    "  max_softmax = 0\n",
    "  for s in new_softmax:\n",
    "    max_softmax += np.max(s)\n",
    "  new_max = max_softmax / len(new_softmax)\n",
    "  # new_max = np.max(new_softmax)\n",
    "  ref_vector_ID_with_tmp.append(new_max)\n",
    "\n",
    "ref_vector_ID_with_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "464421c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8569068440908119,\n",
       " 0.8970223466555277,\n",
       " 0.7936741019167551,\n",
       " 0.710397071596505,\n",
       " 0.8461606570436985,\n",
       " 0.8106797691434622,\n",
       " 0.6374774582502318,\n",
       " 0.6833199269887877,\n",
       " 0.7488633279617016]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding ref vector for OOD - with temp scaling\n",
    "ref_vector_OOD_with_tmp = []\n",
    "\n",
    "for new_ood_softmax in new_ood_softmax_list:\n",
    "  max_softmax = 0\n",
    "  for s in new_ood_softmax:\n",
    "    max_softmax += np.max(s)\n",
    "  max = max_softmax / len(new_ood_softmax)\n",
    "  # new_max = np.max(new_softmax)\n",
    "  ref_vector_OOD_with_tmp.append(max)\n",
    "\n",
    "ref_vector_OOD_with_tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5f5fdd",
   "metadata": {},
   "source": [
    "# Compute entropy values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bba59e34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09597307926155983"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding entropy of ID - after temp scaling\n",
    "id_entropy = 0\n",
    "for new_softmax in new_softmax_list:\n",
    "  ent_classifier = 0\n",
    "  for sm in new_softmax:\n",
    "    ent = entropy(sm, base=len(sm))\n",
    "    ent_classifier += ent\n",
    "  ent_classifier = ent_classifier / len(new_softmax)\n",
    "  id_entropy += ent_classifier\n",
    "id_entropy = id_entropy / len(new_softmax_list)\n",
    "id_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0481bc9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34136378063117623"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding entropy of OOD - after temp scaling\n",
    "ood_entropy = 0\n",
    "for new_ood_softmax in new_ood_softmax_list:\n",
    "  ent_classifier = 0\n",
    "  for sm in new_ood_softmax:\n",
    "    ent = entropy(sm, base=len(sm))\n",
    "    ent_classifier += ent\n",
    "  ent_classifier = ent_classifier / len(new_ood_softmax)\n",
    "  ood_entropy += ent_classifier\n",
    "ood_entropy = ood_entropy / len(new_ood_softmax_list)\n",
    "ood_entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14644de4",
   "metadata": {},
   "source": [
    "# Reference vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c643ea85",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_softmax_list = []\n",
    "for temp, output in zip(temp_list, outputs):\n",
    "  test_softmax = tf.nn.softmax(temp_scaling(output['logits_test'], temp))\n",
    "  test_softmax_list.append(test_softmax)\n",
    "\n",
    "anom_softmax_list = []\n",
    "for temp, output in zip(temp_list, outputs):\n",
    "  anom_softmax = tf.nn.softmax(temp_scaling(output['logits_anom'], temp))\n",
    "  anom_softmax_list.append(anom_softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b5454268",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1654/1654 [00:02<00:00, 665.81it/s]\n",
      "100%|██████████| 981/981 [00:01<00:00, 672.97it/s]\n"
     ]
    }
   ],
   "source": [
    "y_true = []\n",
    "y_true_ = []\n",
    "y_pred_softmax = []\n",
    "y_pred = []\n",
    "sim_ID = []\n",
    "sim_OOD = []\n",
    "for ind in tqdm(range(len(test_softmax_list[0]))):\n",
    "  pred_vector_max = []\n",
    "  # pred_vector_min = []\n",
    "  for test_softmax in test_softmax_list:\n",
    "    pred_vector_max.append(np.max(test_softmax[ind]))\n",
    "    # pred_vector_min.append(np.min(test_softmax[ind]))\n",
    "\n",
    "  dist_from_ID = distance.euclidean(pred_vector_max, ref_vector_ID_with_tmp)\n",
    "  dist_from_OOD = distance.euclidean(pred_vector_max, ref_vector_OOD_with_tmp)\n",
    "  # dist_from_ID_min = distance.euclidean(pred_vector_min, ref_vector_ID_with_tmp_min)\n",
    "  # dist_from_OOD_min = distance.euclidean(pred_vector_min, ref_vector_OOD_with_tmp_min)\n",
    "  sim_with_ID = (1 / (1 + dist_from_ID)) # + (1 / (1 + dist_from_ID_min))\n",
    "  sim_with_OOD = (1 / (1 + dist_from_OOD)) # + (1 / (1 + dist_from_OOD_min))\n",
    "  sim_ID.append(sim_with_ID)\n",
    "  sim_OOD.append(sim_with_OOD)\n",
    "  \n",
    "  if sim_with_ID >= sim_with_OOD:\n",
    "    pred = 1 # ID\n",
    "  else:\n",
    "    pred = 0 # OOD\n",
    "  y_pred.append(pred)\n",
    "  y_pred_softmax.append(np.max(pred_vector_max))\n",
    "  y_true.append(1) # because ID data\n",
    "  y_true_.append(0) # because ID data\n",
    "\n",
    "\n",
    "for ind in tqdm(range(len(anom_softmax_list[0]))):\n",
    "  pred_vector_max = []\n",
    "  # pred_vector_min = []\n",
    "  for anom_softmax in anom_softmax_list:\n",
    "    pred_vector_max.append(np.max(anom_softmax[ind]))\n",
    "    # pred_vector_min.append(np.min(anom_softmax[ind]))\n",
    "\n",
    "  dist_from_ID = distance.euclidean(pred_vector_max, ref_vector_ID_with_tmp)\n",
    "  dist_from_OOD = distance.euclidean(pred_vector_max, ref_vector_OOD_with_tmp)\n",
    "  # dist_from_ID_min = distance.euclidean(pred_vector_min, ref_vector_ID_with_tmp_min)\n",
    "  # dist_from_OOD_min = distance.euclidean(pred_vector_min, ref_vector_OOD_with_tmp_min)\n",
    "  sim_with_ID = (1 / (1 + dist_from_ID)) # + (1 / (1 + dist_from_ID_min))\n",
    "  sim_with_OOD = (1 / (1 + dist_from_OOD)) # + (1 / (1 + dist_from_OOD_min))\n",
    "  sim_ID.append(sim_with_ID)\n",
    "  sim_OOD.append(sim_with_OOD)\n",
    "  \n",
    "  if sim_with_ID >= sim_with_OOD:\n",
    "    pred = 1 # ID\n",
    "  else:\n",
    "    pred = 0 # OOD\n",
    "  y_pred.append(pred)\n",
    "  y_pred_softmax.append(np.max(pred_vector_max))\n",
    "  y_true.append(0) # because OOD data\n",
    "  y_true_.append(1) # because ID data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "434ca8fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores with temperature scaling - considering only softmax values, no similarity checked\n",
      "AUROC (%): 90.76\n",
      "Scores with temperature scaling - giving predictions (1 for ID and 0 for OOD)  comparing similarity with both ref vectors\n",
      "AUROC (%): 74.56\n",
      "Scores with temperature scaling - giving sim_ID scores\n",
      "AUROC (%): 75.36\n",
      "Scores with temperature scaling - giving sim_OOD scores\n",
      "AUROC (%): 68.5\n"
     ]
    }
   ],
   "source": [
    "print(\"Scores with temperature scaling - considering only softmax values, no similarity checked\")\n",
    "\n",
    "auroc_ensemble = sk.roc_auc_score(y_true, y_pred_softmax)\n",
    "print('AUROC (%):', round(100*auroc_ensemble, 2))\n",
    "\n",
    "print(\"Scores with temperature scaling \\\n",
    "- giving predictions (1 for ID and 0 for OOD) \\\n",
    " comparing similarity with both ref vectors\")\n",
    "auroc_ref_detection = sk.roc_auc_score(y_true, y_pred)\n",
    "print('AUROC (%):', round(100*auroc_ref_detection, 2))\n",
    "\n",
    "\n",
    "print(\"Scores with temperature scaling \\\n",
    "- giving sim_ID scores\")\n",
    "auroc_ref_sim = sk.roc_auc_score(y_true, sim_ID)\n",
    "print('AUROC (%):', round(100*auroc_ref_sim, 2))\n",
    "\n",
    "print(\"Scores with temperature scaling \\\n",
    "- giving sim_OOD scores\")\n",
    "# auroc_ref_sim_ood = sk.roc_auc_score(y_true, sim_OOD)\n",
    "# print('AUROC (%):', round(100*auroc_ref_sim_ood, 2))\n",
    "auroc_ref_sim_ood = sk.roc_auc_score(y_true_, sim_OOD)\n",
    "print('AUROC (%):', round(100*auroc_ref_sim_ood, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f41669a",
   "metadata": {},
   "source": [
    "# Reference vector + Decision Rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "124c0bfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'sci.med',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.religion.misc',\n",
       " 'sci.electronics']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_test_class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d99ee0d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{0: 0, 1: 1, 2: 3, 3: 4, 4: 5, 5: 6, 6: 7, 7: 8},\n",
       " {0: 0, 1: 2, 2: 3, 3: 4, 4: 5, 5: 6, 6: 7, 7: 8},\n",
       " {0: 0, 1: 1, 2: 2, 3: 4, 4: 5, 5: 6, 6: 7, 7: 8},\n",
       " {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 8},\n",
       " {0: 1, 1: 2, 2: 3, 3: 4, 4: 5, 5: 6, 6: 7, 7: 8},\n",
       " {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 7, 7: 8},\n",
       " {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 6, 6: 7, 7: 8},\n",
       " {0: 0, 1: 1, 2: 2, 3: 3, 4: 5, 5: 6, 6: 7, 7: 8},\n",
       " {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7}]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mappings = []\n",
    "for output in outputs:\n",
    "  # map_train_to_test_indices\n",
    "  mapping = {}\n",
    "  for test_ind, test_class_name in enumerate(all_test_class_names):\n",
    "    for train_ind, class_name in enumerate(output['train_class_names']):\n",
    "      if test_class_name == class_name:\n",
    "        mapping[train_ind] = test_ind\n",
    "  mappings.append(mapping)\n",
    "\n",
    "mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c8eb3cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision rule\n",
    "def get_auroc_with_threshold_count(threshold_count):\n",
    "  y_pred_decision_ref = []\n",
    "  y_pred_only_decision = []\n",
    "  y_true = []\n",
    "\n",
    "  for ind in tqdm(range(len(test_softmax_list[0]))):\n",
    "    preds = []\n",
    "    pred_vector = []\n",
    "    for test_softmax, mapping in zip(test_softmax_list, mappings):\n",
    "      pred_vector.append(np.max(test_softmax[ind]))\n",
    "      pred_classifier = np.argmax(test_softmax[ind])\n",
    "      mapped_pred = mapping[pred_classifier]\n",
    "      preds.append(mapped_pred)\n",
    "    counts = np.bincount(preds)\n",
    "    max_count = np.max(counts)\n",
    "\n",
    "    dist_from_ID = distance.euclidean(pred_vector, ref_vector_ID_with_tmp)\n",
    "    dist_from_OOD = distance.euclidean(pred_vector, ref_vector_OOD_with_tmp)\n",
    "    sim_with_ID = 1 / (1 + dist_from_ID)\n",
    "    sim_with_OOD = 1 / (1 + dist_from_OOD)\n",
    "\n",
    "    if max_count >= threshold_count:\n",
    "      y_pred_only_decision.append(1)\n",
    "    else:\n",
    "      y_pred_only_decision.append(0)\n",
    "\n",
    "    if sim_with_ID >= sim_with_OOD and max_count >= threshold_count:\n",
    "      y_pred_decision_ref.append(1)\n",
    "    else:\n",
    "      y_pred_decision_ref.append(0)\n",
    "    y_true.append(1) # because ID data\n",
    "\n",
    "\n",
    "  for ind in tqdm(range(len(anom_softmax_list[0]))):\n",
    "    preds = []\n",
    "    pred_vector = []\n",
    "    for anom_softmax, mapping in zip(anom_softmax_list, mappings):\n",
    "      pred_vector.append(np.max(test_softmax[ind]))\n",
    "      pred_classifier = np.argmax(anom_softmax[ind])\n",
    "      mapped_pred = mapping[pred_classifier]\n",
    "      preds.append(mapped_pred)\n",
    "    counts = np.bincount(preds)\n",
    "    max_count = np.max(counts)\n",
    "\n",
    "    dist_from_ID = distance.euclidean(pred_vector, ref_vector_ID_with_tmp)\n",
    "    dist_from_OOD = distance.euclidean(pred_vector, ref_vector_OOD_with_tmp)\n",
    "    sim_with_ID = 1 / (1 + dist_from_ID)\n",
    "    sim_with_OOD = 1 / (1 + dist_from_OOD)\n",
    "\n",
    "    if max_count >= threshold_count:\n",
    "      y_pred_only_decision.append(1)\n",
    "    else:\n",
    "      y_pred_only_decision.append(0)\n",
    "\n",
    "    if sim_with_ID >= sim_with_OOD and max_count >= threshold_count:\n",
    "      y_pred_decision_ref.append(1)\n",
    "    else:\n",
    "      y_pred_decision_ref.append(0)\n",
    "    y_true.append(0) # because OOD data\n",
    "\n",
    "  print(\"\\n\\nScores with Decision rule with threshold count =\", threshold_count)\n",
    "  auroc_only_dec = sk.roc_auc_score(y_true, y_pred_only_decision)\n",
    "  print('AUROC (%):', round(100*auroc_only_dec, 2))\n",
    "\n",
    "  print(\"\\n\\nScores with Decision rule with threshold count =\", threshold_count, \n",
    "        \"\\n and reference vector\")\n",
    "  auroc_dec_ref = sk.roc_auc_score(y_true, y_pred_decision_ref)\n",
    "  print('AUROC (%):', round(100*auroc_dec_ref, 2))\n",
    "  return auroc_only_dec, auroc_dec_ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fe56ff12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1654/1654 [00:04<00:00, 344.20it/s]\n",
      "100%|██████████| 981/981 [00:02<00:00, 347.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Scores with Decision rule with threshold count = 7\n",
      "AUROC (%): 59.85\n",
      "\n",
      "\n",
      "Scores with Decision rule with threshold count = 7 \n",
      " and reference vector\n",
      "AUROC (%): 61.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "auroc_only_dec_7, auroc_dec_ref_7 = get_auroc_with_threshold_count(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "bc275659",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1654/1654 [00:04<00:00, 335.66it/s]\n",
      "100%|██████████| 981/981 [00:02<00:00, 328.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Scores with Decision rule with threshold count = 8\n",
      "AUROC (%): 65.64\n",
      "\n",
      "\n",
      "Scores with Decision rule with threshold count = 8 \n",
      " and reference vector\n",
      "AUROC (%): 68.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "auroc_only_dec_8, auroc_dec_ref_8 = get_auroc_with_threshold_count(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62aea875",
   "metadata": {},
   "source": [
    "# Entropy values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c15ba747",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1654/1654 [00:02<00:00, 565.14it/s]\n",
      "100%|██████████| 981/981 [00:01<00:00, 578.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Scores with Entropy ref value - detecting ID and OOD and giving these to AUROC\n",
      "AUROC (%): 78.13\n",
      "\n",
      "\n",
      "Scores with Entropy ref value - sim ID to AUROC\n",
      "AUROC (%): 82.78\n",
      "\n",
      "\n",
      "Scores with Entropy ref value - sim OOD to AUROC\n",
      "AUROC (%): 20.55\n",
      "AUROC (%): 20.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "  y_pred = []\n",
    "  y_true = []\n",
    "  y_true_ = []\n",
    "  sim_ID = []\n",
    "  sim_OOD = []\n",
    "\n",
    "  for ind in tqdm(range(len(test_softmax_list[0]))):\n",
    "    pred_entropy = 0\n",
    "    for test_softmax in test_softmax_list:\n",
    "      pred = test_softmax[ind]\n",
    "      ent = entropy(pred, base=len(pred))\n",
    "      pred_entropy += ent\n",
    "\n",
    "    pred_entropy = pred_entropy/len(test_softmax_list)\n",
    "    dist_from_ID = distance.euclidean(pred_entropy, id_entropy)\n",
    "    dist_from_OOD = distance.euclidean(pred_entropy, ood_entropy)\n",
    "    sim_with_ID = 1 / (1 + dist_from_ID)\n",
    "    sim_with_OOD = 1 / (1 + dist_from_OOD)\n",
    "    sim_ID.append(sim_with_ID)\n",
    "    sim_OOD.append(sim_with_OOD)\n",
    "\n",
    "    if sim_with_ID >= sim_with_OOD:\n",
    "      y_pred.append(1)\n",
    "    else:\n",
    "      y_pred.append(0)\n",
    "    y_true.append(1) # because ID data\n",
    "    y_true_.append(0)\n",
    "\n",
    "\n",
    "  for ind in tqdm(range(len(anom_softmax_list[0]))):\n",
    "    pred_entropy = 0\n",
    "    for test_softmax in anom_softmax_list:\n",
    "      pred = test_softmax[ind]\n",
    "      ent = entropy(pred, base=len(pred))\n",
    "      pred_entropy += ent\n",
    "    \n",
    "    pred_entropy = pred_entropy/len(anom_softmax_list)\n",
    "    dist_from_ID = distance.euclidean(pred_entropy, id_entropy)\n",
    "    dist_from_OOD = distance.euclidean(pred_entropy, ood_entropy)\n",
    "    sim_with_ID = 1 / (1 + dist_from_ID)\n",
    "    sim_with_OOD = 1 / (1 + dist_from_OOD)\n",
    "    sim_ID.append(sim_with_ID)\n",
    "    sim_OOD.append(sim_with_OOD)\n",
    "\n",
    "    if sim_with_ID >= sim_with_OOD:\n",
    "      y_pred.append(1)\n",
    "    else:\n",
    "      y_pred.append(0)\n",
    "    y_true.append(0) # because OOD data\n",
    "    y_true_.append(1)\n",
    "\n",
    "  print(\"\\n\\nScores with Entropy ref value - detecting ID and OOD and giving these to AUROC\")\n",
    "  auroc_ent_detection = sk.roc_auc_score(y_true, y_pred)\n",
    "  print('AUROC (%):', round(100*auroc_ent_detection, 2))\n",
    "\n",
    "  print(\"\\n\\nScores with Entropy ref value - sim ID to AUROC\")\n",
    "  auroc_ent_sim = sk.roc_auc_score(y_true, sim_ID)\n",
    "  print('AUROC (%):', round(100*auroc_ent_sim, 2))\n",
    "\n",
    "  print(\"\\n\\nScores with Entropy ref value - sim OOD to AUROC\")\n",
    "  auroc = sk.roc_auc_score(y_true, sim_OOD)\n",
    "  print('AUROC (%):', round(100*auroc, 2))\n",
    "\n",
    "  auroc_ent_sim_ood = sk.roc_auc_score(y_true_, sim_OOD)\n",
    "  print('AUROC (%):', round(100*auroc, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479e1d61",
   "metadata": {},
   "source": [
    "# Entropy value + Decision Rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "10df7f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_auroc_with_threshold_count(threshold_count):\n",
    "  y_pred_decision_ref = []\n",
    "  y_true = []\n",
    "\n",
    "  for ind in tqdm(range(len(test_softmax_list[0]))):\n",
    "    preds = []\n",
    "    pred_entropy = 0\n",
    "    for test_softmax, mapping in zip(test_softmax_list, mappings):\n",
    "      # to get entropy\n",
    "      pred = test_softmax[ind]  # vector of length 9\n",
    "      ent = entropy(pred, base=len(pred))\n",
    "      pred_entropy += ent\n",
    "      # to get max count\n",
    "      pred_classifier = np.argmax(test_softmax[ind])  # argmax of vector\n",
    "      mapped_pred = mapping[pred_classifier]\n",
    "      preds.append(mapped_pred)\n",
    "    counts = np.bincount(preds)\n",
    "    max_count = np.max(counts)\n",
    "\n",
    "    pred_entropy = pred_entropy/len(test_softmax_list)\n",
    "    dist_from_ID = distance.euclidean(pred_entropy, id_entropy)\n",
    "    dist_from_OOD = distance.euclidean(pred_entropy, ood_entropy)\n",
    "    sim_with_ID = 1 / (1 + dist_from_ID)\n",
    "    sim_with_OOD = 1 / (1 + dist_from_OOD)\n",
    "\n",
    "    if sim_with_ID >= sim_with_OOD and max_count >= threshold_count:\n",
    "      y_pred_decision_ref.append(1)\n",
    "    else:\n",
    "      y_pred_decision_ref.append(0)\n",
    "    y_true.append(1) # because ID data\n",
    "\n",
    "\n",
    "  for ind in tqdm(range(len(anom_softmax_list[0]))):\n",
    "    preds = []\n",
    "    pred_entropy = 0\n",
    "    for test_softmax, mapping in zip(anom_softmax_list, mappings):\n",
    "      # to get entropy\n",
    "      pred = test_softmax[ind]  # vector of length 9\n",
    "      ent = entropy(pred, base=len(pred))\n",
    "      pred_entropy += ent\n",
    "      # to get max count\n",
    "      pred_classifier = np.argmax(test_softmax[ind])  # argmax of vector\n",
    "      mapped_pred = mapping[pred_classifier]\n",
    "      preds.append(mapped_pred)\n",
    "    counts = np.bincount(preds)\n",
    "    max_count = np.max(counts)\n",
    "\n",
    "    pred_entropy = pred_entropy/len(anom_softmax_list)\n",
    "    dist_from_ID = distance.euclidean(pred_entropy, id_entropy)\n",
    "    dist_from_OOD = distance.euclidean(pred_entropy, ood_entropy)\n",
    "    sim_with_ID = 1 / (1 + dist_from_ID)\n",
    "    sim_with_OOD = 1 / (1 + dist_from_OOD)\n",
    "\n",
    "    if sim_with_ID >= sim_with_OOD and max_count >= threshold_count:\n",
    "      y_pred_decision_ref.append(1)\n",
    "    else:\n",
    "      y_pred_decision_ref.append(0)\n",
    "    y_true.append(0) # because OOD data\n",
    "\n",
    "  print(\"\\n\\nScores with Decision rule with threshold count =\", threshold_count, \n",
    "        \"\\n and entropy reference\")\n",
    "  auroc_dec_ent = sk.roc_auc_score(y_true, y_pred_decision_ref)\n",
    "  print('AUROC (%):', round(100*auroc_dec_ent, 2))\n",
    "  return auroc_dec_ent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "972a98f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1654/1654 [00:05<00:00, 315.97it/s]\n",
      "100%|██████████| 981/981 [00:03<00:00, 312.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Scores with Decision rule with threshold count = 7 \n",
      " and entropy reference\n",
      "AUROC (%): 78.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "auroc_dec_ent_7 = get_auroc_with_threshold_count(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "dd3bf167",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1654/1654 [00:05<00:00, 315.55it/s]\n",
      "100%|██████████| 981/981 [00:03<00:00, 316.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Scores with Decision rule with threshold count = 8 \n",
      " and entropy reference\n",
      "AUROC (%): 78.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "auroc_dec_ent_8 = get_auroc_with_threshold_count(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26653c2",
   "metadata": {},
   "source": [
    "# Method 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4e9f0e2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6174, 6174)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "for new_softmax in new_softmax_list:\n",
    "  for sm in new_softmax:\n",
    "    x_train.append(sm)\n",
    "    y_train.append(1)\n",
    "\n",
    "for new_softmax in new_ood_softmax_list:\n",
    "  for sm in new_softmax:\n",
    "    x_train.append(sm)\n",
    "    y_train.append(0)\n",
    "\n",
    "len(x_train), len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7e3bcd86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23715, 23715)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test = []\n",
    "y_test = []\n",
    "\n",
    "for new_softmax in test_softmax_list:\n",
    "  for sm in new_softmax:\n",
    "    x_test.append(sm)\n",
    "    y_test.append(1)\n",
    "\n",
    "for new_softmax in anom_softmax_list:\n",
    "  for sm in new_softmax:\n",
    "    x_test.append(sm)\n",
    "    y_test.append(0)\n",
    "\n",
    "len(x_test), len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4ceda494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4939 1235 4939\n"
     ]
    }
   ],
   "source": [
    "svm_train_ip, svm_test_ip, svm_train_lb, svm_test_lb = train_test_split(x_train, y_train, test_size=0.20, stratify=y_train)\n",
    "print(len(svm_train_ip),len(svm_test_ip),len(svm_train_lb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a1681649",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sudhi/.local/lib/python3.8/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass classes=[0 1], y=[1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: 4.498178506375227, 1: 0.5625284738041002}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "class_wts = compute_class_weight('balanced', np.unique(svm_train_lb), svm_train_lb)\n",
    "class_wts ={0:class_wts[0], 1:class_wts[1]}\n",
    "class_wts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6fbe8b48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('svc',\n",
       "                 SVC(class_weight={0: 4.498178506375227, 1: 0.5625284738041002},\n",
       "                     gamma='auto'))])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "clf = make_pipeline(StandardScaler(), SVC(gamma='auto',class_weight=class_wts))\n",
    "clf.fit(svm_train_ip, svm_train_lb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "31d1e2fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1235"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = clf.predict(svm_test_ip)\n",
    "len(pred) ### svm fitted on whole data with weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e9b8648f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8178137651821862"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(svm_test_ip,svm_test_lb) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1d03c093",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "efc7f7cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores for predictions from trained SVM (Method 2)\n",
      "AUROC (%): 61.24\n"
     ]
    }
   ],
   "source": [
    "print(\"Scores for predictions from trained SVM (Method 2)\")\n",
    "auroc_method_2 = sk.roc_auc_score(y_test, y_pred)\n",
    "print('AUROC (%):', round(100*auroc_method_2, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d536be",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "34b3e822",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = \\\n",
    "[\n",
    "'Euclidean Distance Between Reference Vector',\t\n",
    "'Similarity score with just IN Reference Vector',\n",
    "'Similarity score with just OOD Reference Vector',\n",
    "'Euclidean Distance between Entropy Reference Value',\n",
    "'Similarity score with just IN Entropy Reference Value',\n",
    "'Similarity score with just OOD Entropy Reference Value',\n",
    "'Decision Rule (>=7)',\n",
    "'Decision Rule (>=8)',\n",
    "'Decision Rule(>=7) + Reference Vector',\n",
    "'Decision Rule(>=8) + Reference Vector',\n",
    "'Decision Rule(>=7) + Entropy Reference Value',\n",
    "'Decision Rule(>=8) + Entropy Reference Value',\n",
    "'Average Max softmax value of each classifier',\n",
    "'Method 2 - Learning Softmax Pattern'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7946385f",
   "metadata": {},
   "outputs": [],
   "source": [
    "values = [\n",
    "          auroc_ref_detection,\n",
    "          auroc_ref_sim,\n",
    "          auroc_ref_sim_ood,\n",
    "          auroc_ent_detection,\n",
    "          auroc_ent_sim,\n",
    "          auroc_ent_sim_ood,\n",
    "          auroc_only_dec_7,\n",
    "          auroc_only_dec_8,\n",
    "          auroc_dec_ref_7,\n",
    "          auroc_dec_ref_8,\n",
    "          auroc_dec_ent_7,\n",
    "          auroc_dec_ent_8,\n",
    "          auroc_ensemble,\n",
    "          auroc_method_2\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a16396f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "values_rounded = []\n",
    "for value in values:\n",
    "  values_rounded.append(round(100*value, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ded36569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Euclidean Distance Between Reference Vector \t\t 74.56\n",
      "Similarity score with just IN Reference Vector \t\t 75.36\n",
      "Similarity score with just OOD Reference Vector \t\t 68.5\n",
      "Euclidean Distance between Entropy Reference Value \t\t 78.13\n",
      "Similarity score with just IN Entropy Reference Value \t\t 82.78\n",
      "Similarity score with just OOD Entropy Reference Value \t\t 79.45\n",
      "Decision Rule (>=7) \t\t 59.85\n",
      "Decision Rule (>=8) \t\t 65.64\n",
      "Decision Rule(>=7) + Reference Vector \t\t 61.98\n",
      "Decision Rule(>=8) + Reference Vector \t\t 68.08\n",
      "Decision Rule(>=7) + Entropy Reference Value \t\t 78.1\n",
      "Decision Rule(>=8) + Entropy Reference Value \t\t 78.29\n",
      "Average Max softmax value of each classifier \t\t 90.76\n",
      "Method 2 - Learning Softmax Pattern \t\t 61.24\n",
      "[74.56, 75.36, 68.5, 78.13, 82.78, 79.45, 59.85, 65.64, 61.98, 68.08, 78.1, 78.29, 90.76, 61.24]\n"
     ]
    }
   ],
   "source": [
    "for metric, value in zip(metrics, values_rounded):\n",
    "  print(metric, \"\\t\\t\", value)\n",
    "\n",
    "print(values_rounded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c6e44e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
