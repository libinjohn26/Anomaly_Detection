{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "_XgTpm9ZxoN9"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "from official.nlp import optimization  # to create AdamW optmizer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "import math\n",
    "import numpy as np\n",
    "import sklearn.metrics as sk \n",
    "import pickle\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.spatial import distance\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from scipy.stats import entropy\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R9V5qAn1k840"
   },
   "source": [
    "## Train and save classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "MeUgRpYsDSt1"
   },
   "outputs": [],
   "source": [
    "if os.path.exists('20news-18828'):\n",
    "  shutil.rmtree('20news-18828')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ErRLh-xWDQfK"
   },
   "outputs": [],
   "source": [
    "url = 'http://qwone.com/~jason/20Newsgroups/20news-18828.tar.gz'\n",
    "\n",
    "dataset = tf.keras.utils.get_file('20news-18828.tar.gz', url,\n",
    "                                  untar=True, cache_dir='.',\n",
    "                                  cache_subdir='')\n",
    "\n",
    "dataset_dir = os.path.join(os.path.dirname(dataset), '20news')\n",
    "train_dir = os.path.join(dataset_dir, 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RXtUtc3ZiMTm",
    "outputId": "3b9a9304-e6c9-4ef2-f669-b1382d7756bd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'comp.sys.mac.hardware',\n",
       " 1: 'comp.os.ms-windows.misc',\n",
       " 2: 'rec.motorcycles',\n",
       " 3: 'talk.politics.misc',\n",
       " 4: 'comp.graphics',\n",
       " 5: 'talk.politics.mideast',\n",
       " 6: 'sci.med',\n",
       " 7: 'rec.sport.baseball',\n",
       " 8: 'talk.religion.misc',\n",
       " 9: 'sci.electronics',\n",
       " 10: 'comp.windows.x',\n",
       " 11: 'sci.crypt',\n",
       " 12: 'talk.politics.guns',\n",
       " 13: 'rec.sport.hockey',\n",
       " 14: 'rec.autos',\n",
       " 15: 'sci.space',\n",
       " 16: 'comp.sys.ibm.pc.hardware',\n",
       " 17: 'soc.religion.christian',\n",
       " 18: 'misc.forsale',\n",
       " 19: 'alt.atheism'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rootPath = '20news-18828'\n",
    "files = os.listdir(rootPath)\n",
    "\n",
    "all_classes = {}\n",
    "for ind in range(len(files)):\n",
    "  all_classes[ind] = files[ind]\n",
    "\n",
    "all_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "M1X0phsfBu3u"
   },
   "outputs": [],
   "source": [
    "# models_path = \"/content/drive/MyDrive/Uni Projects/Anomaly Detection using Ensembles/Experiments/Text Dataset/models/outputs/\"\n",
    "# pickle_file_name = models_path + 'all_classes'\n",
    "# out_file = open(pickle_file_name,\"wb\")\n",
    "# pickle.dump(all_classes, out_file)\n",
    "# out_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ux6J_4MBBj_J"
   },
   "source": [
    "## Set the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "SA8nBRzyBhdn"
   },
   "outputs": [],
   "source": [
    "models_path = \"outputs/\"\n",
    "pickle_file_name = models_path + 'all_classes'\n",
    "out_file = open(pickle_file_name,\"rb\")\n",
    "all_classes = pickle.load(out_file)\n",
    "out_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VDF4sRk0CNwk",
    "outputId": "02881c5a-3e14-49f8-ab75-8da8fab88794"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'comp.sys.mac.hardware',\n",
       " 1: 'comp.os.ms-windows.misc',\n",
       " 2: 'rec.motorcycles',\n",
       " 3: 'talk.politics.misc',\n",
       " 4: 'comp.graphics',\n",
       " 5: 'talk.politics.mideast',\n",
       " 6: 'sci.med',\n",
       " 7: 'rec.sport.baseball',\n",
       " 8: 'talk.religion.misc',\n",
       " 9: 'sci.electronics',\n",
       " 10: 'comp.windows.x',\n",
       " 11: 'sci.crypt',\n",
       " 12: 'talk.politics.guns',\n",
       " 13: 'rec.sport.hockey',\n",
       " 14: 'rec.autos',\n",
       " 15: 'sci.space',\n",
       " 16: 'comp.sys.ibm.pc.hardware',\n",
       " 17: 'soc.religion.christian',\n",
       " 18: 'misc.forsale',\n",
       " 19: 'alt.atheism'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 694
    },
    "id": "SZx0rGStCQJh",
    "outputId": "dd404a71-35bf-4d10-a604-70854d636cbc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first_10_classes_dict\n",
      "{   0: 'comp.sys.mac.hardware',\n",
      "    1: 'comp.os.ms-windows.misc',\n",
      "    2: 'rec.motorcycles',\n",
      "    3: 'talk.politics.misc',\n",
      "    4: 'comp.graphics',\n",
      "    5: 'talk.politics.mideast',\n",
      "    6: 'sci.med',\n",
      "    7: 'rec.sport.baseball',\n",
      "    8: 'talk.religion.misc',\n",
      "    9: 'sci.electronics'}\n",
      "id_classes_dict\n",
      "{   0: 'comp.sys.mac.hardware',\n",
      "    1: 'comp.os.ms-windows.misc',\n",
      "    2: 'rec.motorcycles',\n",
      "    3: 'talk.politics.misc',\n",
      "    4: 'comp.graphics',\n",
      "    5: 'talk.politics.mideast',\n",
      "    6: 'sci.med',\n",
      "    7: 'rec.sport.baseball',\n",
      "    8: 'talk.religion.misc'}\n",
      "anom_classes_dict\n",
      "{9: 'sci.electronics'}\n",
      "\n",
      "ID Classes\n",
      "------------\n",
      "[   'comp.sys.mac.hardware',\n",
      "    'comp.os.ms-windows.misc',\n",
      "    'rec.motorcycles',\n",
      "    'talk.politics.misc',\n",
      "    'comp.graphics',\n",
      "    'talk.politics.mideast',\n",
      "    'sci.med',\n",
      "    'rec.sport.baseball',\n",
      "    'talk.religion.misc']\n",
      "Anomalous Classes\n",
      "------------\n",
      "['sci.electronics']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'anom_9'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_10_classes_dict = {}\n",
    "for ind in all_classes:\n",
    "  if ind <= 9:\n",
    "    first_10_classes_dict[ind] = all_classes[ind]\n",
    "\n",
    "id_classes_ind = [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
    "anom_classes_ind = [9]\n",
    "\n",
    "id_classes_dict = {}\n",
    "for ind in all_classes:\n",
    "  if ind in id_classes_ind:\n",
    "    id_classes_dict[ind] = first_10_classes_dict[ind]\n",
    "\n",
    "anom_classes_dict = {}\n",
    "for ind in all_classes:\n",
    "  if ind in anom_classes_ind:\n",
    "    anom_classes_dict[ind] = first_10_classes_dict[ind]\n",
    "\n",
    "print(\"first_10_classes_dict\")\n",
    "pp.pprint(first_10_classes_dict)\n",
    "print(\"id_classes_dict\")\n",
    "pp.pprint(id_classes_dict)\n",
    "print(\"anom_classes_dict\")\n",
    "pp.pprint(anom_classes_dict)\n",
    "\n",
    "id_classes_whole = list(id_classes_dict.values())\n",
    "anom_classes = list(anom_classes_dict.values())\n",
    "\n",
    "print(\"\\nID Classes\\n------------\")\n",
    "pp.pprint(id_classes_whole)\n",
    "print(\"Anomalous Classes\\n------------\")\n",
    "pp.pprint(anom_classes)\n",
    "\n",
    "anom_class_name_for_path = \"anom_%d\" % (anom_classes_ind[0])\n",
    "anom_class_name_for_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zEKkVAIY0YxU",
    "outputId": "071e8523-35fa-49d0-ed89-e0f16a8042c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comp.sys.mac.hardware 961 192\n",
      "comp.os.ms-windows.misc 985 197\n",
      "rec.motorcycles 994 198\n",
      "talk.politics.misc 775 155\n",
      "comp.graphics 973 194\n",
      "talk.politics.mideast 940 188\n",
      "sci.med 990 198\n",
      "rec.sport.baseball 994 198\n",
      "talk.religion.misc 628 125\n"
     ]
    }
   ],
   "source": [
    "# Test has all class labels 0 - 9. Further separated by Test_OOD\n",
    "testPath = rootPath + \"/test\"\n",
    "if os.path.exists(testPath):\n",
    "  shutil.rmtree(testPath)\n",
    "os.mkdir(testPath)\n",
    "\n",
    "for className in files:\n",
    "  if className in first_10_classes_dict.values() and className not in anom_classes:\n",
    "    path = os.path.join(rootPath, className)\n",
    "    classTestPath = testPath+\"/\"+className\n",
    "    os.mkdir(classTestPath)\n",
    "    idFiles = os.listdir(path)\n",
    "    lenIdFiles = len(idFiles)\n",
    "    testLen = math.floor(0.2 * lenIdFiles)\n",
    "    print(className, lenIdFiles, testLen)\n",
    "    for ind, idFile in enumerate(idFiles):\n",
    "      if ind <= testLen:\n",
    "        shutil.move(os.path.join(rootPath, className, idFile), classTestPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tdo4K0XhEEZA",
    "outputId": "70c5c261-ee48-4238-f873-3dcfccd0b734"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comp.sys.mac.hardware 768 153\n",
      "comp.os.ms-windows.misc 787 157\n",
      "rec.motorcycles 795 159\n",
      "talk.politics.misc 619 123\n",
      "comp.graphics 778 155\n",
      "talk.politics.mideast 751 150\n",
      "sci.med 791 158\n",
      "rec.sport.baseball 795 159\n",
      "talk.religion.misc 502 100\n"
     ]
    }
   ],
   "source": [
    "# Validation has all class labels except for anomalous class \n",
    "# Here, 0 - 8\n",
    "testPath = rootPath + \"/val\"\n",
    "if os.path.exists(testPath):\n",
    "  shutil.rmtree(testPath)\n",
    "os.mkdir(testPath)\n",
    "\n",
    "for className in files:\n",
    "  if className in id_classes_whole:\n",
    "    path = os.path.join(rootPath, className)\n",
    "    classTestPath = testPath+\"/\"+className\n",
    "    os.mkdir(classTestPath)\n",
    "    idFiles = os.listdir(path)\n",
    "    lenIdFiles = len(idFiles)\n",
    "    testLen = math.floor(0.2 * lenIdFiles)\n",
    "    print(className, lenIdFiles, testLen)\n",
    "    for ind, idFile in enumerate(idFiles):\n",
    "      if ind <= testLen:\n",
    "        shutil.move(os.path.join(rootPath, className, idFile), classTestPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e7JPauUAJ1Kk",
    "outputId": "81278651-d198-4891-f178-8c331f4ea505"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comp.sys.mac.hardware 614\n",
      "comp.os.ms-windows.misc 629\n",
      "rec.motorcycles 635\n",
      "talk.politics.misc 495\n",
      "comp.graphics 622\n",
      "talk.politics.mideast 600\n",
      "sci.med 632\n",
      "rec.sport.baseball 635\n",
      "talk.religion.misc 401\n"
     ]
    }
   ],
   "source": [
    "# Train has all class labels except for anomalous class \n",
    "# Here, 0 - 8\n",
    "testPath = rootPath + \"/train\"\n",
    "if os.path.exists(testPath):\n",
    "  shutil.rmtree(testPath)\n",
    "os.mkdir(testPath)\n",
    "\n",
    "for className in files:\n",
    "  if className in id_classes_whole:\n",
    "    path = os.path.join(rootPath, className)\n",
    "    classTestPath = testPath+\"/\"+className\n",
    "    os.mkdir(classTestPath)\n",
    "    idFiles = os.listdir(path)\n",
    "    lenIdFiles = len(idFiles)\n",
    "    # testLen = math.floor(0.2 * lenIdFiles)\n",
    "    print(className, lenIdFiles)\n",
    "    for idFile in idFiles:\n",
    "      shutil.move(os.path.join(rootPath, className, idFile), classTestPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "iGmLrLyFLlfH"
   },
   "outputs": [],
   "source": [
    "# Test_OOD separates anomalous classes in the test.\n",
    "# Test contains 0 - 8\n",
    "# Test_OOD contains 9\n",
    "# files = os.listdir(rootPath + \"/test\")\n",
    "\n",
    "testPath = rootPath + \"/test_ood\"\n",
    "if os.path.exists(testPath):\n",
    "  shutil.rmtree(testPath)\n",
    "os.mkdir(testPath)\n",
    "\n",
    "for className in files:\n",
    "  if className in anom_classes:\n",
    "    path = os.path.join(rootPath, className)\n",
    "    classTestPath = testPath+\"/\"+className\n",
    "    os.mkdir(classTestPath)\n",
    "    idFiles = os.listdir(path)\n",
    "    lenIdFiles = len(idFiles)\n",
    "    # testLen = math.floor(0.2 * lenIdFiles)\n",
    "    # print(className, lenIdFiles, testLen)\n",
    "    for idFile in idFiles:\n",
    "      shutil.move(os.path.join(rootPath, className, idFile), classTestPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "VXSN3ZZS4qPW"
   },
   "outputs": [],
   "source": [
    "def update_files_to_txt(id_ood_path):\n",
    "  print(\"Files in folder '%s' are renamed as .txt\" % id_ood_path)\n",
    "  files = os.listdir(id_ood_path)\n",
    "  \n",
    "  for i in files:\n",
    "    path = os.path.join(id_ood_path, i)\n",
    "    files = os.listdir(path)  \n",
    "    for index, file in enumerate(files):\n",
    "      os.rename(os.path.join(path, file), os.path.join(path, ''.join([str(index), '.txt'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eqcxv3UR447g",
    "outputId": "e0c74c56-b356-45ec-9a30-8237d716af4a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in folder '20news-18828/test' are renamed as .txt\n",
      "Files in folder '20news-18828/test_ood' are renamed as .txt\n",
      "Files in folder '20news-18828/val' are renamed as .txt\n",
      "Files in folder '20news-18828/train' are renamed as .txt\n"
     ]
    }
   ],
   "source": [
    "update_files_to_txt('20news-18828/test')\n",
    "update_files_to_txt('20news-18828/test_ood')\n",
    "update_files_to_txt('20news-18828/val')\n",
    "update_files_to_txt('20news-18828/train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "umYLWCuM4MNK",
    "outputId": "5b50ed86-fef2-4e77-a6ba-cd182e2c6422"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1654 files belonging to 9 classes.\n"
     ]
    }
   ],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "batch_size = 32\n",
    "seed = 42\n",
    "\n",
    "test_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
    "    '20news-18828/test',\n",
    "    batch_size=batch_size)\n",
    "\n",
    "test_class_names = test_ds.class_names\n",
    "test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z4BE-hhg86Dd",
    "outputId": "3f844f8f-0a69-4067-cb88-02ade998ba8a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'sci.med',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.religion.misc']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PVxYL4A3MgY9",
    "outputId": "d8d30396-5b24-44e2-b430-fb6943607dc9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 981 files belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "batch_size = 32\n",
    "seed = 42\n",
    "\n",
    "test_ood_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
    "    '20news-18828/test_ood',\n",
    "    batch_size=batch_size)\n",
    "\n",
    "test_ood_class_names = test_ood_ds.class_names\n",
    "test_ood_ds = test_ood_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bl87mALNGLjX",
    "outputId": "2c256ff3-864e-438e-f6ec-2726de9f2e9d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sci.electronics']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ood_class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X4Jkd3PfK156",
    "outputId": "3074519a-2a1f-459a-fd6a-39a0cb0e590f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5263 files belonging to 9 classes.\n"
     ]
    }
   ],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "batch_size = 32\n",
    "seed = 42\n",
    "\n",
    "train_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
    "    '20news-18828/train',\n",
    "    batch_size=batch_size)\n",
    "\n",
    "train_class_names = train_ds.class_names\n",
    "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ySBdKPCvGNgZ",
    "outputId": "a6f8b2a5-10d1-4ad4-e8c8-0b8a7db554df"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'sci.med',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.religion.misc']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-1TJ2G-1K8ip",
    "outputId": "61047be1-3a2f-4310-9262-891f0be2e133"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1323 files belonging to 9 classes.\n"
     ]
    }
   ],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "batch_size = 32\n",
    "seed = 42\n",
    "\n",
    "val_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
    "    '20news-18828/val',\n",
    "    batch_size=batch_size)\n",
    "\n",
    "val_class_names = val_ds.class_names\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "drxkVGmCGQEA",
    "outputId": "2842a7f9-9e79-4464-da1b-a240ae06704e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'sci.med',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.religion.misc']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0Txvsc-Y-4OA",
    "outputId": "f1753bc5-e187-4070-b68d-c16a2c66a6e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train labels {0, 1, 2, 3, 4, 5, 6, 7, 8}\n",
      "Val labels {0, 1, 2, 3, 4, 5, 6, 7, 8}\n",
      "Test ID labels {0, 1, 2, 3, 4, 5, 6, 7, 8}\n",
      "Test OOD labels {0}\n"
     ]
    }
   ],
   "source": [
    "# Checking for class labels\n",
    "def get_set_labels(ds):\n",
    "  labels = []\n",
    "  for _, label in ds:\n",
    "    labels.extend(label.numpy())\n",
    "  return set(labels)\n",
    "\n",
    "print(\"Train labels\", get_set_labels(train_ds))\n",
    "print(\"Val labels\", get_set_labels(val_ds))\n",
    "print(\"Test ID labels\", get_set_labels(test_ds))\n",
    "print(\"Test OOD labels\", get_set_labels(test_ood_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X_ijCbyRAWmC",
    "outputId": "2920975c-8119-4d83-b568-f46b29f805e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train class names\n",
      "0 comp.graphics\n",
      "1 comp.os.ms-windows.misc\n",
      "2 comp.sys.mac.hardware\n",
      "3 rec.motorcycles\n",
      "4 rec.sport.baseball\n",
      "5 sci.med\n",
      "6 talk.politics.mideast\n",
      "7 talk.politics.misc\n",
      "8 talk.religion.misc\n",
      "\n",
      "Val class names\n",
      "0 comp.graphics\n",
      "1 comp.os.ms-windows.misc\n",
      "2 comp.sys.mac.hardware\n",
      "3 rec.motorcycles\n",
      "4 rec.sport.baseball\n",
      "5 sci.med\n",
      "6 talk.politics.mideast\n",
      "7 talk.politics.misc\n",
      "8 talk.religion.misc\n",
      "\n",
      "Test ID class names\n",
      "0 comp.graphics\n",
      "1 comp.os.ms-windows.misc\n",
      "2 comp.sys.mac.hardware\n",
      "3 rec.motorcycles\n",
      "4 rec.sport.baseball\n",
      "5 sci.med\n",
      "6 talk.politics.mideast\n",
      "7 talk.politics.misc\n",
      "8 talk.religion.misc\n",
      "\n",
      "Test OOD class names\n",
      "0 sci.electronics\n"
     ]
    }
   ],
   "source": [
    "# Class labels and class names\n",
    "def get_class_names(class_names):\n",
    "  for ind, name in enumerate(class_names):\n",
    "    print(ind, name)\n",
    "\n",
    "print(\"Train class names\")\n",
    "get_class_names(train_class_names)\n",
    "print(\"\\nVal class names\")\n",
    "get_class_names(val_class_names)\n",
    "print(\"\\nTest ID class names\")\n",
    "get_class_names(test_class_names)\n",
    "print(\"\\nTest OOD class names\")\n",
    "get_class_names(test_ood_class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "BPcmDy-yK99B"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs/anom_9/ is already present.\n"
     ]
    }
   ],
   "source": [
    "all_test_class_names = test_class_names + test_ood_class_names\n",
    "\n",
    "models_path = \"outputs/\" + anom_class_name_for_path + \"/\"\n",
    "\n",
    "try:\n",
    "  os.mkdir(models_path)\n",
    "except:\n",
    "  print(models_path, \"is already present.\")\n",
    "  pass\n",
    "\n",
    "pickle_file_name = models_path + 'all_test_class_names'\n",
    "out_file = open(pickle_file_name,\"wb\")\n",
    "pickle.dump(all_test_class_names, out_file)\n",
    "out_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "WBsJz7_zOWYa"
   },
   "outputs": [],
   "source": [
    "class BERTModel:\n",
    "  def __init__(self, train_ds):\n",
    "    self.tfhub_handle_encoder = 'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3'\n",
    "    self.tfhub_handle_preprocess = 'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3'\n",
    "    self.bert_preprocess_model = hub.KerasLayer(self.tfhub_handle_preprocess)\n",
    "    self.bert_model = hub.KerasLayer(self.tfhub_handle_encoder)\n",
    "    self.train_ds = train_ds\n",
    "    \n",
    "    self.num_of_classes = 9 # not leaving out one class, so 9 classes\n",
    "    self.classifier_model = self.build_classifier_model()\n",
    "\n",
    "    self.loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "    self.metrics = tf.metrics.SparseCategoricalAccuracy()\n",
    "    self.optimizer = self.build_optimizer()\n",
    "\n",
    "    self.classifier_model.compile(\n",
    "        optimizer=self.optimizer,\n",
    "        loss=self.loss,\n",
    "        metrics=self.metrics,\n",
    "      )\n",
    "\n",
    "\n",
    "  def build_classifier_model(self):\n",
    "    text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
    "    preprocessing_layer = hub.KerasLayer(self.tfhub_handle_preprocess, name='preprocessing')\n",
    "    encoder_inputs = preprocessing_layer(text_input)\n",
    "    encoder = hub.KerasLayer(self.tfhub_handle_encoder, trainable=True, name='BERT_encoder')\n",
    "    outputs = encoder(encoder_inputs)\n",
    "    net = outputs['pooled_output']\n",
    "    net = tf.keras.layers.Dropout(0.1)(net)\n",
    "    net = tf.keras.layers.Dense(self.num_of_classes, activation=None, name='classifier')(net)\n",
    "    return tf.keras.Model(text_input, net)\n",
    "\n",
    "  def build_optimizer(self):\n",
    "    epochs = 10\n",
    "    steps_per_epoch = tf.data.experimental.cardinality(self.train_ds).numpy()\n",
    "    num_train_steps = steps_per_epoch * epochs\n",
    "    num_warmup_steps = int(0.1*num_train_steps)\n",
    "    # print(num_train_steps)\n",
    "    init_lr = 3e-5\n",
    "    optimizer = optimization.create_optimizer(init_lr=init_lr,\n",
    "                                              num_train_steps=num_train_steps,\n",
    "                                              num_warmup_steps=num_warmup_steps,\n",
    "                                              optimizer_type='adamw')\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "EWkYcZ1wHPqM"
   },
   "outputs": [],
   "source": [
    "def getScores(model):\n",
    "  def get_labels_and_logits(ds):\n",
    "    y = []\n",
    "    logits = []\n",
    "    for text_batch, label_batch in ds:\n",
    "      label = label_batch.numpy()\n",
    "      for lbl in label:\n",
    "        y.append(lbl)\n",
    "      text_test = text_batch\n",
    "      bert_raw_result = model(text_test)\n",
    "      for batch in bert_raw_result:\n",
    "        logits.append(batch)\n",
    "    return y, logits\n",
    "\n",
    "  y_val, logits_val = get_labels_and_logits(val_ds)\n",
    "  y_test, logits_test = get_labels_and_logits(test_ds)\n",
    "  y_anom, logits_anom = get_labels_and_logits(test_ood_ds)\n",
    "\n",
    "  out = {\n",
    "      'y_val': y_val,\n",
    "      'y_test': y_test,\n",
    "      'y_anom': y_anom,\n",
    "      'logits_val': logits_val,\n",
    "      'logits_test': logits_test,\n",
    "      'logits_anom': logits_anom\n",
    "  }\n",
    "  \n",
    "  models_path = \"outputs/\" + anom_class_name_for_path + \"/\"\n",
    "  #if os.path.exists(models_path):\n",
    "  #  shutil.rmtree(models_path)\n",
    "  \n",
    "  pickle_file_name = models_path + 'baseline'\n",
    "  out_file = open(pickle_file_name,\"wb\")\n",
    "  pickle.dump(out, out_file)\n",
    "  out_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "FpoLvinZH8ZS"
   },
   "outputs": [],
   "source": [
    "def train_model():\n",
    "  # Fetch dataset\n",
    "  # class_ind = InOutData(leave_out_ind=leave_out_ind, id_classes_whole=id_classes_whole)\n",
    "  # Build and plot model\n",
    "  classifier_ind = BERTModel(train_ds)\n",
    "\n",
    "  # Train model\n",
    "  classifier_ind.classifier_model.fit(x=train_ds,\n",
    "                                      batch_size=32,\n",
    "                                      validation_data=val_ds,\n",
    "                                      epochs=10, \n",
    "                                      verbose=1)\n",
    "\n",
    "  # Save model\n",
    "  # models_path = '/content/drive/MyDrive/Uni Projects/Anomaly Detection using Ensembles/Experiments/Text Dataset/models/'\n",
    "  # dataset_name = '%s_model' % classifier_name\n",
    "  # saved_model_path = models_path+'{}'.format(dataset_name.replace('/', '_'))\n",
    "  # classifier_ind.classifier_model.save(saved_model_path, include_optimizer=True)\n",
    "  getScores(classifier_ind.classifier_model)\n",
    "\n",
    "  return classifier_ind.classifier_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6Y_n3qvlXppU",
    "outputId": "79f55e40-23e0-44dd-86d7-3868a29896cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "165/165 [==============================] - 93s 489ms/step - loss: 2.0609 - sparse_categorical_accuracy: 0.2747 - val_loss: 0.3212 - val_sparse_categorical_accuracy: 0.9078\n",
      "Epoch 2/10\n",
      "165/165 [==============================] - 80s 487ms/step - loss: 0.3107 - sparse_categorical_accuracy: 0.9088 - val_loss: 0.2522 - val_sparse_categorical_accuracy: 0.9335\n",
      "Epoch 3/10\n",
      "165/165 [==============================] - 80s 487ms/step - loss: 0.1268 - sparse_categorical_accuracy: 0.9589 - val_loss: 0.2386 - val_sparse_categorical_accuracy: 0.9426\n",
      "Epoch 4/10\n",
      "165/165 [==============================] - 80s 488ms/step - loss: 0.0593 - sparse_categorical_accuracy: 0.9839 - val_loss: 0.2015 - val_sparse_categorical_accuracy: 0.9501\n",
      "Epoch 5/10\n",
      "165/165 [==============================] - 81s 488ms/step - loss: 0.0203 - sparse_categorical_accuracy: 0.9940 - val_loss: 0.2346 - val_sparse_categorical_accuracy: 0.9531\n",
      "Epoch 6/10\n",
      "165/165 [==============================] - 80s 488ms/step - loss: 0.0096 - sparse_categorical_accuracy: 0.9970 - val_loss: 0.2385 - val_sparse_categorical_accuracy: 0.9539\n",
      "Epoch 7/10\n",
      "165/165 [==============================] - 81s 488ms/step - loss: 0.0037 - sparse_categorical_accuracy: 0.9983 - val_loss: 0.2444 - val_sparse_categorical_accuracy: 0.9554\n",
      "Epoch 8/10\n",
      "165/165 [==============================] - 81s 488ms/step - loss: 6.9740e-04 - sparse_categorical_accuracy: 0.9997 - val_loss: 0.2432 - val_sparse_categorical_accuracy: 0.9562\n",
      "Epoch 9/10\n",
      "165/165 [==============================] - 80s 488ms/step - loss: 0.0012 - sparse_categorical_accuracy: 0.9997 - val_loss: 0.2469 - val_sparse_categorical_accuracy: 0.9539\n",
      "Epoch 10/10\n",
      "165/165 [==============================] - 81s 489ms/step - loss: 4.1035e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.2523 - val_sparse_categorical_accuracy: 0.9546\n"
     ]
    }
   ],
   "source": [
    "model = train_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lh9hjsX1kt2v"
   },
   "source": [
    "## Reload logits from pickle files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "63fmghBVL7op"
   },
   "outputs": [],
   "source": [
    "models_path = \"outputs/\" + anom_class_name_for_path + \"/\"\n",
    "pickle_file_name = models_path + 'all_test_class_names'\n",
    "out_file = open(pickle_file_name,\"rb\")\n",
    "all_test_class_names = pickle.load(out_file)\n",
    "out_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "7aBUCjtGkKlr"
   },
   "outputs": [],
   "source": [
    "models_path = \"outputs/\" + anom_class_name_for_path + \"/\"\n",
    "pickle_file_name = models_path + 'baseline'\n",
    "out_file = open(pickle_file_name,\"rb\")\n",
    "output = pickle.load(out_file)\n",
    "out_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "BoILZJklnEbx"
   },
   "outputs": [],
   "source": [
    "outputs = [\n",
    "           output\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "89ZTl6y13QP5"
   },
   "source": [
    "## Temperature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "-NLtSNJX1VHv"
   },
   "outputs": [],
   "source": [
    "def temp_cal(y_pred, y):\n",
    "\n",
    "  temp = tf.Variable(initial_value=1.0, trainable=True, dtype=tf.float32) \n",
    "\n",
    "  def compute_loss():\n",
    "      y_pred_model_w_temp = tf.math.divide(y_pred, temp)\n",
    "      loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\\\n",
    "                                  tf.convert_to_tensor(keras.utils.to_categorical(np.asarray(y))), y_pred_model_w_temp))\n",
    "      return loss\n",
    "\n",
    "  optimizer = tf.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "  print('Temperature Initial value: {}'.format(temp.numpy()))\n",
    "\n",
    "  for i in range(300):\n",
    "      opts = optimizer.minimize(compute_loss, var_list=[temp])\n",
    "\n",
    "\n",
    "  print('Temperature Final value: {}'.format(temp.numpy()))\n",
    "\n",
    "  return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_zG8-gDmNjqx",
    "outputId": "33a19a7b-17a3-46dc-da39-303666764d29"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temperature Initial value: 1.0\n",
      "Temperature Final value: 1.866462230682373\n"
     ]
    }
   ],
   "source": [
    "temp_list = []\n",
    "\n",
    "for output in outputs:\n",
    "  temp = temp_cal(output['logits_val'], output['y_val'])\n",
    "  temp_list.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "XqEVppg69VtY"
   },
   "outputs": [],
   "source": [
    "def temp_scaling(y_pred, temp):\n",
    "  return tf.math.divide(y_pred, temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "pyxszAueNrft"
   },
   "outputs": [],
   "source": [
    "softmax_list = []\n",
    "\n",
    "for output in outputs:\n",
    "    softmax = tf.nn.softmax(output['logits_val'])\n",
    "    softmax_list.append(softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "WCcc5rgrNxyo"
   },
   "outputs": [],
   "source": [
    "new_logits_list = []\n",
    "new_softmax_list = []\n",
    "\n",
    "for temp, output in zip(temp_list, outputs):\n",
    "  new_logits = temp_scaling(output['logits_val'], temp)\n",
    "  new_logits_list.append(new_logits)\n",
    "\n",
    "  new_softmax = tf.nn.softmax(new_logits)\n",
    "  new_softmax_list.append(new_softmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gZEiQ8A4OD7X"
   },
   "source": [
    "## Reference Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "ccyN0vna73ls"
   },
   "outputs": [],
   "source": [
    "new_logits_list = []\n",
    "test_softmax_list = []\n",
    "\n",
    "for temp, output in zip(temp_list, outputs):\n",
    "  new_logits = temp_scaling(output['logits_test'], temp)\n",
    "  new_logits_list.append(new_logits)\n",
    "\n",
    "  new_softmax = tf.nn.softmax(new_logits)\n",
    "  test_softmax_list.append(new_softmax)\n",
    "\n",
    "new_logits_list = []\n",
    "anom_softmax_list = []\n",
    "\n",
    "for temp, output in zip(temp_list, outputs):\n",
    "  new_logits = temp_scaling(output['logits_anom'], temp)\n",
    "  new_logits_list.append(new_logits)\n",
    "\n",
    "  new_softmax = tf.nn.softmax(new_logits)\n",
    "  anom_softmax_list.append(new_softmax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p9AaO-0WOb_n",
    "outputId": "7218a987-bc55-4e67-fb22-3ff69d6305f1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1654/1654 [00:00<00:00, 5806.00it/s]\n",
      "100%|██████████| 981/981 [00:00<00:00, 5948.75it/s]\n"
     ]
    }
   ],
   "source": [
    "y_true = []\n",
    "y_pred_softmax = []\n",
    "\n",
    "for ind in tqdm(range(len(test_softmax_list[0]))):\n",
    "  pred_vector = []\n",
    "  for test_softmax in test_softmax_list:\n",
    "    pred_vector.append(np.max(test_softmax[ind]))\n",
    "\n",
    "  y_pred_softmax.append(np.max(pred_vector))\n",
    "  y_true.append(1) # because ID data\n",
    "\n",
    "for ind in tqdm(range(len(anom_softmax_list[0]))):\n",
    "  pred_vector = []\n",
    "  for anom_softmax in anom_softmax_list:\n",
    "    pred_vector.append(np.max(anom_softmax[ind]))\n",
    "\n",
    "  y_pred_softmax.append(np.max(pred_vector))\n",
    "  y_true.append(0) # because OOD data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DkaQG7zdOdda",
    "outputId": "ba1f8832-ca41-4fe6-826a-6642b4bcfac9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores with temperature scaling - considering only softmax values, no similarity checked\n",
      "AUROC (%): 90.66\n"
     ]
    }
   ],
   "source": [
    "print(\"Scores with temperature scaling - considering only softmax values, no similarity checked\")\n",
    "\n",
    "auroc = sk.roc_auc_score(y_true, y_pred_softmax)\n",
    "print('AUROC (%):', round(100*auroc, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9wIuHeMx8C1K"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "R9V5qAn1k840",
    "lh9hjsX1kt2v",
    "89ZTl6y13QP5"
   ],
   "name": "TextClassification_20NewsGrps_OnlyBaseline.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
