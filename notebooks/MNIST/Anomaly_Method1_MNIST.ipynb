{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Anomaly_Method1_MNIST.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "_WFZ33vZBhJL",
        "o2CPsMdU_Xzz",
        "sH89EaIVf6_J",
        "QTqj6-WoGQw3",
        "YWUZh-rpilra",
        "-I-BAayAR2nP",
        "0D-J_-cD1t7W",
        "RAJzlpiX5DE8",
        "d22XwKBi3qeM"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZTshmCS9Xto"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import pickle\n",
        "\n",
        "from tqdm import tqdm\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from scipy.stats import entropy"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7daiKRP9lLx",
        "outputId": "20039db6-a95f-47d7-f312-61ad3a2424d6"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q9GV5c-v9nuf",
        "outputId": "50ab85d3-d865-4a28-856c-c6e3f1e7f498"
      },
      "source": [
        "import os\n",
        "print(os.getcwd())\n",
        "os.chdir(\"/content/drive/My Drive/Libin's Project/\")\n",
        "print(os.getcwd())"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "/content/drive/My Drive/Libin's Project\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTxj9LiX9xQ1"
      },
      "source": [
        "class Model(): #tf.Module\n",
        "  def __init__(self, name=None):\n",
        "\n",
        "    self.name = name\n",
        "    self.loss_fn = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "    self.train_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "    self.test_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "    self.opt = tf.optimizers.Adam()\n",
        "\n",
        "  def build(self):\n",
        "\n",
        "    self.model =  tf.keras.Sequential()\n",
        "\n",
        "    self.model.add(tf.keras.layers.Conv2D(32, (3, 3), padding='same',strides=1, input_shape=(28,28,1), use_bias=False))\n",
        "    self.model.add(tf.keras.layers.BatchNormalization())\n",
        "    self.model.add(tf.keras.layers.LeakyReLU(alpha=0.2))\n",
        "    self.model.add(tf.keras.layers.Conv2D( 64, (3, 3), padding='same',strides=1, use_bias=False))\n",
        "    self.model.add(tf.keras.layers.BatchNormalization())\n",
        "    self.model.add(tf.keras.layers.LeakyReLU(alpha=0.2))\n",
        "    self.model.add(tf.keras.layers.Conv2D( 64, (3, 3), padding='same',strides=1, use_bias=False))\n",
        "    self.model.add(tf.keras.layers.BatchNormalization())\n",
        "    self.model.add(tf.keras.layers.LeakyReLU(alpha=0.2))\n",
        "    self.model.add(tf.keras.layers.Dropout(0.25))\n",
        "\n",
        "    self.model.add(tf.keras.layers.Conv2D(128, (3, 3), padding='same',strides=1, use_bias=False))\n",
        "    self.model.add(tf.keras.layers.BatchNormalization())\n",
        "    self.model.add(tf.keras.layers.LeakyReLU(alpha=0.2))\n",
        "    self.model.add(tf.keras.layers.Conv2D( 128, (3, 3), padding='same',strides=1, use_bias=False))\n",
        "    self.model.add(tf.keras.layers.BatchNormalization())\n",
        "    self.model.add(tf.keras.layers.LeakyReLU(alpha=0.2))\n",
        "    self.model.add(tf.keras.layers.Conv2D( 128, (3, 3), padding='same',strides=1, use_bias=False))\n",
        "    self.model.add(tf.keras.layers.BatchNormalization())\n",
        "    self.model.add(tf.keras.layers.LeakyReLU(alpha=0.2))\n",
        "    self.model.add(tf.keras.layers.Dropout(0.25))\n",
        "\n",
        "    self.model.add(tf.keras.layers.Conv2D(128, (3, 3), padding='same',strides=1, use_bias=False))\n",
        "    self.model.add(tf.keras.layers.BatchNormalization())\n",
        "    self.model.add(tf.keras.layers.LeakyReLU(alpha=0.2))\n",
        "    self.model.add(tf.keras.layers.Conv2D( 128, (3, 3), padding='same',strides=1, use_bias=False))\n",
        "    self.model.add(tf.keras.layers.BatchNormalization())\n",
        "    self.model.add(tf.keras.layers.LeakyReLU(alpha=0.2))\n",
        "    self.model.add(tf.keras.layers.Conv2D( 128, (3, 3), padding='same',strides=1, use_bias=False))\n",
        "    self.model.add(tf.keras.layers.BatchNormalization())\n",
        "    self.model.add(tf.keras.layers.LeakyReLU(alpha=0.2))\n",
        "    self.model.add(tf.keras.layers.Dropout(0.25))\n",
        "\n",
        "    self.model.add(tf.keras.layers.MaxPooling2D((2,2)))\n",
        "    self.model.add(tf.keras.layers.Flatten())\n",
        "    self.model.add(tf.keras.layers.Dense(128))\n",
        "    self.model.add(tf.keras.layers.Dense(8)) #, activation='softmax'))\n",
        "    self.model.add(Activation('softmax'))\n",
        "    return self.model\n",
        "\n",
        "  def apply_softmax(self, logits):\n",
        "    return tf.nn.softmax(logits)\n",
        "\n",
        "  def train(self, train_data):\n",
        "\n",
        "    for step, (img_batch, lbl_batch) in enumerate(train_data):\n",
        "\n",
        "      with tf.GradientTape() as tape:\n",
        "          logits = self.model(img_batch)\n",
        "#          logits = self.apply_softmax(logits)\n",
        "          xent = self.loss_fn(lbl_batch, logits)\n",
        "\n",
        "      varis = self.model.trainable_variables\n",
        "      grads = tape.gradient(xent, varis)\n",
        "\n",
        "      self.opt.apply_gradients(zip(grads, varis))\n",
        "      \n",
        "      self.train_acc_metric(lbl_batch, logits)\n",
        "      \n",
        "      if tf.equal(step % 100, 0): #not step % 500:\n",
        "        acc = self.train_acc_metric.result()\n",
        "        tf.print(\"Loss: {} Accuracy: {}\".format(xent, acc))\n",
        "        self.train_acc_metric.reset_states()\n",
        "\n",
        "  def train2(self, train_imgs, train_lbls, val_imgs, val_lbls):\n",
        "    self.model.compile(\n",
        "      optimizer='adam',\n",
        "      loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "      metrics = ['accuracy']\n",
        "      )\n",
        "\n",
        "    self.model.fit(train_imgs, train_lbls, validation_data= (val_imgs, val_lbls), epochs=20)\n",
        "\n",
        "  def test(self,test_data, temp=None):\n",
        "    for img_batch, lbl_batch in test_data:\n",
        "      logits = self.model(img_batch)\n",
        "      if not temp is None:\n",
        "        logits = tf.math.divide(logits, temp)\n",
        "      pred = self.apply_softmax(logits)\n",
        "      self.test_acc_metric(lbl_batch, pred)\n",
        "    tf.print(\"Test acc: {}\".format(self.test_acc_metric.result()))\n",
        "\n",
        "  def save_model(self, path):\n",
        "    self.model.save(path)\n",
        "\n",
        "  def load_model(self, path):\n",
        "    self.model = tf.keras.models.load_model(path)\n",
        "    return self.model\n",
        "\n",
        "  def get_max_pred_value(self, data, temp=None):\n",
        "    logits = self.model(data)\n",
        "    if not temp is None:\n",
        "      logits = tf.math.divide(logits, temp)\n",
        "    pred = self.apply_softmax(logits)\n",
        "    return np.max(pred)\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "auCiAUHxEJWB"
      },
      "source": [
        "class BaselineModel(): #tf.Module\n",
        "  def __init__(self, name=None):\n",
        "\n",
        "    self.name = name\n",
        "    self.loss_fn = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "    self.train_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "    self.test_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "    self.opt = tf.optimizers.Adam()\n",
        "\n",
        "  def build(self):\n",
        "\n",
        "    self.model =  tf.keras.Sequential()\n",
        "\n",
        "    self.model.add(tf.keras.layers.Conv2D(32, (3, 3), padding='same',strides=1, input_shape=(28,28,1), use_bias=False))\n",
        "    self.model.add(tf.keras.layers.BatchNormalization())\n",
        "    self.model.add(tf.keras.layers.LeakyReLU(alpha=0.2))\n",
        "    self.model.add(tf.keras.layers.Conv2D( 64, (3, 3), padding='same',strides=1, use_bias=False))\n",
        "    self.model.add(tf.keras.layers.BatchNormalization())\n",
        "    self.model.add(tf.keras.layers.LeakyReLU(alpha=0.2))\n",
        "    self.model.add(tf.keras.layers.Conv2D( 64, (3, 3), padding='same',strides=1, use_bias=False))\n",
        "    self.model.add(tf.keras.layers.BatchNormalization())\n",
        "    self.model.add(tf.keras.layers.LeakyReLU(alpha=0.2))\n",
        "    self.model.add(tf.keras.layers.Dropout(0.25))\n",
        "\n",
        "    self.model.add(tf.keras.layers.Conv2D(128, (3, 3), padding='same',strides=1, use_bias=False))\n",
        "    self.model.add(tf.keras.layers.BatchNormalization())\n",
        "    self.model.add(tf.keras.layers.LeakyReLU(alpha=0.2))\n",
        "    self.model.add(tf.keras.layers.Conv2D( 128, (3, 3), padding='same',strides=1, use_bias=False))\n",
        "    self.model.add(tf.keras.layers.BatchNormalization())\n",
        "    self.model.add(tf.keras.layers.LeakyReLU(alpha=0.2))\n",
        "    self.model.add(tf.keras.layers.Conv2D( 128, (3, 3), padding='same',strides=1, use_bias=False))\n",
        "    self.model.add(tf.keras.layers.BatchNormalization())\n",
        "    self.model.add(tf.keras.layers.LeakyReLU(alpha=0.2))\n",
        "    self.model.add(tf.keras.layers.Dropout(0.25))\n",
        "\n",
        "    self.model.add(tf.keras.layers.Conv2D(128, (3, 3), padding='same',strides=1, use_bias=False))\n",
        "    self.model.add(tf.keras.layers.BatchNormalization())\n",
        "    self.model.add(tf.keras.layers.LeakyReLU(alpha=0.2))\n",
        "    self.model.add(tf.keras.layers.Conv2D( 128, (3, 3), padding='same',strides=1, use_bias=False))\n",
        "    self.model.add(tf.keras.layers.BatchNormalization())\n",
        "    self.model.add(tf.keras.layers.LeakyReLU(alpha=0.2))\n",
        "    self.model.add(tf.keras.layers.Conv2D( 128, (3, 3), padding='same',strides=1, use_bias=False))\n",
        "    self.model.add(tf.keras.layers.BatchNormalization())\n",
        "    self.model.add(tf.keras.layers.LeakyReLU(alpha=0.2))\n",
        "    self.model.add(tf.keras.layers.Dropout(0.25))\n",
        "\n",
        "    self.model.add(tf.keras.layers.MaxPooling2D((2,2)))\n",
        "    self.model.add(tf.keras.layers.Flatten())\n",
        "    self.model.add(tf.keras.layers.Dense(128))\n",
        "    self.model.add(tf.keras.layers.Dense(9)) #, activation='softmax'))\n",
        "    self.model.add(Activation('softmax'))\n",
        "    return self.model\n",
        "\n",
        "  def apply_softmax(self, logits):\n",
        "    return tf.nn.softmax(logits)\n",
        "\n",
        "  def train(self, train_data):\n",
        "\n",
        "    for step, (img_batch, lbl_batch) in enumerate(train_data):\n",
        "\n",
        "      with tf.GradientTape() as tape:\n",
        "          logits = self.model(img_batch)\n",
        "#          logits = self.apply_softmax(logits)\n",
        "          xent = self.loss_fn(lbl_batch, logits)\n",
        "\n",
        "      varis = self.model.trainable_variables\n",
        "      grads = tape.gradient(xent, varis)\n",
        "\n",
        "      self.opt.apply_gradients(zip(grads, varis))\n",
        "      \n",
        "      self.train_acc_metric(lbl_batch, logits)\n",
        "      \n",
        "      if tf.equal(step % 100, 0): #not step % 500:\n",
        "        acc = self.train_acc_metric.result()\n",
        "        tf.print(\"Loss: {} Accuracy: {}\".format(xent, acc))\n",
        "        self.train_acc_metric.reset_states()\n",
        "\n",
        "  def train2(self, train_imgs, train_lbls, val_imgs, val_lbls):\n",
        "    self.model.compile(\n",
        "      optimizer='adam',\n",
        "      loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "      metrics = ['accuracy']\n",
        "      )\n",
        "\n",
        "    self.model.fit(train_imgs, train_lbls, validation_data= (val_imgs, val_lbls), epochs=20)\n",
        "\n",
        "  def test(self,test_data, temp=None):\n",
        "    for img_batch, lbl_batch in test_data:\n",
        "      logits = self.model(img_batch)\n",
        "      if not temp is None:\n",
        "        logits = tf.math.divide(logits, temp)\n",
        "      pred = self.apply_softmax(logits)\n",
        "      self.test_acc_metric(lbl_batch, pred)\n",
        "    tf.print(\"Test acc: {}\".format(self.test_acc_metric.result()))\n",
        "\n",
        "  def save_model(self, path):\n",
        "    self.model.save(path)\n",
        "\n",
        "  def load_model(self, path):\n",
        "    self.model = tf.keras.models.load_model(path)\n",
        "    return self.model\n",
        "\n",
        "  def get_max_pred_value(self, data, temp=None):\n",
        "    logits = self.model(data)\n",
        "    if not temp is None:\n",
        "      logits = tf.math.divide(logits, temp)\n",
        "    pred = self.apply_softmax(logits)\n",
        "    return np.max(pred)\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sjYysZ6sBOmG",
        "outputId": "17c98afd-f537-4b43-bc70-eb6838e8d7aa"
      },
      "source": [
        "(train_imgs, train_lbls), (test_imgs, test_lbls) = tf.keras.datasets.mnist.load_data()\n",
        "train_imgs = (train_imgs.astype(np.float32) / 255.).reshape((-1, 28, 28, 1))\n",
        "train_lbls = train_lbls.astype(np.int32)\n",
        "\n",
        "\n",
        "test_imgs = (test_imgs.astype(np.float32) / 255.).reshape((-1, 28, 28, 1))\n",
        "test_lbls = test_lbls.astype(np.int32)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hg-xxghBCIAk"
      },
      "source": [
        "train_images, val_images, train_labels, val_labels = train_test_split(train_imgs, train_lbls, test_size=0.20, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhIuqcWNBq_L"
      },
      "source": [
        "pickle_out = open(\"mnist_data\",\"wb\")\n",
        "pickle.dump([train_images, train_labels, val_images, val_labels, test_imgs, test_lbls], pickle_out)\n",
        "pickle_out.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyPx6a4JO-Up"
      },
      "source": [
        "pickle_in = open(\"mnist_data\",\"rb\")\n",
        "train_images, train_labels, val_images, val_labels, test_imgs, test_lbls = pickle.load(pickle_in)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOn1TTPvCcPR"
      },
      "source": [
        "def separate_class(class_val, train_images, train_labels, val_images, val_labels):\n",
        "  new_train_images = []\n",
        "  new_train_labels = []\n",
        "  for ind, im in enumerate(train_images):\n",
        "    if train_labels[ind] != class_val:\n",
        "      new_train_images.append(im)\n",
        "      new_train_labels.append(train_labels[ind])\n",
        "\n",
        "  new_train_images = np.asarray(new_train_images)\n",
        "  new_train_labels = np.asarray(new_train_labels)\n",
        "\n",
        "  new_val_images = []\n",
        "  new_val_labels = []\n",
        "  for ind, im in enumerate(val_images):\n",
        "    if val_labels[ind] != class_val:\n",
        "      new_val_images.append(im)\n",
        "      new_val_labels.append(val_labels[ind])\n",
        "\n",
        "  new_val_images = np.asarray(new_val_images)\n",
        "  new_val_labels = np.asarray(new_val_labels)\n",
        "\n",
        "  return new_train_images, new_train_labels, new_val_images, new_val_labels"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mcNGsjHvDaV5"
      },
      "source": [
        "trial = set(new_train_labels)\n",
        "trial.remove(1)\n",
        "print(trial)\n",
        "trial = sorted(trial)\n",
        "print(trial)\n",
        "mapping = {}\n",
        "for i,j in enumerate(trial):\n",
        "  mapping[j] = i\n",
        "print(mapping)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWLP3dXECnor"
      },
      "source": [
        "def get_train_data(leave_out_class, train_images, train_labels):\n",
        "  class_train_images = []\n",
        "  class_train_labels = []\n",
        "  mapping = {}\n",
        "  \n",
        "  labels = set(train_labels)\n",
        "  labels.remove(leave_out_class)\n",
        "  labels = sorted(labels)\n",
        "  for i,j in enumerate(labels):\n",
        "    mapping[j] = i\n",
        "  print(mapping)\n",
        "\n",
        "  for ind, im in enumerate(train_images):\n",
        "    if train_labels[ind] != leave_out_class:\n",
        "      class_train_images.append(im)\n",
        "      class_train_labels.append(mapping[train_labels[ind]]) #(train_labels[ind])\n",
        "\n",
        "\n",
        "  class_train_images = np.asarray(class_train_images)\n",
        "  class_train_labels = np.asarray(class_train_labels)\n",
        "\n",
        "  print(set(class_train_labels))\n",
        "  print(class_train_labels.shape)\n",
        "\n",
        "  train_data = tf.data.Dataset.from_tensor_slices((class_train_images, class_train_labels))\n",
        "\n",
        "  train_data = train_data.shuffle(class_train_images.shape[0])\n",
        "  train_data = train_data.batch(128)\n",
        "  train_data = train_data.repeat(20)\n",
        "\n",
        "  return class_train_images, class_train_labels # train_data"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mW9CLrvuF_6L"
      },
      "source": [
        "def temp_cal(y_pred, val_labels):\n",
        "\n",
        "  temp = tf.Variable(initial_value=1.0, trainable=True, dtype=tf.float32) \n",
        "\n",
        "  def compute_loss():\n",
        "      y_pred_model_w_temp = tf.math.divide(y_pred, temp)\n",
        "      loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\\\n",
        "                                  tf.convert_to_tensor(keras.utils.to_categorical(val_labels)), y_pred_model_w_temp))\n",
        "      return loss\n",
        "\n",
        "  optimizer = tf.optimizers.Adam(learning_rate=0.01)\n",
        "\n",
        "  print('Temperature Initial value: {}'.format(temp.numpy()))\n",
        "\n",
        "  for i in range(300):\n",
        "      opts = optimizer.minimize(compute_loss, var_list=[temp])\n",
        "\n",
        "\n",
        "  print('Temperature Final value: {}'.format(temp.numpy()))\n",
        "\n",
        "  return temp"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yH4csCdiGJnf"
      },
      "source": [
        "def temp_scaling(y_pred, temp):\n",
        "  return tf.math.divide(y_pred, temp)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WFZ33vZBhJL"
      },
      "source": [
        "# Baseline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jf5RxmyPBjF1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fB-qbznCCQa"
      },
      "source": [
        "model0 = BaselineModel(name='baseline:anomaly0')\n",
        "model1 = BaselineModel(name='baseline:anomaly1')\n",
        "model2 = BaselineModel(name='baseline:anomaly2')\n",
        "model3 = BaselineModel(name='baseline:anomaly3')\n",
        "model4 = BaselineModel(name='baseline:anomaly4')\n",
        "model5 = BaselineModel(name='baseline:anomaly5')\n",
        "model6 = BaselineModel(name='baseline:anomaly6')\n",
        "model7 = BaselineModel(name='baseline:anomaly7')\n",
        "model8 = BaselineModel(name='baseline:anomaly8')\n",
        "model9 = BaselineModel(name='baseline:anomaly9')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hz1CM0uPCCQw"
      },
      "source": [
        "class_0 = model0.build()\n",
        "class_1 = model1.build()\n",
        "class_2 = model2.build()\n",
        "class_3 = model3.build()\n",
        "class_4 = model4.build()\n",
        "class_5 = model5.build()\n",
        "class_6 = model6.build()\n",
        "class_7 = model7.build()\n",
        "class_8 = model8.build()\n",
        "class_9 = model9.build()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kCpaWqaJDYXm",
        "outputId": "55503fbf-c8a4-494a-95ed-5c51ad03c013"
      },
      "source": [
        "set(train_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4b4SGbenCCQx",
        "outputId": "e87af943-dcfa-4eed-f647-d2b8cc42218b"
      },
      "source": [
        "\n",
        "train_imgs0, train_lbls0 = get_train_data(0, train_images, train_labels)\n",
        "val_imgs0, val_lbls0 = get_train_data(0, val_images, val_labels)\n",
        "class_0 = model0.build()\n",
        "model0.train2(train_imgs0, train_lbls0, val_imgs0, val_lbls0)\n",
        "#model0.train(train_data0)\n",
        "model0.save_model(\"final_models/baseline-anomaly0\")\n",
        "print('Model 0 saved')\n",
        "\n",
        "train_imgs1, train_lbls1 = get_train_data(1, train_images, train_labels)\n",
        "val_imgs1, val_lbls1 = get_train_data(1, val_images, val_labels)\n",
        "class_1 = model1.build()\n",
        "model1.train2(train_imgs1, train_lbls1, val_imgs1, val_lbls1)\n",
        "#model1.train(train_data1)\n",
        "model1.save_model(\"final_models/baseline-anomaly1\")\n",
        "print('Model 1 saved')\n",
        "\n",
        "#train_data2 = get_train_data(2, new_train_images)\n",
        "train_imgs2, train_lbls2 = get_train_data(2, train_images, train_labels)\n",
        "val_imgs2, val_lbls2 = get_train_data(2, val_images, val_labels)\n",
        "class_2 = model2.build()\n",
        "model2.train2(train_imgs2, train_lbls2, val_imgs2, val_lbls2)\n",
        "#model2.train(train_data2)\n",
        "model2.save_model(\"final_models/baseline-anomaly2\")\n",
        "print('Model 2 saved')\n",
        "\n",
        "#train_data3 = get_train_data(3, new_train_images)\n",
        "train_imgs3, train_lbls3 = get_train_data(3, train_images, train_labels)\n",
        "val_imgs3, val_lbls3 = get_train_data(3, val_images, val_labels)\n",
        "class_3 = model3.build()\n",
        "model3.train2(train_imgs3, train_lbls3, val_imgs3, val_lbls3)\n",
        "#model3.train(train_data3)\n",
        "model3.save_model(\"final_models/baseline-anomaly3\")\n",
        "print('Model 3 saved')\n",
        "\n",
        "#train_data4 = get_train_data(4, new_train_images)\n",
        "train_imgs4, train_lbls4 = get_train_data(4, train_images, train_labels)\n",
        "val_imgs4, val_lbls4 = get_train_data(4, val_images, val_labels)\n",
        "class_4 = model4.build()\n",
        "model4.train2(train_imgs4, train_lbls4, val_imgs4, val_lbls4)\n",
        "#model4.train(train_data4)\n",
        "model4.save_model(\"final_models/baseline-anomaly4\")\n",
        "print('Model 4 saved')\n",
        "\n",
        "#train_data5 = get_train_data(5, new_train_images)\n",
        "train_imgs5, train_lbls5 = get_train_data(5, train_images, train_labels)\n",
        "val_imgs5, val_lbls5 = get_train_data(5, val_images, val_labels)\n",
        "class_5 = model5.build()\n",
        "model5.train2(train_imgs5, train_lbls5, val_imgs5, val_lbls5)\n",
        "#model5.train(train_data5)\n",
        "model5.save_model(\"final_models/baseline-anomaly5\")\n",
        "print('Model 5 saved')\n",
        "\n",
        "#train_data6 = get_train_data(6, new_train_images)\n",
        "train_imgs6, train_lbls6 = get_train_data(6, train_images, train_labels)\n",
        "val_imgs6, val_lbls6 = get_train_data(6, val_images, val_labels)\n",
        "class_6 = model6.build()\n",
        "model6.train2(train_imgs6, train_lbls6, val_imgs6, val_lbls6)\n",
        "#model6.train(train_data6)\n",
        "model6.save_model(\"final_models/baseline-anomaly6\")\n",
        "print('Model 6 saved')\n",
        "\n",
        "#train_data7 = get_train_data(7, new_train_images)\n",
        "train_imgs7, train_lbls7 = get_train_data(7, train_images, train_labels)\n",
        "val_imgs7, val_lbls7 = get_train_data(7, val_images, val_labels)\n",
        "class_7 = model7.build()\n",
        "#model7.train(train_data7)\n",
        "model7.train2(train_imgs7, train_lbls7, val_imgs7, val_lbls7)\n",
        "model7.save_model(\"final_models/baseline-anomaly7\")\n",
        "print('Model 7 saved')\n",
        "\n",
        "#train_data8 = get_train_data(8, new_train_images)\n",
        "train_imgs8, train_lbls8 = get_train_data(8, train_images, train_labels)\n",
        "val_imgs8, val_lbls8 = get_train_data(8, val_images, val_labels)\n",
        "class_8 = model8.build()\n",
        "#model8.train(train_data8)\n",
        "model8.train2(train_imgs8, train_lbls8, val_imgs8, val_lbls8)\n",
        "model8.save_model(\"final_models/baseline-anomaly8\")\n",
        "print('Model 8 saved')\n",
        "\n",
        "train_imgs9, train_lbls9 = get_train_data(9, train_images, train_labels)\n",
        "val_imgs9, val_lbls9 = get_train_data(9, val_images, val_labels)\n",
        "class_9 = model9.build()\n",
        "model9.train2(train_imgs9, train_lbls9, val_imgs9, val_lbls9)\n",
        "#model9.train(train_data9)\n",
        "model9.save_model(\"final_models/baseline-anomaly9\")\n",
        "print('Model 9 saved')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{1: 0, 2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, 8: 7, 9: 8}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7, 8}\n",
            "(43252,)\n",
            "{1: 0, 2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, 8: 7, 9: 8}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7, 8}\n",
            "(10825,)\n",
            "Epoch 1/20\n",
            "1352/1352 [==============================] - 45s 33ms/step - loss: 5.5498 - accuracy: 0.7934 - val_loss: 0.1134 - val_accuracy: 0.9708\n",
            "Epoch 2/20\n",
            "1352/1352 [==============================] - 44s 32ms/step - loss: 0.1002 - accuracy: 0.9734 - val_loss: 0.0683 - val_accuracy: 0.9805\n",
            "Epoch 3/20\n",
            "1352/1352 [==============================] - 44s 32ms/step - loss: 0.0720 - accuracy: 0.9786 - val_loss: 0.1099 - val_accuracy: 0.9719\n",
            "Epoch 4/20\n",
            "1352/1352 [==============================] - 44s 32ms/step - loss: 0.0701 - accuracy: 0.9786 - val_loss: 0.5159 - val_accuracy: 0.9167\n",
            "Epoch 5/20\n",
            "1352/1352 [==============================] - 44s 32ms/step - loss: 0.0660 - accuracy: 0.9802 - val_loss: 0.1031 - val_accuracy: 0.9752\n",
            "Epoch 6/20\n",
            "1352/1352 [==============================] - 44s 32ms/step - loss: 0.0577 - accuracy: 0.9827 - val_loss: 0.0761 - val_accuracy: 0.9777\n",
            "Epoch 7/20\n",
            "1352/1352 [==============================] - 44s 32ms/step - loss: 0.0511 - accuracy: 0.9844 - val_loss: 0.1310 - val_accuracy: 0.9707\n",
            "Epoch 8/20\n",
            "1352/1352 [==============================] - 44s 32ms/step - loss: 0.0485 - accuracy: 0.9846 - val_loss: 0.0807 - val_accuracy: 0.9792\n",
            "Epoch 9/20\n",
            "1352/1352 [==============================] - 44s 32ms/step - loss: 0.0421 - accuracy: 0.9872 - val_loss: 0.1030 - val_accuracy: 0.9766\n",
            "Epoch 10/20\n",
            "1352/1352 [==============================] - 44s 32ms/step - loss: 0.0320 - accuracy: 0.9897 - val_loss: 0.1135 - val_accuracy: 0.9739\n",
            "Epoch 11/20\n",
            "1352/1352 [==============================] - 44s 32ms/step - loss: 0.0332 - accuracy: 0.9900 - val_loss: 0.0792 - val_accuracy: 0.9824\n",
            "Epoch 12/20\n",
            "1352/1352 [==============================] - 44s 32ms/step - loss: 0.0344 - accuracy: 0.9892 - val_loss: 0.0614 - val_accuracy: 0.9843\n",
            "Epoch 13/20\n",
            "1352/1352 [==============================] - 44s 32ms/step - loss: 0.0268 - accuracy: 0.9921 - val_loss: 0.1527 - val_accuracy: 0.9725\n",
            "Epoch 14/20\n",
            "1352/1352 [==============================] - 44s 32ms/step - loss: 0.0253 - accuracy: 0.9922 - val_loss: 0.1126 - val_accuracy: 0.9749\n",
            "Epoch 15/20\n",
            "1352/1352 [==============================] - 44s 32ms/step - loss: 0.0253 - accuracy: 0.9924 - val_loss: 0.0604 - val_accuracy: 0.9851\n",
            "Epoch 16/20\n",
            "1352/1352 [==============================] - 44s 32ms/step - loss: 0.0208 - accuracy: 0.9937 - val_loss: 0.0668 - val_accuracy: 0.9873\n",
            "Epoch 17/20\n",
            "1352/1352 [==============================] - 44s 32ms/step - loss: 0.0194 - accuracy: 0.9946 - val_loss: 0.0828 - val_accuracy: 0.9825\n",
            "Epoch 18/20\n",
            "1352/1352 [==============================] - 44s 32ms/step - loss: 0.0192 - accuracy: 0.9946 - val_loss: 0.0689 - val_accuracy: 0.9863\n",
            "Epoch 19/20\n",
            "1352/1352 [==============================] - 44s 32ms/step - loss: 0.0149 - accuracy: 0.9951 - val_loss: 0.0765 - val_accuracy: 0.9852\n",
            "Epoch 20/20\n",
            "1352/1352 [==============================] - 44s 32ms/step - loss: 0.0173 - accuracy: 0.9944 - val_loss: 0.0930 - val_accuracy: 0.9801\n",
            "INFO:tensorflow:Assets written to: final_models/baseline-anomaly0/assets\n",
            "Model 0 saved\n",
            "{0: 0, 2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, 8: 7, 9: 8}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7, 8}\n",
            "(42580,)\n",
            "{0: 0, 2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, 8: 7, 9: 8}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7, 8}\n",
            "(10678,)\n",
            "Epoch 1/20\n",
            "1331/1331 [==============================] - 44s 33ms/step - loss: 4.7059 - accuracy: 0.8032 - val_loss: 0.1357 - val_accuracy: 0.9644\n",
            "Epoch 2/20\n",
            "1331/1331 [==============================] - 43s 32ms/step - loss: 0.1022 - accuracy: 0.9725 - val_loss: 0.2729 - val_accuracy: 0.9384\n",
            "Epoch 3/20\n",
            "1331/1331 [==============================] - 43s 32ms/step - loss: 0.0716 - accuracy: 0.9789 - val_loss: 0.3241 - val_accuracy: 0.9333\n",
            "Epoch 4/20\n",
            "1331/1331 [==============================] - 43s 32ms/step - loss: 0.0703 - accuracy: 0.9795 - val_loss: 0.1734 - val_accuracy: 0.9623\n",
            "Epoch 5/20\n",
            "1331/1331 [==============================] - 43s 32ms/step - loss: 0.0671 - accuracy: 0.9804 - val_loss: 0.1939 - val_accuracy: 0.9518\n",
            "Epoch 6/20\n",
            "1331/1331 [==============================] - 43s 32ms/step - loss: 0.0598 - accuracy: 0.9827 - val_loss: 0.3977 - val_accuracy: 0.9244\n",
            "Epoch 7/20\n",
            "1331/1331 [==============================] - 43s 32ms/step - loss: 0.0550 - accuracy: 0.9832 - val_loss: 0.1181 - val_accuracy: 0.9707\n",
            "Epoch 8/20\n",
            "1331/1331 [==============================] - 43s 32ms/step - loss: 0.0479 - accuracy: 0.9854 - val_loss: 0.2099 - val_accuracy: 0.9557\n",
            "Epoch 9/20\n",
            "1331/1331 [==============================] - 43s 32ms/step - loss: 0.0408 - accuracy: 0.9878 - val_loss: 0.2312 - val_accuracy: 0.9500\n",
            "Epoch 10/20\n",
            "1331/1331 [==============================] - 43s 32ms/step - loss: 0.0341 - accuracy: 0.9891 - val_loss: 0.1399 - val_accuracy: 0.9717\n",
            "Epoch 11/20\n",
            "1331/1331 [==============================] - 43s 32ms/step - loss: 0.0327 - accuracy: 0.9903 - val_loss: 0.1312 - val_accuracy: 0.9722\n",
            "Epoch 12/20\n",
            "1331/1331 [==============================] - 43s 32ms/step - loss: 0.0304 - accuracy: 0.9904 - val_loss: 0.1382 - val_accuracy: 0.9687\n",
            "Epoch 13/20\n",
            "1331/1331 [==============================] - 43s 32ms/step - loss: 0.0258 - accuracy: 0.9917 - val_loss: 0.1357 - val_accuracy: 0.9710\n",
            "Epoch 14/20\n",
            "1331/1331 [==============================] - 43s 32ms/step - loss: 0.0227 - accuracy: 0.9924 - val_loss: 0.1927 - val_accuracy: 0.9619\n",
            "Epoch 15/20\n",
            "1331/1331 [==============================] - 43s 32ms/step - loss: 0.0199 - accuracy: 0.9941 - val_loss: 0.1601 - val_accuracy: 0.9725\n",
            "Epoch 16/20\n",
            "1331/1331 [==============================] - 43s 32ms/step - loss: 0.0221 - accuracy: 0.9931 - val_loss: 0.0978 - val_accuracy: 0.9790\n",
            "Epoch 17/20\n",
            "1331/1331 [==============================] - 43s 32ms/step - loss: 0.0179 - accuracy: 0.9941 - val_loss: 0.1508 - val_accuracy: 0.9741\n",
            "Epoch 18/20\n",
            "1331/1331 [==============================] - 43s 32ms/step - loss: 0.0202 - accuracy: 0.9933 - val_loss: 0.0924 - val_accuracy: 0.9824\n",
            "Epoch 19/20\n",
            "1331/1331 [==============================] - 43s 32ms/step - loss: 0.0206 - accuracy: 0.9939 - val_loss: 0.1266 - val_accuracy: 0.9771\n",
            "Epoch 20/20\n",
            "1331/1331 [==============================] - 43s 32ms/step - loss: 0.0177 - accuracy: 0.9951 - val_loss: 0.0951 - val_accuracy: 0.9823\n",
            "INFO:tensorflow:Assets written to: final_models/baseline-anomaly1/assets\n",
            "Model 1 saved\n",
            "{0: 0, 1: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, 8: 7, 9: 8}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7, 8}\n",
            "(43216,)\n",
            "{0: 0, 1: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, 8: 7, 9: 8}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7, 8}\n",
            "(10826,)\n",
            "Epoch 1/20\n",
            "1351/1351 [==============================] - 45s 33ms/step - loss: 4.6200 - accuracy: 0.7788 - val_loss: 0.2812 - val_accuracy: 0.9479\n",
            "Epoch 2/20\n",
            "1351/1351 [==============================] - 43s 32ms/step - loss: 0.1675 - accuracy: 0.9633 - val_loss: 0.1590 - val_accuracy: 0.9608\n",
            "Epoch 3/20\n",
            "1351/1351 [==============================] - 44s 32ms/step - loss: 0.0868 - accuracy: 0.9748 - val_loss: 0.0973 - val_accuracy: 0.9728\n",
            "Epoch 4/20\n",
            "1351/1351 [==============================] - 44s 32ms/step - loss: 0.0698 - accuracy: 0.9791 - val_loss: 0.0715 - val_accuracy: 0.9797\n",
            "Epoch 5/20\n",
            "1351/1351 [==============================] - 44s 32ms/step - loss: 0.0604 - accuracy: 0.9812 - val_loss: 0.1319 - val_accuracy: 0.9629\n",
            "Epoch 6/20\n",
            "1351/1351 [==============================] - 44s 32ms/step - loss: 0.0541 - accuracy: 0.9828 - val_loss: 0.1882 - val_accuracy: 0.9543\n",
            "Epoch 7/20\n",
            "1351/1351 [==============================] - 44s 32ms/step - loss: 0.0480 - accuracy: 0.9853 - val_loss: 0.2100 - val_accuracy: 0.9612\n",
            "Epoch 8/20\n",
            "1351/1351 [==============================] - 43s 32ms/step - loss: 0.0475 - accuracy: 0.9854 - val_loss: 0.0837 - val_accuracy: 0.9798\n",
            "Epoch 9/20\n",
            "1351/1351 [==============================] - 43s 32ms/step - loss: 0.0378 - accuracy: 0.9884 - val_loss: 0.2524 - val_accuracy: 0.9449\n",
            "Epoch 10/20\n",
            "1351/1351 [==============================] - 44s 32ms/step - loss: 0.0323 - accuracy: 0.9900 - val_loss: 0.0625 - val_accuracy: 0.9834\n",
            "Epoch 11/20\n",
            "1351/1351 [==============================] - 44s 32ms/step - loss: 0.0307 - accuracy: 0.9903 - val_loss: 0.0520 - val_accuracy: 0.9871\n",
            "Epoch 12/20\n",
            "1351/1351 [==============================] - 44s 32ms/step - loss: 0.0275 - accuracy: 0.9917 - val_loss: 0.0859 - val_accuracy: 0.9804\n",
            "Epoch 13/20\n",
            "1351/1351 [==============================] - 44s 32ms/step - loss: 0.0260 - accuracy: 0.9920 - val_loss: 0.0655 - val_accuracy: 0.9838\n",
            "Epoch 14/20\n",
            "1351/1351 [==============================] - 43s 32ms/step - loss: 0.0234 - accuracy: 0.9927 - val_loss: 0.0699 - val_accuracy: 0.9832\n",
            "Epoch 15/20\n",
            "1351/1351 [==============================] - 44s 32ms/step - loss: 0.0216 - accuracy: 0.9930 - val_loss: 0.0615 - val_accuracy: 0.9861\n",
            "Epoch 16/20\n",
            "1351/1351 [==============================] - 43s 32ms/step - loss: 0.0211 - accuracy: 0.9933 - val_loss: 0.1160 - val_accuracy: 0.9753\n",
            "Epoch 17/20\n",
            "1351/1351 [==============================] - 44s 32ms/step - loss: 0.0204 - accuracy: 0.9940 - val_loss: 0.1054 - val_accuracy: 0.9768\n",
            "Epoch 18/20\n",
            "1351/1351 [==============================] - 44s 32ms/step - loss: 0.0185 - accuracy: 0.9943 - val_loss: 0.0614 - val_accuracy: 0.9866\n",
            "Epoch 19/20\n",
            "1351/1351 [==============================] - 44s 32ms/step - loss: 0.0159 - accuracy: 0.9949 - val_loss: 0.0607 - val_accuracy: 0.9872\n",
            "Epoch 20/20\n",
            "1351/1351 [==============================] - 44s 32ms/step - loss: 0.0154 - accuracy: 0.9948 - val_loss: 0.1064 - val_accuracy: 0.9778\n",
            "INFO:tensorflow:Assets written to: final_models/baseline-anomaly2/assets\n",
            "Model 2 saved\n",
            "{0: 0, 1: 1, 2: 2, 4: 3, 5: 4, 6: 5, 7: 6, 8: 7, 9: 8}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7, 8}\n",
            "(43088,)\n",
            "{0: 0, 1: 1, 2: 2, 4: 3, 5: 4, 6: 5, 7: 6, 8: 7, 9: 8}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7, 8}\n",
            "(10781,)\n",
            "Epoch 1/20\n",
            "1347/1347 [==============================] - 45s 33ms/step - loss: 4.0860 - accuracy: 0.8595 - val_loss: 0.5869 - val_accuracy: 0.9359\n",
            "Epoch 2/20\n",
            "1347/1347 [==============================] - 44s 32ms/step - loss: 0.1202 - accuracy: 0.9704 - val_loss: 0.0924 - val_accuracy: 0.9723\n",
            "Epoch 3/20\n",
            "1347/1347 [==============================] - 43s 32ms/step - loss: 0.0793 - accuracy: 0.9778 - val_loss: 0.1069 - val_accuracy: 0.9693\n",
            "Epoch 4/20\n",
            "1347/1347 [==============================] - 44s 32ms/step - loss: 0.0778 - accuracy: 0.9778 - val_loss: 0.0962 - val_accuracy: 0.9752\n",
            "Epoch 5/20\n",
            "1347/1347 [==============================] - 43s 32ms/step - loss: 0.0654 - accuracy: 0.9807 - val_loss: 0.0681 - val_accuracy: 0.9823\n",
            "Epoch 6/20\n",
            "1347/1347 [==============================] - 44s 32ms/step - loss: 0.0552 - accuracy: 0.9832 - val_loss: 0.2326 - val_accuracy: 0.9545\n",
            "Epoch 7/20\n",
            "1347/1347 [==============================] - 43s 32ms/step - loss: 0.0483 - accuracy: 0.9859 - val_loss: 0.0959 - val_accuracy: 0.9771\n",
            "Epoch 8/20\n",
            "1347/1347 [==============================] - 43s 32ms/step - loss: 0.0399 - accuracy: 0.9884 - val_loss: 0.0649 - val_accuracy: 0.9834\n",
            "Epoch 9/20\n",
            "1347/1347 [==============================] - 43s 32ms/step - loss: 0.0381 - accuracy: 0.9889 - val_loss: 0.0978 - val_accuracy: 0.9795\n",
            "Epoch 10/20\n",
            "1347/1347 [==============================] - 44s 32ms/step - loss: 0.0308 - accuracy: 0.9906 - val_loss: 0.1083 - val_accuracy: 0.9750\n",
            "Epoch 11/20\n",
            "1347/1347 [==============================] - 44s 32ms/step - loss: 0.0315 - accuracy: 0.9902 - val_loss: 0.0664 - val_accuracy: 0.9833\n",
            "Epoch 12/20\n",
            "1347/1347 [==============================] - 44s 32ms/step - loss: 0.0283 - accuracy: 0.9910 - val_loss: 0.0987 - val_accuracy: 0.9801\n",
            "Epoch 13/20\n",
            "1347/1347 [==============================] - 44s 32ms/step - loss: 0.0309 - accuracy: 0.9903 - val_loss: 0.0654 - val_accuracy: 0.9855\n",
            "Epoch 14/20\n",
            "1347/1347 [==============================] - 43s 32ms/step - loss: 0.0201 - accuracy: 0.9932 - val_loss: 0.0639 - val_accuracy: 0.9855\n",
            "Epoch 15/20\n",
            "1347/1347 [==============================] - 44s 32ms/step - loss: 0.0222 - accuracy: 0.9933 - val_loss: 0.0802 - val_accuracy: 0.9814\n",
            "Epoch 16/20\n",
            "1347/1347 [==============================] - 44s 32ms/step - loss: 0.0204 - accuracy: 0.9935 - val_loss: 0.1164 - val_accuracy: 0.9750\n",
            "Epoch 17/20\n",
            "1347/1347 [==============================] - 44s 32ms/step - loss: 0.0166 - accuracy: 0.9947 - val_loss: 0.1089 - val_accuracy: 0.9786\n",
            "Epoch 18/20\n",
            "1347/1347 [==============================] - 44s 32ms/step - loss: 0.0181 - accuracy: 0.9938 - val_loss: 0.0587 - val_accuracy: 0.9868\n",
            "Epoch 19/20\n",
            "1347/1347 [==============================] - 44s 32ms/step - loss: 0.0150 - accuracy: 0.9952 - val_loss: 0.0703 - val_accuracy: 0.9865\n",
            "Epoch 20/20\n",
            "1347/1347 [==============================] - 43s 32ms/step - loss: 0.0172 - accuracy: 0.9947 - val_loss: 0.0871 - val_accuracy: 0.9833\n",
            "INFO:tensorflow:Assets written to: final_models/baseline-anomaly3/assets\n",
            "Model 3 saved\n",
            "{0: 0, 1: 1, 2: 2, 3: 3, 5: 4, 6: 5, 7: 6, 8: 7, 9: 8}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7, 8}\n",
            "(43334,)\n",
            "{0: 0, 1: 1, 2: 2, 3: 3, 5: 4, 6: 5, 7: 6, 8: 7, 9: 8}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7, 8}\n",
            "(10824,)\n",
            "Epoch 1/20\n",
            "1355/1355 [==============================] - 45s 33ms/step - loss: 5.6881 - accuracy: 0.7992 - val_loss: 0.3452 - val_accuracy: 0.9390\n",
            "Epoch 2/20\n",
            "1355/1355 [==============================] - 44s 32ms/step - loss: 0.1618 - accuracy: 0.9718 - val_loss: 0.1447 - val_accuracy: 0.9611\n",
            "Epoch 3/20\n",
            "1355/1355 [==============================] - 44s 32ms/step - loss: 0.0706 - accuracy: 0.9794 - val_loss: 0.1488 - val_accuracy: 0.9641\n",
            "Epoch 4/20\n",
            "1355/1355 [==============================] - 44s 32ms/step - loss: 0.0583 - accuracy: 0.9828 - val_loss: 0.5638 - val_accuracy: 0.9132\n",
            "Epoch 5/20\n",
            "1355/1355 [==============================] - 44s 32ms/step - loss: 0.0600 - accuracy: 0.9832 - val_loss: 0.0735 - val_accuracy: 0.9799\n",
            "Epoch 6/20\n",
            "1355/1355 [==============================] - 44s 32ms/step - loss: 0.0522 - accuracy: 0.9835 - val_loss: 0.1185 - val_accuracy: 0.9736\n",
            "Epoch 7/20\n",
            "1355/1355 [==============================] - 44s 32ms/step - loss: 0.0497 - accuracy: 0.9840 - val_loss: 0.1373 - val_accuracy: 0.9674\n",
            "Epoch 8/20\n",
            "1355/1355 [==============================] - 44s 32ms/step - loss: 0.0444 - accuracy: 0.9865 - val_loss: 0.1537 - val_accuracy: 0.9601\n",
            "Epoch 9/20\n",
            "1355/1355 [==============================] - 44s 32ms/step - loss: 0.0391 - accuracy: 0.9880 - val_loss: 0.1046 - val_accuracy: 0.9729\n",
            "Epoch 10/20\n",
            "1355/1355 [==============================] - 44s 32ms/step - loss: 0.0356 - accuracy: 0.9892 - val_loss: 0.0796 - val_accuracy: 0.9792\n",
            "Epoch 11/20\n",
            "1355/1355 [==============================] - 44s 32ms/step - loss: 0.0326 - accuracy: 0.9898 - val_loss: 0.1283 - val_accuracy: 0.9706\n",
            "Epoch 12/20\n",
            "1355/1355 [==============================] - 44s 32ms/step - loss: 0.0296 - accuracy: 0.9909 - val_loss: 0.0977 - val_accuracy: 0.9774\n",
            "Epoch 13/20\n",
            "1355/1355 [==============================] - 44s 32ms/step - loss: 0.0250 - accuracy: 0.9917 - val_loss: 0.0657 - val_accuracy: 0.9836\n",
            "Epoch 14/20\n",
            "1355/1355 [==============================] - 44s 32ms/step - loss: 0.0227 - accuracy: 0.9926 - val_loss: 0.1109 - val_accuracy: 0.9761\n",
            "Epoch 15/20\n",
            "1355/1355 [==============================] - 44s 32ms/step - loss: 0.0212 - accuracy: 0.9926 - val_loss: 0.1320 - val_accuracy: 0.9716\n",
            "Epoch 16/20\n",
            "1355/1355 [==============================] - 44s 32ms/step - loss: 0.0150 - accuracy: 0.9951 - val_loss: 0.0835 - val_accuracy: 0.9836\n",
            "Epoch 17/20\n",
            "1355/1355 [==============================] - 44s 32ms/step - loss: 0.0212 - accuracy: 0.9935 - val_loss: 0.2242 - val_accuracy: 0.9561\n",
            "Epoch 18/20\n",
            "1355/1355 [==============================] - 44s 32ms/step - loss: 0.0143 - accuracy: 0.9952 - val_loss: 0.1797 - val_accuracy: 0.9668\n",
            "Epoch 19/20\n",
            "1355/1355 [==============================] - 44s 32ms/step - loss: 0.0153 - accuracy: 0.9953 - val_loss: 0.1693 - val_accuracy: 0.9704\n",
            "Epoch 20/20\n",
            "1355/1355 [==============================] - 44s 32ms/step - loss: 0.0194 - accuracy: 0.9941 - val_loss: 0.0843 - val_accuracy: 0.9840\n",
            "INFO:tensorflow:Assets written to: final_models/baseline-anomaly4/assets\n",
            "Model 4 saved\n",
            "{0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 6: 5, 7: 6, 8: 7, 9: 8}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7, 8}\n",
            "(43683,)\n",
            "{0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 6: 5, 7: 6, 8: 7, 9: 8}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7, 8}\n",
            "(10896,)\n",
            "Epoch 1/20\n",
            "1366/1366 [==============================] - 46s 33ms/step - loss: 3.7770 - accuracy: 0.8476 - val_loss: 0.1736 - val_accuracy: 0.9569\n",
            "Epoch 2/20\n",
            "1366/1366 [==============================] - 44s 32ms/step - loss: 0.1082 - accuracy: 0.9715 - val_loss: 0.2263 - val_accuracy: 0.9403\n",
            "Epoch 3/20\n",
            "1366/1366 [==============================] - 44s 32ms/step - loss: 0.0883 - accuracy: 0.9750 - val_loss: 0.2578 - val_accuracy: 0.9568\n",
            "Epoch 4/20\n",
            "1366/1366 [==============================] - 44s 32ms/step - loss: 0.0799 - accuracy: 0.9779 - val_loss: 0.1428 - val_accuracy: 0.9706\n",
            "Epoch 5/20\n",
            "1366/1366 [==============================] - 44s 32ms/step - loss: 0.0641 - accuracy: 0.9817 - val_loss: 0.1077 - val_accuracy: 0.9741\n",
            "Epoch 6/20\n",
            "1366/1366 [==============================] - 44s 32ms/step - loss: 0.0562 - accuracy: 0.9835 - val_loss: 0.1531 - val_accuracy: 0.9700\n",
            "Epoch 7/20\n",
            "1366/1366 [==============================] - 44s 32ms/step - loss: 0.0506 - accuracy: 0.9843 - val_loss: 0.0967 - val_accuracy: 0.9762\n",
            "Epoch 8/20\n",
            "1366/1366 [==============================] - 44s 32ms/step - loss: 0.0440 - accuracy: 0.9868 - val_loss: 0.1113 - val_accuracy: 0.9769\n",
            "Epoch 9/20\n",
            "1366/1366 [==============================] - 44s 32ms/step - loss: 0.0370 - accuracy: 0.9886 - val_loss: 0.0818 - val_accuracy: 0.9818\n",
            "Epoch 10/20\n",
            "1366/1366 [==============================] - 44s 32ms/step - loss: 0.0333 - accuracy: 0.9901 - val_loss: 0.0570 - val_accuracy: 0.9862\n",
            "Epoch 11/20\n",
            "1366/1366 [==============================] - 44s 32ms/step - loss: 0.0273 - accuracy: 0.9917 - val_loss: 0.3388 - val_accuracy: 0.9465\n",
            "Epoch 12/20\n",
            "1366/1366 [==============================] - 44s 32ms/step - loss: 0.0274 - accuracy: 0.9913 - val_loss: 0.2909 - val_accuracy: 0.9514\n",
            "Epoch 13/20\n",
            "1366/1366 [==============================] - 44s 32ms/step - loss: 0.0266 - accuracy: 0.9913 - val_loss: 0.1014 - val_accuracy: 0.9751\n",
            "Epoch 14/20\n",
            "1366/1366 [==============================] - 44s 32ms/step - loss: 0.0217 - accuracy: 0.9934 - val_loss: 0.0492 - val_accuracy: 0.9881\n",
            "Epoch 15/20\n",
            "1366/1366 [==============================] - 44s 32ms/step - loss: 0.0185 - accuracy: 0.9944 - val_loss: 0.1117 - val_accuracy: 0.9787\n",
            "Epoch 16/20\n",
            "1366/1366 [==============================] - 44s 32ms/step - loss: 0.0207 - accuracy: 0.9937 - val_loss: 0.0971 - val_accuracy: 0.9798\n",
            "Epoch 17/20\n",
            "1366/1366 [==============================] - 44s 32ms/step - loss: 0.0196 - accuracy: 0.9938 - val_loss: 0.1094 - val_accuracy: 0.9779\n",
            "Epoch 18/20\n",
            "1366/1366 [==============================] - 44s 32ms/step - loss: 0.0190 - accuracy: 0.9944 - val_loss: 0.1073 - val_accuracy: 0.9798\n",
            "Epoch 19/20\n",
            "1366/1366 [==============================] - 44s 32ms/step - loss: 0.0143 - accuracy: 0.9956 - val_loss: 0.0721 - val_accuracy: 0.9864\n",
            "Epoch 20/20\n",
            "1366/1366 [==============================] - 44s 32ms/step - loss: 0.0169 - accuracy: 0.9949 - val_loss: 0.1715 - val_accuracy: 0.9701\n",
            "INFO:tensorflow:Assets written to: final_models/baseline-anomaly5/assets\n",
            "Model 5 saved\n",
            "{0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 7: 6, 8: 7, 9: 8}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7, 8}\n",
            "(43259,)\n",
            "{0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 7: 6, 8: 7, 9: 8}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7, 8}\n",
            "(10823,)\n",
            "Epoch 1/20\n",
            "1352/1352 [==============================] - 46s 33ms/step - loss: 4.1056 - accuracy: 0.8425 - val_loss: 0.1437 - val_accuracy: 0.9602\n",
            "Epoch 2/20\n",
            "1352/1352 [==============================] - 44s 32ms/step - loss: 0.1052 - accuracy: 0.9704 - val_loss: 0.1649 - val_accuracy: 0.9530\n",
            "Epoch 3/20\n",
            "1352/1352 [==============================] - 44s 33ms/step - loss: 0.0799 - accuracy: 0.9773 - val_loss: 0.1586 - val_accuracy: 0.9616\n",
            "Epoch 4/20\n",
            "1352/1352 [==============================] - 44s 32ms/step - loss: 0.0702 - accuracy: 0.9788 - val_loss: 0.0881 - val_accuracy: 0.9761\n",
            "Epoch 5/20\n",
            "1352/1352 [==============================] - 44s 32ms/step - loss: 0.0700 - accuracy: 0.9802 - val_loss: 0.1529 - val_accuracy: 0.9625\n",
            "Epoch 6/20\n",
            "1352/1352 [==============================] - 44s 32ms/step - loss: 0.0598 - accuracy: 0.9823 - val_loss: 0.1180 - val_accuracy: 0.9713\n",
            "Epoch 7/20\n",
            "1352/1352 [==============================] - 44s 32ms/step - loss: 0.0554 - accuracy: 0.9831 - val_loss: 0.1613 - val_accuracy: 0.9655\n",
            "Epoch 8/20\n",
            "1352/1352 [==============================] - 44s 32ms/step - loss: 0.0492 - accuracy: 0.9850 - val_loss: 0.1208 - val_accuracy: 0.9727\n",
            "Epoch 9/20\n",
            "1352/1352 [==============================] - 44s 32ms/step - loss: 0.0442 - accuracy: 0.9863 - val_loss: 0.0662 - val_accuracy: 0.9833\n",
            "Epoch 10/20\n",
            "1352/1352 [==============================] - 44s 32ms/step - loss: 0.0379 - accuracy: 0.9884 - val_loss: 0.0748 - val_accuracy: 0.9807\n",
            "Epoch 11/20\n",
            "1352/1352 [==============================] - 44s 32ms/step - loss: 0.0335 - accuracy: 0.9892 - val_loss: 0.0764 - val_accuracy: 0.9822\n",
            "Epoch 12/20\n",
            "1352/1352 [==============================] - 44s 33ms/step - loss: 0.0303 - accuracy: 0.9909 - val_loss: 0.0948 - val_accuracy: 0.9766\n",
            "Epoch 13/20\n",
            "1352/1352 [==============================] - 44s 32ms/step - loss: 0.0286 - accuracy: 0.9912 - val_loss: 0.0681 - val_accuracy: 0.9847\n",
            "Epoch 14/20\n",
            "1352/1352 [==============================] - 44s 33ms/step - loss: 0.0266 - accuracy: 0.9925 - val_loss: 0.0846 - val_accuracy: 0.9827\n",
            "Epoch 15/20\n",
            "1352/1352 [==============================] - 44s 33ms/step - loss: 0.0241 - accuracy: 0.9924 - val_loss: 0.0860 - val_accuracy: 0.9818\n",
            "Epoch 16/20\n",
            "1352/1352 [==============================] - 44s 32ms/step - loss: 0.0212 - accuracy: 0.9933 - val_loss: 0.0934 - val_accuracy: 0.9802\n",
            "Epoch 17/20\n",
            "1352/1352 [==============================] - 44s 33ms/step - loss: 0.0229 - accuracy: 0.9926 - val_loss: 0.0674 - val_accuracy: 0.9848\n",
            "Epoch 18/20\n",
            "1352/1352 [==============================] - 44s 32ms/step - loss: 0.0170 - accuracy: 0.9946 - val_loss: 0.0752 - val_accuracy: 0.9842\n",
            "Epoch 19/20\n",
            "1352/1352 [==============================] - 44s 32ms/step - loss: 0.0201 - accuracy: 0.9936 - val_loss: 0.0960 - val_accuracy: 0.9797\n",
            "Epoch 20/20\n",
            "1352/1352 [==============================] - 44s 32ms/step - loss: 0.0155 - accuracy: 0.9952 - val_loss: 0.0963 - val_accuracy: 0.9814\n",
            "INFO:tensorflow:Assets written to: final_models/baseline-anomaly6/assets\n",
            "Model 6 saved\n",
            "{0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 8: 7, 9: 8}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7, 8}\n",
            "(43034,)\n",
            "{0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 8: 7, 9: 8}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7, 8}\n",
            "(10701,)\n",
            "Epoch 1/20\n",
            "1345/1345 [==============================] - 45s 33ms/step - loss: 3.8796 - accuracy: 0.8398 - val_loss: 0.2830 - val_accuracy: 0.9491\n",
            "Epoch 2/20\n",
            "1345/1345 [==============================] - 43s 32ms/step - loss: 0.1165 - accuracy: 0.9706 - val_loss: 0.2854 - val_accuracy: 0.9366\n",
            "Epoch 3/20\n",
            "1345/1345 [==============================] - 44s 33ms/step - loss: 0.0761 - accuracy: 0.9769 - val_loss: 0.1317 - val_accuracy: 0.9651\n",
            "Epoch 4/20\n",
            "1345/1345 [==============================] - 43s 32ms/step - loss: 0.0737 - accuracy: 0.9784 - val_loss: 0.1431 - val_accuracy: 0.9645\n",
            "Epoch 5/20\n",
            "1345/1345 [==============================] - 44s 32ms/step - loss: 0.0577 - accuracy: 0.9824 - val_loss: 0.1143 - val_accuracy: 0.9704\n",
            "Epoch 6/20\n",
            "1345/1345 [==============================] - 44s 32ms/step - loss: 0.0635 - accuracy: 0.9826 - val_loss: 0.1114 - val_accuracy: 0.9707\n",
            "Epoch 7/20\n",
            "1345/1345 [==============================] - 44s 32ms/step - loss: 0.0507 - accuracy: 0.9851 - val_loss: 0.1096 - val_accuracy: 0.9766\n",
            "Epoch 8/20\n",
            "1345/1345 [==============================] - 44s 32ms/step - loss: 0.0450 - accuracy: 0.9856 - val_loss: 0.0668 - val_accuracy: 0.9840\n",
            "Epoch 9/20\n",
            "1345/1345 [==============================] - 44s 32ms/step - loss: 0.0399 - accuracy: 0.9879 - val_loss: 0.1404 - val_accuracy: 0.9729\n",
            "Epoch 10/20\n",
            "1345/1345 [==============================] - 44s 32ms/step - loss: 0.0361 - accuracy: 0.9894 - val_loss: 0.1885 - val_accuracy: 0.9673\n",
            "Epoch 11/20\n",
            "1345/1345 [==============================] - 44s 32ms/step - loss: 0.0320 - accuracy: 0.9906 - val_loss: 0.1547 - val_accuracy: 0.9646\n",
            "Epoch 12/20\n",
            "1345/1345 [==============================] - 44s 32ms/step - loss: 0.0297 - accuracy: 0.9908 - val_loss: 0.1378 - val_accuracy: 0.9717\n",
            "Epoch 13/20\n",
            "1345/1345 [==============================] - 43s 32ms/step - loss: 0.0298 - accuracy: 0.9913 - val_loss: 0.0500 - val_accuracy: 0.9882\n",
            "Epoch 14/20\n",
            "1345/1345 [==============================] - 44s 32ms/step - loss: 0.0237 - accuracy: 0.9924 - val_loss: 0.0892 - val_accuracy: 0.9785\n",
            "Epoch 15/20\n",
            "1345/1345 [==============================] - 44s 32ms/step - loss: 0.0212 - accuracy: 0.9935 - val_loss: 0.1140 - val_accuracy: 0.9775\n",
            "Epoch 16/20\n",
            "1345/1345 [==============================] - 44s 32ms/step - loss: 0.0214 - accuracy: 0.9932 - val_loss: 0.1190 - val_accuracy: 0.9765\n",
            "Epoch 17/20\n",
            "1345/1345 [==============================] - 44s 32ms/step - loss: 0.0207 - accuracy: 0.9932 - val_loss: 0.1337 - val_accuracy: 0.9754\n",
            "Epoch 18/20\n",
            "1345/1345 [==============================] - 44s 32ms/step - loss: 0.0214 - accuracy: 0.9940 - val_loss: 0.1035 - val_accuracy: 0.9807\n",
            "Epoch 19/20\n",
            "1345/1345 [==============================] - 44s 32ms/step - loss: 0.0173 - accuracy: 0.9941 - val_loss: 0.0951 - val_accuracy: 0.9823\n",
            "Epoch 20/20\n",
            "1345/1345 [==============================] - 44s 32ms/step - loss: 0.0156 - accuracy: 0.9952 - val_loss: 0.1292 - val_accuracy: 0.9782\n",
            "INFO:tensorflow:Assets written to: final_models/baseline-anomaly7/assets\n",
            "Model 7 saved\n",
            "{0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 9: 8}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7, 8}\n",
            "(43309,)\n",
            "{0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 9: 8}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7, 8}\n",
            "(10840,)\n",
            "Epoch 1/20\n",
            "1354/1354 [==============================] - 45s 33ms/step - loss: 4.4342 - accuracy: 0.8365 - val_loss: 0.1136 - val_accuracy: 0.9683\n",
            "Epoch 2/20\n",
            "1354/1354 [==============================] - 44s 32ms/step - loss: 0.1120 - accuracy: 0.9737 - val_loss: 0.0874 - val_accuracy: 0.9726\n",
            "Epoch 3/20\n",
            "1354/1354 [==============================] - 44s 33ms/step - loss: 0.0699 - accuracy: 0.9800 - val_loss: 0.1776 - val_accuracy: 0.9623\n",
            "Epoch 4/20\n",
            "1354/1354 [==============================] - 44s 32ms/step - loss: 0.0683 - accuracy: 0.9809 - val_loss: 0.0972 - val_accuracy: 0.9753\n",
            "Epoch 5/20\n",
            "1354/1354 [==============================] - 44s 32ms/step - loss: 0.0548 - accuracy: 0.9837 - val_loss: 0.1436 - val_accuracy: 0.9677\n",
            "Epoch 6/20\n",
            "1354/1354 [==============================] - 44s 33ms/step - loss: 0.0547 - accuracy: 0.9834 - val_loss: 0.1166 - val_accuracy: 0.9729\n",
            "Epoch 7/20\n",
            "1354/1354 [==============================] - 44s 33ms/step - loss: 0.0486 - accuracy: 0.9852 - val_loss: 0.1148 - val_accuracy: 0.9679\n",
            "Epoch 8/20\n",
            "1354/1354 [==============================] - 44s 33ms/step - loss: 0.0487 - accuracy: 0.9857 - val_loss: 0.1813 - val_accuracy: 0.9596\n",
            "Epoch 9/20\n",
            "1354/1354 [==============================] - 44s 33ms/step - loss: 0.0353 - accuracy: 0.9897 - val_loss: 0.0904 - val_accuracy: 0.9815\n",
            "Epoch 10/20\n",
            "1354/1354 [==============================] - 44s 33ms/step - loss: 0.0402 - accuracy: 0.9883 - val_loss: 0.0735 - val_accuracy: 0.9825\n",
            "Epoch 11/20\n",
            "1354/1354 [==============================] - 44s 33ms/step - loss: 0.0322 - accuracy: 0.9899 - val_loss: 0.0953 - val_accuracy: 0.9792\n",
            "Epoch 12/20\n",
            "1354/1354 [==============================] - 44s 33ms/step - loss: 0.0307 - accuracy: 0.9903 - val_loss: 0.0850 - val_accuracy: 0.9807\n",
            "Epoch 13/20\n",
            "1354/1354 [==============================] - 44s 32ms/step - loss: 0.0250 - accuracy: 0.9917 - val_loss: 0.0903 - val_accuracy: 0.9791\n",
            "Epoch 14/20\n",
            "1354/1354 [==============================] - 44s 33ms/step - loss: 0.0208 - accuracy: 0.9933 - val_loss: 0.0867 - val_accuracy: 0.9816\n",
            "Epoch 15/20\n",
            "1354/1354 [==============================] - 44s 32ms/step - loss: 0.0213 - accuracy: 0.9934 - val_loss: 0.0610 - val_accuracy: 0.9865\n",
            "Epoch 16/20\n",
            "1354/1354 [==============================] - 44s 32ms/step - loss: 0.0220 - accuracy: 0.9931 - val_loss: 0.0812 - val_accuracy: 0.9837\n",
            "Epoch 17/20\n",
            "1354/1354 [==============================] - 44s 32ms/step - loss: 0.0186 - accuracy: 0.9943 - val_loss: 0.0902 - val_accuracy: 0.9828\n",
            "Epoch 18/20\n",
            "1354/1354 [==============================] - 44s 33ms/step - loss: 0.0240 - accuracy: 0.9932 - val_loss: 0.0941 - val_accuracy: 0.9823\n",
            "Epoch 19/20\n",
            "1354/1354 [==============================] - 44s 33ms/step - loss: 0.0184 - accuracy: 0.9943 - val_loss: 0.0639 - val_accuracy: 0.9867\n",
            "Epoch 20/20\n",
            "1354/1354 [==============================] - 44s 33ms/step - loss: 0.0149 - accuracy: 0.9955 - val_loss: 0.1446 - val_accuracy: 0.9726\n",
            "INFO:tensorflow:Assets written to: final_models/baseline-anomaly8/assets\n",
            "Model 8 saved\n",
            "{0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: 8}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7, 8}\n",
            "(43245,)\n",
            "{0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: 8}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7, 8}\n",
            "(10806,)\n",
            "Epoch 1/20\n",
            "1352/1352 [==============================] - 45s 33ms/step - loss: 4.7840 - accuracy: 0.8108 - val_loss: 0.3284 - val_accuracy: 0.9378\n",
            "Epoch 2/20\n",
            "1352/1352 [==============================] - 44s 32ms/step - loss: 0.1099 - accuracy: 0.9752 - val_loss: 0.2061 - val_accuracy: 0.9511\n",
            "Epoch 3/20\n",
            "1352/1352 [==============================] - 44s 32ms/step - loss: 0.0649 - accuracy: 0.9817 - val_loss: 0.0931 - val_accuracy: 0.9733\n",
            "Epoch 4/20\n",
            "1352/1352 [==============================] - 44s 32ms/step - loss: 0.0521 - accuracy: 0.9845 - val_loss: 0.2637 - val_accuracy: 0.9534\n",
            "Epoch 5/20\n",
            "1352/1352 [==============================] - 44s 32ms/step - loss: 0.0611 - accuracy: 0.9820 - val_loss: 0.0988 - val_accuracy: 0.9754\n",
            "Epoch 6/20\n",
            "1352/1352 [==============================] - 44s 32ms/step - loss: 0.0509 - accuracy: 0.9851 - val_loss: 0.1293 - val_accuracy: 0.9705\n",
            "Epoch 7/20\n",
            "1352/1352 [==============================] - 44s 32ms/step - loss: 0.0452 - accuracy: 0.9865 - val_loss: 0.2931 - val_accuracy: 0.9410\n",
            "Epoch 8/20\n",
            "1352/1352 [==============================] - 44s 32ms/step - loss: 0.0421 - accuracy: 0.9867 - val_loss: 0.2488 - val_accuracy: 0.9542\n",
            "Epoch 9/20\n",
            "1352/1352 [==============================] - 44s 32ms/step - loss: 0.0422 - accuracy: 0.9871 - val_loss: 0.3237 - val_accuracy: 0.9392\n",
            "Epoch 10/20\n",
            "1352/1352 [==============================] - 44s 32ms/step - loss: 0.0355 - accuracy: 0.9894 - val_loss: 0.1053 - val_accuracy: 0.9767\n",
            "Epoch 11/20\n",
            "1352/1352 [==============================] - 44s 32ms/step - loss: 0.0259 - accuracy: 0.9918 - val_loss: 0.0738 - val_accuracy: 0.9792\n",
            "Epoch 12/20\n",
            "1352/1352 [==============================] - 44s 32ms/step - loss: 0.0247 - accuracy: 0.9926 - val_loss: 0.3452 - val_accuracy: 0.9461\n",
            "Epoch 13/20\n",
            "1352/1352 [==============================] - 44s 33ms/step - loss: 0.0252 - accuracy: 0.9927 - val_loss: 0.1364 - val_accuracy: 0.9696\n",
            "Epoch 14/20\n",
            "1352/1352 [==============================] - 44s 32ms/step - loss: 0.0251 - accuracy: 0.9918 - val_loss: 0.0950 - val_accuracy: 0.9773\n",
            "Epoch 15/20\n",
            "1352/1352 [==============================] - 44s 32ms/step - loss: 0.0219 - accuracy: 0.9929 - val_loss: 0.0959 - val_accuracy: 0.9805\n",
            "Epoch 16/20\n",
            "1352/1352 [==============================] - 44s 32ms/step - loss: 0.0182 - accuracy: 0.9949 - val_loss: 0.0685 - val_accuracy: 0.9854\n",
            "Epoch 17/20\n",
            "1352/1352 [==============================] - 44s 32ms/step - loss: 0.0154 - accuracy: 0.9950 - val_loss: 0.1397 - val_accuracy: 0.9723\n",
            "Epoch 18/20\n",
            "1352/1352 [==============================] - 44s 32ms/step - loss: 0.0209 - accuracy: 0.9944 - val_loss: 0.1446 - val_accuracy: 0.9775\n",
            "Epoch 19/20\n",
            "1352/1352 [==============================] - 44s 32ms/step - loss: 0.0147 - accuracy: 0.9954 - val_loss: 0.0841 - val_accuracy: 0.9837\n",
            "Epoch 20/20\n",
            "1352/1352 [==============================] - 44s 32ms/step - loss: 0.0148 - accuracy: 0.9957 - val_loss: 0.1144 - val_accuracy: 0.9809\n",
            "INFO:tensorflow:Assets written to: final_models/baseline-anomaly9/assets\n",
            "Model 9 saved\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FskpCvpyCCQ1"
      },
      "source": [
        "class_0 = model0.load_model(\"final_models/baseline-anomaly0\")\n",
        "class_1 = model1.load_model(\"final_models/baseline-anomaly1\")\n",
        "class_2 = model2.load_model(\"final_models/baseline-anomaly2\")\n",
        "class_3 = model3.load_model(\"final_models/baseline-anomaly3\")\n",
        "class_4 = model4.load_model(\"final_models/baseline-anomaly4\")\n",
        "class_5 = model5.load_model(\"final_models/baseline-anomaly5\")\n",
        "class_6 = model6.load_model(\"final_models/baseline-anomaly6\")\n",
        "class_7 = model7.load_model(\"final_models/baseline-anomaly7\")\n",
        "class_8 = model8.load_model(\"final_models/baseline-anomaly8\")\n",
        "class_9 = model9.load_model(\"final_models/baseline-anomaly9\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X3DfQObeCCQ2"
      },
      "source": [
        "def get_max_pred_value(model, img):\n",
        "  pred = model(img)\n",
        "\n",
        "#  logits = tf.math.divide(logits, temp)\n",
        "#  pred = tf.nn.softmax(logits)\n",
        "#  e = entropy(pred[0])\n",
        "\n",
        "  return np.max(pred), tf.argmax(pred[0]).numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGadB82ICCQ4"
      },
      "source": [
        "def get_mapping(anomaly_class):\n",
        "  mapping = {}\n",
        "\n",
        "  labels = set(train_labels)\n",
        "  labels.remove(anomaly_class)\n",
        "  labels = sorted(labels)\n",
        "\n",
        "  for i,j in enumerate(labels):\n",
        "    mapping[i] = j\n",
        "\n",
        "  return mapping\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZFp6NddCCQ5"
      },
      "source": [
        "ood = 0\n",
        "ind = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9l5eeydFov0"
      },
      "source": [
        "def get_bl_sm(model, anomaly_class):\n",
        "  max_sm_all_bl = []\n",
        "  y_true = []\n",
        "  for data, label in tqdm(zip(test_imgs, test_lbls)):\n",
        "    img = data.reshape([-1, 28, 28, 1])\n",
        "    if label == anomaly_class:\n",
        "      lbl = ood\n",
        "    else:\n",
        "      lbl = ind\n",
        "    y_true.append(lbl)\n",
        "    max0, pred_0 = get_max_pred_value(model, img)\n",
        "    map0 = get_mapping(anomaly_class)\n",
        "    pred_0 = map0[pred_0]\n",
        "\n",
        "    max_sm_all_bl.append(max0)\n",
        "\n",
        "  return y_true, max_sm_all_bl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWT6us03I47i"
      },
      "source": [
        "from sklearn.metrics import roc_auc_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9eV4PqPR0nd"
      },
      "source": [
        "print('For 0 as anomaly')\n",
        "y_true, y_sm = get_bl_sm(class_0, 0)\n",
        "a0 = roc_auc_score(y_true, y_sm)\n",
        "print('AUROC: ', a0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tSBXM7fmS4e7",
        "outputId": "fc833101-4d98-49cd-b841-926de0f07296"
      },
      "source": [
        "y_temp = []\n",
        "for i in y_true:\n",
        "  if i == 0:\n",
        "    lbl = ood\n",
        "  else:\n",
        "    lbl = ind\n",
        "  y_temp.append(lbl)\n",
        "roc_auc_score(y_temp, y_sm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8521517941988326"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ilX3UT1cVnNL",
        "outputId": "dc2e0733-d97b-445d-c7f0-5e9acd16e06e"
      },
      "source": [
        "for i, j in zip(y_temp, y_sm):\n",
        "  print(i,j)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "1 0.99999976\n",
            "1 0.9999715\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99999917\n",
            "1 0.9999999\n",
            "0 0.9999795\n",
            "1 1.0\n",
            "0 0.99959475\n",
            "1 0.9999987\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 0.9999995\n",
            "1 1.0\n",
            "1 0.9999981\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99999976\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 0.9919872\n",
            "1 1.0\n",
            "1 0.9999994\n",
            "1 1.0\n",
            "0 0.91993225\n",
            "1 1.0\n",
            "0 0.8818021\n",
            "1 1.0\n",
            "0 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99999845\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.9999995\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 0.95992136\n",
            "1 1.0\n",
            "1 0.9999908\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.9999993\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99999785\n",
            "1 1.0\n",
            "1 0.99999905\n",
            "1 1.0\n",
            "1 0.9999944\n",
            "1 1.0\n",
            "1 0.9999993\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99999976\n",
            "1 1.0\n",
            "1 0.6005787\n",
            "1 0.87515426\n",
            "0 0.9979354\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999939\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 0.99950373\n",
            "0 0.8030544\n",
            "1 1.0\n",
            "1 0.99999964\n",
            "1 0.9999807\n",
            "1 0.9981358\n",
            "1 0.99999595\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.60002834\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.999995\n",
            "1 0.99999297\n",
            "1 0.99999964\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999932\n",
            "1 0.9999994\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99995637\n",
            "1 0.99999666\n",
            "1 1.0\n",
            "0 1.0\n",
            "0 0.9937168\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99999976\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9993274\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.99997604\n",
            "1 0.99985754\n",
            "1 0.9999995\n",
            "1 0.9999746\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.72682136\n",
            "1 1.0\n",
            "1 0.999946\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.998933\n",
            "1 0.8779492\n",
            "0 0.9591887\n",
            "1 1.0\n",
            "1 0.9999994\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.42326984\n",
            "1 0.9999958\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999995\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.99999845\n",
            "1 0.99999976\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.97940135\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999976\n",
            "1 1.0\n",
            "1 0.9999976\n",
            "0 0.9999993\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.999997\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999993\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 0.9999914\n",
            "1 1.0\n",
            "1 0.9999982\n",
            "1 1.0\n",
            "1 0.9999943\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99999976\n",
            "1 0.9999465\n",
            "1 0.99999976\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99999976\n",
            "1 0.99998605\n",
            "1 0.9825996\n",
            "1 0.99999964\n",
            "1 0.9999126\n",
            "1 1.0\n",
            "1 0.99999964\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999943\n",
            "1 1.0\n",
            "1 0.9993936\n",
            "1 0.9999993\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999987\n",
            "1 1.0\n",
            "1 0.99979514\n",
            "1 0.99999976\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 0.99999833\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99999905\n",
            "0 0.9999999\n",
            "1 0.999705\n",
            "0 0.99910706\n",
            "0 0.990248\n",
            "1 1.0\n",
            "1 0.96835816\n",
            "1 0.9999926\n",
            "1 1.0\n",
            "0 0.9993799\n",
            "1 0.9999999\n",
            "0 0.999106\n",
            "1 1.0\n",
            "0 0.9987134\n",
            "1 0.9999993\n",
            "0 0.99872714\n",
            "1 1.0\n",
            "0 0.79100245\n",
            "1 1.0\n",
            "0 0.9999931\n",
            "1 0.99987984\n",
            "1 0.9993463\n",
            "1 0.9998764\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9893763\n",
            "1 0.84064984\n",
            "0 0.9963797\n",
            "1 0.9999995\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99999976\n",
            "1 1.0\n",
            "0 0.9974843\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99899346\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9996458\n",
            "1 0.9999999\n",
            "0 0.99940336\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.8875294\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.7385105\n",
            "1 1.0\n",
            "0 0.64169925\n",
            "1 1.0\n",
            "1 0.9999975\n",
            "1 1.0\n",
            "1 0.9999443\n",
            "1 0.99999976\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 0.99990714\n",
            "0 0.53676295\n",
            "0 0.9963238\n",
            "1 0.99993205\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99999917\n",
            "1 1.0\n",
            "1 0.94894767\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9995115\n",
            "1 1.0\n",
            "0 0.999979\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.99999964\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999565\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.55454916\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.99967253\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99996233\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.918867\n",
            "0 0.96850216\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99999976\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99999976\n",
            "1 0.9999968\n",
            "1 1.0\n",
            "1 0.99999166\n",
            "1 1.0\n",
            "1 0.99999976\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99999976\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999994\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.9380712\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.9997758\n",
            "1 1.0\n",
            "1 0.99983513\n",
            "1 1.0\n",
            "1 0.6229404\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.8584006\n",
            "1 0.9999968\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999925\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.99977356\n",
            "1 0.99999774\n",
            "0 0.9999982\n",
            "1 1.0\n",
            "1 0.99999917\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.9556252\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999989\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.99999464\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999981\n",
            "1 0.99999964\n",
            "1 1.0\n",
            "1 0.9999956\n",
            "0 0.99999166\n",
            "1 1.0\n",
            "0 0.9999924\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 0.9999975\n",
            "1 1.0\n",
            "0 0.99999976\n",
            "1 0.99999964\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.9999182\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.9999163\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9994894\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99999845\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.73171824\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999994\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.99831885\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.99999404\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999995\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.99883026\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99966836\n",
            "1 1.0\n",
            "1 0.9999604\n",
            "0 0.5756407\n",
            "1 0.9987808\n",
            "1 1.0\n",
            "0 0.52756697\n",
            "1 1.0\n",
            "0 0.73956895\n",
            "1 0.99999917\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 0.9999995\n",
            "1 0.999995\n",
            "1 0.9998274\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 0.9997925\n",
            "1 0.9999609\n",
            "1 0.99999046\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.99855214\n",
            "1 1.0\n",
            "1 0.9999995\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 0.9999988\n",
            "1 1.0\n",
            "1 0.99971646\n",
            "1 0.9999999\n",
            "1 0.99999964\n",
            "0 0.9997812\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.78157365\n",
            "1 1.0\n",
            "1 0.99999964\n",
            "1 1.0\n",
            "1 0.99994373\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 0.9999654\n",
            "1 1.0\n",
            "1 0.99999595\n",
            "1 0.99990773\n",
            "0 0.8203852\n",
            "1 1.0\n",
            "1 0.9999993\n",
            "1 0.99999976\n",
            "1 0.99999905\n",
            "1 1.0\n",
            "1 0.99999964\n",
            "1 1.0\n",
            "0 0.83083683\n",
            "0 1.0\n",
            "1 1.0\n",
            "1 0.9995741\n",
            "1 1.0\n",
            "1 0.98909676\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9635981\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "0 0.9999254\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.7006952\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99967873\n",
            "1 0.99999785\n",
            "0 0.99999917\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.5367103\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 0.9999995\n",
            "1 0.9426839\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 0.9999993\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999995\n",
            "1 0.5441124\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99999547\n",
            "1 0.99999917\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 0.9999989\n",
            "1 0.96325064\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999621\n",
            "1 0.9999989\n",
            "1 1.0\n",
            "1 0.99999976\n",
            "1 0.99999976\n",
            "1 0.9999994\n",
            "1 1.0\n",
            "1 0.99994755\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "0 0.9997832\n",
            "0 0.99999917\n",
            "1 0.9996295\n",
            "1 0.9999969\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.99671257\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99999976\n",
            "1 0.99628854\n",
            "1 1.0\n",
            "1 0.9999982\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "0 0.99994683\n",
            "1 1.0\n",
            "1 0.9999995\n",
            "1 1.0\n",
            "0 0.9565994\n",
            "1 0.9999795\n",
            "1 0.9999999\n",
            "1 0.99069524\n",
            "1 0.9970592\n",
            "1 0.99919015\n",
            "1 0.99999976\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999976\n",
            "0 0.99998164\n",
            "0 0.64736694\n",
            "0 0.9404175\n",
            "1 1.0\n",
            "1 0.9999995\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9899742\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.9630144\n",
            "1 0.6420428\n",
            "1 1.0\n",
            "1 0.96275496\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999918\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 0.9999981\n",
            "1 0.99994195\n",
            "1 0.9999958\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99205047\n",
            "1 0.9999962\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.99240464\n",
            "1 0.9978205\n",
            "1 0.804287\n",
            "0 0.68796515\n",
            "1 0.99999976\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99999595\n",
            "0 0.9999472\n",
            "1 0.9999994\n",
            "1 1.0\n",
            "1 0.4505448\n",
            "1 0.9825507\n",
            "1 0.9999441\n",
            "0 0.75169384\n",
            "1 0.99999964\n",
            "1 1.0\n",
            "1 0.99998915\n",
            "1 0.9970962\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.8741027\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9995485\n",
            "0 0.7644266\n",
            "1 1.0\n",
            "1 0.8616184\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.9999994\n",
            "1 0.9998215\n",
            "1 0.999998\n",
            "1 0.99999964\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999994\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99975175\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999684\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "0 0.99999833\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99998796\n",
            "1 0.9999999\n",
            "1 0.9999943\n",
            "1 1.0\n",
            "1 0.99999976\n",
            "1 0.99999785\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "0 0.99999964\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99999964\n",
            "1 1.0\n",
            "1 0.99999976\n",
            "0 0.99999976\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "0 0.99989486\n",
            "1 1.0\n",
            "1 0.9988851\n",
            "1 1.0\n",
            "1 0.9999993\n",
            "1 0.9999864\n",
            "0 0.87976706\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999832\n",
            "1 0.9999964\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999987\n",
            "1 1.0\n",
            "0 1.0\n",
            "0 0.9999994\n",
            "1 1.0\n",
            "0 0.8635293\n",
            "1 0.99999976\n",
            "1 0.99999726\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999945\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "0 0.94283587\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99999654\n",
            "1 0.9999989\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.9869441\n",
            "1 0.9999999\n",
            "1 0.9998901\n",
            "1 1.0\n",
            "1 0.99997914\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.9770995\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 0.99999964\n",
            "0 0.49895394\n",
            "1 0.9999882\n",
            "1 0.9999974\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99996555\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99255294\n",
            "1 0.424255\n",
            "1 1.0\n",
            "0 0.49230343\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99999654\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "0 0.9988286\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999995\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999964\n",
            "1 0.9999975\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.96400845\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99999964\n",
            "0 0.9996846\n",
            "1 0.9999981\n",
            "1 1.0\n",
            "1 0.9981756\n",
            "1 1.0\n",
            "1 0.9998615\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 0.99984086\n",
            "1 0.9999964\n",
            "1 1.0\n",
            "0 0.73671293\n",
            "0 0.999806\n",
            "1 1.0\n",
            "0 0.9999975\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999671\n",
            "1 0.8531155\n",
            "1 0.99003893\n",
            "1 1.0\n",
            "1 0.99999976\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.99387\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99999654\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99999964\n",
            "1 0.99999917\n",
            "1 0.9999994\n",
            "0 0.9999957\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.48414516\n",
            "1 0.9999932\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999994\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.99999785\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9996613\n",
            "1 1.0\n",
            "1 0.99999905\n",
            "1 1.0\n",
            "1 0.9999336\n",
            "0 0.999998\n",
            "1 0.99996424\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999174\n",
            "0 0.99999964\n",
            "1 0.9999993\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99998975\n",
            "0 0.99997187\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.9999521\n",
            "1 1.0\n",
            "1 0.99999917\n",
            "0 0.99999857\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9822494\n",
            "1 0.99999976\n",
            "1 0.99999905\n",
            "1 1.0\n",
            "1 0.99999046\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.99939096\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 0.9999975\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99992716\n",
            "1 0.9999963\n",
            "1 0.97445935\n",
            "1 1.0\n",
            "1 0.99999595\n",
            "1 1.0\n",
            "0 0.99987435\n",
            "0 0.9999939\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999552\n",
            "1 1.0\n",
            "1 0.99989593\n",
            "1 1.0\n",
            "1 0.9999113\n",
            "1 1.0\n",
            "1 0.99998844\n",
            "1 0.99996674\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999926\n",
            "1 1.0\n",
            "1 0.99898154\n",
            "1 1.0\n",
            "1 0.99999964\n",
            "0 0.99960595\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999995\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9987878\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.9999993\n",
            "1 0.9999747\n",
            "1 1.0\n",
            "1 0.83243805\n",
            "1 0.9999964\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999981\n",
            "1 0.67675406\n",
            "0 1.0\n",
            "1 0.99999905\n",
            "1 1.0\n",
            "1 0.9996966\n",
            "1 0.9999969\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9970592\n",
            "1 0.9999411\n",
            "0 0.9999999\n",
            "1 0.9999864\n",
            "1 1.0\n",
            "1 0.9999883\n",
            "1 0.9999757\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99984884\n",
            "1 1.0\n",
            "1 0.9999995\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999994\n",
            "0 0.99999356\n",
            "1 0.9999999\n",
            "0 0.99998283\n",
            "1 0.9999976\n",
            "1 0.9999689\n",
            "1 0.99999225\n",
            "1 0.9999962\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.999984\n",
            "1 0.999998\n",
            "1 1.0\n",
            "1 0.9999989\n",
            "1 0.99999976\n",
            "1 0.95978814\n",
            "1 1.0\n",
            "0 0.9998073\n",
            "1 0.99999976\n",
            "1 0.99999416\n",
            "0 0.99999905\n",
            "1 0.99999714\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.8145708\n",
            "1 1.0\n",
            "1 0.9110735\n",
            "0 0.9968155\n",
            "1 1.0\n",
            "0 0.97975576\n",
            "1 1.0\n",
            "0 0.99997616\n",
            "1 1.0\n",
            "0 0.99999285\n",
            "1 1.0\n",
            "1 0.9999993\n",
            "1 1.0\n",
            "1 0.99999917\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "0 0.99999976\n",
            "1 0.9999994\n",
            "1 1.0\n",
            "1 0.99999845\n",
            "1 0.9999974\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99999964\n",
            "1 0.9999871\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9723451\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.81719124\n",
            "1 0.9999995\n",
            "0 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9631053\n",
            "1 1.0\n",
            "1 0.97893685\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99556714\n",
            "1 0.7823945\n",
            "1 0.9798487\n",
            "1 1.0\n",
            "1 0.99996316\n",
            "1 0.9999989\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999995\n",
            "0 0.92682624\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99997485\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.9922152\n",
            "1 0.9999989\n",
            "1 1.0\n",
            "1 0.99999726\n",
            "1 0.9999943\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999907\n",
            "0 0.99802387\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99999917\n",
            "0 0.9999989\n",
            "1 1.0\n",
            "1 0.9999844\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99999976\n",
            "1 0.9999999\n",
            "1 0.99999976\n",
            "1 0.99999976\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99999976\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999994\n",
            "1 1.0\n",
            "1 0.9999995\n",
            "1 0.9999995\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999995\n",
            "1 1.0\n",
            "0 0.99987614\n",
            "1 0.9999969\n",
            "1 0.99980277\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999988\n",
            "1 1.0\n",
            "1 0.9993789\n",
            "0 0.99996185\n",
            "1 0.9999989\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99999976\n",
            "1 1.0\n",
            "1 0.9999989\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.9999999\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.9999157\n",
            "1 0.9999989\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99999595\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.9999758\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999951\n",
            "1 1.0\n",
            "0 0.91363806\n",
            "0 0.5593799\n",
            "0 0.992311\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.99998736\n",
            "1 1.0\n",
            "1 0.99999726\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 0.9999989\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999975\n",
            "0 0.9963355\n",
            "1 0.99999976\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.99833727\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99999344\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.72088015\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999993\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.86550564\n",
            "1 1.0\n",
            "0 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.84009945\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999752\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999994\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999995\n",
            "1 1.0\n",
            "1 0.9999995\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999896\n",
            "1 0.99999976\n",
            "1 1.0\n",
            "1 0.9999925\n",
            "1 0.99997425\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.9095229\n",
            "1 1.0\n",
            "1 0.99999845\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999994\n",
            "1 0.9991855\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.9998159\n",
            "1 1.0\n",
            "0 0.99999547\n",
            "1 0.99998784\n",
            "1 1.0\n",
            "1 0.9999995\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999995\n",
            "1 0.99999845\n",
            "1 0.99999845\n",
            "1 0.9999976\n",
            "1 0.99986815\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99992\n",
            "1 0.9999535\n",
            "1 1.0\n",
            "1 0.9999355\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "0 0.99999976\n",
            "1 1.0\n",
            "0 0.99999714\n",
            "1 0.99999225\n",
            "0 0.98231333\n",
            "0 0.82636964\n",
            "1 0.99999976\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999974\n",
            "1 0.9999418\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.9926237\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999912\n",
            "1 1.0\n",
            "1 0.9999813\n",
            "0 0.9999999\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99999845\n",
            "1 0.99999857\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99999785\n",
            "1 1.0\n",
            "0 0.9990108\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 0.9993549\n",
            "1 1.0\n",
            "1 0.999959\n",
            "0 0.99999976\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.95663935\n",
            "1 0.95794135\n",
            "1 1.0\n",
            "0 0.77091646\n",
            "1 0.99974304\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.9713461\n",
            "1 1.0\n",
            "1 0.9999988\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99999964\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99999535\n",
            "1 1.0\n",
            "0 0.72713715\n",
            "1 0.99999964\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99968755\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99997556\n",
            "1 1.0\n",
            "1 0.65893567\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99999976\n",
            "1 1.0\n",
            "0 0.9501039\n",
            "1 0.9999999\n",
            "1 0.9999993\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99914074\n",
            "1 0.99999917\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.99952006\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99999845\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.99957865\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99996686\n",
            "1 0.9999862\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999988\n",
            "1 1.0\n",
            "1 0.99999976\n",
            "1 0.99999666\n",
            "1 1.0\n",
            "1 0.99999964\n",
            "0 0.99433583\n",
            "1 0.99999666\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999825\n",
            "1 0.9934356\n",
            "1 0.99372995\n",
            "1 0.99880886\n",
            "1 0.9999993\n",
            "0 0.998483\n",
            "1 0.99447155\n",
            "1 0.99992836\n",
            "1 0.8428801\n",
            "1 0.9987105\n",
            "1 1.0\n",
            "1 0.9999995\n",
            "1 0.99980503\n",
            "1 0.9990095\n",
            "1 1.0\n",
            "0 0.9999894\n",
            "1 0.72673804\n",
            "1 0.6568925\n",
            "1 0.72927177\n",
            "1 0.9947577\n",
            "1 0.9986118\n",
            "1 0.9999937\n",
            "1 0.99967766\n",
            "1 0.60906273\n",
            "1 0.9983425\n",
            "1 0.99884254\n",
            "1 0.9997576\n",
            "1 0.9999963\n",
            "0 0.8956679\n",
            "1 0.9999981\n",
            "1 0.99963665\n",
            "0 0.97276556\n",
            "1 1.0\n",
            "1 0.9999633\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "0 0.5317431\n",
            "1 0.9999994\n",
            "0 0.9777109\n",
            "1 1.0\n",
            "1 0.5507106\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.98737854\n",
            "1 0.95581627\n",
            "1 0.77629656\n",
            "1 0.99999475\n",
            "1 0.9999993\n",
            "0 0.6549661\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 0.9997658\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 0.9775354\n",
            "1 0.99985015\n",
            "1 0.9999796\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.999984\n",
            "1 0.9999987\n",
            "1 1.0\n",
            "1 0.999997\n",
            "1 0.99999654\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "0 0.84211695\n",
            "1 0.99999213\n",
            "1 0.9999993\n",
            "1 0.997543\n",
            "1 0.854982\n",
            "1 0.9942521\n",
            "1 0.99995935\n",
            "1 0.99999416\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9898224\n",
            "0 0.97739375\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99999917\n",
            "1 0.7650353\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.81670666\n",
            "1 0.9999987\n",
            "0 0.9511582\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999534\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 0.9999975\n",
            "0 0.7258154\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99999976\n",
            "1 0.99999976\n",
            "1 0.99999845\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 0.99999976\n",
            "1 0.99966204\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "0 0.8740715\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9889538\n",
            "1 0.99999976\n",
            "1 0.9999995\n",
            "1 0.99999833\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99999833\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99998283\n",
            "1 1.0\n",
            "1 0.99999905\n",
            "1 0.9682864\n",
            "1 0.99999917\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999852\n",
            "1 0.99805546\n",
            "0 0.9906087\n",
            "1 0.99999964\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99999976\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.999683\n",
            "1 0.99999833\n",
            "0 0.948979\n",
            "1 0.99999964\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999982\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 0.99999154\n",
            "0 0.9097211\n",
            "1 0.9999999\n",
            "1 0.9999932\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99999976\n",
            "1 0.7617512\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9967294\n",
            "1 0.99999905\n",
            "1 0.99999976\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 0.9999994\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99970955\n",
            "1 0.9999801\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9995628\n",
            "1 0.99980325\n",
            "1 0.9955236\n",
            "1 0.9909943\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "0 0.98050046\n",
            "1 1.0\n",
            "0 0.9843008\n",
            "0 1.0\n",
            "1 1.0\n",
            "1 0.99999964\n",
            "1 0.99999833\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99999964\n",
            "0 1.0\n",
            "1 1.0\n",
            "1 0.9999994\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.92285883\n",
            "0 0.97367454\n",
            "1 1.0\n",
            "1 0.9999696\n",
            "1 0.9998834\n",
            "0 0.9999989\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99998176\n",
            "0 0.99997675\n",
            "1 0.99088496\n",
            "0 0.9999988\n",
            "1 1.0\n",
            "1 0.6835735\n",
            "1 0.99997175\n",
            "1 0.9999982\n",
            "0 0.9854193\n",
            "1 0.9997911\n",
            "1 0.9999975\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99996865\n",
            "1 1.0\n",
            "1 0.9996629\n",
            "1 1.0\n",
            "0 0.9999789\n",
            "1 0.99999356\n",
            "1 1.0\n",
            "0 0.99572563\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999995\n",
            "1 0.99992955\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999988\n",
            "1 1.0\n",
            "1 0.9978824\n",
            "0 0.9999708\n",
            "1 0.9999989\n",
            "1 1.0\n",
            "1 0.99957687\n",
            "1 0.9992447\n",
            "1 0.9999589\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9993774\n",
            "0 0.80388373\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99999976\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99999976\n",
            "1 1.0\n",
            "1 0.9999908\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 0.9999901\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.99959236\n",
            "1 1.0\n",
            "0 0.6296347\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9991781\n",
            "0 0.99996495\n",
            "1 1.0\n",
            "0 0.9998142\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999988\n",
            "1 1.0\n",
            "1 0.99998856\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 0.99998856\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 0.99989116\n",
            "1 1.0\n",
            "1 0.9999758\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "0 0.9999988\n",
            "1 0.97750753\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999808\n",
            "1 1.0\n",
            "1 0.9999547\n",
            "1 1.0\n",
            "1 0.9999976\n",
            "1 0.99999845\n",
            "1 1.0\n",
            "1 0.99999964\n",
            "1 0.9999999\n",
            "0 0.99773765\n",
            "1 1.0\n",
            "0 0.99984527\n",
            "1 0.99999857\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 0.99999976\n",
            "1 0.99999964\n",
            "1 1.0\n",
            "1 0.9994522\n",
            "1 0.99945897\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99998355\n",
            "1 1.0\n",
            "1 0.9872879\n",
            "1 0.99999976\n",
            "1 0.99998903\n",
            "1 0.9999993\n",
            "1 0.99999845\n",
            "1 0.9999999\n",
            "1 0.9999999\n",
            "1 0.9993395\n",
            "1 1.0\n",
            "0 0.9997738\n",
            "1 1.0\n",
            "0 0.62602055\n",
            "1 0.99999356\n",
            "0 0.9858192\n",
            "1 1.0\n",
            "0 0.9991221\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99999905\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "0 0.99708647\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 0.9999907\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 0.99987674\n",
            "1 0.99999976\n",
            "0 0.9999924\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999728\n",
            "1 1.0\n",
            "1 0.99999833\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.9825203\n",
            "1 1.0\n",
            "1 0.99999964\n",
            "0 0.999592\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99961746\n",
            "0 0.992242\n",
            "1 1.0\n",
            "0 0.8488019\n",
            "0 0.9999902\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999976\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.9999993\n",
            "0 0.95950055\n",
            "1 0.9999989\n",
            "1 0.9999851\n",
            "1 1.0\n",
            "1 0.9999441\n",
            "1 0.9999981\n",
            "1 1.0\n",
            "1 0.99999976\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 0.99997854\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99999297\n",
            "1 0.9998938\n",
            "1 0.9999386\n",
            "1 0.99999154\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99999917\n",
            "1 0.9999968\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999994\n",
            "1 0.9999937\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 0.9999995\n",
            "1 1.0\n",
            "1 0.9999995\n",
            "1 1.0\n",
            "1 0.9999982\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999969\n",
            "1 1.0\n",
            "1 0.99635386\n",
            "0 0.99758327\n",
            "1 1.0\n",
            "1 0.9993284\n",
            "1 1.0\n",
            "1 0.9999814\n",
            "1 1.0\n",
            "0 0.99994993\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.999943\n",
            "1 0.9999887\n",
            "1 0.99942744\n",
            "1 1.0\n",
            "1 0.9999472\n",
            "1 1.0\n",
            "0 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.99924505\n",
            "1 0.99999964\n",
            "1 0.7381816\n",
            "1 1.0\n",
            "1 0.99999785\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999949\n",
            "0 0.9879601\n",
            "1 0.99999976\n",
            "1 0.9973189\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999733\n",
            "0 0.9982444\n",
            "1 1.0\n",
            "1 0.9998852\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99989307\n",
            "1 1.0\n",
            "1 0.99999404\n",
            "0 0.9986326\n",
            "1 0.99999964\n",
            "0 0.995828\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 0.9999914\n",
            "1 0.9999962\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999968\n",
            "1 1.0\n",
            "1 0.9996413\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.999985\n",
            "1 0.99999976\n",
            "1 0.9999962\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999809\n",
            "1 0.9998894\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.8821489\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.999225\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999993\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999888\n",
            "1 1.0\n",
            "1 0.999997\n",
            "1 1.0\n",
            "1 0.9999951\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999949\n",
            "0 0.5719647\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999813\n",
            "0 0.97771454\n",
            "1 0.99999964\n",
            "1 0.99584264\n",
            "1 0.99999785\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.9109498\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99999154\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999156\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "0 0.9994874\n",
            "0 0.6016546\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.9992519\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 0.99999976\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99999213\n",
            "0 0.89386564\n",
            "1 1.0\n",
            "1 0.9883057\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99999976\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999995\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.9995453\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999994\n",
            "1 0.9999989\n",
            "1 1.0\n",
            "1 0.99999\n",
            "1 0.9998883\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.98248476\n",
            "0 0.7909478\n",
            "1 0.99999976\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99993885\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99996996\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 1.0\n",
            "1 0.9999999\n",
            "1 0.9955515\n",
            "1 0.9999995\n",
            "1 0.9999938\n",
            "0 0.9996252\n",
            "1 1.0\n",
            "1 0.99999917\n",
            "1 1.0\n",
            "0 0.99995613\n",
            "1 0.99999976\n",
            "1 0.99999976\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.99964106\n",
            "1 0.99999964\n",
            "1 0.9584294\n",
            "1 1.0\n",
            "1 0.9998442\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9985765\n",
            "1 1.0\n",
            "1 0.99999964\n",
            "1 0.9999988\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99999416\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.99800366\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999981\n",
            "1 0.9999999\n",
            "0 0.7698545\n",
            "1 0.9999999\n",
            "0 0.9943666\n",
            "1 1.0\n",
            "1 0.99979204\n",
            "1 1.0\n",
            "1 0.99999547\n",
            "1 0.9846815\n",
            "0 0.88891035\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999782\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99999964\n",
            "1 1.0\n",
            "1 0.99999666\n",
            "0 0.9986395\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.999183\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 0.9999999\n",
            "1 0.99999845\n",
            "0 0.9890708\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9995029\n",
            "1 0.9999989\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999951\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99332196\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99999976\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99999785\n",
            "0 0.9999999\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99999774\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.99994946\n",
            "1 1.0\n",
            "1 0.94422156\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 0.99999976\n",
            "0 0.96365124\n",
            "1 0.7158654\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 0.9999181\n",
            "0 0.54554987\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 0.99999917\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999994\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9996718\n",
            "1 1.0\n",
            "0 0.9999974\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999995\n",
            "0 0.9927879\n",
            "0 0.91305083\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.999997\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 0.99999905\n",
            "1 0.999634\n",
            "1 0.99999917\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99999774\n",
            "0 0.94499564\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 0.9999962\n",
            "0 0.99698216\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999994\n",
            "1 0.9999906\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9794714\n",
            "1 0.99999833\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999987\n",
            "1 0.9964641\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999989\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999063\n",
            "1 1.0\n",
            "0 0.9993782\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9258795\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999989\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.999998\n",
            "1 1.0\n",
            "1 0.9999914\n",
            "1 1.0\n",
            "1 0.9974891\n",
            "1 1.0\n",
            "1 0.999928\n",
            "1 0.99995744\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99999905\n",
            "1 0.99771523\n",
            "1 0.99999976\n",
            "1 0.9842106\n",
            "1 0.99999917\n",
            "1 0.9138015\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999994\n",
            "0 0.97544837\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99998903\n",
            "0 0.9999236\n",
            "1 0.99999845\n",
            "1 1.0\n",
            "0 0.5415227\n",
            "1 1.0\n",
            "1 0.9995165\n",
            "0 0.97201365\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999616\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.999456\n",
            "1 0.99999976\n",
            "1 1.0\n",
            "1 0.99999976\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.6209311\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99975973\n",
            "1 0.9908283\n",
            "1 0.98734915\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99914575\n",
            "1 0.9999994\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99999964\n",
            "1 1.0\n",
            "0 0.6479161\n",
            "1 1.0\n",
            "1 0.99999404\n",
            "1 0.9999939\n",
            "1 0.99999964\n",
            "1 0.9999995\n",
            "0 0.99905854\n",
            "1 0.9997285\n",
            "1 0.9999995\n",
            "1 0.83796835\n",
            "1 0.9999981\n",
            "1 0.99999905\n",
            "1 0.9999999\n",
            "1 0.99999964\n",
            "1 0.99999964\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999993\n",
            "0 0.9999993\n",
            "0 0.9979748\n",
            "1 0.99999976\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99933904\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 0.95583665\n",
            "1 0.99999905\n",
            "0 0.86984193\n",
            "1 0.99999917\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999621\n",
            "1 0.99999905\n",
            "1 1.0\n",
            "1 0.99777055\n",
            "1 0.99999833\n",
            "1 0.999998\n",
            "0 0.7565808\n",
            "1 0.9999988\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.8628689\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 0.9999981\n",
            "1 0.9999995\n",
            "0 0.93922126\n",
            "0 0.9497761\n",
            "1 0.9996247\n",
            "1 0.9989863\n",
            "1 1.0\n",
            "1 0.99999917\n",
            "1 0.9999995\n",
            "1 1.0\n",
            "1 0.9999938\n",
            "1 0.99999976\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99977857\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99999976\n",
            "1 1.0\n",
            "0 0.9999999\n",
            "1 0.9999795\n",
            "1 0.9999989\n",
            "0 0.7687682\n",
            "1 1.0\n",
            "1 0.9735014\n",
            "1 0.99999905\n",
            "1 0.9999993\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99999964\n",
            "0 0.9999956\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99999964\n",
            "1 1.0\n",
            "1 0.9999969\n",
            "1 0.9727606\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 0.9999745\n",
            "1 0.9996966\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99999976\n",
            "1 0.99997663\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 0.99999857\n",
            "1 0.9980153\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99997854\n",
            "0 0.97202635\n",
            "1 0.99999857\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.9977093\n",
            "1 1.0\n",
            "0 0.9998454\n",
            "1 1.0\n",
            "1 0.9999995\n",
            "1 1.0\n",
            "1 0.9999995\n",
            "1 0.9995976\n",
            "0 0.83634114\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999782\n",
            "0 0.9999951\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999565\n",
            "1 0.99999976\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 0.99999976\n",
            "0 0.9999907\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 0.99998856\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99999523\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99942243\n",
            "1 0.99999964\n",
            "1 0.9999639\n",
            "1 1.0\n",
            "1 0.9999993\n",
            "1 0.9993062\n",
            "1 1.0\n",
            "0 0.9787734\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99999845\n",
            "1 1.0\n",
            "1 0.9997671\n",
            "1 0.9996748\n",
            "1 0.9999957\n",
            "1 1.0\n",
            "0 0.55131966\n",
            "1 0.99999845\n",
            "1 0.9999988\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 0.99998677\n",
            "1 1.0\n",
            "1 0.99999464\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "0 0.99994206\n",
            "1 0.99999976\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99999344\n",
            "1 0.9999902\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 0.99999833\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.9862563\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99956876\n",
            "0 0.9999999\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99999964\n",
            "1 0.9999249\n",
            "1 1.0\n",
            "0 0.9996038\n",
            "1 0.9999988\n",
            "1 1.0\n",
            "0 0.997855\n",
            "0 0.684334\n",
            "1 0.9999908\n",
            "1 1.0\n",
            "0 0.9586456\n",
            "1 0.99999213\n",
            "1 0.99999976\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999924\n",
            "1 1.0\n",
            "1 0.9999924\n",
            "1 0.9999975\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.995138\n",
            "1 1.0\n",
            "1 0.99999917\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99999475\n",
            "0 0.9977191\n",
            "1 0.99999964\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99865675\n",
            "1 0.9973828\n",
            "0 0.9976799\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999584\n",
            "0 0.99999905\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99991727\n",
            "1 0.99999905\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999993\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999801\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99999976\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.99998844\n",
            "1 1.0\n",
            "0 0.99999475\n",
            "1 0.9999994\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99995315\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99999917\n",
            "0 0.9999999\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999893\n",
            "1 1.0\n",
            "1 0.5770993\n",
            "1 1.0\n",
            "1 0.999992\n",
            "1 0.99997365\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99999917\n",
            "1 0.9999827\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.9998988\n",
            "1 1.0\n",
            "1 0.99999523\n",
            "1 0.81298035\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.99999976\n",
            "1 0.99999976\n",
            "1 1.0\n",
            "0 1.0\n",
            "1 0.9986523\n",
            "1 0.99999726\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99999964\n",
            "1 0.9999999\n",
            "1 0.99999523\n",
            "1 1.0\n",
            "0 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99999845\n",
            "1 1.0\n",
            "0 0.998643\n",
            "1 1.0\n",
            "1 0.99609214\n",
            "0 0.9999994\n",
            "1 0.99679357\n",
            "1 1.0\n",
            "1 0.9995633\n",
            "1 0.9994803\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.99990916\n",
            "1 0.99986815\n",
            "1 1.0\n",
            "1 0.99427336\n",
            "1 0.9999881\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999981\n",
            "1 0.9999982\n",
            "0 0.94008154\n",
            "1 0.99967885\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 0.999998\n",
            "1 1.0\n",
            "1 0.9999994\n",
            "1 0.99999976\n",
            "1 0.99999416\n",
            "1 0.99999917\n",
            "1 1.0\n",
            "0 0.99999964\n",
            "1 0.99999964\n",
            "0 0.83445436\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.9999987\n",
            "1 0.9986551\n",
            "1 1.0\n",
            "1 0.9998455\n",
            "1 0.9999763\n",
            "1 1.0\n",
            "1 0.9999932\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.99253064\n",
            "1 0.99999976\n",
            "1 1.0\n",
            "1 0.999998\n",
            "1 0.9999995\n",
            "0 1.0\n",
            "1 0.9999999\n",
            "0 0.9999994\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99999845\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999994\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "0 1.0\n",
            "1 0.9999716\n",
            "1 0.99992025\n",
            "1 1.0\n",
            "1 0.99983907\n",
            "1 0.99999964\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9993358\n",
            "1 0.9999963\n",
            "1 0.99975115\n",
            "0 0.99997854\n",
            "1 1.0\n",
            "1 0.998686\n",
            "1 0.99993324\n",
            "1 1.0\n",
            "1 0.99912816\n",
            "1 1.0\n",
            "1 0.9999801\n",
            "1 0.9927094\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99999464\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9978732\n",
            "1 0.9937365\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99999917\n",
            "1 0.99999964\n",
            "0 0.95982295\n",
            "1 0.99999976\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999925\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999989\n",
            "0 0.9937365\n",
            "1 0.99999976\n",
            "1 0.99998593\n",
            "1 1.0\n",
            "1 0.99998164\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999937\n",
            "0 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999995\n",
            "1 1.0\n",
            "1 0.9998078\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.9999931\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99961877\n",
            "1 0.9999881\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999982\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999814\n",
            "1 0.9999988\n",
            "1 0.9999933\n",
            "1 0.99999785\n",
            "1 0.99999976\n",
            "0 0.9963258\n",
            "1 1.0\n",
            "0 0.99993014\n",
            "1 0.9999987\n",
            "1 0.80164665\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9996798\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 0.80204785\n",
            "1 1.0\n",
            "1 0.99999857\n",
            "1 0.9999738\n",
            "1 0.9999974\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.99999976\n",
            "1 0.9999974\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99995947\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.99994016\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 1.0\n",
            "1 0.9998921\n",
            "0 0.9999323\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99994874\n",
            "0 0.99999595\n",
            "1 0.99999976\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999871\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99999976\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999958\n",
            "1 0.999824\n",
            "1 0.9999993\n",
            "1 1.0\n",
            "1 0.99999654\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99999666\n",
            "1 1.0\n",
            "1 0.99972576\n",
            "1 0.99999976\n",
            "0 0.9997764\n",
            "0 0.99227214\n",
            "0 0.9032601\n",
            "1 0.9999995\n",
            "1 0.9862379\n",
            "1 1.0\n",
            "1 0.49165508\n",
            "1 0.9999993\n",
            "1 1.0\n",
            "1 0.99998534\n",
            "1 0.9981153\n",
            "1 0.99997103\n",
            "0 0.99999166\n",
            "1 0.99999964\n",
            "1 0.9986577\n",
            "1 1.0\n",
            "1 0.9982646\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99999905\n",
            "1 0.99999535\n",
            "0 0.9019015\n",
            "1 0.9999995\n",
            "1 0.99996066\n",
            "1 1.0\n",
            "1 0.99976724\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99998736\n",
            "0 0.9937331\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 0.99999976\n",
            "1 1.0\n",
            "1 0.9999951\n",
            "1 0.99867886\n",
            "1 0.89890844\n",
            "1 0.9998944\n",
            "1 0.66279685\n",
            "1 0.9805792\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.99999964\n",
            "1 0.9999999\n",
            "1 0.9999987\n",
            "1 0.99989355\n",
            "1 0.9999653\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99980813\n",
            "1 0.99730504\n",
            "1 0.99433315\n",
            "1 0.99999964\n",
            "1 0.99999404\n",
            "1 0.9999094\n",
            "0 0.7728977\n",
            "1 0.9999999\n",
            "1 0.9999999\n",
            "0 0.99995756\n",
            "1 0.9999913\n",
            "1 1.0\n",
            "0 0.9999993\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999964\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "0 0.9999993\n",
            "1 0.9994936\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999994\n",
            "0 0.81812966\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 0.99999475\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999995\n",
            "1 0.99999404\n",
            "0 0.9999987\n",
            "1 0.9999442\n",
            "1 1.0\n",
            "1 0.99999964\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 0.99999964\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.9977616\n",
            "1 1.0\n",
            "1 0.99626726\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99999166\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 0.9999999\n",
            "0 0.99999833\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99999964\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 1.0\n",
            "1 1.0\n",
            "1 0.79932016\n",
            "1 0.9998801\n",
            "1 0.5104001\n",
            "1 0.6135826\n",
            "1 0.9999994\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 0.9999999\n",
            "0 0.99944466\n",
            "0 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99228436\n",
            "0 0.9435616\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 0.9999975\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "0 0.99286604\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99999976\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.9999143\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999411\n",
            "0 0.9714565\n",
            "1 0.99999976\n",
            "1 0.9999728\n",
            "1 0.99999976\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99999976\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999628\n",
            "0 1.0\n",
            "1 0.999992\n",
            "1 0.99293983\n",
            "1 0.793786\n",
            "1 0.9999902\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.999997\n",
            "0 0.99985886\n",
            "1 1.0\n",
            "1 0.99999714\n",
            "1 0.84571236\n",
            "1 0.9996667\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99993193\n",
            "0 1.0\n",
            "1 1.0\n",
            "1 0.9996076\n",
            "1 1.0\n",
            "1 0.99999046\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999739\n",
            "1 1.0\n",
            "1 0.99999046\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99999976\n",
            "0 0.7147289\n",
            "1 0.99999964\n",
            "1 0.620194\n",
            "1 1.0\n",
            "1 0.998863\n",
            "0 0.9933333\n",
            "1 0.9999845\n",
            "1 0.99967575\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.9999937\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 0.99999976\n",
            "1 1.0\n",
            "1 0.9983089\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99998534\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9985435\n",
            "1 1.0\n",
            "1 0.9998944\n",
            "1 0.99997663\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "0 0.9999999\n",
            "1 0.9992206\n",
            "1 0.99999154\n",
            "1 0.99940026\n",
            "1 1.0\n",
            "1 0.99999976\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99999964\n",
            "1 0.9999883\n",
            "1 0.999995\n",
            "1 1.0\n",
            "1 0.99985254\n",
            "1 1.0\n",
            "1 0.99999964\n",
            "1 0.9999511\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.99999523\n",
            "1 1.0\n",
            "1 0.99999857\n",
            "1 1.0\n",
            "1 0.9999894\n",
            "1 1.0\n",
            "1 0.99999976\n",
            "1 0.9998078\n",
            "1 1.0\n",
            "1 0.99995005\n",
            "0 0.9712035\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.9999689\n",
            "1 0.99999523\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.9995353\n",
            "0 0.9900692\n",
            "1 0.99999976\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99999356\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.78444886\n",
            "1 0.99999964\n",
            "1 1.0\n",
            "1 0.99993813\n",
            "1 0.99999607\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99999297\n",
            "0 0.9958605\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99500966\n",
            "1 0.9999987\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 0.9999995\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 0.9999801\n",
            "0 0.99999774\n",
            "1 0.9999999\n",
            "1 0.99995446\n",
            "1 0.99995756\n",
            "1 1.0\n",
            "1 0.9999305\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.999984\n",
            "0 0.9999906\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.67025656\n",
            "0 0.99947125\n",
            "1 0.99999964\n",
            "1 0.99997985\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 0.99195415\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999479\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9866615\n",
            "1 1.0\n",
            "1 0.9999167\n",
            "1 1.0\n",
            "1 0.99722195\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 0.9999939\n",
            "0 0.99999857\n",
            "1 1.0\n",
            "1 0.99981874\n",
            "1 1.0\n",
            "1 0.99999976\n",
            "1 1.0\n",
            "1 0.99999964\n",
            "1 1.0\n",
            "1 0.99999833\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.999595\n",
            "1 0.99999857\n",
            "1 0.9999994\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999995\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.999995\n",
            "1 0.99996984\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999051\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.9997831\n",
            "1 0.9999995\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.999998\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.99999106\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99997306\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99999964\n",
            "1 0.99999857\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "0 0.42343444\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999994\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99999964\n",
            "1 1.0\n",
            "0 0.99999535\n",
            "1 0.9999999\n",
            "1 0.9999999\n",
            "1 0.99999785\n",
            "1 0.9999999\n",
            "1 0.9999999\n",
            "0 0.99320483\n",
            "1 0.9999964\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "0 0.9999963\n",
            "1 1.0\n",
            "1 0.99999046\n",
            "1 0.8993584\n",
            "1 1.0\n",
            "1 0.999992\n",
            "1 1.0\n",
            "1 0.79758793\n",
            "1 0.99998164\n",
            "1 0.9999887\n",
            "1 0.9999937\n",
            "1 1.0\n",
            "0 0.9999964\n",
            "0 0.49458355\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99981135\n",
            "1 0.72237694\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 0.9920555\n",
            "1 1.0\n",
            "1 0.99999785\n",
            "1 1.0\n",
            "1 0.8370219\n",
            "0 0.9910314\n",
            "1 0.999998\n",
            "1 0.9999857\n",
            "1 1.0\n",
            "1 0.9999994\n",
            "1 1.0\n",
            "1 0.99997926\n",
            "0 0.9942029\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999988\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.99999833\n",
            "1 0.99999976\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 1.0\n",
            "1 0.99999964\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999938\n",
            "1 1.0\n",
            "0 0.999019\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.99996567\n",
            "1 0.99994314\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.9999852\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99999964\n",
            "1 0.9999981\n",
            "1 1.0\n",
            "1 0.9999454\n",
            "1 1.0\n",
            "0 1.0\n",
            "1 0.99994266\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99994874\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 0.99999917\n",
            "0 0.6486671\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.5398694\n",
            "1 1.0\n",
            "1 0.9999776\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.9999987\n",
            "1 1.0\n",
            "0 0.9999795\n",
            "1 1.0\n",
            "1 0.9999912\n",
            "1 0.9999995\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.99993193\n",
            "1 1.0\n",
            "1 0.9999994\n",
            "1 1.0\n",
            "1 0.99999917\n",
            "0 0.815805\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99999917\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999993\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "0 0.98082167\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99997616\n",
            "1 1.0\n",
            "1 0.9999993\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.9878655\n",
            "1 0.99999976\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999994\n",
            "0 0.999998\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999987\n",
            "0 0.41328624\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999957\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99999917\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999968\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999888\n",
            "1 1.0\n",
            "1 0.99999094\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99999917\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.99999416\n",
            "0 0.9955243\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.9999982\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 0.99999416\n",
            "1 0.99999964\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.99932265\n",
            "1 1.0\n",
            "1 0.9999994\n",
            "1 1.0\n",
            "0 0.99283266\n",
            "1 1.0\n",
            "1 0.99999976\n",
            "1 0.99999666\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99999833\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.999895\n",
            "0 0.99991596\n",
            "0 0.56956893\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "0 0.99998784\n",
            "1 0.99999964\n",
            "1 1.0\n",
            "1 0.9999796\n",
            "1 0.9999993\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99947125\n",
            "1 0.99989736\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999989\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.9999975\n",
            "1 0.99999905\n",
            "1 0.9999999\n",
            "0 0.99953306\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999887\n",
            "1 0.9999981\n",
            "0 0.9826119\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9997675\n",
            "1 0.9999999\n",
            "0 0.99694484\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.999992\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999995\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99999976\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.99880207\n",
            "1 0.9999274\n",
            "1 0.9998072\n",
            "1 1.0\n",
            "0 0.9999887\n",
            "1 0.9999999\n",
            "0 0.99771106\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.9999732\n",
            "0 0.9999999\n",
            "1 1.0\n",
            "1 0.9999987\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.99944085\n",
            "1 1.0\n",
            "1 0.9999994\n",
            "0 0.9999974\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99999976\n",
            "1 1.0\n",
            "0 0.99798787\n",
            "1 0.9999682\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99999964\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.99366075\n",
            "1 1.0\n",
            "1 0.99998796\n",
            "1 0.99999917\n",
            "1 1.0\n",
            "1 0.9999968\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 0.99992836\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.99999857\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.9834615\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.8818723\n",
            "1 1.0\n",
            "1 0.99999964\n",
            "1 1.0\n",
            "1 0.99999845\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.9998745\n",
            "1 0.9999988\n",
            "1 0.9999999\n",
            "1 0.9999856\n",
            "1 0.9999999\n",
            "1 0.9999857\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999938\n",
            "1 0.9999938\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99999607\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99999976\n",
            "0 0.999884\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.9999995\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.995811\n",
            "0 0.9637562\n",
            "1 0.9999912\n",
            "1 0.9999993\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99991393\n",
            "0 0.9999999\n",
            "1 0.99999976\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.7677053\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.54188544\n",
            "1 0.9997651\n",
            "1 1.0\n",
            "1 0.99963546\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99626046\n",
            "0 0.9884538\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.73279995\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99999976\n",
            "1 0.99999774\n",
            "1 0.9620702\n",
            "1 0.99999905\n",
            "1 0.99999654\n",
            "1 1.0\n",
            "1 0.9999982\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99999905\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999815\n",
            "0 0.9999995\n",
            "0 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 0.9998449\n",
            "1 0.9999994\n",
            "1 0.99999475\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9911116\n",
            "0 0.9999145\n",
            "1 1.0\n",
            "1 0.999959\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99969053\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.99556077\n",
            "1 0.9999974\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99999964\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99965096\n",
            "0 0.9999889\n",
            "1 0.99999654\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99999857\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999924\n",
            "0 0.6272923\n",
            "1 0.99999964\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999981\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 0.99999976\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99999285\n",
            "1 0.99997973\n",
            "0 0.9999937\n",
            "1 0.99999976\n",
            "1 1.0\n",
            "1 0.99999976\n",
            "1 0.9999994\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99999964\n",
            "1 0.67920387\n",
            "1 0.9996612\n",
            "0 0.9999993\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99999917\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99999964\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 0.99999845\n",
            "1 0.9999989\n",
            "1 1.0\n",
            "1 0.99999845\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.993274\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.9999114\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.99978155\n",
            "1 1.0\n",
            "1 0.99999976\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999976\n",
            "1 0.9999999\n",
            "1 0.9999906\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999267\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999938\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.9995715\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.99996674\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.999998\n",
            "1 1.0\n",
            "0 0.7302845\n",
            "1 0.99999475\n",
            "1 1.0\n",
            "1 0.99991965\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.99987614\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.957766\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999902\n",
            "1 1.0\n",
            "1 0.9999765\n",
            "0 0.7427953\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99999297\n",
            "0 0.99766004\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99999654\n",
            "1 0.99991834\n",
            "1 1.0\n",
            "1 0.5384135\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 0.9999732\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999473\n",
            "1 1.0\n",
            "1 0.99999845\n",
            "1 1.0\n",
            "1 0.99999666\n",
            "1 1.0\n",
            "0 0.9994604\n",
            "0 0.76985985\n",
            "1 0.9999999\n",
            "0 0.9999963\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 0.99999976\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.98584753\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.56350046\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.9998203\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.999985\n",
            "0 0.99999905\n",
            "1 0.9999429\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999993\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9895197\n",
            "1 0.9701217\n",
            "1 0.9999987\n",
            "1 0.99994576\n",
            "1 1.0\n",
            "1 0.9999987\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.9315734\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 0.99999654\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.9994579\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999989\n",
            "0 0.72279805\n",
            "1 0.99999976\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 0.9999989\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "0 0.99999\n",
            "0 0.99999654\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99999964\n",
            "1 1.0\n",
            "0 0.9388447\n",
            "0 0.96818817\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999993\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999993\n",
            "1 0.9999858\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.96887356\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99999213\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.8692265\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 0.96855795\n",
            "1 1.0\n",
            "1 0.9999995\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999875\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 0.99996877\n",
            "1 1.0\n",
            "0 0.9999919\n",
            "1 0.9999981\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99999976\n",
            "1 0.99999976\n",
            "0 0.9999863\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99999976\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.99987364\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.999997\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9997385\n",
            "1 1.0\n",
            "0 0.9999995\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999964\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 1.0\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99999976\n",
            "0 1.0\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.9999976\n",
            "1 0.99999917\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99999213\n",
            "1 0.99999976\n",
            "1 0.99997723\n",
            "0 0.9783276\n",
            "1 0.99999976\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9993629\n",
            "1 1.0\n",
            "0 1.0\n",
            "1 1.0\n",
            "1 0.99999964\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 0.99999917\n",
            "0 0.990562\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.9972608\n",
            "0 0.9999999\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9983254\n",
            "1 0.9999995\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "0 0.999948\n",
            "1 0.9999583\n",
            "0 1.0\n",
            "1 1.0\n",
            "0 0.9998666\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 0.9999993\n",
            "1 0.9999999\n",
            "1 0.99999094\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99996805\n",
            "1 0.9999994\n",
            "1 0.9999995\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999995\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99999356\n",
            "1 0.99999905\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 1.0\n",
            "1 0.99999905\n",
            "1 0.9999876\n",
            "1 0.99998593\n",
            "1 0.9967906\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999995\n",
            "1 1.0\n",
            "1 0.98657495\n",
            "0 0.99899167\n",
            "1 0.9999999\n",
            "1 0.9999963\n",
            "1 0.9999999\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9973416\n",
            "1 1.0\n",
            "1 0.99998355\n",
            "0 0.62931806\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9992349\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9955781\n",
            "1 0.9999999\n",
            "0 0.999418\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 0.9999943\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 0.99999845\n",
            "0 1.0\n",
            "0 0.9832932\n",
            "1 1.0\n",
            "1 0.9994605\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99999976\n",
            "1 1.0\n",
            "1 0.99999917\n",
            "1 0.9999032\n",
            "1 0.9937297\n",
            "1 0.9996051\n",
            "1 0.99930155\n",
            "1 0.99975246\n",
            "0 0.72595835\n",
            "1 1.0\n",
            "1 0.60501647\n",
            "1 1.0\n",
            "1 0.99999774\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99999917\n",
            "1 0.99999917\n",
            "1 0.99685895\n",
            "0 0.9914892\n",
            "1 0.9999169\n",
            "1 0.998938\n",
            "1 1.0\n",
            "1 0.99999785\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9998305\n",
            "1 1.0\n",
            "1 0.997969\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99999607\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 0.999744\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999801\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99699664\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 1.0\n",
            "1 1.0\n",
            "1 0.99933535\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99999976\n",
            "1 0.9994235\n",
            "1 0.99999964\n",
            "1 0.9998442\n",
            "1 0.9999988\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9994618\n",
            "1 1.0\n",
            "0 0.9982728\n",
            "1 0.99999905\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999249\n",
            "1 0.9999435\n",
            "1 0.9999546\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999939\n",
            "0 0.9841174\n",
            "1 0.9999993\n",
            "1 0.99999535\n",
            "1 0.9999995\n",
            "1 0.9262315\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999938\n",
            "1 1.0\n",
            "1 0.55762637\n",
            "0 0.43208024\n",
            "1 0.9999989\n",
            "1 0.99999964\n",
            "1 1.0\n",
            "1 0.9045554\n",
            "1 0.9999759\n",
            "1 0.54140794\n",
            "1 0.999997\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.9672985\n",
            "1 0.99997985\n",
            "0 0.992857\n",
            "0 0.8265296\n",
            "1 1.0\n",
            "1 0.9996953\n",
            "1 0.99999833\n",
            "1 0.9859282\n",
            "1 0.99940896\n",
            "1 0.99999464\n",
            "1 0.99999726\n",
            "1 0.9989918\n",
            "1 0.99998474\n",
            "1 0.9999218\n",
            "1 0.99998367\n",
            "1 0.9988188\n",
            "0 0.5220543\n",
            "0 0.9233302\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.999498\n",
            "1 0.9997081\n",
            "1 0.9999981\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99999976\n",
            "1 1.0\n",
            "1 0.99999976\n",
            "1 1.0\n",
            "1 0.9999976\n",
            "1 1.0\n",
            "0 0.99998665\n",
            "1 0.8819144\n",
            "1 1.0\n",
            "0 0.7021068\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9304785\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9391923\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99999976\n",
            "1 0.9999908\n",
            "0 0.73635703\n",
            "1 1.0\n",
            "1 0.99840134\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999995\n",
            "1 0.98327947\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.98851645\n",
            "0 0.9598387\n",
            "0 0.9713921\n",
            "1 0.99999976\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9142289\n",
            "1 0.9999999\n",
            "1 0.9999943\n",
            "1 1.0\n",
            "1 0.99996567\n",
            "1 1.0\n",
            "1 0.9850684\n",
            "1 0.9999995\n",
            "1 0.9219665\n",
            "1 0.9999877\n",
            "1 1.0\n",
            "1 0.99986124\n",
            "0 0.9997719\n",
            "1 1.0\n",
            "1 0.99985194\n",
            "1 1.0\n",
            "1 0.9987852\n",
            "1 0.9321893\n",
            "1 1.0\n",
            "1 0.9999968\n",
            "1 1.0\n",
            "1 0.9999727\n",
            "0 0.9999999\n",
            "1 1.0\n",
            "1 0.99998283\n",
            "1 1.0\n",
            "1 0.999966\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999968\n",
            "1 1.0\n",
            "1 0.9994118\n",
            "0 0.5520863\n",
            "1 1.0\n",
            "1 0.9999453\n",
            "1 1.0\n",
            "1 0.9991997\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999778\n",
            "1 1.0\n",
            "1 0.99954957\n",
            "1 0.99999976\n",
            "1 0.99701667\n",
            "1 1.0\n",
            "1 0.99999976\n",
            "1 0.8372998\n",
            "0 0.99247885\n",
            "1 0.9995627\n",
            "1 0.9999714\n",
            "1 1.0\n",
            "1 0.99988425\n",
            "1 0.99958426\n",
            "1 0.997809\n",
            "1 0.9999993\n",
            "1 0.9999895\n",
            "1 1.0\n",
            "1 0.9710786\n",
            "1 1.0\n",
            "1 0.9999993\n",
            "1 0.9999615\n",
            "0 0.9131206\n",
            "1 0.99896634\n",
            "1 0.92417705\n",
            "1 1.0\n",
            "0 0.9500019\n",
            "1 0.9997185\n",
            "1 1.0\n",
            "1 0.9999995\n",
            "0 0.9808348\n",
            "1 0.9998963\n",
            "0 0.64650667\n",
            "1 0.93861914\n",
            "1 0.9999988\n",
            "1 0.99940634\n",
            "1 0.9999683\n",
            "1 0.9958728\n",
            "1 0.99999094\n",
            "1 0.9999895\n",
            "1 0.9999993\n",
            "1 1.0\n",
            "1 0.99999464\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99775606\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999994\n",
            "1 0.99992037\n",
            "1 1.0\n",
            "1 0.9991755\n",
            "1 0.9999995\n",
            "1 0.9999999\n",
            "1 0.99999094\n",
            "1 1.0\n",
            "1 0.99999475\n",
            "1 0.9998964\n",
            "1 1.0\n",
            "0 0.98422575\n",
            "1 0.8989488\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999993\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "0 0.88815737\n",
            "0 0.99141496\n",
            "1 1.0\n",
            "1 0.9999964\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999776\n",
            "0 0.6125554\n",
            "1 0.9999999\n",
            "1 0.6042263\n",
            "1 1.0\n",
            "1 0.9999976\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99999976\n",
            "1 1.0\n",
            "0 0.47222662\n",
            "1 1.0\n",
            "1 0.9999995\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.99993265\n",
            "1 1.0\n",
            "1 0.9956032\n",
            "1 0.9998871\n",
            "1 0.99999917\n",
            "1 0.9994548\n",
            "1 0.99998295\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.999645\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 0.99999964\n",
            "1 0.94616276\n",
            "1 0.99966466\n",
            "1 0.99934226\n",
            "1 1.0\n",
            "1 0.9999943\n",
            "1 0.99999964\n",
            "1 0.9999994\n",
            "1 0.9999999\n",
            "1 0.9999951\n",
            "1 1.0\n",
            "1 0.9999951\n",
            "0 0.99999976\n",
            "1 1.0\n",
            "1 0.99999976\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.999997\n",
            "1 0.9593377\n",
            "1 1.0\n",
            "1 0.9999976\n",
            "1 1.0\n",
            "1 0.99999845\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99999785\n",
            "1 0.9999999\n",
            "0 0.46240252\n",
            "1 0.9999988\n",
            "1 0.9997948\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999714\n",
            "1 0.99999833\n",
            "1 1.0\n",
            "1 0.9997968\n",
            "1 0.99967015\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 0.9999999\n",
            "0 0.83840245\n",
            "1 0.99999976\n",
            "1 1.0\n",
            "1 0.9999988\n",
            "1 0.72873485\n",
            "1 0.99998486\n",
            "0 0.9882734\n",
            "1 0.9999999\n",
            "1 0.9999995\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99995196\n",
            "1 0.98807156\n",
            "1 0.99999917\n",
            "1 0.9997304\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "0 0.8619003\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999993\n",
            "0 0.99904364\n",
            "1 0.99999976\n",
            "1 0.9999708\n",
            "1 0.9967397\n",
            "1 0.9994217\n",
            "1 0.99998045\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999944\n",
            "0 0.9981572\n",
            "1 1.0\n",
            "1 0.99999976\n",
            "1 1.0\n",
            "1 0.9999994\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99999774\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.98655814\n",
            "1 1.0\n",
            "1 0.9999994\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999994\n",
            "1 1.0\n",
            "0 0.5072596\n",
            "1 0.9999987\n",
            "1 0.99999917\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.99944407\n",
            "1 1.0\n",
            "1 0.99981636\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 0.9999999\n",
            "1 0.9997954\n",
            "0 0.6192361\n",
            "1 1.0\n",
            "1 1.0\n",
            "0 0.9487977\n",
            "0 0.9712281\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.99999976\n",
            "1 0.9999919\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "0 0.77016246\n",
            "1 1.0\n",
            "0 0.999949\n",
            "1 0.99999845\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999987\n",
            "1 0.9999956\n",
            "1 0.9999993\n",
            "1 0.99999976\n",
            "1 1.0\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9947968\n",
            "0 0.64609367\n",
            "1 0.9999999\n",
            "1 0.9999654\n",
            "1 1.0\n",
            "1 0.99998045\n",
            "1 1.0\n",
            "1 1.0\n",
            "1 0.9999995\n",
            "1 1.0\n",
            "1 0.9999993\n",
            "0 0.999833\n",
            "1 0.9999999\n",
            "1 1.0\n",
            "1 0.99999964\n",
            "1 0.9999988\n",
            "1 1.0\n",
            "1 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wtovbiPWGVaq",
        "outputId": "31f04fe0-7def-4c88-e700-c0bb39547e51"
      },
      "source": [
        "print('For 0 as anomaly')\n",
        "y_true, y_sm = get_bl_sm(class_0, 0)\n",
        "a0 = roc_auc_score(y_true, y_sm)\n",
        "print('AUROC: ', a0)\n",
        "\n",
        "print('-------------------')\n",
        "\n",
        "print('For 1 as anomaly')\n",
        "y_true, y_sm = get_bl_sm(class_1, 1)\n",
        "a1 = roc_auc_score(y_true, y_sm)\n",
        "print('AUROC: ', a1)\n",
        "\n",
        "print('-------------------')\n",
        "\n",
        "print('For 2 as anomaly')\n",
        "y_true, y_sm = get_bl_sm(class_2, 2)\n",
        "a2 = roc_auc_score(y_true, y_sm)\n",
        "print('AUROC: ', a2)\n",
        "\n",
        "print('-------------------')\n",
        "\n",
        "print('For 3 as anomaly')\n",
        "y_true, y_sm = get_bl_sm(class_3, 3)\n",
        "a3 = roc_auc_score(y_true, y_sm)\n",
        "print('AUROC: ', a3)\n",
        "\n",
        "print('-------------------')\n",
        "\n",
        "print('For 4 as anomaly')\n",
        "y_true, y_sm = get_bl_sm(class_4, 4)\n",
        "a4 = roc_auc_score(y_true, y_sm)\n",
        "print('AUROC: ', a4)\n",
        "\n",
        "print('-------------------')\n",
        "\n",
        "print('For 5 as anomaly')\n",
        "y_true, y_sm = get_bl_sm(class_5, 5)\n",
        "a5 = roc_auc_score(y_true, y_sm)\n",
        "print('AUROC: ', a5)\n",
        "\n",
        "print('-------------------')\n",
        "\n",
        "print('For 6 as anomaly')\n",
        "y_true, y_sm = get_bl_sm(class_6, 6)\n",
        "a6 = roc_auc_score(y_true, y_sm)\n",
        "print('AUROC: ', a6)\n",
        "\n",
        "print('-------------------')\n",
        "\n",
        "print('For 7 as anomaly')\n",
        "y_true, y_sm = get_bl_sm(class_7, 7)\n",
        "a7 = roc_auc_score(y_true, y_sm)\n",
        "print('AUROC: ', a7)\n",
        "\n",
        "print('-------------------')\n",
        "\n",
        "print('For 8 as anomaly')\n",
        "y_true, y_sm = get_bl_sm(class_8, 8)\n",
        "a8 = roc_auc_score(y_true, y_sm)\n",
        "print('AUROC: ', a8)\n",
        "\n",
        "print('-------------------')\n",
        "\n",
        "print('For 9 as anomaly')\n",
        "y_true, y_sm = get_bl_sm(class_9, 9)\n",
        "a9 = roc_auc_score(y_true, y_sm)\n",
        "print('AUROC: ', a9)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7it [00:00, 66.49it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "For 0 as anomaly\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "10000it [02:18, 72.43it/s]\n",
            "8it [00:00, 74.27it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "AUROC:  0.8521517941988326\n",
            "-------------------\n",
            "For 1 as anomaly\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "10000it [02:18, 71.99it/s]\n",
            "7it [00:00, 68.48it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "AUROC:  0.9860681639174003\n",
            "-------------------\n",
            "For 2 as anomaly\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "10000it [02:18, 72.06it/s]\n",
            "8it [00:00, 71.28it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "AUROC:  0.9083203997503613\n",
            "-------------------\n",
            "For 3 as anomaly\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "10000it [02:18, 72.18it/s]\n",
            "7it [00:00, 67.01it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "AUROC:  0.9341155188933798\n",
            "-------------------\n",
            "For 4 as anomaly\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "10000it [02:17, 72.81it/s]\n",
            "7it [00:00, 69.04it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "AUROC:  0.8360977750315166\n",
            "-------------------\n",
            "For 5 as anomaly\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "10000it [02:18, 71.98it/s]\n",
            "7it [00:00, 68.88it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "AUROC:  0.926282898688582\n",
            "-------------------\n",
            "For 6 as anomaly\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "10000it [02:20, 71.31it/s]\n",
            "8it [00:00, 73.65it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "AUROC:  0.8581720701213866\n",
            "-------------------\n",
            "For 7 as anomaly\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "10000it [02:19, 71.47it/s]\n",
            "7it [00:00, 68.52it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "AUROC:  0.8219270263214047\n",
            "-------------------\n",
            "For 8 as anomaly\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "10000it [02:17, 72.50it/s]\n",
            "8it [00:00, 75.08it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "AUROC:  0.7536742474739868\n",
            "-------------------\n",
            "For 9 as anomaly\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "10000it [02:18, 72.23it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "AUROC:  0.9370816692697543\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8s2JPZhgcCqX",
        "outputId": "09a330cc-38b5-4197-f4b4-8382e5a3ac65"
      },
      "source": [
        "len(y_true), len(y_sm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 10000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgwjUw-9CCQ8"
      },
      "source": [
        "pickle_out = open(\"sm_all_wt_0an.pickle\",\"wb\")\n",
        "pickle.dump(max_sm_all_wt_0an, pickle_out)\n",
        "pickle_out.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLdj_3IbCCQ9"
      },
      "source": [
        "pickle_in = open(\"sm_all_wt_0an.pickle\",\"rb\")\n",
        "max_sm_all_wt_0an = pickle.load(pickle_in)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "icdn3IMxBjwc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8WZeBI5WBjmH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmne2UHmGMZH"
      },
      "source": [
        "# 0 as anomaly"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FktFwBdgGLyV"
      },
      "source": [
        "new_train_images, new_train_labels, new_val_images, new_val_labels = separate_class(0, train_images, train_labels, val_images, val_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jdxoel9UGc97"
      },
      "source": [
        "model0 = Model(name='0anomaly:classifier0')\n",
        "model1 = Model(name='0anomaly:classifier1')\n",
        "model2 = Model(name='0anomaly:classifier2')\n",
        "model3 = Model(name='0anomaly:classifier3')\n",
        "model4 = Model(name='0anomaly:classifier4')\n",
        "model5 = Model(name='0anomaly:classifier5')\n",
        "model6 = Model(name='0anomaly:classifier6')\n",
        "model7 = Model(name='0anomaly:classifier7')\n",
        "model8 = Model(name='0anomaly:classifier8')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRef6um6Gug0"
      },
      "source": [
        "class_0 = model0.build()\n",
        "class_1 = model1.build()\n",
        "class_2 = model2.build()\n",
        "class_3 = model3.build()\n",
        "class_4 = model4.build()\n",
        "class_5 = model5.build()\n",
        "class_6 = model6.build()\n",
        "class_7 = model7.build()\n",
        "class_8 = model8.build()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XfjOrG5yHaZk",
        "outputId": "2cdc8dc3-8df5-46fb-ee9f-d15c0d8c5d77"
      },
      "source": [
        "set(new_train_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{1, 2, 3, 4, 5, 6, 7, 8, 9}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2WXk27zOGycC",
        "outputId": "6d71ae83-d75e-4ea8-fac4-e1fb94c8f72f"
      },
      "source": [
        "train_imgs0, train_lbls0 = get_train_data(1, new_train_images, new_train_labels)\n",
        "val_imgs0, val_lbls0 = get_train_data(1, new_val_images, new_val_labels)\n",
        "class_0 = model0.build()\n",
        "model0.train2(train_imgs0, train_lbls0, val_imgs0, val_lbls0)\n",
        "#model0.train(train_data0)\n",
        "model0.save_model(\"final_models/0anomaly-classifier0\")\n",
        "print('Model 0 saved')\n",
        "\n",
        "train_imgs1, train_lbls1 = get_train_data(2, new_train_images, new_train_labels)\n",
        "val_imgs1, val_lbls1 = get_train_data(2, new_val_images, new_val_labels)\n",
        "class_1 = model1.build()\n",
        "model1.train2(train_imgs1, train_lbls1, val_imgs1, val_lbls1)\n",
        "#model1.train(train_data1)\n",
        "model1.save_model(\"final_models/0anomaly-classifier1\")\n",
        "print('Model 1 saved')\n",
        "\n",
        "#train_data2 = get_train_data(2, new_train_images)\n",
        "train_imgs2, train_lbls2 = get_train_data(3, new_train_images, new_train_labels)\n",
        "val_imgs2, val_lbls2 = get_train_data(3, new_val_images, new_val_labels)\n",
        "class_2 = model2.build()\n",
        "model2.train2(train_imgs2, train_lbls2, val_imgs2, val_lbls2)\n",
        "#model2.train(train_data2)\n",
        "model2.save_model(\"final_models/0anomaly-classifier2\")\n",
        "print('Model 2 saved')\n",
        "\n",
        "#train_data3 = get_train_data(3, new_train_images)\n",
        "train_imgs3, train_lbls3 = get_train_data(4, new_train_images, new_train_labels)\n",
        "val_imgs3, val_lbls3 = get_train_data(4, new_val_images, new_val_labels)\n",
        "class_3 = model3.build()\n",
        "model3.train2(train_imgs3, train_lbls3, val_imgs3, val_lbls3)\n",
        "#model3.train(train_data3)\n",
        "model3.save_model(\"final_models/0anomaly-classifier3\")\n",
        "print('Model 3 saved')\n",
        "\n",
        "#train_data4 = get_train_data(4, new_train_images)\n",
        "train_imgs4, train_lbls4 = get_train_data(5, new_train_images, new_train_labels)\n",
        "val_imgs4, val_lbls4 = get_train_data(5, new_val_images, new_val_labels)\n",
        "class_4 = model4.build()\n",
        "model4.train2(train_imgs4, train_lbls4, val_imgs4, val_lbls4)\n",
        "#model4.train(train_data4)\n",
        "model4.save_model(\"final_models/0anomaly-classifier4\")\n",
        "print('Model 4 saved')\n",
        "\n",
        "#train_data5 = get_train_data(5, new_train_images)\n",
        "train_imgs5, train_lbls5 = get_train_data(6, new_train_images, new_train_labels)\n",
        "val_imgs5, val_lbls5 = get_train_data(6, new_val_images, new_val_labels)\n",
        "class_5 = model5.build()\n",
        "model5.train2(train_imgs5, train_lbls5, val_imgs5, val_lbls5)\n",
        "#model5.train(train_data5)\n",
        "model5.save_model(\"final_models/0anomaly-classifier5\")\n",
        "print('Model 5 saved')\n",
        "\n",
        "#train_data6 = get_train_data(6, new_train_images)\n",
        "train_imgs6, train_lbls6 = get_train_data(7, new_train_images, new_train_labels)\n",
        "val_imgs6, val_lbls6 = get_train_data(7, new_val_images, new_val_labels)\n",
        "class_6 = model6.build()\n",
        "model6.train2(train_imgs6, train_lbls6, val_imgs6, val_lbls6)\n",
        "#model6.train(train_data6)\n",
        "model6.save_model(\"final_models/0anomaly-classifier6\")\n",
        "print('Model 6 saved')\n",
        "\n",
        "#train_data7 = get_train_data(7, new_train_images)\n",
        "train_imgs7, train_lbls7 = get_train_data(8, new_train_images, new_train_labels)\n",
        "val_imgs7, val_lbls7 = get_train_data(8, new_val_images, new_val_labels)\n",
        "class_7 = model7.build()\n",
        "#model7.train(train_data7)\n",
        "model7.train2(train_imgs7, train_lbls7, val_imgs7, val_lbls7)\n",
        "model7.save_model(\"final_models/0anomaly-classifier7\")\n",
        "print('Model 7 saved')\n",
        "\n",
        "#train_data8 = get_train_data(8, new_train_images)\n",
        "train_imgs8, train_lbls8 = get_train_data(9, new_train_images, new_train_labels)\n",
        "val_imgs8, val_lbls8 = get_train_data(9, new_val_images, new_val_labels)\n",
        "class_8 = model8.build()\n",
        "#model8.train(train_data8)\n",
        "model8.train2(train_imgs8, train_lbls8, val_imgs8, val_lbls8)\n",
        "model8.save_model(\"final_models/0anomaly-classifier8\")\n",
        "print('Model 8 saved')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{2: 0, 3: 1, 4: 2, 5: 3, 6: 4, 7: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(37832,)\n",
            "{2: 0, 3: 1, 4: 2, 5: 3, 6: 4, 7: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9503,)\n",
            "Epoch 1/20\n",
            "1183/1183 [==============================] - 37s 31ms/step - loss: 5.3148 - accuracy: 0.7415 - val_loss: 0.7003 - val_accuracy: 0.9368\n",
            "Epoch 2/20\n",
            "1183/1183 [==============================] - 36s 31ms/step - loss: 0.1938 - accuracy: 0.9551 - val_loss: 1.0786 - val_accuracy: 0.9144\n",
            "Epoch 3/20\n",
            "1183/1183 [==============================] - 37s 31ms/step - loss: 0.1143 - accuracy: 0.9708 - val_loss: 0.1462 - val_accuracy: 0.9636\n",
            "Epoch 4/20\n",
            "1183/1183 [==============================] - 37s 31ms/step - loss: 0.0951 - accuracy: 0.9747 - val_loss: 0.2603 - val_accuracy: 0.9512\n",
            "Epoch 5/20\n",
            "1183/1183 [==============================] - 37s 32ms/step - loss: 0.0732 - accuracy: 0.9776 - val_loss: 0.0987 - val_accuracy: 0.9764\n",
            "Epoch 6/20\n",
            "1183/1183 [==============================] - 38s 32ms/step - loss: 0.0584 - accuracy: 0.9822 - val_loss: 0.1660 - val_accuracy: 0.9606\n",
            "Epoch 7/20\n",
            "1183/1183 [==============================] - 38s 32ms/step - loss: 0.0516 - accuracy: 0.9838 - val_loss: 0.0793 - val_accuracy: 0.9796\n",
            "Epoch 8/20\n",
            "1183/1183 [==============================] - 38s 32ms/step - loss: 0.0530 - accuracy: 0.9843 - val_loss: 0.1198 - val_accuracy: 0.9690\n",
            "Epoch 9/20\n",
            "1183/1183 [==============================] - 37s 32ms/step - loss: 0.0469 - accuracy: 0.9863 - val_loss: 0.0970 - val_accuracy: 0.9757\n",
            "Epoch 10/20\n",
            "1183/1183 [==============================] - 38s 32ms/step - loss: 0.0454 - accuracy: 0.9856 - val_loss: 0.1518 - val_accuracy: 0.9641\n",
            "Epoch 11/20\n",
            "1183/1183 [==============================] - 38s 32ms/step - loss: 0.0341 - accuracy: 0.9897 - val_loss: 0.1212 - val_accuracy: 0.9681\n",
            "Epoch 12/20\n",
            "1183/1183 [==============================] - 37s 32ms/step - loss: 0.0301 - accuracy: 0.9904 - val_loss: 0.0740 - val_accuracy: 0.9832\n",
            "Epoch 13/20\n",
            "1183/1183 [==============================] - 38s 32ms/step - loss: 0.0294 - accuracy: 0.9905 - val_loss: 0.0902 - val_accuracy: 0.9776\n",
            "Epoch 14/20\n",
            "1183/1183 [==============================] - 38s 32ms/step - loss: 0.0249 - accuracy: 0.9922 - val_loss: 0.1323 - val_accuracy: 0.9690\n",
            "Epoch 15/20\n",
            "1183/1183 [==============================] - 38s 32ms/step - loss: 0.0269 - accuracy: 0.9917 - val_loss: 0.0645 - val_accuracy: 0.9828\n",
            "Epoch 16/20\n",
            "1183/1183 [==============================] - 38s 32ms/step - loss: 0.0207 - accuracy: 0.9932 - val_loss: 0.0638 - val_accuracy: 0.9850\n",
            "Epoch 17/20\n",
            "1183/1183 [==============================] - 38s 32ms/step - loss: 0.0195 - accuracy: 0.9939 - val_loss: 0.1386 - val_accuracy: 0.9697\n",
            "Epoch 18/20\n",
            "1183/1183 [==============================] - 38s 32ms/step - loss: 0.0196 - accuracy: 0.9938 - val_loss: 0.1067 - val_accuracy: 0.9763\n",
            "Epoch 19/20\n",
            "1183/1183 [==============================] - 38s 32ms/step - loss: 0.0208 - accuracy: 0.9931 - val_loss: 0.1094 - val_accuracy: 0.9777\n",
            "Epoch 20/20\n",
            "1183/1183 [==============================] - 38s 32ms/step - loss: 0.0168 - accuracy: 0.9957 - val_loss: 0.0858 - val_accuracy: 0.9848\n",
            "INFO:tensorflow:Assets written to: final_models/0anomaly-classifier0/assets\n",
            "Model 0 saved\n",
            "{1: 0, 3: 1, 4: 2, 5: 3, 6: 4, 7: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(38468,)\n",
            "{1: 0, 3: 1, 4: 2, 5: 3, 6: 4, 7: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9651,)\n",
            "Epoch 1/20\n",
            "1203/1203 [==============================] - 40s 32ms/step - loss: 5.2200 - accuracy: 0.8271 - val_loss: 0.3387 - val_accuracy: 0.9488\n",
            "Epoch 2/20\n",
            "1203/1203 [==============================] - 38s 32ms/step - loss: 0.1762 - accuracy: 0.9708 - val_loss: 0.4048 - val_accuracy: 0.9110\n",
            "Epoch 3/20\n",
            "1203/1203 [==============================] - 38s 32ms/step - loss: 0.0775 - accuracy: 0.9796 - val_loss: 0.4326 - val_accuracy: 0.9074\n",
            "Epoch 4/20\n",
            "1203/1203 [==============================] - 38s 32ms/step - loss: 0.0597 - accuracy: 0.9825 - val_loss: 0.1644 - val_accuracy: 0.9599\n",
            "Epoch 5/20\n",
            "1203/1203 [==============================] - 38s 32ms/step - loss: 0.0589 - accuracy: 0.9828 - val_loss: 0.1284 - val_accuracy: 0.9653\n",
            "Epoch 6/20\n",
            "1203/1203 [==============================] - 38s 32ms/step - loss: 0.0591 - accuracy: 0.9817 - val_loss: 0.0997 - val_accuracy: 0.9742\n",
            "Epoch 7/20\n",
            "1203/1203 [==============================] - 38s 32ms/step - loss: 0.0509 - accuracy: 0.9847 - val_loss: 0.3686 - val_accuracy: 0.9321\n",
            "Epoch 8/20\n",
            "1203/1203 [==============================] - 38s 32ms/step - loss: 0.0553 - accuracy: 0.9833 - val_loss: 0.1524 - val_accuracy: 0.9622\n",
            "Epoch 9/20\n",
            "1203/1203 [==============================] - 38s 32ms/step - loss: 0.0443 - accuracy: 0.9857 - val_loss: 0.1079 - val_accuracy: 0.9740\n",
            "Epoch 10/20\n",
            "1203/1203 [==============================] - 38s 32ms/step - loss: 0.0411 - accuracy: 0.9874 - val_loss: 0.0886 - val_accuracy: 0.9789\n",
            "Epoch 11/20\n",
            "1203/1203 [==============================] - 38s 32ms/step - loss: 0.0363 - accuracy: 0.9885 - val_loss: 0.0928 - val_accuracy: 0.9752\n",
            "Epoch 12/20\n",
            "1203/1203 [==============================] - 38s 32ms/step - loss: 0.0293 - accuracy: 0.9911 - val_loss: 0.0867 - val_accuracy: 0.9794\n",
            "Epoch 13/20\n",
            "1203/1203 [==============================] - 38s 32ms/step - loss: 0.0296 - accuracy: 0.9909 - val_loss: 0.0588 - val_accuracy: 0.9854\n",
            "Epoch 14/20\n",
            "1203/1203 [==============================] - 38s 32ms/step - loss: 0.0341 - accuracy: 0.9888 - val_loss: 0.0678 - val_accuracy: 0.9844\n",
            "Epoch 15/20\n",
            "1203/1203 [==============================] - 38s 32ms/step - loss: 0.0227 - accuracy: 0.9922 - val_loss: 0.0645 - val_accuracy: 0.9860\n",
            "Epoch 16/20\n",
            "1203/1203 [==============================] - 38s 32ms/step - loss: 0.0227 - accuracy: 0.9929 - val_loss: 0.0833 - val_accuracy: 0.9775\n",
            "Epoch 17/20\n",
            "1203/1203 [==============================] - 38s 32ms/step - loss: 0.0230 - accuracy: 0.9924 - val_loss: 0.0835 - val_accuracy: 0.9804\n",
            "Epoch 18/20\n",
            "1203/1203 [==============================] - 38s 32ms/step - loss: 0.0184 - accuracy: 0.9940 - val_loss: 0.0601 - val_accuracy: 0.9855\n",
            "Epoch 19/20\n",
            "1203/1203 [==============================] - 38s 32ms/step - loss: 0.0199 - accuracy: 0.9933 - val_loss: 0.0598 - val_accuracy: 0.9877\n",
            "Epoch 20/20\n",
            "1203/1203 [==============================] - 38s 32ms/step - loss: 0.0173 - accuracy: 0.9945 - val_loss: 0.0843 - val_accuracy: 0.9813\n",
            "INFO:tensorflow:Assets written to: final_models/0anomaly-classifier1/assets\n",
            "Model 1 saved\n",
            "{1: 0, 2: 1, 4: 2, 5: 3, 6: 4, 7: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(38340,)\n",
            "{1: 0, 2: 1, 4: 2, 5: 3, 6: 4, 7: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9606,)\n",
            "Epoch 1/20\n",
            "1199/1199 [==============================] - 40s 32ms/step - loss: 4.7870 - accuracy: 0.8536 - val_loss: 0.3203 - val_accuracy: 0.9533\n",
            "Epoch 2/20\n",
            "1199/1199 [==============================] - 38s 32ms/step - loss: 0.1813 - accuracy: 0.9690 - val_loss: 0.1691 - val_accuracy: 0.9554\n",
            "Epoch 3/20\n",
            "1199/1199 [==============================] - 38s 32ms/step - loss: 0.0703 - accuracy: 0.9798 - val_loss: 0.0906 - val_accuracy: 0.9742\n",
            "Epoch 4/20\n",
            "1199/1199 [==============================] - 38s 32ms/step - loss: 0.0596 - accuracy: 0.9820 - val_loss: 0.1308 - val_accuracy: 0.9656\n",
            "Epoch 5/20\n",
            "1199/1199 [==============================] - 38s 32ms/step - loss: 0.0595 - accuracy: 0.9820 - val_loss: 0.1485 - val_accuracy: 0.9561\n",
            "Epoch 6/20\n",
            "1199/1199 [==============================] - 38s 32ms/step - loss: 0.0642 - accuracy: 0.9810 - val_loss: 0.1650 - val_accuracy: 0.9576\n",
            "Epoch 7/20\n",
            "1199/1199 [==============================] - 38s 32ms/step - loss: 0.0566 - accuracy: 0.9829 - val_loss: 0.1533 - val_accuracy: 0.9641\n",
            "Epoch 8/20\n",
            "1199/1199 [==============================] - 38s 32ms/step - loss: 0.0478 - accuracy: 0.9860 - val_loss: 0.1871 - val_accuracy: 0.9506\n",
            "Epoch 9/20\n",
            "1199/1199 [==============================] - 38s 32ms/step - loss: 0.0453 - accuracy: 0.9869 - val_loss: 0.0887 - val_accuracy: 0.9769\n",
            "Epoch 10/20\n",
            "1199/1199 [==============================] - 38s 32ms/step - loss: 0.0378 - accuracy: 0.9883 - val_loss: 0.1167 - val_accuracy: 0.9714\n",
            "Epoch 11/20\n",
            "1199/1199 [==============================] - 38s 32ms/step - loss: 0.0366 - accuracy: 0.9897 - val_loss: 0.1146 - val_accuracy: 0.9732\n",
            "Epoch 12/20\n",
            "1199/1199 [==============================] - 38s 32ms/step - loss: 0.0297 - accuracy: 0.9906 - val_loss: 0.1012 - val_accuracy: 0.9765\n",
            "Epoch 13/20\n",
            "1199/1199 [==============================] - 38s 32ms/step - loss: 0.0308 - accuracy: 0.9900 - val_loss: 0.0748 - val_accuracy: 0.9819\n",
            "Epoch 14/20\n",
            "1199/1199 [==============================] - 38s 32ms/step - loss: 0.0228 - accuracy: 0.9924 - val_loss: 0.0628 - val_accuracy: 0.9826\n",
            "Epoch 15/20\n",
            "1199/1199 [==============================] - 38s 32ms/step - loss: 0.0330 - accuracy: 0.9908 - val_loss: 0.0715 - val_accuracy: 0.9822\n",
            "Epoch 16/20\n",
            "1199/1199 [==============================] - 38s 32ms/step - loss: 0.0211 - accuracy: 0.9936 - val_loss: 0.0941 - val_accuracy: 0.9788\n",
            "Epoch 17/20\n",
            "1199/1199 [==============================] - 38s 32ms/step - loss: 0.0238 - accuracy: 0.9926 - val_loss: 0.1741 - val_accuracy: 0.9634\n",
            "Epoch 18/20\n",
            "1199/1199 [==============================] - 38s 32ms/step - loss: 0.0206 - accuracy: 0.9927 - val_loss: 0.0972 - val_accuracy: 0.9808\n",
            "Epoch 19/20\n",
            "1199/1199 [==============================] - 38s 32ms/step - loss: 0.0204 - accuracy: 0.9938 - val_loss: 0.0951 - val_accuracy: 0.9769\n",
            "Epoch 20/20\n",
            "1199/1199 [==============================] - 38s 32ms/step - loss: 0.0163 - accuracy: 0.9944 - val_loss: 0.1115 - val_accuracy: 0.9766\n",
            "INFO:tensorflow:Assets written to: final_models/0anomaly-classifier2/assets\n",
            "Model 2 saved\n",
            "{1: 0, 2: 1, 3: 2, 5: 3, 6: 4, 7: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(38586,)\n",
            "{1: 0, 2: 1, 3: 2, 5: 3, 6: 4, 7: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9649,)\n",
            "Epoch 1/20\n",
            "1206/1206 [==============================] - 40s 32ms/step - loss: 4.7882 - accuracy: 0.8071 - val_loss: 0.2054 - val_accuracy: 0.9624\n",
            "Epoch 2/20\n",
            "1206/1206 [==============================] - 38s 32ms/step - loss: 0.1315 - accuracy: 0.9713 - val_loss: 0.0990 - val_accuracy: 0.9709\n",
            "Epoch 3/20\n",
            "1206/1206 [==============================] - 38s 32ms/step - loss: 0.0670 - accuracy: 0.9810 - val_loss: 0.4476 - val_accuracy: 0.9054\n",
            "Epoch 4/20\n",
            "1206/1206 [==============================] - 38s 32ms/step - loss: 0.0669 - accuracy: 0.9815 - val_loss: 0.1111 - val_accuracy: 0.9646\n",
            "Epoch 5/20\n",
            "1206/1206 [==============================] - 39s 32ms/step - loss: 0.0581 - accuracy: 0.9833 - val_loss: 0.0892 - val_accuracy: 0.9763\n",
            "Epoch 6/20\n",
            "1206/1206 [==============================] - 38s 32ms/step - loss: 0.0512 - accuracy: 0.9845 - val_loss: 0.1519 - val_accuracy: 0.9642\n",
            "Epoch 7/20\n",
            "1206/1206 [==============================] - 38s 32ms/step - loss: 0.0445 - accuracy: 0.9864 - val_loss: 0.1243 - val_accuracy: 0.9706\n",
            "Epoch 8/20\n",
            "1206/1206 [==============================] - 38s 32ms/step - loss: 0.0418 - accuracy: 0.9879 - val_loss: 0.1396 - val_accuracy: 0.9664\n",
            "Epoch 9/20\n",
            "1206/1206 [==============================] - 38s 32ms/step - loss: 0.0397 - accuracy: 0.9883 - val_loss: 0.0655 - val_accuracy: 0.9826\n",
            "Epoch 10/20\n",
            "1206/1206 [==============================] - 38s 32ms/step - loss: 0.0338 - accuracy: 0.9889 - val_loss: 0.1314 - val_accuracy: 0.9664\n",
            "Epoch 11/20\n",
            "1206/1206 [==============================] - 38s 32ms/step - loss: 0.0288 - accuracy: 0.9911 - val_loss: 0.1945 - val_accuracy: 0.9488\n",
            "Epoch 12/20\n",
            "1206/1206 [==============================] - 38s 32ms/step - loss: 0.0294 - accuracy: 0.9907 - val_loss: 0.1235 - val_accuracy: 0.9696\n",
            "Epoch 13/20\n",
            "1206/1206 [==============================] - 38s 32ms/step - loss: 0.0303 - accuracy: 0.9892 - val_loss: 0.0703 - val_accuracy: 0.9829\n",
            "Epoch 14/20\n",
            "1206/1206 [==============================] - 38s 32ms/step - loss: 0.0217 - accuracy: 0.9933 - val_loss: 0.1031 - val_accuracy: 0.9752\n",
            "Epoch 15/20\n",
            "1206/1206 [==============================] - 38s 32ms/step - loss: 0.0205 - accuracy: 0.9924 - val_loss: 0.1108 - val_accuracy: 0.9776\n",
            "Epoch 16/20\n",
            "1206/1206 [==============================] - 38s 32ms/step - loss: 0.0199 - accuracy: 0.9932 - val_loss: 0.0986 - val_accuracy: 0.9774\n",
            "Epoch 17/20\n",
            "1206/1206 [==============================] - 38s 32ms/step - loss: 0.0187 - accuracy: 0.9938 - val_loss: 0.1003 - val_accuracy: 0.9800\n",
            "Epoch 18/20\n",
            "1206/1206 [==============================] - 38s 32ms/step - loss: 0.0138 - accuracy: 0.9953 - val_loss: 0.0845 - val_accuracy: 0.9839\n",
            "Epoch 19/20\n",
            "1206/1206 [==============================] - 38s 32ms/step - loss: 0.0191 - accuracy: 0.9937 - val_loss: 0.0954 - val_accuracy: 0.9808\n",
            "Epoch 20/20\n",
            "1206/1206 [==============================] - 38s 32ms/step - loss: 0.0140 - accuracy: 0.9956 - val_loss: 0.0847 - val_accuracy: 0.9844\n",
            "INFO:tensorflow:Assets written to: final_models/0anomaly-classifier3/assets\n",
            "Model 3 saved\n",
            "{1: 0, 2: 1, 3: 2, 4: 3, 6: 4, 7: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(38935,)\n",
            "{1: 0, 2: 1, 3: 2, 4: 3, 6: 4, 7: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9721,)\n",
            "Epoch 1/20\n",
            "1217/1217 [==============================] - 40s 32ms/step - loss: 4.5054 - accuracy: 0.8336 - val_loss: 0.4318 - val_accuracy: 0.9364\n",
            "Epoch 2/20\n",
            "1217/1217 [==============================] - 39s 32ms/step - loss: 0.1179 - accuracy: 0.9686 - val_loss: 0.1639 - val_accuracy: 0.9639\n",
            "Epoch 3/20\n",
            "1217/1217 [==============================] - 39s 32ms/step - loss: 0.0869 - accuracy: 0.9753 - val_loss: 0.1480 - val_accuracy: 0.9640\n",
            "Epoch 4/20\n",
            "1217/1217 [==============================] - 39s 32ms/step - loss: 0.0748 - accuracy: 0.9784 - val_loss: 0.1780 - val_accuracy: 0.9581\n",
            "Epoch 5/20\n",
            "1217/1217 [==============================] - 39s 32ms/step - loss: 0.0647 - accuracy: 0.9809 - val_loss: 0.0791 - val_accuracy: 0.9797\n",
            "Epoch 6/20\n",
            "1217/1217 [==============================] - 39s 32ms/step - loss: 0.0610 - accuracy: 0.9833 - val_loss: 0.0868 - val_accuracy: 0.9776\n",
            "Epoch 7/20\n",
            "1217/1217 [==============================] - 39s 32ms/step - loss: 0.0501 - accuracy: 0.9849 - val_loss: 0.0907 - val_accuracy: 0.9761\n",
            "Epoch 8/20\n",
            "1217/1217 [==============================] - 39s 32ms/step - loss: 0.0433 - accuracy: 0.9869 - val_loss: 0.0955 - val_accuracy: 0.9778\n",
            "Epoch 9/20\n",
            "1217/1217 [==============================] - 39s 32ms/step - loss: 0.0436 - accuracy: 0.9874 - val_loss: 0.0702 - val_accuracy: 0.9792\n",
            "Epoch 10/20\n",
            "1217/1217 [==============================] - 39s 32ms/step - loss: 0.0350 - accuracy: 0.9889 - val_loss: 0.0847 - val_accuracy: 0.9763\n",
            "Epoch 11/20\n",
            "1217/1217 [==============================] - 39s 32ms/step - loss: 0.0326 - accuracy: 0.9905 - val_loss: 0.0823 - val_accuracy: 0.9817\n",
            "Epoch 12/20\n",
            "1217/1217 [==============================] - 39s 32ms/step - loss: 0.0269 - accuracy: 0.9915 - val_loss: 0.0674 - val_accuracy: 0.9853\n",
            "Epoch 13/20\n",
            "1217/1217 [==============================] - 39s 32ms/step - loss: 0.0297 - accuracy: 0.9906 - val_loss: 0.0809 - val_accuracy: 0.9787\n",
            "Epoch 14/20\n",
            "1217/1217 [==============================] - 39s 32ms/step - loss: 0.0268 - accuracy: 0.9922 - val_loss: 0.0831 - val_accuracy: 0.9837\n",
            "Epoch 15/20\n",
            "1217/1217 [==============================] - 39s 32ms/step - loss: 0.0259 - accuracy: 0.9912 - val_loss: 0.0614 - val_accuracy: 0.9850\n",
            "Epoch 16/20\n",
            "1217/1217 [==============================] - 39s 32ms/step - loss: 0.0203 - accuracy: 0.9938 - val_loss: 0.0755 - val_accuracy: 0.9824\n",
            "Epoch 17/20\n",
            "1217/1217 [==============================] - 39s 32ms/step - loss: 0.0181 - accuracy: 0.9942 - val_loss: 0.0648 - val_accuracy: 0.9881\n",
            "Epoch 18/20\n",
            "1217/1217 [==============================] - 39s 32ms/step - loss: 0.0199 - accuracy: 0.9931 - val_loss: 0.0651 - val_accuracy: 0.9861\n",
            "Epoch 19/20\n",
            "1217/1217 [==============================] - 39s 32ms/step - loss: 0.0164 - accuracy: 0.9949 - val_loss: 0.0746 - val_accuracy: 0.9852\n",
            "Epoch 20/20\n",
            "1217/1217 [==============================] - 39s 32ms/step - loss: 0.0196 - accuracy: 0.9945 - val_loss: 0.1127 - val_accuracy: 0.9794\n",
            "INFO:tensorflow:Assets written to: final_models/0anomaly-classifier4/assets\n",
            "Model 4 saved\n",
            "{1: 0, 2: 1, 3: 2, 4: 3, 5: 4, 7: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(38511,)\n",
            "{1: 0, 2: 1, 3: 2, 4: 3, 5: 4, 7: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9648,)\n",
            "Epoch 1/20\n",
            "1204/1204 [==============================] - 40s 32ms/step - loss: 5.5154 - accuracy: 0.7759 - val_loss: 0.2115 - val_accuracy: 0.9634\n",
            "Epoch 2/20\n",
            "1204/1204 [==============================] - 38s 32ms/step - loss: 0.1604 - accuracy: 0.9651 - val_loss: 3.0528 - val_accuracy: 0.7838\n",
            "Epoch 3/20\n",
            "1204/1204 [==============================] - 38s 32ms/step - loss: 0.1078 - accuracy: 0.9724 - val_loss: 0.2020 - val_accuracy: 0.9594\n",
            "Epoch 4/20\n",
            "1204/1204 [==============================] - 38s 32ms/step - loss: 0.0732 - accuracy: 0.9787 - val_loss: 0.2399 - val_accuracy: 0.9399\n",
            "Epoch 5/20\n",
            "1204/1204 [==============================] - 38s 32ms/step - loss: 0.0656 - accuracy: 0.9803 - val_loss: 0.0986 - val_accuracy: 0.9774\n",
            "Epoch 6/20\n",
            "1204/1204 [==============================] - 38s 32ms/step - loss: 0.0579 - accuracy: 0.9827 - val_loss: 0.0871 - val_accuracy: 0.9771\n",
            "Epoch 7/20\n",
            "1204/1204 [==============================] - 38s 32ms/step - loss: 0.0501 - accuracy: 0.9842 - val_loss: 0.3307 - val_accuracy: 0.9230\n",
            "Epoch 8/20\n",
            "1204/1204 [==============================] - 38s 32ms/step - loss: 0.0481 - accuracy: 0.9859 - val_loss: 0.0816 - val_accuracy: 0.9795\n",
            "Epoch 9/20\n",
            "1204/1204 [==============================] - 38s 32ms/step - loss: 0.0463 - accuracy: 0.9857 - val_loss: 0.1233 - val_accuracy: 0.9664\n",
            "Epoch 10/20\n",
            "1204/1204 [==============================] - 38s 32ms/step - loss: 0.0396 - accuracy: 0.9867 - val_loss: 0.0926 - val_accuracy: 0.9755\n",
            "Epoch 11/20\n",
            "1204/1204 [==============================] - 38s 32ms/step - loss: 0.0383 - accuracy: 0.9885 - val_loss: 0.0674 - val_accuracy: 0.9823\n",
            "Epoch 12/20\n",
            "1204/1204 [==============================] - 38s 32ms/step - loss: 0.0317 - accuracy: 0.9894 - val_loss: 0.0661 - val_accuracy: 0.9853\n",
            "Epoch 13/20\n",
            "1204/1204 [==============================] - 38s 32ms/step - loss: 0.0325 - accuracy: 0.9897 - val_loss: 0.0665 - val_accuracy: 0.9848\n",
            "Epoch 14/20\n",
            "1204/1204 [==============================] - 38s 32ms/step - loss: 0.0271 - accuracy: 0.9912 - val_loss: 0.0943 - val_accuracy: 0.9783\n",
            "Epoch 15/20\n",
            "1204/1204 [==============================] - 39s 32ms/step - loss: 0.0232 - accuracy: 0.9926 - val_loss: 0.0727 - val_accuracy: 0.9857\n",
            "Epoch 16/20\n",
            "1204/1204 [==============================] - 38s 32ms/step - loss: 0.0203 - accuracy: 0.9933 - val_loss: 0.0587 - val_accuracy: 0.9871\n",
            "Epoch 17/20\n",
            "1204/1204 [==============================] - 38s 32ms/step - loss: 0.0192 - accuracy: 0.9936 - val_loss: 0.1043 - val_accuracy: 0.9770\n",
            "Epoch 18/20\n",
            "1204/1204 [==============================] - 38s 32ms/step - loss: 0.0234 - accuracy: 0.9931 - val_loss: 0.1042 - val_accuracy: 0.9801\n",
            "Epoch 19/20\n",
            "1204/1204 [==============================] - 38s 32ms/step - loss: 0.0174 - accuracy: 0.9946 - val_loss: 0.1025 - val_accuracy: 0.9798\n",
            "Epoch 20/20\n",
            "1204/1204 [==============================] - 38s 32ms/step - loss: 0.0174 - accuracy: 0.9944 - val_loss: 0.0624 - val_accuracy: 0.9864\n",
            "INFO:tensorflow:Assets written to: final_models/0anomaly-classifier5/assets\n",
            "Model 5 saved\n",
            "{1: 0, 2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(38286,)\n",
            "{1: 0, 2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9526,)\n",
            "Epoch 1/20\n",
            "1197/1197 [==============================] - 39s 32ms/step - loss: 6.0554 - accuracy: 0.7532 - val_loss: 0.1423 - val_accuracy: 0.9718\n",
            "Epoch 2/20\n",
            "1197/1197 [==============================] - 38s 32ms/step - loss: 0.1270 - accuracy: 0.9719 - val_loss: 0.1263 - val_accuracy: 0.9683\n",
            "Epoch 3/20\n",
            "1197/1197 [==============================] - 38s 32ms/step - loss: 0.0697 - accuracy: 0.9799 - val_loss: 0.2679 - val_accuracy: 0.9397\n",
            "Epoch 4/20\n",
            "1197/1197 [==============================] - 38s 32ms/step - loss: 0.0547 - accuracy: 0.9838 - val_loss: 0.0911 - val_accuracy: 0.9766\n",
            "Epoch 5/20\n",
            "1197/1197 [==============================] - 38s 32ms/step - loss: 0.0601 - accuracy: 0.9819 - val_loss: 0.0590 - val_accuracy: 0.9836\n",
            "Epoch 6/20\n",
            "1197/1197 [==============================] - 38s 32ms/step - loss: 0.0519 - accuracy: 0.9837 - val_loss: 0.1102 - val_accuracy: 0.9698\n",
            "Epoch 7/20\n",
            "1197/1197 [==============================] - 38s 32ms/step - loss: 0.0541 - accuracy: 0.9846 - val_loss: 0.1141 - val_accuracy: 0.9751\n",
            "Epoch 8/20\n",
            "1197/1197 [==============================] - 38s 32ms/step - loss: 0.0520 - accuracy: 0.9858 - val_loss: 0.1641 - val_accuracy: 0.9634\n",
            "Epoch 9/20\n",
            "1197/1197 [==============================] - 38s 32ms/step - loss: 0.0402 - accuracy: 0.9874 - val_loss: 0.1207 - val_accuracy: 0.9754\n",
            "Epoch 10/20\n",
            "1197/1197 [==============================] - 38s 32ms/step - loss: 0.0327 - accuracy: 0.9896 - val_loss: 0.0877 - val_accuracy: 0.9763\n",
            "Epoch 11/20\n",
            "1197/1197 [==============================] - 38s 32ms/step - loss: 0.0344 - accuracy: 0.9896 - val_loss: 0.1094 - val_accuracy: 0.9749\n",
            "Epoch 12/20\n",
            "1197/1197 [==============================] - 38s 32ms/step - loss: 0.0295 - accuracy: 0.9903 - val_loss: 0.0616 - val_accuracy: 0.9854\n",
            "Epoch 13/20\n",
            "1197/1197 [==============================] - 38s 32ms/step - loss: 0.0282 - accuracy: 0.9915 - val_loss: 0.2016 - val_accuracy: 0.9579\n",
            "Epoch 14/20\n",
            "1197/1197 [==============================] - 38s 32ms/step - loss: 0.0235 - accuracy: 0.9922 - val_loss: 0.1030 - val_accuracy: 0.9790\n",
            "Epoch 15/20\n",
            "1197/1197 [==============================] - 38s 32ms/step - loss: 0.0217 - accuracy: 0.9931 - val_loss: 0.0973 - val_accuracy: 0.9820\n",
            "Epoch 16/20\n",
            "1197/1197 [==============================] - 38s 32ms/step - loss: 0.0254 - accuracy: 0.9924 - val_loss: 0.0950 - val_accuracy: 0.9846\n",
            "Epoch 17/20\n",
            "1197/1197 [==============================] - 38s 32ms/step - loss: 0.0236 - accuracy: 0.9926 - val_loss: 0.0832 - val_accuracy: 0.9824\n",
            "Epoch 18/20\n",
            "1197/1197 [==============================] - 38s 32ms/step - loss: 0.0170 - accuracy: 0.9943 - val_loss: 0.0577 - val_accuracy: 0.9889\n",
            "Epoch 19/20\n",
            "1197/1197 [==============================] - 38s 32ms/step - loss: 0.0174 - accuracy: 0.9948 - val_loss: 0.0883 - val_accuracy: 0.9825\n",
            "Epoch 20/20\n",
            "1197/1197 [==============================] - 38s 32ms/step - loss: 0.0195 - accuracy: 0.9940 - val_loss: 0.1275 - val_accuracy: 0.9769\n",
            "INFO:tensorflow:Assets written to: final_models/0anomaly-classifier6/assets\n",
            "Model 6 saved\n",
            "{1: 0, 2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(38561,)\n",
            "{1: 0, 2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9665,)\n",
            "Epoch 1/20\n",
            "1206/1206 [==============================] - 40s 32ms/step - loss: 5.7612 - accuracy: 0.8002 - val_loss: 0.2190 - val_accuracy: 0.9565\n",
            "Epoch 2/20\n",
            "1206/1206 [==============================] - 38s 32ms/step - loss: 0.1555 - accuracy: 0.9669 - val_loss: 0.1252 - val_accuracy: 0.9705\n",
            "Epoch 3/20\n",
            "1206/1206 [==============================] - 38s 32ms/step - loss: 0.0928 - accuracy: 0.9755 - val_loss: 7.8013 - val_accuracy: 0.5147\n",
            "Epoch 4/20\n",
            "1206/1206 [==============================] - 38s 32ms/step - loss: 0.0670 - accuracy: 0.9807 - val_loss: 1.8307 - val_accuracy: 0.7225\n",
            "Epoch 5/20\n",
            "1206/1206 [==============================] - 38s 32ms/step - loss: 0.2987 - accuracy: 0.9438 - val_loss: 0.1357 - val_accuracy: 0.9607\n",
            "Epoch 6/20\n",
            "1206/1206 [==============================] - 38s 32ms/step - loss: 0.0592 - accuracy: 0.9821 - val_loss: 0.0985 - val_accuracy: 0.9743\n",
            "Epoch 7/20\n",
            "1206/1206 [==============================] - 38s 32ms/step - loss: 0.0551 - accuracy: 0.9816 - val_loss: 0.0819 - val_accuracy: 0.9778\n",
            "Epoch 8/20\n",
            "1206/1206 [==============================] - 38s 32ms/step - loss: 0.0499 - accuracy: 0.9841 - val_loss: 0.0621 - val_accuracy: 0.9835\n",
            "Epoch 9/20\n",
            "1206/1206 [==============================] - 38s 32ms/step - loss: 0.0448 - accuracy: 0.9870 - val_loss: 0.0717 - val_accuracy: 0.9821\n",
            "Epoch 10/20\n",
            "1206/1206 [==============================] - 38s 32ms/step - loss: 0.0395 - accuracy: 0.9875 - val_loss: 0.1042 - val_accuracy: 0.9745\n",
            "Epoch 11/20\n",
            "1206/1206 [==============================] - 38s 32ms/step - loss: 0.0351 - accuracy: 0.9892 - val_loss: 0.1700 - val_accuracy: 0.9584\n",
            "Epoch 12/20\n",
            "1206/1206 [==============================] - 38s 32ms/step - loss: 0.0334 - accuracy: 0.9893 - val_loss: 0.0747 - val_accuracy: 0.9824\n",
            "Epoch 13/20\n",
            "1206/1206 [==============================] - 38s 32ms/step - loss: 0.0260 - accuracy: 0.9914 - val_loss: 0.1060 - val_accuracy: 0.9743\n",
            "Epoch 14/20\n",
            "1206/1206 [==============================] - 38s 32ms/step - loss: 0.0307 - accuracy: 0.9908 - val_loss: 0.1248 - val_accuracy: 0.9727\n",
            "Epoch 15/20\n",
            "1206/1206 [==============================] - 38s 32ms/step - loss: 0.0245 - accuracy: 0.9921 - val_loss: 0.0695 - val_accuracy: 0.9839\n",
            "Epoch 16/20\n",
            "1206/1206 [==============================] - 38s 32ms/step - loss: 0.0253 - accuracy: 0.9924 - val_loss: 0.0775 - val_accuracy: 0.9821\n",
            "Epoch 17/20\n",
            "1206/1206 [==============================] - 38s 32ms/step - loss: 0.0206 - accuracy: 0.9944 - val_loss: 0.1211 - val_accuracy: 0.9745\n",
            "Epoch 18/20\n",
            "1206/1206 [==============================] - 38s 32ms/step - loss: 0.0186 - accuracy: 0.9936 - val_loss: 0.0713 - val_accuracy: 0.9823\n",
            "Epoch 19/20\n",
            "1206/1206 [==============================] - 38s 32ms/step - loss: 0.0598 - accuracy: 0.9828 - val_loss: 0.0681 - val_accuracy: 0.9858\n",
            "Epoch 20/20\n",
            "1206/1206 [==============================] - 38s 32ms/step - loss: 0.0139 - accuracy: 0.9958 - val_loss: 0.0609 - val_accuracy: 0.9878\n",
            "INFO:tensorflow:Assets written to: final_models/0anomaly-classifier7/assets\n",
            "Model 7 saved\n",
            "{1: 0, 2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, 8: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(38497,)\n",
            "{1: 0, 2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, 8: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9631,)\n",
            "Epoch 1/20\n",
            "1204/1204 [==============================] - 39s 32ms/step - loss: 5.1970 - accuracy: 0.8491 - val_loss: 0.8407 - val_accuracy: 0.8793\n",
            "Epoch 2/20\n",
            "1204/1204 [==============================] - 38s 32ms/step - loss: 0.3977 - accuracy: 0.9556 - val_loss: 0.1305 - val_accuracy: 0.9616\n",
            "Epoch 3/20\n",
            "1204/1204 [==============================] - 38s 32ms/step - loss: 0.0641 - accuracy: 0.9813 - val_loss: 0.1463 - val_accuracy: 0.9642\n",
            "Epoch 4/20\n",
            "1204/1204 [==============================] - 38s 32ms/step - loss: 0.0552 - accuracy: 0.9833 - val_loss: 0.1213 - val_accuracy: 0.9646\n",
            "Epoch 5/20\n",
            "1204/1204 [==============================] - 38s 32ms/step - loss: 0.0562 - accuracy: 0.9828 - val_loss: 0.0803 - val_accuracy: 0.9786\n",
            "Epoch 6/20\n",
            "1204/1204 [==============================] - 38s 32ms/step - loss: 0.0545 - accuracy: 0.9843 - val_loss: 0.2451 - val_accuracy: 0.9467\n",
            "Epoch 7/20\n",
            "1204/1204 [==============================] - 38s 32ms/step - loss: 0.0501 - accuracy: 0.9846 - val_loss: 0.2271 - val_accuracy: 0.9530\n",
            "Epoch 8/20\n",
            "1204/1204 [==============================] - 38s 32ms/step - loss: 0.0385 - accuracy: 0.9874 - val_loss: 0.0778 - val_accuracy: 0.9785\n",
            "Epoch 9/20\n",
            "1204/1204 [==============================] - 38s 32ms/step - loss: 0.0397 - accuracy: 0.9877 - val_loss: 0.1456 - val_accuracy: 0.9690\n",
            "Epoch 10/20\n",
            "1204/1204 [==============================] - 38s 32ms/step - loss: 0.0867 - accuracy: 0.9762 - val_loss: 0.0885 - val_accuracy: 0.9756\n",
            "Epoch 11/20\n",
            "1204/1204 [==============================] - 38s 32ms/step - loss: 0.0243 - accuracy: 0.9928 - val_loss: 0.0655 - val_accuracy: 0.9830\n",
            "Epoch 12/20\n",
            "1204/1204 [==============================] - 38s 32ms/step - loss: 0.0253 - accuracy: 0.9918 - val_loss: 0.1278 - val_accuracy: 0.9762\n",
            "Epoch 13/20\n",
            "1204/1204 [==============================] - 38s 32ms/step - loss: 0.0319 - accuracy: 0.9898 - val_loss: 0.0600 - val_accuracy: 0.9861\n",
            "Epoch 14/20\n",
            "1204/1204 [==============================] - 38s 32ms/step - loss: 0.0205 - accuracy: 0.9938 - val_loss: 0.0950 - val_accuracy: 0.9802\n",
            "Epoch 15/20\n",
            "1204/1204 [==============================] - 38s 32ms/step - loss: 0.0217 - accuracy: 0.9933 - val_loss: 0.0982 - val_accuracy: 0.9807\n",
            "Epoch 16/20\n",
            "1204/1204 [==============================] - 38s 32ms/step - loss: 0.0177 - accuracy: 0.9941 - val_loss: 0.1011 - val_accuracy: 0.9792\n",
            "Epoch 17/20\n",
            "1204/1204 [==============================] - 38s 32ms/step - loss: 0.0205 - accuracy: 0.9934 - val_loss: 0.0691 - val_accuracy: 0.9870\n",
            "Epoch 18/20\n",
            "1204/1204 [==============================] - 38s 32ms/step - loss: 0.0212 - accuracy: 0.9936 - val_loss: 0.0895 - val_accuracy: 0.9843\n",
            "Epoch 19/20\n",
            "1204/1204 [==============================] - 38s 32ms/step - loss: 0.0164 - accuracy: 0.9950 - val_loss: 0.1306 - val_accuracy: 0.9759\n",
            "Epoch 20/20\n",
            "1204/1204 [==============================] - 38s 32ms/step - loss: 0.0540 - accuracy: 0.9864 - val_loss: 0.0613 - val_accuracy: 0.9885\n",
            "INFO:tensorflow:Assets written to: final_models/0anomaly-classifier8/assets\n",
            "Model 8 saved\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Qdf3x9UHMQ3"
      },
      "source": [
        "class_0 = model0.load_model(\"final_models/0anomaly-classifier0\")\n",
        "class_1 = model1.load_model(\"final_models/0anomaly-classifier1\")\n",
        "class_2 = model2.load_model(\"final_models/0anomaly-classifier2\")\n",
        "class_3 = model3.load_model(\"final_models/0anomaly-classifier3\")\n",
        "class_4 = model4.load_model(\"final_models/0anomaly-classifier4\")\n",
        "class_5 = model5.load_model(\"final_models/0anomaly-classifier5\")\n",
        "class_6 = model6.load_model(\"final_models/0anomaly-classifier6\")\n",
        "class_7 = model7.load_model(\"final_models/0anomaly-classifier7\")\n",
        "class_8 = model8.load_model(\"final_models/0anomaly-classifier8\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iaC7gU74pG6j",
        "outputId": "1921f143-f51c-4f51-9c69-24d084bffe91"
      },
      "source": [
        "layer_name_list = []\n",
        "\n",
        "layer_name_list.append(class_0.layers[-2:][0].name)\n",
        "layer_name_list.append(class_1.layers[-2:][0].name)\n",
        "layer_name_list.append(class_2.layers[-2:][0].name)\n",
        "layer_name_list.append(class_3.layers[-2:][0].name)\n",
        "layer_name_list.append(class_4.layers[-2:][0].name)\n",
        "layer_name_list.append(class_5.layers[-2:][0].name)\n",
        "layer_name_list.append(class_6.layers[-2:][0].name)\n",
        "layer_name_list.append(class_7.layers[-2:][0].name)\n",
        "layer_name_list.append(class_8.layers[-2:][0].name)\n",
        "\n",
        "print(layer_name_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['dense_25', 'dense_27', 'dense_29', 'dense_31', 'dense_33', 'dense_35', 'dense_37', 'dense_39', 'dense_41']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-UCLL_OpHku"
      },
      "source": [
        "from keras import Model\n",
        "model_dict = {}\n",
        "model_output0 = class_0.get_layer(layer_name_list[0]).output\n",
        "m0 = Model(inputs=class_0.input, outputs=model_output0)\n",
        "model_dict[0] = m0\n",
        "\n",
        "model_output1 = class_1.get_layer(layer_name_list[1]).output\n",
        "m1 = Model(inputs=class_1.input, outputs=model_output1)\n",
        "model_dict[1] = m1\n",
        "\n",
        "model_output2 = class_2.get_layer(layer_name_list[2]).output\n",
        "m2 = Model(inputs=class_2.input, outputs=model_output2)\n",
        "model_dict[2] = m2\n",
        "\n",
        "model_output3 = class_3.get_layer(layer_name_list[3]).output\n",
        "m3 = Model(inputs=class_3.input, outputs=model_output3)\n",
        "model_dict[3] = m3\n",
        "\n",
        "model_output4 = class_4.get_layer(layer_name_list[4]).output\n",
        "m4 = Model(inputs=class_4.input, outputs=model_output4)\n",
        "model_dict[4] = m4\n",
        "\n",
        "model_output5 = class_5.get_layer(layer_name_list[5]).output\n",
        "m5 = Model(inputs=class_5.input, outputs=model_output5)\n",
        "model_dict[5] = m5\n",
        "\n",
        "model_output6 = class_6.get_layer(layer_name_list[6]).output\n",
        "m6 = Model(inputs=class_6.input, outputs=model_output6)\n",
        "model_dict[6] = m6\n",
        "\n",
        "model_output7 = class_7.get_layer(layer_name_list[7]).output\n",
        "m7 = Model(inputs=class_7.input, outputs=model_output7)\n",
        "model_dict[7] = m7\n",
        "\n",
        "model_output8 = class_8.get_layer(layer_name_list[8]).output\n",
        "m8 = Model(inputs=class_8.input, outputs=model_output8)\n",
        "model_dict[8] = m8\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OY2GPp3upMb7",
        "outputId": "a54ee91e-b320-454c-d02e-cfe26c507c91"
      },
      "source": [
        "temp_val = []\n",
        "y_pred = []\n",
        "labels = set(new_val_labels)\n",
        "for i, lo in zip(range(9), labels):\n",
        "  m = model_dict[i]\n",
        "  val_imgs_, val_lbls_ = get_train_data(lo, new_val_images, new_val_labels)\n",
        "  y_p = m.predict(val_imgs_)\n",
        "  y_pred.append(y_p)\n",
        "  temp = temp_cal(y_p, val_lbls_)\n",
        "  temp_val.append(temp)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{2: 0, 3: 1, 4: 2, 5: 3, 6: 4, 7: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9503,)\n",
            "Temperature Initial value: 1.0\n",
            "Temperature Final value: 2.29171085357666\n",
            "{1: 0, 3: 1, 4: 2, 5: 3, 6: 4, 7: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9651,)\n",
            "Temperature Initial value: 1.0\n",
            "Temperature Final value: 1.7892318964004517\n",
            "{1: 0, 2: 1, 4: 2, 5: 3, 6: 4, 7: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9606,)\n",
            "Temperature Initial value: 1.0\n",
            "Temperature Final value: 2.168271780014038\n",
            "{1: 0, 2: 1, 3: 2, 5: 3, 6: 4, 7: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9649,)\n",
            "Temperature Initial value: 1.0\n",
            "Temperature Final value: 2.192014694213867\n",
            "{1: 0, 2: 1, 3: 2, 4: 3, 6: 4, 7: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9721,)\n",
            "Temperature Initial value: 1.0\n",
            "Temperature Final value: 2.3539624214172363\n",
            "{1: 0, 2: 1, 3: 2, 4: 3, 5: 4, 7: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9648,)\n",
            "Temperature Initial value: 1.0\n",
            "Temperature Final value: 1.8671849966049194\n",
            "{1: 0, 2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9526,)\n",
            "Temperature Initial value: 1.0\n",
            "Temperature Final value: 2.2140533924102783\n",
            "{1: 0, 2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9665,)\n",
            "Temperature Initial value: 1.0\n",
            "Temperature Final value: 1.8692173957824707\n",
            "{1: 0, 2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, 8: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9631,)\n",
            "Temperature Initial value: 1.0\n",
            "Temperature Final value: 2.201385021209717\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K9uaw8a3qGnN",
        "outputId": "b042dad7-a9ac-44fc-a491-894f8f4279f4"
      },
      "source": [
        "temp_val"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=2.2917109>,\n",
              " <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=1.7892319>,\n",
              " <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=2.1682718>,\n",
              " <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=2.1920147>,\n",
              " <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=2.3539624>,\n",
              " <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=1.867185>,\n",
              " <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=2.2140534>,\n",
              " <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=1.8692174>,\n",
              " <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=2.201385>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EjMoeRiam3WQ"
      },
      "source": [
        "temp_val = [2.2917109, 1.7892319, 2.1682718, 2.1920147, 2.3539624, 1.867185, 2.2140534, 1.8692174, 2.201385]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Zf2TZfFq64f"
      },
      "source": [
        "from tqdm import tqdm\n",
        "avg = [0,0,0,0,0,0,0,0,0]\n",
        "count = [0,0,0,0,0,0,0,0,0]\n",
        "for img, lbl in tqdm(zip(new_val_images,new_val_labels)):\n",
        "  img = img.reshape([-1, 28, 28, 1])\n",
        "  if not lbl == 1:\n",
        "    logits = model_dict[0](img)\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    max_val0 = np.max(pred)\n",
        "    avg[0] = avg[0] + max_val0\n",
        "    count[0] = count[0] + 1\n",
        "  if not lbl == 2:\n",
        "    logits = model_dict[1](img)\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    max_val1 = np.max(pred)\n",
        "    avg[1] = avg[1] + max_val1\n",
        "    count[1] = count[1] + 1\n",
        "  if not lbl == 3:\n",
        "    logits = model_dict[2](img)\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    max_val2 = np.max(pred)\n",
        "    avg[2] = avg[2] + max_val2\n",
        "    count[2] = count[2] + 1\n",
        "  if not lbl == 4:\n",
        "    logits = model_dict[3](img)\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    max_val3 = np.max(pred)  \n",
        "    avg[3] = avg[3] + max_val3\n",
        "    count[3] = count[3] + 1\n",
        "  if not lbl == 5:\n",
        "    logits = model_dict[4](img)\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    max_val4 = np.max(pred)\n",
        "    avg[4] = avg[4] + max_val4\n",
        "    count[4] = count[4] + 1\n",
        "  if not lbl == 6:\n",
        "    logits = model_dict[5](img)\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    max_val5 = np.max(pred)\n",
        "    avg[5] = avg[5] + max_val5\n",
        "    count[5] = count[5] + 1\n",
        "  if not lbl == 7:\n",
        "    logits = model_dict[6](img)\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    max_val6 = np.max(pred)\n",
        "    avg[6] = avg[6] + max_val6\n",
        "    count[6] = count[6] + 1\n",
        "  if not lbl == 8:\n",
        "    logits = model_dict[7](img)\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    max_val7 = np.max(pred)\n",
        "    avg[7] = avg[7] + max_val7\n",
        "    count[7] = count[7] + 1\n",
        "  if not lbl == 9:\n",
        "    logits = model_dict[8](img)\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    max_val8 = np.max(pred)\n",
        "    avg[8] = avg[8] + max_val8\n",
        "    count[8] = count[8] + 1\n",
        "\n",
        "print(avg)\n",
        "print(count)\n",
        "\n",
        "classifier_avg = [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]\n",
        "for i in range(9):\n",
        "  classifier_avg[i] = avg[i]/count[i]\n",
        "\n",
        "print('Each Classifier Average: ',classifier_avg)\n",
        "\n",
        "treshold_value = 0.0\n",
        "for i in range(9):\n",
        "  treshold_value = treshold_value + classifier_avg[i]\n",
        "\n",
        "treshold = treshold_value/len(classifier_avg)\n",
        "\n",
        "print('Threshold:', treshold)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hIgzG_kkrvqP",
        "outputId": "69b5a8cb-641c-4131-8e53-4f77c9161a10"
      },
      "source": [
        "set(new_val_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{1, 2, 3, 4, 5, 6, 7, 8, 9}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A1IpzDGGrZOI",
        "outputId": "8e401f0a-93c0-4471-aede-b99f3097764a"
      },
      "source": [
        "from tqdm import tqdm\n",
        "avg = [0,0,0,0,0,0,0,0,0]\n",
        "count = [0,0,0,0,0,0,0,0,0]\n",
        "entropy_list = [0,0,0,0,0,0,0,0,0]\n",
        "for img, lbl in tqdm(zip(new_val_images,new_val_labels)):\n",
        "  img = img.reshape([-1, 28, 28, 1])\n",
        "  if not lbl == 1:\n",
        "    logits = model_dict[0](img)\n",
        "    logits = tf.math.divide(logits, temp_val[0])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e0 = entropy(pred[0])\n",
        "    entropy_list[0] = entropy_list[0] + e0\n",
        "    max_val0 = np.max(pred)\n",
        "    avg[0] = avg[0] + max_val0\n",
        "    count[0] = count[0] + 1\n",
        "  if not lbl == 2:\n",
        "    logits = model_dict[1](img)\n",
        "    logits = tf.math.divide(logits, temp_val[1])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e1 = entropy(pred[0])\n",
        "    entropy_list[1] = entropy_list[1] + e1\n",
        "    max_val1 = np.max(pred)\n",
        "    avg[1] = avg[1] + max_val1\n",
        "    count[1] = count[1] + 1\n",
        "  if not lbl == 3:\n",
        "    logits = model_dict[2](img)\n",
        "    logits = tf.math.divide(logits, temp_val[2])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e2 = entropy(pred[0])\n",
        "    entropy_list[2] = entropy_list[2] + e2\n",
        "    max_val2 = np.max(pred)\n",
        "    avg[2] = avg[2] + max_val2\n",
        "    count[2] = count[2] + 1\n",
        "  if not lbl == 4:\n",
        "    logits = model_dict[3](img)\n",
        "    logits = tf.math.divide(logits, temp_val[3])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e3 = entropy(pred[0])\n",
        "    entropy_list[3] = entropy_list[3] + e3\n",
        "    max_val3 = np.max(pred)  \n",
        "    avg[3] = avg[3] + max_val3\n",
        "    count[3] = count[3] + 1\n",
        "  if not lbl == 5:\n",
        "    logits = model_dict[4](img)\n",
        "    logits = tf.math.divide(logits, temp_val[4])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e4 = entropy(pred[0])\n",
        "    entropy_list[4] = entropy_list[4] + e4\n",
        "    max_val4 = np.max(pred)\n",
        "    avg[4] = avg[4] + max_val4\n",
        "    count[4] = count[4] + 1\n",
        "  if not lbl == 6:\n",
        "    logits = model_dict[5](img)\n",
        "    logits = tf.math.divide(logits, temp_val[5])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e5 = entropy(pred[0])\n",
        "    entropy_list[5] = entropy_list[5] + e5\n",
        "    max_val5 = np.max(pred)\n",
        "    avg[5] = avg[5] + max_val5\n",
        "    count[5] = count[5] + 1\n",
        "  if not lbl == 7:\n",
        "    logits = model_dict[6](img)\n",
        "    logits = tf.math.divide(logits, temp_val[6])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e6 = entropy(pred[0])\n",
        "    entropy_list[6] = entropy_list[6] + e6\n",
        "    max_val6 = np.max(pred)\n",
        "    avg[6] = avg[6] + max_val6\n",
        "    count[6] = count[6] + 1\n",
        "  if not lbl == 8:\n",
        "    logits = model_dict[7](img)\n",
        "    logits = tf.math.divide(logits, temp_val[7])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e7 = entropy(pred[0])\n",
        "    entropy_list[7] = entropy_list[7] + e7\n",
        "    max_val7 = np.max(pred)\n",
        "    avg[7] = avg[7] + max_val7\n",
        "    count[7] = count[7] + 1\n",
        "  if not lbl == 9:\n",
        "    logits = model_dict[8](img)\n",
        "    logits = tf.math.divide(logits, temp_val[8])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e8 = entropy(pred[0])\n",
        "    entropy_list[8] = entropy_list[8] + e8\n",
        "    max_val8 = np.max(pred)\n",
        "    avg[8] = avg[8] + max_val8\n",
        "    count[8] = count[8] + 1\n",
        "\n",
        "print(avg)\n",
        "print(count)\n",
        "print(entropy_list)\n",
        "\n",
        "entropy_avg_t = [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]\n",
        "for i in range(9):\n",
        "  entropy_avg_t[i] = entropy_list[i]/count[i]\n",
        "\n",
        "entropy_value_t = 0.0\n",
        "for i in range(9):\n",
        "  entropy_value_t = entropy_value_t + entropy_avg_t[i]\n",
        "\n",
        "entropy_t = entropy_value_t/len(entropy_avg_t)\n",
        "\n",
        "print('Entropy:', entropy_t)\n",
        "\n",
        "classifier_avg_t = [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]\n",
        "for i in range(9):\n",
        "  classifier_avg_t[i] = avg[i]/count[i]\n",
        "\n",
        "print('Each Classifier Average: ',classifier_avg_t)\n",
        "\n",
        "treshold_value = 0.0\n",
        "for i in range(9):\n",
        "  treshold_value = treshold_value + classifier_avg_t[i]\n",
        "\n",
        "treshold_t = treshold_value/len(classifier_avg_t)\n",
        "\n",
        "print('Threshold:', treshold_t)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "826it [01:01, 13.73it/s]\u001b[A\n",
            "828it [01:01, 13.85it/s]\u001b[A\n",
            "830it [01:02, 14.07it/s]\u001b[A\n",
            "832it [01:02, 14.12it/s]\u001b[A\n",
            "834it [01:02, 13.30it/s]\u001b[A\n",
            "836it [01:02, 12.95it/s]\u001b[A\n",
            "838it [01:02, 12.67it/s]\u001b[A\n",
            "840it [01:02, 13.07it/s]\u001b[A\n",
            "842it [01:02, 13.19it/s]\u001b[A\n",
            "844it [01:03, 13.46it/s]\u001b[A\n",
            "846it [01:03, 13.78it/s]\u001b[A\n",
            "848it [01:03, 14.00it/s]\u001b[A\n",
            "850it [01:03, 13.91it/s]\u001b[A\n",
            "852it [01:03, 13.99it/s]\u001b[A\n",
            "854it [01:03, 13.79it/s]\u001b[A\n",
            "856it [01:04, 13.63it/s]\u001b[A\n",
            "858it [01:04, 13.88it/s]\u001b[A\n",
            "860it [01:04, 13.75it/s]\u001b[A\n",
            "862it [01:04, 13.96it/s]\u001b[A\n",
            "864it [01:04, 14.14it/s]\u001b[A\n",
            "866it [01:04, 14.05it/s]\u001b[A\n",
            "868it [01:04, 14.02it/s]\u001b[A\n",
            "870it [01:04, 14.04it/s]\u001b[A\n",
            "872it [01:05, 14.19it/s]\u001b[A\n",
            "874it [01:05, 14.03it/s]\u001b[A\n",
            "876it [01:05, 13.80it/s]\u001b[A\n",
            "878it [01:05, 13.26it/s]\u001b[A\n",
            "880it [01:05, 12.80it/s]\u001b[A\n",
            "882it [01:05, 13.07it/s]\u001b[A\n",
            "884it [01:06, 13.18it/s]\u001b[A\n",
            "886it [01:06, 13.36it/s]\u001b[A\n",
            "888it [01:06, 13.29it/s]\u001b[A\n",
            "890it [01:06, 13.59it/s]\u001b[A\n",
            "892it [01:06, 13.76it/s]\u001b[A\n",
            "894it [01:06, 13.83it/s]\u001b[A\n",
            "896it [01:06, 13.65it/s]\u001b[A\n",
            "898it [01:07, 13.89it/s]\u001b[A\n",
            "900it [01:07, 14.00it/s]\u001b[A\n",
            "902it [01:07, 14.02it/s]\u001b[A\n",
            "904it [01:07, 13.86it/s]\u001b[A\n",
            "906it [01:07, 14.02it/s]\u001b[A\n",
            "908it [01:07, 13.93it/s]\u001b[A\n",
            "910it [01:07, 13.99it/s]\u001b[A\n",
            "912it [01:08, 13.99it/s]\u001b[A\n",
            "914it [01:08, 13.46it/s]\u001b[A\n",
            "916it [01:08, 13.48it/s]\u001b[A\n",
            "918it [01:08, 13.69it/s]\u001b[A\n",
            "920it [01:08, 13.59it/s]\u001b[A\n",
            "922it [01:08, 13.24it/s]\u001b[A\n",
            "924it [01:08, 12.89it/s]\u001b[A\n",
            "926it [01:09, 12.74it/s]\u001b[A\n",
            "928it [01:09, 12.55it/s]\u001b[A\n",
            "930it [01:09, 12.46it/s]\u001b[A\n",
            "932it [01:09, 12.44it/s]\u001b[A\n",
            "934it [01:09, 12.44it/s]\u001b[A\n",
            "936it [01:09, 12.68it/s]\u001b[A\n",
            "938it [01:10, 12.70it/s]\u001b[A\n",
            "940it [01:10, 13.12it/s]\u001b[A\n",
            "942it [01:10, 13.49it/s]\u001b[A\n",
            "944it [01:10, 13.10it/s]\u001b[A\n",
            "946it [01:10, 12.86it/s]\u001b[A\n",
            "948it [01:10, 12.60it/s]\u001b[A\n",
            "950it [01:11, 12.96it/s]\u001b[A\n",
            "952it [01:11, 13.14it/s]\u001b[A\n",
            "954it [01:11, 13.39it/s]\u001b[A\n",
            "956it [01:11, 12.83it/s]\u001b[A\n",
            "958it [01:11, 12.72it/s]\u001b[A\n",
            "960it [01:11, 12.69it/s]\u001b[A\n",
            "962it [01:11, 13.16it/s]\u001b[A\n",
            "964it [01:12, 13.01it/s]\u001b[A\n",
            "966it [01:12, 12.88it/s]\u001b[A\n",
            "968it [01:12, 13.14it/s]\u001b[A\n",
            "970it [01:12, 13.35it/s]\u001b[A\n",
            "972it [01:12, 13.36it/s]\u001b[A\n",
            "974it [01:12, 13.24it/s]\u001b[A\n",
            "976it [01:12, 13.51it/s]\u001b[A\n",
            "978it [01:13, 13.78it/s]\u001b[A\n",
            "980it [01:13, 13.40it/s]\u001b[A\n",
            "982it [01:13, 13.26it/s]\u001b[A\n",
            "984it [01:13, 12.91it/s]\u001b[A\n",
            "986it [01:13, 12.70it/s]\u001b[A\n",
            "988it [01:13, 12.30it/s]\u001b[A\n",
            "990it [01:14, 12.83it/s]\u001b[A\n",
            "992it [01:14, 13.12it/s]\u001b[A\n",
            "994it [01:14, 13.42it/s]\u001b[A\n",
            "996it [01:14, 13.66it/s]\u001b[A\n",
            "998it [01:14, 13.90it/s]\u001b[A\n",
            "1000it [01:14, 13.98it/s]\u001b[A\n",
            "1002it [01:14, 13.83it/s]\u001b[A\n",
            "1004it [01:15, 14.00it/s]\u001b[A\n",
            "1006it [01:15, 14.00it/s]\u001b[A\n",
            "1008it [01:15, 13.49it/s]\u001b[A\n",
            "1010it [01:15, 13.45it/s]\u001b[A\n",
            "1012it [01:15, 13.28it/s]\u001b[A\n",
            "1014it [01:15, 13.45it/s]\u001b[A\n",
            "1016it [01:15, 13.63it/s]\u001b[A\n",
            "1018it [01:16, 13.77it/s]\u001b[A\n",
            "1020it [01:16, 13.71it/s]\u001b[A\n",
            "1022it [01:16, 13.47it/s]\u001b[A\n",
            "1024it [01:16, 13.69it/s]\u001b[A\n",
            "1026it [01:16, 13.69it/s]\u001b[A\n",
            "1028it [01:16, 13.52it/s]\u001b[A\n",
            "1030it [01:16, 13.76it/s]\u001b[A\n",
            "1032it [01:17, 13.83it/s]\u001b[A\n",
            "1034it [01:17, 13.94it/s]\u001b[A\n",
            "1036it [01:17, 13.77it/s]\u001b[A\n",
            "1038it [01:17, 13.94it/s]\u001b[A\n",
            "1040it [01:17, 13.93it/s]\u001b[A\n",
            "1042it [01:17, 13.90it/s]\u001b[A\n",
            "1044it [01:18, 13.93it/s]\u001b[A\n",
            "1046it [01:18, 13.80it/s]\u001b[A\n",
            "1048it [01:18, 13.41it/s]\u001b[A\n",
            "1050it [01:18, 13.46it/s]\u001b[A\n",
            "1052it [01:18, 13.52it/s]\u001b[A\n",
            "1054it [01:18, 13.53it/s]\u001b[A\n",
            "1056it [01:18, 13.52it/s]\u001b[A\n",
            "1058it [01:19, 13.77it/s]\u001b[A\n",
            "1060it [01:19, 13.78it/s]\u001b[A\n",
            "1062it [01:19, 13.71it/s]\u001b[A\n",
            "1064it [01:19, 13.78it/s]\u001b[A\n",
            "1066it [01:19, 13.95it/s]\u001b[A\n",
            "1068it [01:19, 13.97it/s]\u001b[A\n",
            "1070it [01:19, 13.90it/s]\u001b[A\n",
            "1072it [01:20, 14.01it/s]\u001b[A\n",
            "1074it [01:20, 13.62it/s]\u001b[A\n",
            "1076it [01:20, 13.39it/s]\u001b[A\n",
            "1078it [01:20, 13.58it/s]\u001b[A\n",
            "1080it [01:20, 13.24it/s]\u001b[A\n",
            "1082it [01:20, 13.18it/s]\u001b[A\n",
            "1084it [01:20, 13.14it/s]\u001b[A\n",
            "1086it [01:21, 13.43it/s]\u001b[A\n",
            "1088it [01:21, 13.36it/s]\u001b[A\n",
            "1090it [01:21, 13.54it/s]\u001b[A\n",
            "1092it [01:21, 13.75it/s]\u001b[A\n",
            "1094it [01:21, 13.80it/s]\u001b[A\n",
            "1096it [01:21, 13.68it/s]\u001b[A\n",
            "1098it [01:21, 13.10it/s]\u001b[A\n",
            "1100it [01:22, 12.93it/s]\u001b[A\n",
            "1102it [01:22, 13.11it/s]\u001b[A\n",
            "1104it [01:22, 13.21it/s]\u001b[A\n",
            "1106it [01:22, 13.56it/s]\u001b[A\n",
            "1108it [01:22, 13.78it/s]\u001b[A\n",
            "1110it [01:22, 13.95it/s]\u001b[A\n",
            "1112it [01:23, 14.00it/s]\u001b[A\n",
            "1114it [01:23, 14.12it/s]\u001b[A\n",
            "1116it [01:23, 13.80it/s]\u001b[A\n",
            "1118it [01:23, 13.95it/s]\u001b[A\n",
            "1120it [01:23, 14.06it/s]\u001b[A\n",
            "1122it [01:23, 14.22it/s]\u001b[A\n",
            "1124it [01:23, 14.19it/s]\u001b[A\n",
            "1126it [01:24, 13.81it/s]\u001b[A\n",
            "1128it [01:24, 13.77it/s]\u001b[A\n",
            "1130it [01:24, 13.91it/s]\u001b[A\n",
            "1132it [01:24, 14.03it/s]\u001b[A\n",
            "1134it [01:24, 14.16it/s]\u001b[A\n",
            "1136it [01:24, 14.23it/s]\u001b[A\n",
            "1138it [01:24, 14.33it/s]\u001b[A\n",
            "1140it [01:25, 14.03it/s]\u001b[A\n",
            "1142it [01:25, 13.94it/s]\u001b[A\n",
            "1144it [01:25, 14.00it/s]\u001b[A\n",
            "1146it [01:25, 14.04it/s]\u001b[A\n",
            "1148it [01:25, 13.81it/s]\u001b[A\n",
            "1150it [01:25, 13.27it/s]\u001b[A\n",
            "1152it [01:25, 13.42it/s]\u001b[A\n",
            "1154it [01:26, 12.71it/s]\u001b[A\n",
            "1156it [01:26, 13.19it/s]\u001b[A\n",
            "1158it [01:26, 13.34it/s]\u001b[A\n",
            "1160it [01:26, 13.47it/s]\u001b[A\n",
            "1162it [01:26, 13.67it/s]\u001b[A\n",
            "1164it [01:26, 13.86it/s]\u001b[A\n",
            "1166it [01:26, 13.71it/s]\u001b[A\n",
            "1168it [01:27, 13.74it/s]\u001b[A\n",
            "1170it [01:27, 13.66it/s]\u001b[A\n",
            "1172it [01:27, 13.56it/s]\u001b[A\n",
            "1174it [01:27, 13.72it/s]\u001b[A\n",
            "1176it [01:27, 13.96it/s]\u001b[A\n",
            "1178it [01:27, 13.75it/s]\u001b[A\n",
            "1180it [01:27, 13.30it/s]\u001b[A\n",
            "1182it [01:28, 13.16it/s]\u001b[A\n",
            "1184it [01:28, 12.93it/s]\u001b[A\n",
            "1186it [01:28, 13.28it/s]\u001b[A\n",
            "1188it [01:28, 13.15it/s]\u001b[A\n",
            "1190it [01:28, 13.40it/s]\u001b[A\n",
            "1192it [01:28, 13.40it/s]\u001b[A\n",
            "1194it [01:29, 13.27it/s]\u001b[A\n",
            "1196it [01:29, 12.91it/s]\u001b[A\n",
            "1198it [01:29, 12.69it/s]\u001b[A\n",
            "1200it [01:29, 13.10it/s]\u001b[A\n",
            "1202it [01:29, 13.11it/s]\u001b[A\n",
            "1204it [01:29, 13.44it/s]\u001b[A\n",
            "1206it [01:29, 13.36it/s]\u001b[A\n",
            "1208it [01:30, 12.90it/s]\u001b[A\n",
            "1210it [01:30, 13.14it/s]\u001b[A\n",
            "1212it [01:30, 13.19it/s]\u001b[A\n",
            "1214it [01:30, 13.47it/s]\u001b[A\n",
            "1216it [01:30, 13.18it/s]\u001b[A\n",
            "1218it [01:30, 13.20it/s]\u001b[A\n",
            "1220it [01:31, 13.25it/s]\u001b[A\n",
            "1222it [01:31, 13.43it/s]\u001b[A\n",
            "1224it [01:31, 13.08it/s]\u001b[A\n",
            "1226it [01:31, 12.72it/s]\u001b[A\n",
            "1228it [01:31, 12.56it/s]\u001b[A\n",
            "1230it [01:31, 12.65it/s]\u001b[A\n",
            "1232it [01:31, 12.50it/s]\u001b[A\n",
            "1234it [01:32, 12.24it/s]\u001b[A\n",
            "1236it [01:32, 12.10it/s]\u001b[A\n",
            "1238it [01:32, 12.51it/s]\u001b[A\n",
            "1240it [01:32, 13.07it/s]\u001b[A\n",
            "1242it [01:32, 13.23it/s]\u001b[A\n",
            "1244it [01:32, 13.41it/s]\u001b[A\n",
            "1246it [01:33, 13.57it/s]\u001b[A\n",
            "1248it [01:33, 13.57it/s]\u001b[A\n",
            "1250it [01:33, 13.57it/s]\u001b[A\n",
            "1252it [01:33, 13.66it/s]\u001b[A\n",
            "1254it [01:33, 13.84it/s]\u001b[A\n",
            "1256it [01:33, 13.40it/s]\u001b[A\n",
            "1258it [01:33, 13.60it/s]\u001b[A\n",
            "1260it [01:34, 13.60it/s]\u001b[A\n",
            "1262it [01:34, 13.19it/s]\u001b[A\n",
            "1264it [01:34, 13.36it/s]\u001b[A\n",
            "1266it [01:34, 13.58it/s]\u001b[A\n",
            "1268it [01:34, 13.55it/s]\u001b[A\n",
            "1270it [01:34, 13.68it/s]\u001b[A\n",
            "1272it [01:34, 13.53it/s]\u001b[A\n",
            "1274it [01:35, 13.41it/s]\u001b[A\n",
            "1276it [01:35, 13.05it/s]\u001b[A\n",
            "1278it [01:35, 13.03it/s]\u001b[A\n",
            "1280it [01:35, 13.39it/s]\u001b[A\n",
            "1282it [01:35, 13.51it/s]\u001b[A\n",
            "1284it [01:35, 13.39it/s]\u001b[A\n",
            "1286it [01:35, 13.54it/s]\u001b[A\n",
            "1288it [01:36, 13.53it/s]\u001b[A\n",
            "1290it [01:36, 13.30it/s]\u001b[A\n",
            "1292it [01:36, 13.58it/s]\u001b[A\n",
            "1294it [01:36, 13.47it/s]\u001b[A\n",
            "1296it [01:36, 13.61it/s]\u001b[A\n",
            "1298it [01:36, 13.75it/s]\u001b[A\n",
            "1300it [01:37, 14.00it/s]\u001b[A\n",
            "1302it [01:37, 14.01it/s]\u001b[A\n",
            "1304it [01:37, 13.84it/s]\u001b[A\n",
            "1306it [01:37, 14.04it/s]\u001b[A\n",
            "1308it [01:37, 14.17it/s]\u001b[A\n",
            "1310it [01:37, 14.15it/s]\u001b[A\n",
            "1312it [01:37, 14.25it/s]\u001b[A\n",
            "1314it [01:38, 14.00it/s]\u001b[A\n",
            "1316it [01:38, 13.97it/s]\u001b[A\n",
            "1318it [01:38, 13.43it/s]\u001b[A\n",
            "1320it [01:38, 13.69it/s]\u001b[A\n",
            "1322it [01:38, 13.93it/s]\u001b[A\n",
            "1324it [01:38, 13.81it/s]\u001b[A\n",
            "1326it [01:38, 13.82it/s]\u001b[A\n",
            "1328it [01:39, 14.04it/s]\u001b[A\n",
            "1330it [01:39, 13.85it/s]\u001b[A\n",
            "1332it [01:39, 13.91it/s]\u001b[A\n",
            "1334it [01:39, 13.93it/s]\u001b[A\n",
            "1336it [01:39, 13.98it/s]\u001b[A\n",
            "1338it [01:39, 13.79it/s]\u001b[A\n",
            "1340it [01:39, 13.98it/s]\u001b[A\n",
            "1342it [01:40, 13.99it/s]\u001b[A\n",
            "1344it [01:40, 14.03it/s]\u001b[A\n",
            "1346it [01:40, 14.16it/s]\u001b[A\n",
            "1348it [01:40, 13.78it/s]\u001b[A\n",
            "1350it [01:40, 13.27it/s]\u001b[A\n",
            "1352it [01:40, 12.90it/s]\u001b[A\n",
            "1354it [01:40, 12.77it/s]\u001b[A\n",
            "1356it [01:41, 12.38it/s]\u001b[A\n",
            "1358it [01:41, 12.14it/s]\u001b[A\n",
            "1360it [01:41, 12.06it/s]\u001b[A\n",
            "1362it [01:41, 12.06it/s]\u001b[A\n",
            "1364it [01:41, 12.07it/s]\u001b[A\n",
            "1366it [01:41, 12.05it/s]\u001b[A\n",
            "1368it [01:42, 11.85it/s]\u001b[A\n",
            "1370it [01:42, 12.04it/s]\u001b[A\n",
            "1372it [01:42, 12.40it/s]\u001b[A\n",
            "1374it [01:42, 12.87it/s]\u001b[A\n",
            "1376it [01:42, 13.21it/s]\u001b[A\n",
            "1378it [01:42, 13.35it/s]\u001b[A\n",
            "1380it [01:43, 13.62it/s]\u001b[A\n",
            "1382it [01:43, 13.41it/s]\u001b[A\n",
            "1384it [01:43, 13.59it/s]\u001b[A\n",
            "1386it [01:43, 13.06it/s]\u001b[A\n",
            "1388it [01:43, 12.83it/s]\u001b[A\n",
            "1390it [01:43, 12.96it/s]\u001b[A\n",
            "1392it [01:43, 13.25it/s]\u001b[A\n",
            "1394it [01:44, 13.22it/s]\u001b[A\n",
            "1396it [01:44, 13.39it/s]\u001b[A\n",
            "1398it [01:44, 12.77it/s]\u001b[A\n",
            "1400it [01:44, 13.07it/s]\u001b[A\n",
            "1402it [01:44, 13.41it/s]\u001b[A\n",
            "1404it [01:44, 13.51it/s]\u001b[A\n",
            "1406it [01:44, 13.65it/s]\u001b[A\n",
            "1408it [01:45, 13.77it/s]\u001b[A\n",
            "1410it [01:45, 13.73it/s]\u001b[A\n",
            "1412it [01:45, 13.27it/s]\u001b[A\n",
            "1414it [01:45, 12.68it/s]\u001b[A\n",
            "1416it [01:45, 13.11it/s]\u001b[A\n",
            "1418it [01:45, 13.25it/s]\u001b[A\n",
            "1420it [01:46, 13.48it/s]\u001b[A\n",
            "1422it [01:46, 13.38it/s]\u001b[A\n",
            "1424it [01:46, 12.51it/s]\u001b[A\n",
            "1426it [01:46, 11.87it/s]\u001b[A\n",
            "1428it [01:46, 12.06it/s]\u001b[A\n",
            "1430it [01:46, 11.91it/s]\u001b[A\n",
            "1432it [01:47, 11.78it/s]\u001b[A\n",
            "1434it [01:47, 11.94it/s]\u001b[A\n",
            "1436it [01:47, 12.29it/s]\u001b[A\n",
            "1438it [01:47, 12.77it/s]\u001b[A\n",
            "1440it [01:47, 13.20it/s]\u001b[A\n",
            "1442it [01:47, 13.34it/s]\u001b[A\n",
            "1444it [01:47, 13.03it/s]\u001b[A\n",
            "1446it [01:48, 12.96it/s]\u001b[A\n",
            "1448it [01:48, 13.02it/s]\u001b[A\n",
            "1450it [01:48, 12.71it/s]\u001b[A\n",
            "1452it [01:48, 12.91it/s]\u001b[A\n",
            "1454it [01:48, 12.85it/s]\u001b[A\n",
            "1456it [01:48, 12.35it/s]\u001b[A\n",
            "1458it [01:49, 12.31it/s]\u001b[A\n",
            "1460it [01:49, 12.11it/s]\u001b[A\n",
            "1462it [01:49, 12.51it/s]\u001b[A\n",
            "1464it [01:49, 12.85it/s]\u001b[A\n",
            "1466it [01:49, 13.19it/s]\u001b[A\n",
            "1468it [01:49, 12.83it/s]\u001b[A\n",
            "1470it [01:50, 13.11it/s]\u001b[A\n",
            "1472it [01:50, 13.31it/s]\u001b[A\n",
            "1474it [01:50, 13.25it/s]\u001b[A\n",
            "1476it [01:50, 13.29it/s]\u001b[A\n",
            "1478it [01:50, 13.42it/s]\u001b[A\n",
            "1480it [01:50, 13.71it/s]\u001b[A\n",
            "1482it [01:50, 13.81it/s]\u001b[A\n",
            "1484it [01:51, 13.89it/s]\u001b[A\n",
            "1486it [01:51, 13.53it/s]\u001b[A\n",
            "1488it [01:51, 13.03it/s]\u001b[A\n",
            "1490it [01:51, 13.44it/s]\u001b[A\n",
            "1492it [01:51, 13.46it/s]\u001b[A\n",
            "1494it [01:51, 13.72it/s]\u001b[A\n",
            "1496it [01:51, 13.89it/s]\u001b[A\n",
            "1498it [01:52, 13.84it/s]\u001b[A\n",
            "1500it [01:52, 13.49it/s]\u001b[A\n",
            "1502it [01:52, 13.38it/s]\u001b[A\n",
            "1504it [01:52, 13.44it/s]\u001b[A\n",
            "1506it [01:52, 13.64it/s]\u001b[A\n",
            "1508it [01:52, 13.54it/s]\u001b[A\n",
            "1510it [01:52, 13.70it/s]\u001b[A\n",
            "1512it [01:53, 13.66it/s]\u001b[A\n",
            "1514it [01:53, 13.69it/s]\u001b[A\n",
            "1516it [01:53, 13.39it/s]\u001b[A\n",
            "1518it [01:53, 12.84it/s]\u001b[A\n",
            "1520it [01:53, 12.56it/s]\u001b[A\n",
            "1522it [01:53, 12.66it/s]\u001b[A\n",
            "1524it [01:54, 12.58it/s]\u001b[A\n",
            "1526it [01:54, 12.83it/s]\u001b[A\n",
            "1528it [01:54, 12.54it/s]\u001b[A\n",
            "1530it [01:54, 12.89it/s]\u001b[A\n",
            "1532it [01:54, 13.06it/s]\u001b[A\n",
            "1534it [01:54, 13.42it/s]\u001b[A\n",
            "1536it [01:54, 13.61it/s]\u001b[A\n",
            "1538it [01:55, 13.84it/s]\u001b[A\n",
            "1540it [01:55, 13.80it/s]\u001b[A\n",
            "1542it [01:55, 13.51it/s]\u001b[A\n",
            "1544it [01:55, 13.72it/s]\u001b[A\n",
            "1546it [01:55, 13.80it/s]\u001b[A\n",
            "1548it [01:55, 13.74it/s]\u001b[A\n",
            "1550it [01:55, 13.80it/s]\u001b[A\n",
            "1552it [01:56, 13.91it/s]\u001b[A\n",
            "1554it [01:56, 13.97it/s]\u001b[A\n",
            "1556it [01:56, 13.35it/s]\u001b[A\n",
            "1558it [01:56, 12.59it/s]\u001b[A\n",
            "1560it [01:56, 12.49it/s]\u001b[A\n",
            "1562it [01:56, 12.33it/s]\u001b[A\n",
            "1564it [01:57, 12.34it/s]\u001b[A\n",
            "1566it [01:57, 12.62it/s]\u001b[A\n",
            "1568it [01:57, 12.29it/s]\u001b[A\n",
            "1570it [01:57, 12.77it/s]\u001b[A\n",
            "1572it [01:57, 13.09it/s]\u001b[A\n",
            "1574it [01:57, 13.50it/s]\u001b[A\n",
            "1576it [01:57, 13.55it/s]\u001b[A\n",
            "1578it [01:58, 13.49it/s]\u001b[A\n",
            "1580it [01:58, 13.71it/s]\u001b[A\n",
            "1582it [01:58, 13.59it/s]\u001b[A\n",
            "1584it [01:58, 13.60it/s]\u001b[A\n",
            "1586it [01:58, 13.73it/s]\u001b[A\n",
            "1588it [01:58, 13.40it/s]\u001b[A\n",
            "1590it [01:58, 13.64it/s]\u001b[A\n",
            "1592it [01:59, 13.86it/s]\u001b[A\n",
            "1594it [01:59, 13.94it/s]\u001b[A\n",
            "1596it [01:59, 13.76it/s]\u001b[A\n",
            "1598it [01:59, 13.86it/s]\u001b[A\n",
            "1600it [01:59, 14.02it/s]\u001b[A\n",
            "1602it [01:59, 13.90it/s]\u001b[A\n",
            "1604it [01:59, 13.91it/s]\u001b[A\n",
            "1606it [02:00, 13.68it/s]\u001b[A\n",
            "1608it [02:00, 13.81it/s]\u001b[A\n",
            "1610it [02:00, 13.51it/s]\u001b[A\n",
            "1612it [02:00, 13.10it/s]\u001b[A\n",
            "1614it [02:00, 13.09it/s]\u001b[A\n",
            "1616it [02:00, 12.98it/s]\u001b[A\n",
            "1618it [02:01, 13.37it/s]\u001b[A\n",
            "1620it [02:01, 13.59it/s]\u001b[A\n",
            "1622it [02:01, 13.75it/s]\u001b[A\n",
            "1624it [02:01, 13.58it/s]\u001b[A\n",
            "1626it [02:01, 13.57it/s]\u001b[A\n",
            "1628it [02:01, 13.42it/s]\u001b[A\n",
            "1630it [02:01, 13.51it/s]\u001b[A\n",
            "1632it [02:02, 13.62it/s]\u001b[A\n",
            "1634it [02:02, 13.72it/s]\u001b[A\n",
            "1636it [02:02, 13.33it/s]\u001b[A\n",
            "1638it [02:02, 13.25it/s]\u001b[A\n",
            "1640it [02:02, 13.47it/s]\u001b[A\n",
            "1642it [02:02, 13.65it/s]\u001b[A\n",
            "1644it [02:02, 13.86it/s]\u001b[A\n",
            "1646it [02:03, 13.71it/s]\u001b[A\n",
            "1648it [02:03, 13.89it/s]\u001b[A\n",
            "1650it [02:03, 13.92it/s]\u001b[A\n",
            "1652it [02:03, 13.80it/s]\u001b[A\n",
            "1654it [02:03, 12.84it/s]\u001b[A\n",
            "1656it [02:03, 12.33it/s]\u001b[A\n",
            "1658it [02:04, 12.13it/s]\u001b[A\n",
            "1660it [02:04, 12.58it/s]\u001b[A\n",
            "1662it [02:04, 12.87it/s]\u001b[A\n",
            "1664it [02:04, 12.41it/s]\u001b[A\n",
            "1666it [02:04, 12.40it/s]\u001b[A\n",
            "1668it [02:04, 12.33it/s]\u001b[A\n",
            "1670it [02:05, 12.28it/s]\u001b[A\n",
            "1672it [02:05, 12.28it/s]\u001b[A\n",
            "1674it [02:05, 12.72it/s]\u001b[A\n",
            "1676it [02:05, 12.73it/s]\u001b[A\n",
            "1678it [02:05, 12.50it/s]\u001b[A\n",
            "1680it [02:05, 12.55it/s]\u001b[A\n",
            "1682it [02:05, 12.18it/s]\u001b[A\n",
            "1684it [02:06, 12.22it/s]\u001b[A\n",
            "1686it [02:06, 12.20it/s]\u001b[A\n",
            "1688it [02:06, 12.49it/s]\u001b[A\n",
            "1690it [02:06, 12.66it/s]\u001b[A\n",
            "1692it [02:06, 12.79it/s]\u001b[A\n",
            "1694it [02:06, 12.45it/s]\u001b[A\n",
            "1696it [02:07, 12.37it/s]\u001b[A\n",
            "1698it [02:07, 12.32it/s]\u001b[A\n",
            "1700it [02:07, 12.31it/s]\u001b[A\n",
            "1702it [02:07, 11.94it/s]\u001b[A\n",
            "1704it [02:07, 12.30it/s]\u001b[A\n",
            "1706it [02:07, 12.50it/s]\u001b[A\n",
            "1708it [02:08, 12.58it/s]\u001b[A\n",
            "1710it [02:08, 12.87it/s]\u001b[A\n",
            "1712it [02:08, 12.58it/s]\u001b[A\n",
            "1714it [02:08, 12.86it/s]\u001b[A\n",
            "1716it [02:08, 12.87it/s]\u001b[A\n",
            "1718it [02:08, 13.03it/s]\u001b[A\n",
            "1720it [02:08, 13.24it/s]\u001b[A\n",
            "1722it [02:09, 13.05it/s]\u001b[A\n",
            "1724it [02:09, 12.96it/s]\u001b[A\n",
            "1726it [02:09, 13.38it/s]\u001b[A\n",
            "1728it [02:09, 13.51it/s]\u001b[A\n",
            "1730it [02:09, 13.60it/s]\u001b[A\n",
            "1732it [02:09, 13.64it/s]\u001b[A\n",
            "1734it [02:10, 13.74it/s]\u001b[A\n",
            "1736it [02:10, 13.89it/s]\u001b[A\n",
            "1738it [02:10, 13.79it/s]\u001b[A\n",
            "1740it [02:10, 13.14it/s]\u001b[A\n",
            "1742it [02:10, 12.74it/s]\u001b[A\n",
            "1744it [02:10, 13.09it/s]\u001b[A\n",
            "1746it [02:10, 13.40it/s]\u001b[A\n",
            "1748it [02:11, 13.52it/s]\u001b[A\n",
            "1750it [02:11, 13.65it/s]\u001b[A\n",
            "1752it [02:11, 13.82it/s]\u001b[A\n",
            "1754it [02:11, 13.89it/s]\u001b[A\n",
            "1756it [02:11, 13.48it/s]\u001b[A\n",
            "1758it [02:11, 13.53it/s]\u001b[A\n",
            "1760it [02:11, 12.87it/s]\u001b[A\n",
            "1762it [02:12, 12.59it/s]\u001b[A\n",
            "1764it [02:12, 12.56it/s]\u001b[A\n",
            "1766it [02:12, 12.37it/s]\u001b[A\n",
            "1768it [02:12, 12.17it/s]\u001b[A\n",
            "1770it [02:12, 12.65it/s]\u001b[A\n",
            "1772it [02:12, 12.89it/s]\u001b[A\n",
            "1774it [02:13, 12.85it/s]\u001b[A\n",
            "1776it [02:13, 13.19it/s]\u001b[A\n",
            "1778it [02:13, 13.46it/s]\u001b[A\n",
            "1780it [02:13, 13.69it/s]\u001b[A\n",
            "1782it [02:13, 13.34it/s]\u001b[A\n",
            "1784it [02:13, 13.67it/s]\u001b[A\n",
            "1786it [02:13, 13.73it/s]\u001b[A\n",
            "1788it [02:14, 13.91it/s]\u001b[A\n",
            "1790it [02:14, 13.92it/s]\u001b[A\n",
            "1792it [02:14, 13.87it/s]\u001b[A\n",
            "1794it [02:14, 13.98it/s]\u001b[A\n",
            "1796it [02:14, 13.83it/s]\u001b[A\n",
            "1798it [02:14, 13.98it/s]\u001b[A\n",
            "1800it [02:14, 13.79it/s]\u001b[A\n",
            "1802it [02:15, 13.96it/s]\u001b[A\n",
            "1804it [02:15, 13.72it/s]\u001b[A\n",
            "1806it [02:15, 13.55it/s]\u001b[A\n",
            "1808it [02:15, 13.53it/s]\u001b[A\n",
            "1810it [02:15, 13.45it/s]\u001b[A\n",
            "1812it [02:15, 13.52it/s]\u001b[A\n",
            "1814it [02:15, 13.58it/s]\u001b[A\n",
            "1816it [02:16, 13.47it/s]\u001b[A\n",
            "1818it [02:16, 13.59it/s]\u001b[A\n",
            "1820it [02:16, 13.72it/s]\u001b[A\n",
            "1822it [02:16, 13.78it/s]\u001b[A\n",
            "1824it [02:16, 13.48it/s]\u001b[A\n",
            "1826it [02:16, 13.47it/s]\u001b[A\n",
            "1828it [02:17, 13.47it/s]\u001b[A\n",
            "1830it [02:17, 13.64it/s]\u001b[A\n",
            "1832it [02:17, 13.48it/s]\u001b[A\n",
            "1834it [02:17, 13.40it/s]\u001b[A\n",
            "1836it [02:17, 13.64it/s]\u001b[A\n",
            "1838it [02:17, 13.71it/s]\u001b[A\n",
            "1840it [02:17, 13.88it/s]\u001b[A\n",
            "1842it [02:18, 13.68it/s]\u001b[A\n",
            "1844it [02:18, 13.83it/s]\u001b[A\n",
            "1846it [02:18, 13.88it/s]\u001b[A\n",
            "1848it [02:18, 13.62it/s]\u001b[A\n",
            "1850it [02:18, 12.78it/s]\u001b[A\n",
            "1852it [02:18, 13.03it/s]\u001b[A\n",
            "1854it [02:18, 13.03it/s]\u001b[A\n",
            "1856it [02:19, 13.34it/s]\u001b[A\n",
            "1858it [02:19, 13.18it/s]\u001b[A\n",
            "1860it [02:19, 13.17it/s]\u001b[A\n",
            "1862it [02:19, 12.94it/s]\u001b[A\n",
            "1864it [02:19, 12.69it/s]\u001b[A\n",
            "1866it [02:19, 13.09it/s]\u001b[A\n",
            "1868it [02:20, 13.22it/s]\u001b[A\n",
            "1870it [02:20, 13.40it/s]\u001b[A\n",
            "1872it [02:20, 13.71it/s]\u001b[A\n",
            "1874it [02:20, 13.47it/s]\u001b[A\n",
            "1876it [02:20, 13.23it/s]\u001b[A\n",
            "1878it [02:20, 12.79it/s]\u001b[A\n",
            "1880it [02:20, 13.09it/s]\u001b[A\n",
            "1882it [02:21, 13.23it/s]\u001b[A\n",
            "1884it [02:21, 12.77it/s]\u001b[A\n",
            "1886it [02:21, 12.71it/s]\u001b[A\n",
            "1888it [02:21, 12.62it/s]\u001b[A\n",
            "1890it [02:21, 12.52it/s]\u001b[A\n",
            "1892it [02:21, 12.69it/s]\u001b[A\n",
            "1894it [02:22, 12.94it/s]\u001b[A\n",
            "1896it [02:22, 13.00it/s]\u001b[A\n",
            "1898it [02:22, 13.22it/s]\u001b[A\n",
            "1900it [02:22, 13.24it/s]\u001b[A\n",
            "1902it [02:22, 13.27it/s]\u001b[A\n",
            "1904it [02:22, 13.34it/s]\u001b[A\n",
            "1906it [02:22, 13.50it/s]\u001b[A\n",
            "1908it [02:23, 13.50it/s]\u001b[A\n",
            "1910it [02:23, 13.15it/s]\u001b[A\n",
            "1912it [02:23, 13.07it/s]\u001b[A\n",
            "1914it [02:23, 12.82it/s]\u001b[A\n",
            "1916it [02:23, 12.37it/s]\u001b[A\n",
            "1918it [02:23, 12.30it/s]\u001b[A\n",
            "1920it [02:24, 12.19it/s]\u001b[A\n",
            "1922it [02:24, 12.46it/s]\u001b[A\n",
            "1924it [02:24, 12.61it/s]\u001b[A\n",
            "1926it [02:24, 12.95it/s]\u001b[A\n",
            "1928it [02:24, 13.30it/s]\u001b[A\n",
            "1930it [02:24, 13.39it/s]\u001b[A\n",
            "1932it [02:24, 13.59it/s]\u001b[A\n",
            "1934it [02:25, 13.44it/s]\u001b[A\n",
            "1936it [02:25, 13.51it/s]\u001b[A\n",
            "1938it [02:25, 13.69it/s]\u001b[A\n",
            "1940it [02:25, 13.77it/s]\u001b[A\n",
            "1942it [02:25, 13.62it/s]\u001b[A\n",
            "1944it [02:25, 13.65it/s]\u001b[A\n",
            "1946it [02:25, 13.28it/s]\u001b[A\n",
            "1948it [02:26, 13.60it/s]\u001b[A\n",
            "1950it [02:26, 13.50it/s]\u001b[A\n",
            "1952it [02:26, 13.32it/s]\u001b[A\n",
            "1954it [02:26, 13.46it/s]\u001b[A\n",
            "1956it [02:26, 13.59it/s]\u001b[A\n",
            "1958it [02:26, 12.65it/s]\u001b[A\n",
            "1960it [02:27, 12.37it/s]\u001b[A\n",
            "1962it [02:27, 11.94it/s]\u001b[A\n",
            "1964it [02:27, 12.47it/s]\u001b[A\n",
            "1966it [02:27, 12.75it/s]\u001b[A\n",
            "1968it [02:27, 13.17it/s]\u001b[A\n",
            "1970it [02:27, 13.28it/s]\u001b[A\n",
            "1972it [02:27, 13.53it/s]\u001b[A\n",
            "1974it [02:28, 13.28it/s]\u001b[A\n",
            "1976it [02:28, 13.54it/s]\u001b[A\n",
            "1978it [02:28, 13.75it/s]\u001b[A\n",
            "1980it [02:28, 13.81it/s]\u001b[A\n",
            "1982it [02:28, 13.90it/s]\u001b[A\n",
            "1984it [02:28, 13.46it/s]\u001b[A\n",
            "1986it [02:29, 13.62it/s]\u001b[A\n",
            "1988it [02:29, 13.69it/s]\u001b[A\n",
            "1990it [02:29, 13.77it/s]\u001b[A\n",
            "1992it [02:29, 13.59it/s]\u001b[A\n",
            "1994it [02:29, 13.64it/s]\u001b[A\n",
            "1996it [02:29, 13.72it/s]\u001b[A\n",
            "1998it [02:29, 13.64it/s]\u001b[A\n",
            "2000it [02:30, 13.37it/s]\u001b[A\n",
            "2002it [02:30, 13.62it/s]\u001b[A\n",
            "2004it [02:30, 13.35it/s]\u001b[A\n",
            "2006it [02:30, 12.86it/s]\u001b[A\n",
            "2008it [02:30, 12.62it/s]\u001b[A\n",
            "2010it [02:30, 12.59it/s]\u001b[A\n",
            "2012it [02:30, 12.98it/s]\u001b[A\n",
            "2014it [02:31, 13.22it/s]\u001b[A\n",
            "2016it [02:31, 13.49it/s]\u001b[A\n",
            "2018it [02:31, 13.11it/s]\u001b[A\n",
            "2020it [02:31, 13.48it/s]\u001b[A\n",
            "2022it [02:31, 13.69it/s]\u001b[A\n",
            "2024it [02:31, 13.60it/s]\u001b[A\n",
            "2026it [02:31, 13.72it/s]\u001b[A\n",
            "2028it [02:32, 13.91it/s]\u001b[A\n",
            "2030it [02:32, 13.43it/s]\u001b[A\n",
            "2032it [02:32, 12.95it/s]\u001b[A\n",
            "2034it [02:32, 12.55it/s]\u001b[A\n",
            "2036it [02:32, 12.79it/s]\u001b[A\n",
            "2038it [02:32, 12.99it/s]\u001b[A\n",
            "2040it [02:33, 13.32it/s]\u001b[A\n",
            "2042it [02:33, 13.31it/s]\u001b[A\n",
            "2044it [02:33, 12.96it/s]\u001b[A\n",
            "2046it [02:33, 12.76it/s]\u001b[A\n",
            "2048it [02:33, 12.32it/s]\u001b[A\n",
            "2050it [02:33, 12.09it/s]\u001b[A\n",
            "2052it [02:34, 11.80it/s]\u001b[A\n",
            "2054it [02:34, 11.62it/s]\u001b[A\n",
            "2056it [02:34, 11.93it/s]\u001b[A\n",
            "2058it [02:34, 11.83it/s]\u001b[A\n",
            "2060it [02:34, 12.01it/s]\u001b[A\n",
            "2062it [02:34, 12.25it/s]\u001b[A\n",
            "2064it [02:35, 12.71it/s]\u001b[A\n",
            "2066it [02:35, 12.94it/s]\u001b[A\n",
            "2068it [02:35, 13.24it/s]\u001b[A\n",
            "2070it [02:35, 13.29it/s]\u001b[A\n",
            "2072it [02:35, 13.52it/s]\u001b[A\n",
            "2074it [02:35, 13.52it/s]\u001b[A\n",
            "2076it [02:35, 13.18it/s]\u001b[A\n",
            "2078it [02:36, 13.12it/s]\u001b[A\n",
            "2080it [02:36, 13.08it/s]\u001b[A\n",
            "2082it [02:36, 12.67it/s]\u001b[A\n",
            "2084it [02:36, 12.77it/s]\u001b[A\n",
            "2086it [02:36, 12.99it/s]\u001b[A\n",
            "2088it [02:36, 12.72it/s]\u001b[A\n",
            "2090it [02:37, 12.59it/s]\u001b[A\n",
            "2092it [02:37, 12.68it/s]\u001b[A\n",
            "2094it [02:37, 12.48it/s]\u001b[A\n",
            "2096it [02:37, 12.40it/s]\u001b[A\n",
            "2098it [02:37, 12.74it/s]\u001b[A\n",
            "2100it [02:37, 13.11it/s]\u001b[A\n",
            "2102it [02:37, 13.14it/s]\u001b[A\n",
            "2104it [02:38, 13.23it/s]\u001b[A\n",
            "2106it [02:38, 12.96it/s]\u001b[A\n",
            "2108it [02:38, 12.97it/s]\u001b[A\n",
            "2110it [02:38, 13.37it/s]\u001b[A\n",
            "2112it [02:38, 13.70it/s]\u001b[A\n",
            "2114it [02:38, 13.77it/s]\u001b[A\n",
            "2116it [02:38, 13.60it/s]\u001b[A\n",
            "2118it [02:39, 13.78it/s]\u001b[A\n",
            "2120it [02:39, 14.02it/s]\u001b[A\n",
            "2122it [02:39, 13.91it/s]\u001b[A\n",
            "2124it [02:39, 13.98it/s]\u001b[A\n",
            "2126it [02:39, 14.15it/s]\u001b[A\n",
            "2128it [02:39, 14.15it/s]\u001b[A\n",
            "2130it [02:39, 13.90it/s]\u001b[A\n",
            "2132it [02:40, 14.01it/s]\u001b[A\n",
            "2134it [02:40, 13.60it/s]\u001b[A\n",
            "2136it [02:40, 13.24it/s]\u001b[A\n",
            "2138it [02:40, 13.52it/s]\u001b[A\n",
            "2140it [02:40, 13.68it/s]\u001b[A\n",
            "2142it [02:40, 13.46it/s]\u001b[A\n",
            "2144it [02:41, 13.46it/s]\u001b[A\n",
            "2146it [02:41, 13.63it/s]\u001b[A\n",
            "2148it [02:41, 13.50it/s]\u001b[A\n",
            "2150it [02:41, 13.69it/s]\u001b[A\n",
            "2152it [02:41, 13.85it/s]\u001b[A\n",
            "2154it [02:41, 13.79it/s]\u001b[A\n",
            "2156it [02:41, 13.80it/s]\u001b[A\n",
            "2158it [02:42, 13.79it/s]\u001b[A\n",
            "2160it [02:42, 13.46it/s]\u001b[A\n",
            "2162it [02:42, 13.10it/s]\u001b[A\n",
            "2164it [02:42, 13.36it/s]\u001b[A\n",
            "2166it [02:42, 13.63it/s]\u001b[A\n",
            "2168it [02:42, 13.73it/s]\u001b[A\n",
            "2170it [02:42, 13.69it/s]\u001b[A\n",
            "2172it [02:43, 13.60it/s]\u001b[A\n",
            "2174it [02:43, 13.30it/s]\u001b[A\n",
            "2176it [02:43, 13.44it/s]\u001b[A\n",
            "2178it [02:43, 13.69it/s]\u001b[A\n",
            "2180it [02:43, 13.58it/s]\u001b[A\n",
            "2182it [02:43, 13.85it/s]\u001b[A\n",
            "2184it [02:43, 13.97it/s]\u001b[A\n",
            "2186it [02:44, 13.78it/s]\u001b[A\n",
            "2188it [02:44, 13.63it/s]\u001b[A\n",
            "2190it [02:44, 13.79it/s]\u001b[A\n",
            "2192it [02:44, 13.96it/s]\u001b[A\n",
            "2194it [02:44, 13.84it/s]\u001b[A\n",
            "2196it [02:44, 13.96it/s]\u001b[A\n",
            "2198it [02:44, 14.05it/s]\u001b[A\n",
            "2200it [02:45, 13.65it/s]\u001b[A\n",
            "2202it [02:45, 13.18it/s]\u001b[A\n",
            "2204it [02:45, 13.26it/s]\u001b[A\n",
            "2206it [02:45, 13.59it/s]\u001b[A\n",
            "2208it [02:45, 13.60it/s]\u001b[A\n",
            "2210it [02:45, 13.73it/s]\u001b[A\n",
            "2212it [02:46, 13.92it/s]\u001b[A\n",
            "2214it [02:46, 12.94it/s]\u001b[A\n",
            "2216it [02:46, 12.78it/s]\u001b[A\n",
            "2218it [02:46, 12.87it/s]\u001b[A\n",
            "2220it [02:46, 12.88it/s]\u001b[A\n",
            "2222it [02:46, 12.59it/s]\u001b[A\n",
            "2224it [02:46, 12.58it/s]\u001b[A\n",
            "2226it [02:47, 12.55it/s]\u001b[A\n",
            "2228it [02:47, 12.97it/s]\u001b[A\n",
            "2230it [02:47, 12.74it/s]\u001b[A\n",
            "2232it [02:47, 12.32it/s]\u001b[A\n",
            "2234it [02:47, 12.35it/s]\u001b[A\n",
            "2236it [02:47, 12.55it/s]\u001b[A\n",
            "2238it [02:48, 12.64it/s]\u001b[A\n",
            "2240it [02:48, 12.80it/s]\u001b[A\n",
            "2242it [02:48, 13.08it/s]\u001b[A\n",
            "2244it [02:48, 13.23it/s]\u001b[A\n",
            "2246it [02:48, 13.26it/s]\u001b[A\n",
            "2248it [02:48, 13.55it/s]\u001b[A\n",
            "2250it [02:48, 13.80it/s]\u001b[A\n",
            "2252it [02:49, 13.33it/s]\u001b[A\n",
            "2254it [02:49, 13.49it/s]\u001b[A\n",
            "2256it [02:49, 13.73it/s]\u001b[A\n",
            "2258it [02:49, 13.68it/s]\u001b[A\n",
            "2260it [02:49, 13.84it/s]\u001b[A\n",
            "2262it [02:49, 13.97it/s]\u001b[A\n",
            "2264it [02:49, 13.69it/s]\u001b[A\n",
            "2266it [02:50, 13.45it/s]\u001b[A\n",
            "2268it [02:50, 13.02it/s]\u001b[A\n",
            "2270it [02:50, 13.34it/s]\u001b[A\n",
            "2272it [02:50, 13.41it/s]\u001b[A\n",
            "2274it [02:50, 13.56it/s]\u001b[A\n",
            "2276it [02:50, 13.79it/s]\u001b[A\n",
            "2278it [02:51, 13.72it/s]\u001b[A\n",
            "2280it [02:51, 13.42it/s]\u001b[A\n",
            "2282it [02:51, 13.68it/s]\u001b[A\n",
            "2284it [02:51, 13.46it/s]\u001b[A\n",
            "2286it [02:51, 13.47it/s]\u001b[A\n",
            "2288it [02:51, 13.57it/s]\u001b[A\n",
            "2290it [02:51, 13.23it/s]\u001b[A\n",
            "2292it [02:52, 12.79it/s]\u001b[A\n",
            "2294it [02:52, 12.58it/s]\u001b[A\n",
            "2296it [02:52, 12.91it/s]\u001b[A\n",
            "2298it [02:52, 13.15it/s]\u001b[A\n",
            "2300it [02:52, 13.50it/s]\u001b[A\n",
            "2302it [02:52, 13.78it/s]\u001b[A\n",
            "2304it [02:52, 13.80it/s]\u001b[A\n",
            "2306it [02:53, 13.69it/s]\u001b[A\n",
            "2308it [02:53, 12.91it/s]\u001b[A\n",
            "2310it [02:53, 13.02it/s]\u001b[A\n",
            "2312it [02:53, 13.37it/s]\u001b[A\n",
            "2314it [02:53, 13.38it/s]\u001b[A\n",
            "2316it [02:53, 13.56it/s]\u001b[A\n",
            "2318it [02:54, 13.68it/s]\u001b[A\n",
            "2320it [02:54, 13.10it/s]\u001b[A\n",
            "2322it [02:54, 13.12it/s]\u001b[A\n",
            "2324it [02:54, 13.29it/s]\u001b[A\n",
            "2326it [02:54, 13.38it/s]\u001b[A\n",
            "2328it [02:54, 13.49it/s]\u001b[A\n",
            "2330it [02:54, 13.51it/s]\u001b[A\n",
            "2332it [02:55, 13.67it/s]\u001b[A\n",
            "2334it [02:55, 13.77it/s]\u001b[A\n",
            "2336it [02:55, 13.27it/s]\u001b[A\n",
            "2338it [02:55, 13.42it/s]\u001b[A\n",
            "2340it [02:55, 13.58it/s]\u001b[A\n",
            "2342it [02:55, 13.56it/s]\u001b[A\n",
            "2344it [02:55, 13.69it/s]\u001b[A\n",
            "2346it [02:56, 13.65it/s]\u001b[A\n",
            "2348it [02:56, 12.89it/s]\u001b[A\n",
            "2350it [02:56, 12.58it/s]\u001b[A\n",
            "2352it [02:56, 12.47it/s]\u001b[A\n",
            "2354it [02:56, 12.19it/s]\u001b[A\n",
            "2356it [02:56, 12.17it/s]\u001b[A\n",
            "2358it [02:57, 11.94it/s]\u001b[A\n",
            "2360it [02:57, 11.68it/s]\u001b[A\n",
            "2362it [02:57, 11.77it/s]\u001b[A\n",
            "2364it [02:57, 11.92it/s]\u001b[A\n",
            "2366it [02:57, 12.20it/s]\u001b[A\n",
            "2368it [02:57, 12.48it/s]\u001b[A\n",
            "2370it [02:58, 12.54it/s]\u001b[A\n",
            "2372it [02:58, 12.07it/s]\u001b[A\n",
            "2374it [02:58, 12.57it/s]\u001b[A\n",
            "2376it [02:58, 12.86it/s]\u001b[A\n",
            "2378it [02:58, 13.28it/s]\u001b[A\n",
            "2380it [02:58, 13.45it/s]\u001b[A\n",
            "2382it [02:59, 13.42it/s]\u001b[A\n",
            "2384it [02:59, 13.62it/s]\u001b[A\n",
            "2386it [02:59, 13.15it/s]\u001b[A\n",
            "2388it [02:59, 13.09it/s]\u001b[A\n",
            "2390it [02:59, 13.33it/s]\u001b[A\n",
            "2392it [02:59, 13.58it/s]\u001b[A\n",
            "2394it [02:59, 13.50it/s]\u001b[A\n",
            "2396it [03:00, 13.61it/s]\u001b[A\n",
            "2398it [03:00, 13.72it/s]\u001b[A\n",
            "2400it [03:00, 13.52it/s]\u001b[A\n",
            "2402it [03:00, 13.59it/s]\u001b[A\n",
            "2404it [03:00, 13.55it/s]\u001b[A\n",
            "2406it [03:00, 13.65it/s]\u001b[A\n",
            "2408it [03:00, 13.77it/s]\u001b[A\n",
            "2410it [03:01, 13.84it/s]\u001b[A\n",
            "2412it [03:01, 13.75it/s]\u001b[A\n",
            "2414it [03:01, 13.44it/s]\u001b[A\n",
            "2416it [03:01, 13.32it/s]\u001b[A\n",
            "2418it [03:01, 13.58it/s]\u001b[A\n",
            "2420it [03:01, 13.46it/s]\u001b[A\n",
            "2422it [03:01, 13.24it/s]\u001b[A\n",
            "2424it [03:02, 13.35it/s]\u001b[A\n",
            "2426it [03:02, 13.46it/s]\u001b[A\n",
            "2428it [03:02, 13.03it/s]\u001b[A\n",
            "2430it [03:02, 13.28it/s]\u001b[A\n",
            "2432it [03:02, 13.63it/s]\u001b[A\n",
            "2434it [03:02, 13.67it/s]\u001b[A\n",
            "2436it [03:02, 13.80it/s]\u001b[A\n",
            "2438it [03:03, 13.71it/s]\u001b[A\n",
            "2440it [03:03, 13.51it/s]\u001b[A\n",
            "2442it [03:03, 13.30it/s]\u001b[A\n",
            "2444it [03:03, 12.97it/s]\u001b[A\n",
            "2446it [03:03, 12.92it/s]\u001b[A\n",
            "2448it [03:03, 13.19it/s]\u001b[A\n",
            "2450it [03:04, 13.26it/s]\u001b[A\n",
            "2452it [03:04, 13.07it/s]\u001b[A\n",
            "2454it [03:04, 12.97it/s]\u001b[A\n",
            "2456it [03:04, 12.67it/s]\u001b[A\n",
            "2458it [03:04, 12.48it/s]\u001b[A\n",
            "2460it [03:04, 12.42it/s]\u001b[A\n",
            "2462it [03:05, 12.09it/s]\u001b[A\n",
            "2464it [03:05, 12.14it/s]\u001b[A\n",
            "2466it [03:05, 12.21it/s]\u001b[A\n",
            "2468it [03:05, 11.88it/s]\u001b[A\n",
            "2470it [03:05, 11.97it/s]\u001b[A\n",
            "2472it [03:05, 11.98it/s]\u001b[A\n",
            "2474it [03:06, 11.74it/s]\u001b[A\n",
            "2476it [03:06, 11.77it/s]\u001b[A\n",
            "2478it [03:06, 11.80it/s]\u001b[A\n",
            "2480it [03:06, 11.80it/s]\u001b[A\n",
            "2482it [03:06, 11.98it/s]\u001b[A\n",
            "2484it [03:06, 12.39it/s]\u001b[A\n",
            "2486it [03:07, 12.92it/s]\u001b[A\n",
            "2488it [03:07, 13.20it/s]\u001b[A\n",
            "2490it [03:07, 12.86it/s]\u001b[A\n",
            "2492it [03:07, 13.04it/s]\u001b[A\n",
            "2494it [03:07, 13.28it/s]\u001b[A\n",
            "2496it [03:07, 12.89it/s]\u001b[A\n",
            "2498it [03:07, 13.12it/s]\u001b[A\n",
            "2500it [03:08, 13.21it/s]\u001b[A\n",
            "2502it [03:08, 12.61it/s]\u001b[A\n",
            "2504it [03:08, 12.81it/s]\u001b[A\n",
            "2506it [03:08, 13.18it/s]\u001b[A\n",
            "2508it [03:08, 13.27it/s]\u001b[A\n",
            "2510it [03:08, 13.50it/s]\u001b[A\n",
            "2512it [03:08, 13.65it/s]\u001b[A\n",
            "2514it [03:09, 13.46it/s]\u001b[A\n",
            "2516it [03:09, 13.64it/s]\u001b[A\n",
            "2518it [03:09, 13.67it/s]\u001b[A\n",
            "2520it [03:09, 13.51it/s]\u001b[A\n",
            "2522it [03:09, 13.68it/s]\u001b[A\n",
            "2524it [03:09, 13.53it/s]\u001b[A\n",
            "2526it [03:10, 13.69it/s]\u001b[A\n",
            "2528it [03:10, 13.39it/s]\u001b[A\n",
            "2530it [03:10, 13.40it/s]\u001b[A\n",
            "2532it [03:10, 13.34it/s]\u001b[A\n",
            "2534it [03:10, 13.35it/s]\u001b[A\n",
            "2536it [03:10, 13.39it/s]\u001b[A\n",
            "2538it [03:10, 13.53it/s]\u001b[A\n",
            "2540it [03:11, 13.48it/s]\u001b[A\n",
            "2542it [03:11, 13.02it/s]\u001b[A\n",
            "2544it [03:11, 12.62it/s]\u001b[A\n",
            "2546it [03:11, 13.09it/s]\u001b[A\n",
            "2548it [03:11, 13.38it/s]\u001b[A\n",
            "2550it [03:11, 13.48it/s]\u001b[A\n",
            "2552it [03:11, 13.69it/s]\u001b[A\n",
            "2554it [03:12, 13.73it/s]\u001b[A\n",
            "2556it [03:12, 13.49it/s]\u001b[A\n",
            "2558it [03:12, 13.46it/s]\u001b[A\n",
            "2560it [03:12, 12.73it/s]\u001b[A\n",
            "2562it [03:12, 12.82it/s]\u001b[A\n",
            "2564it [03:12, 12.79it/s]\u001b[A\n",
            "2566it [03:13, 13.10it/s]\u001b[A\n",
            "2568it [03:13, 13.26it/s]\u001b[A\n",
            "2570it [03:13, 13.18it/s]\u001b[A\n",
            "2572it [03:13, 13.31it/s]\u001b[A\n",
            "2574it [03:13, 13.22it/s]\u001b[A\n",
            "2576it [03:13, 13.24it/s]\u001b[A\n",
            "2578it [03:13, 13.53it/s]\u001b[A\n",
            "2580it [03:14, 13.58it/s]\u001b[A\n",
            "2582it [03:14, 13.60it/s]\u001b[A\n",
            "2584it [03:14, 13.58it/s]\u001b[A\n",
            "2586it [03:14, 13.39it/s]\u001b[A\n",
            "2588it [03:14, 13.55it/s]\u001b[A\n",
            "2590it [03:14, 13.32it/s]\u001b[A\n",
            "2592it [03:14, 13.48it/s]\u001b[A\n",
            "2594it [03:15, 13.19it/s]\u001b[A\n",
            "2596it [03:15, 13.22it/s]\u001b[A\n",
            "2598it [03:15, 13.37it/s]\u001b[A\n",
            "2600it [03:15, 13.05it/s]\u001b[A\n",
            "2602it [03:15, 13.34it/s]\u001b[A\n",
            "2604it [03:15, 13.39it/s]\u001b[A\n",
            "2606it [03:16, 13.39it/s]\u001b[A\n",
            "2608it [03:16, 13.12it/s]\u001b[A\n",
            "2610it [03:16, 12.84it/s]\u001b[A\n",
            "2612it [03:16, 12.95it/s]\u001b[A\n",
            "2614it [03:16, 13.08it/s]\u001b[A\n",
            "2616it [03:16, 13.37it/s]\u001b[A\n",
            "2618it [03:16, 13.62it/s]\u001b[A\n",
            "2620it [03:17, 13.53it/s]\u001b[A\n",
            "2622it [03:17, 13.81it/s]\u001b[A\n",
            "2624it [03:17, 13.04it/s]\u001b[A\n",
            "2626it [03:17, 13.08it/s]\u001b[A\n",
            "2628it [03:17, 13.26it/s]\u001b[A\n",
            "2630it [03:17, 13.10it/s]\u001b[A\n",
            "2632it [03:18, 13.24it/s]\u001b[A\n",
            "2634it [03:18, 13.10it/s]\u001b[A\n",
            "2636it [03:18, 13.01it/s]\u001b[A\n",
            "2638it [03:18, 12.62it/s]\u001b[A\n",
            "2640it [03:18, 12.11it/s]\u001b[A\n",
            "2642it [03:18, 12.14it/s]\u001b[A\n",
            "2644it [03:18, 12.02it/s]\u001b[A\n",
            "2646it [03:19, 11.90it/s]\u001b[A\n",
            "2648it [03:19, 11.62it/s]\u001b[A\n",
            "2650it [03:19, 11.69it/s]\u001b[A\n",
            "2652it [03:19, 11.63it/s]\u001b[A\n",
            "2654it [03:19, 11.55it/s]\u001b[A\n",
            "2656it [03:20, 11.70it/s]\u001b[A\n",
            "2658it [03:20, 11.79it/s]\u001b[A\n",
            "2660it [03:20, 11.94it/s]\u001b[A\n",
            "2662it [03:20, 12.44it/s]\u001b[A\n",
            "2664it [03:20, 12.69it/s]\u001b[A\n",
            "2666it [03:20, 13.09it/s]\u001b[A\n",
            "2668it [03:20, 13.41it/s]\u001b[A\n",
            "2670it [03:21, 13.42it/s]\u001b[A\n",
            "2672it [03:21, 13.48it/s]\u001b[A\n",
            "2674it [03:21, 13.43it/s]\u001b[A\n",
            "2676it [03:21, 12.91it/s]\u001b[A\n",
            "2678it [03:21, 12.31it/s]\u001b[A\n",
            "2680it [03:21, 12.63it/s]\u001b[A\n",
            "2682it [03:22, 13.07it/s]\u001b[A\n",
            "2684it [03:22, 13.05it/s]\u001b[A\n",
            "2686it [03:22, 13.32it/s]\u001b[A\n",
            "2688it [03:22, 13.25it/s]\u001b[A\n",
            "2690it [03:22, 13.26it/s]\u001b[A\n",
            "2692it [03:22, 13.38it/s]\u001b[A\n",
            "2694it [03:22, 13.73it/s]\u001b[A\n",
            "2696it [03:23, 13.78it/s]\u001b[A\n",
            "2698it [03:23, 13.56it/s]\u001b[A\n",
            "2700it [03:23, 13.72it/s]\u001b[A\n",
            "2702it [03:23, 13.44it/s]\u001b[A\n",
            "2704it [03:23, 13.47it/s]\u001b[A\n",
            "2706it [03:23, 13.63it/s]\u001b[A\n",
            "2708it [03:23, 13.49it/s]\u001b[A\n",
            "2710it [03:24, 13.34it/s]\u001b[A\n",
            "2712it [03:24, 13.60it/s]\u001b[A\n",
            "2714it [03:24, 13.44it/s]\u001b[A\n",
            "2716it [03:24, 13.68it/s]\u001b[A\n",
            "2718it [03:24, 13.41it/s]\u001b[A\n",
            "2720it [03:24, 13.61it/s]\u001b[A\n",
            "2722it [03:24, 13.63it/s]\u001b[A\n",
            "2724it [03:25, 13.56it/s]\u001b[A\n",
            "2726it [03:25, 13.63it/s]\u001b[A\n",
            "2728it [03:25, 13.15it/s]\u001b[A\n",
            "2730it [03:25, 13.36it/s]\u001b[A\n",
            "2732it [03:25, 13.37it/s]\u001b[A\n",
            "2734it [03:25, 13.54it/s]\u001b[A\n",
            "2736it [03:26, 13.75it/s]\u001b[A\n",
            "2738it [03:26, 13.67it/s]\u001b[A\n",
            "2740it [03:26, 13.68it/s]\u001b[A\n",
            "2742it [03:26, 13.31it/s]\u001b[A\n",
            "2744it [03:26, 12.76it/s]\u001b[A\n",
            "2746it [03:26, 12.47it/s]\u001b[A\n",
            "2748it [03:26, 12.89it/s]\u001b[A\n",
            "2750it [03:27, 13.21it/s]\u001b[A\n",
            "2752it [03:27, 13.33it/s]\u001b[A\n",
            "2754it [03:27, 13.51it/s]\u001b[A\n",
            "2756it [03:27, 13.46it/s]\u001b[A\n",
            "2758it [03:27, 13.33it/s]\u001b[A\n",
            "2760it [03:27, 13.37it/s]\u001b[A\n",
            "2762it [03:28, 12.78it/s]\u001b[A\n",
            "2764it [03:28, 12.49it/s]\u001b[A\n",
            "2766it [03:28, 12.43it/s]\u001b[A\n",
            "2768it [03:28, 12.53it/s]\u001b[A\n",
            "2770it [03:28, 12.59it/s]\u001b[A\n",
            "2772it [03:28, 12.50it/s]\u001b[A\n",
            "2774it [03:28, 12.35it/s]\u001b[A\n",
            "2776it [03:29, 12.17it/s]\u001b[A\n",
            "2778it [03:29, 12.09it/s]\u001b[A\n",
            "2780it [03:29, 11.84it/s]\u001b[A\n",
            "2782it [03:29, 11.80it/s]\u001b[A\n",
            "2784it [03:29, 12.28it/s]\u001b[A\n",
            "2786it [03:29, 12.28it/s]\u001b[A\n",
            "2788it [03:30, 12.62it/s]\u001b[A\n",
            "2790it [03:30, 12.18it/s]\u001b[A\n",
            "2792it [03:30, 12.53it/s]\u001b[A\n",
            "2794it [03:30, 12.96it/s]\u001b[A\n",
            "2796it [03:30, 12.94it/s]\u001b[A\n",
            "2798it [03:30, 13.35it/s]\u001b[A\n",
            "2800it [03:31, 13.30it/s]\u001b[A\n",
            "2802it [03:31, 13.43it/s]\u001b[A\n",
            "2804it [03:31, 13.57it/s]\u001b[A\n",
            "2806it [03:31, 13.01it/s]\u001b[A\n",
            "2808it [03:31, 12.71it/s]\u001b[A\n",
            "2810it [03:31, 12.99it/s]\u001b[A\n",
            "2812it [03:31, 13.11it/s]\u001b[A\n",
            "2814it [03:32, 13.22it/s]\u001b[A\n",
            "2816it [03:32, 13.23it/s]\u001b[A\n",
            "2818it [03:32, 12.70it/s]\u001b[A\n",
            "2820it [03:32, 12.07it/s]\u001b[A\n",
            "2822it [03:32, 12.18it/s]\u001b[A\n",
            "2824it [03:32, 12.63it/s]\u001b[A\n",
            "2826it [03:33, 12.73it/s]\u001b[A\n",
            "2828it [03:33, 12.97it/s]\u001b[A\n",
            "2830it [03:33, 12.87it/s]\u001b[A\n",
            "2832it [03:33, 13.09it/s]\u001b[A\n",
            "2834it [03:33, 13.00it/s]\u001b[A\n",
            "2836it [03:33, 12.43it/s]\u001b[A\n",
            "2838it [03:34, 12.17it/s]\u001b[A\n",
            "2840it [03:34, 11.90it/s]\u001b[A\n",
            "2842it [03:34, 12.01it/s]\u001b[A\n",
            "2844it [03:34, 11.49it/s]\u001b[A\n",
            "2846it [03:34, 12.00it/s]\u001b[A\n",
            "2848it [03:34, 12.45it/s]\u001b[A\n",
            "2850it [03:35, 12.45it/s]\u001b[A\n",
            "2852it [03:35, 12.79it/s]\u001b[A\n",
            "2854it [03:35, 12.87it/s]\u001b[A\n",
            "2856it [03:35, 13.18it/s]\u001b[A\n",
            "2858it [03:35, 13.38it/s]\u001b[A\n",
            "2860it [03:35, 13.24it/s]\u001b[A\n",
            "2862it [03:35, 13.45it/s]\u001b[A\n",
            "2864it [03:36, 13.44it/s]\u001b[A\n",
            "2866it [03:36, 13.20it/s]\u001b[A\n",
            "2868it [03:36, 12.88it/s]\u001b[A\n",
            "2870it [03:36, 13.25it/s]\u001b[A\n",
            "2872it [03:36, 13.40it/s]\u001b[A\n",
            "2874it [03:36, 13.44it/s]\u001b[A\n",
            "2876it [03:36, 13.09it/s]\u001b[A\n",
            "2878it [03:37, 13.01it/s]\u001b[A\n",
            "2880it [03:37, 12.73it/s]\u001b[A\n",
            "2882it [03:37, 12.81it/s]\u001b[A\n",
            "2884it [03:37, 13.23it/s]\u001b[A\n",
            "2886it [03:37, 13.02it/s]\u001b[A\n",
            "2888it [03:37, 13.37it/s]\u001b[A\n",
            "2890it [03:38, 13.40it/s]\u001b[A\n",
            "2892it [03:38, 13.26it/s]\u001b[A\n",
            "2894it [03:38, 13.12it/s]\u001b[A\n",
            "2896it [03:38, 12.98it/s]\u001b[A\n",
            "2898it [03:38, 13.07it/s]\u001b[A\n",
            "2900it [03:38, 12.73it/s]\u001b[A\n",
            "2902it [03:38, 13.06it/s]\u001b[A\n",
            "2904it [03:39, 12.99it/s]\u001b[A\n",
            "2906it [03:39, 13.30it/s]\u001b[A\n",
            "2908it [03:39, 13.28it/s]\u001b[A\n",
            "2910it [03:39, 13.45it/s]\u001b[A\n",
            "2912it [03:39, 13.72it/s]\u001b[A\n",
            "2914it [03:39, 13.55it/s]\u001b[A\n",
            "2916it [03:39, 13.58it/s]\u001b[A\n",
            "2918it [03:40, 13.44it/s]\u001b[A\n",
            "2920it [03:40, 13.50it/s]\u001b[A\n",
            "2922it [03:40, 13.13it/s]\u001b[A\n",
            "2924it [03:40, 12.99it/s]\u001b[A\n",
            "2926it [03:40, 13.07it/s]\u001b[A\n",
            "2928it [03:40, 13.26it/s]\u001b[A\n",
            "2930it [03:41, 13.23it/s]\u001b[A\n",
            "2932it [03:41, 13.48it/s]\u001b[A\n",
            "2934it [03:41, 13.57it/s]\u001b[A\n",
            "2936it [03:41, 12.78it/s]\u001b[A\n",
            "2938it [03:41, 12.64it/s]\u001b[A\n",
            "2940it [03:41, 12.14it/s]\u001b[A\n",
            "2942it [03:42, 12.17it/s]\u001b[A\n",
            "2944it [03:42, 12.13it/s]\u001b[A\n",
            "2946it [03:42, 12.62it/s]\u001b[A\n",
            "2948it [03:42, 12.27it/s]\u001b[A\n",
            "2950it [03:42, 12.26it/s]\u001b[A\n",
            "2952it [03:42, 12.47it/s]\u001b[A\n",
            "2954it [03:42, 12.62it/s]\u001b[A\n",
            "2956it [03:43, 13.02it/s]\u001b[A\n",
            "2958it [03:43, 13.02it/s]\u001b[A\n",
            "2960it [03:43, 13.22it/s]\u001b[A\n",
            "2962it [03:43, 13.19it/s]\u001b[A\n",
            "2964it [03:43, 13.44it/s]\u001b[A\n",
            "2966it [03:43, 13.36it/s]\u001b[A\n",
            "2968it [03:44, 13.50it/s]\u001b[A\n",
            "2970it [03:44, 13.62it/s]\u001b[A\n",
            "2972it [03:44, 13.19it/s]\u001b[A\n",
            "2974it [03:44, 13.30it/s]\u001b[A\n",
            "2976it [03:44, 13.44it/s]\u001b[A\n",
            "2978it [03:44, 13.39it/s]\u001b[A\n",
            "2980it [03:44, 12.88it/s]\u001b[A\n",
            "2982it [03:45, 13.06it/s]\u001b[A\n",
            "2984it [03:45, 13.22it/s]\u001b[A\n",
            "2986it [03:45, 13.24it/s]\u001b[A\n",
            "2988it [03:45, 13.54it/s]\u001b[A\n",
            "2990it [03:45, 13.49it/s]\u001b[A\n",
            "2992it [03:45, 13.66it/s]\u001b[A\n",
            "2994it [03:45, 13.49it/s]\u001b[A\n",
            "2996it [03:46, 13.14it/s]\u001b[A\n",
            "2998it [03:46, 12.71it/s]\u001b[A\n",
            "3000it [03:46, 12.79it/s]\u001b[A\n",
            "3002it [03:46, 12.69it/s]\u001b[A\n",
            "3004it [03:46, 12.75it/s]\u001b[A\n",
            "3006it [03:46, 12.32it/s]\u001b[A\n",
            "3008it [03:47, 12.65it/s]\u001b[A\n",
            "3010it [03:47, 12.97it/s]\u001b[A\n",
            "3012it [03:47, 13.06it/s]\u001b[A\n",
            "3014it [03:47, 13.35it/s]\u001b[A\n",
            "3016it [03:47, 13.26it/s]\u001b[A\n",
            "3018it [03:47, 13.51it/s]\u001b[A\n",
            "3020it [03:47, 13.32it/s]\u001b[A\n",
            "3022it [03:48, 13.17it/s]\u001b[A\n",
            "3024it [03:48, 12.88it/s]\u001b[A\n",
            "3026it [03:48, 12.85it/s]\u001b[A\n",
            "3028it [03:48, 13.12it/s]\u001b[A\n",
            "3030it [03:48, 12.69it/s]\u001b[A\n",
            "3032it [03:48, 12.36it/s]\u001b[A\n",
            "3034it [03:49, 12.02it/s]\u001b[A\n",
            "3036it [03:49, 11.93it/s]\u001b[A\n",
            "3038it [03:49, 12.20it/s]\u001b[A\n",
            "3040it [03:49, 12.58it/s]\u001b[A\n",
            "3042it [03:49, 12.94it/s]\u001b[A\n",
            "3044it [03:49, 12.95it/s]\u001b[A\n",
            "3046it [03:50, 12.39it/s]\u001b[A\n",
            "3048it [03:50, 12.38it/s]\u001b[A\n",
            "3050it [03:50, 12.79it/s]\u001b[A\n",
            "3052it [03:50, 12.93it/s]\u001b[A\n",
            "3054it [03:50, 13.22it/s]\u001b[A\n",
            "3056it [03:50, 12.80it/s]\u001b[A\n",
            "3058it [03:50, 12.99it/s]\u001b[A\n",
            "3060it [03:51, 13.02it/s]\u001b[A\n",
            "3062it [03:51, 13.23it/s]\u001b[A\n",
            "3064it [03:51, 13.41it/s]\u001b[A\n",
            "3066it [03:51, 13.52it/s]\u001b[A\n",
            "3068it [03:51, 13.68it/s]\u001b[A\n",
            "3070it [03:51, 12.97it/s]\u001b[A\n",
            "3072it [03:52, 12.52it/s]\u001b[A\n",
            "3074it [03:52, 12.36it/s]\u001b[A\n",
            "3076it [03:52, 12.62it/s]\u001b[A\n",
            "3078it [03:52, 12.35it/s]\u001b[A\n",
            "3080it [03:52, 12.26it/s]\u001b[A\n",
            "3082it [03:52, 11.98it/s]\u001b[A\n",
            "3084it [03:53, 11.77it/s]\u001b[A\n",
            "3086it [03:53, 11.81it/s]\u001b[A\n",
            "3088it [03:53, 11.50it/s]\u001b[A\n",
            "3090it [03:53, 11.43it/s]\u001b[A\n",
            "3092it [03:53, 11.51it/s]\u001b[A\n",
            "3094it [03:53, 11.91it/s]\u001b[A\n",
            "3096it [03:54, 12.01it/s]\u001b[A\n",
            "3098it [03:54, 12.38it/s]\u001b[A\n",
            "3100it [03:54, 12.63it/s]\u001b[A\n",
            "3102it [03:54, 12.74it/s]\u001b[A\n",
            "3104it [03:54, 12.77it/s]\u001b[A\n",
            "3106it [03:54, 13.10it/s]\u001b[A\n",
            "3108it [03:55, 12.86it/s]\u001b[A\n",
            "3110it [03:55, 12.88it/s]\u001b[A\n",
            "3112it [03:55, 12.78it/s]\u001b[A\n",
            "3114it [03:55, 12.63it/s]\u001b[A\n",
            "3116it [03:55, 12.98it/s]\u001b[A\n",
            "3118it [03:55, 12.85it/s]\u001b[A\n",
            "3120it [03:55, 13.06it/s]\u001b[A\n",
            "3122it [03:56, 12.57it/s]\u001b[A\n",
            "3124it [03:56, 12.76it/s]\u001b[A\n",
            "3126it [03:56, 12.50it/s]\u001b[A\n",
            "3128it [03:56, 12.79it/s]\u001b[A\n",
            "3130it [03:56, 12.68it/s]\u001b[A\n",
            "3132it [03:56, 12.97it/s]\u001b[A\n",
            "3134it [03:57, 12.61it/s]\u001b[A\n",
            "3136it [03:57, 12.84it/s]\u001b[A\n",
            "3138it [03:57, 12.75it/s]\u001b[A\n",
            "3140it [03:57, 12.76it/s]\u001b[A\n",
            "3142it [03:57, 12.83it/s]\u001b[A\n",
            "3144it [03:57, 12.73it/s]\u001b[A\n",
            "3146it [03:57, 12.97it/s]\u001b[A\n",
            "3148it [03:58, 12.51it/s]\u001b[A\n",
            "3150it [03:58, 12.52it/s]\u001b[A\n",
            "3152it [03:58, 12.03it/s]\u001b[A\n",
            "3154it [03:58, 11.94it/s]\u001b[A\n",
            "3156it [03:58, 11.99it/s]\u001b[A\n",
            "3158it [03:58, 11.99it/s]\u001b[A\n",
            "3160it [03:59, 12.00it/s]\u001b[A\n",
            "3162it [03:59, 12.31it/s]\u001b[A\n",
            "3164it [03:59, 12.15it/s]\u001b[A\n",
            "3166it [03:59, 12.15it/s]\u001b[A\n",
            "3168it [03:59, 12.41it/s]\u001b[A\n",
            "3170it [03:59, 12.54it/s]\u001b[A\n",
            "3172it [04:00, 12.74it/s]\u001b[A\n",
            "3174it [04:00, 12.72it/s]\u001b[A\n",
            "3176it [04:00, 12.98it/s]\u001b[A\n",
            "3178it [04:00, 12.81it/s]\u001b[A\n",
            "3180it [04:00, 13.11it/s]\u001b[A\n",
            "3182it [04:00, 12.95it/s]\u001b[A\n",
            "3184it [04:01, 13.24it/s]\u001b[A\n",
            "3186it [04:01, 12.86it/s]\u001b[A\n",
            "3188it [04:01, 12.33it/s]\u001b[A\n",
            "3190it [04:01, 12.34it/s]\u001b[A\n",
            "3192it [04:01, 12.49it/s]\u001b[A\n",
            "3194it [04:01, 12.51it/s]\u001b[A\n",
            "3196it [04:01, 12.53it/s]\u001b[A\n",
            "3198it [04:02, 12.12it/s]\u001b[A\n",
            "3200it [04:02, 12.47it/s]\u001b[A\n",
            "3202it [04:02, 12.51it/s]\u001b[A\n",
            "3204it [04:02, 12.54it/s]\u001b[A\n",
            "3206it [04:02, 12.99it/s]\u001b[A\n",
            "3208it [04:02, 12.95it/s]\u001b[A\n",
            "3210it [04:03, 12.83it/s]\u001b[A\n",
            "3212it [04:03, 12.89it/s]\u001b[A\n",
            "3214it [04:03, 12.99it/s]\u001b[A\n",
            "3216it [04:03, 12.98it/s]\u001b[A\n",
            "3218it [04:03, 12.83it/s]\u001b[A\n",
            "3220it [04:03, 12.29it/s]\u001b[A\n",
            "3222it [04:04, 12.06it/s]\u001b[A\n",
            "3224it [04:04, 12.28it/s]\u001b[A\n",
            "3226it [04:04, 12.33it/s]\u001b[A\n",
            "3228it [04:04, 12.11it/s]\u001b[A\n",
            "3230it [04:04, 11.90it/s]\u001b[A\n",
            "3232it [04:04, 12.50it/s]\u001b[A\n",
            "3234it [04:05, 12.71it/s]\u001b[A\n",
            "3236it [04:05, 12.85it/s]\u001b[A\n",
            "3238it [04:05, 12.45it/s]\u001b[A\n",
            "3240it [04:05, 12.25it/s]\u001b[A\n",
            "3242it [04:05, 12.09it/s]\u001b[A\n",
            "3244it [04:05, 11.98it/s]\u001b[A\n",
            "3246it [04:06, 11.71it/s]\u001b[A\n",
            "3248it [04:06, 11.88it/s]\u001b[A\n",
            "3250it [04:06, 12.13it/s]\u001b[A\n",
            "3252it [04:06, 12.62it/s]\u001b[A\n",
            "3254it [04:06, 12.88it/s]\u001b[A\n",
            "3256it [04:06, 13.26it/s]\u001b[A\n",
            "3258it [04:06, 13.24it/s]\u001b[A\n",
            "3260it [04:07, 13.48it/s]\u001b[A\n",
            "3262it [04:07, 13.29it/s]\u001b[A\n",
            "3264it [04:07, 13.32it/s]\u001b[A\n",
            "3266it [04:07, 13.38it/s]\u001b[A\n",
            "3268it [04:07, 13.23it/s]\u001b[A\n",
            "3270it [04:07, 13.33it/s]\u001b[A\n",
            "3272it [04:07, 13.23it/s]\u001b[A\n",
            "3274it [04:08, 13.13it/s]\u001b[A\n",
            "3276it [04:08, 12.95it/s]\u001b[A\n",
            "3278it [04:08, 13.07it/s]\u001b[A\n",
            "3280it [04:08, 13.09it/s]\u001b[A\n",
            "3282it [04:08, 13.31it/s]\u001b[A\n",
            "3284it [04:08, 13.23it/s]\u001b[A\n",
            "3286it [04:09, 13.17it/s]\u001b[A\n",
            "3288it [04:09, 12.42it/s]\u001b[A\n",
            "3290it [04:09, 12.70it/s]\u001b[A\n",
            "3292it [04:09, 12.74it/s]\u001b[A\n",
            "3294it [04:09, 13.10it/s]\u001b[A\n",
            "3296it [04:09, 13.08it/s]\u001b[A\n",
            "3298it [04:09, 13.23it/s]\u001b[A\n",
            "3300it [04:10, 13.23it/s]\u001b[A\n",
            "3302it [04:10, 13.31it/s]\u001b[A\n",
            "3304it [04:10, 13.22it/s]\u001b[A\n",
            "3306it [04:10, 13.28it/s]\u001b[A\n",
            "3308it [04:10, 13.53it/s]\u001b[A\n",
            "3310it [04:10, 13.49it/s]\u001b[A\n",
            "3312it [04:11, 13.70it/s]\u001b[A\n",
            "3314it [04:11, 13.54it/s]\u001b[A\n",
            "3316it [04:11, 13.51it/s]\u001b[A\n",
            "3318it [04:11, 13.49it/s]\u001b[A\n",
            "3320it [04:11, 13.66it/s]\u001b[A\n",
            "3322it [04:11, 13.38it/s]\u001b[A\n",
            "3324it [04:11, 13.18it/s]\u001b[A\n",
            "3326it [04:12, 13.24it/s]\u001b[A\n",
            "3328it [04:12, 13.29it/s]\u001b[A\n",
            "3330it [04:12, 13.32it/s]\u001b[A\n",
            "3332it [04:12, 13.31it/s]\u001b[A\n",
            "3334it [04:12, 13.46it/s]\u001b[A\n",
            "3336it [04:12, 13.14it/s]\u001b[A\n",
            "3338it [04:12, 13.38it/s]\u001b[A\n",
            "3340it [04:13, 13.31it/s]\u001b[A\n",
            "3342it [04:13, 12.89it/s]\u001b[A\n",
            "3344it [04:13, 12.98it/s]\u001b[A\n",
            "3346it [04:13, 12.50it/s]\u001b[A\n",
            "3348it [04:13, 12.69it/s]\u001b[A\n",
            "3350it [04:13, 12.88it/s]\u001b[A\n",
            "3352it [04:14, 13.22it/s]\u001b[A\n",
            "3354it [04:14, 12.79it/s]\u001b[A\n",
            "3356it [04:14, 12.69it/s]\u001b[A\n",
            "3358it [04:14, 12.77it/s]\u001b[A\n",
            "3360it [04:14, 12.97it/s]\u001b[A\n",
            "3362it [04:14, 13.29it/s]\u001b[A\n",
            "3364it [04:14, 13.33it/s]\u001b[A\n",
            "3366it [04:15, 13.38it/s]\u001b[A\n",
            "3368it [04:15, 12.69it/s]\u001b[A\n",
            "3370it [04:15, 13.03it/s]\u001b[A\n",
            "3372it [04:15, 13.05it/s]\u001b[A\n",
            "3374it [04:15, 13.26it/s]\u001b[A\n",
            "3376it [04:15, 13.20it/s]\u001b[A\n",
            "3378it [04:16, 13.47it/s]\u001b[A\n",
            "3380it [04:16, 12.77it/s]\u001b[A\n",
            "3382it [04:16, 12.52it/s]\u001b[A\n",
            "3384it [04:16, 12.70it/s]\u001b[A\n",
            "3386it [04:16, 13.11it/s]\u001b[A\n",
            "3388it [04:16, 13.27it/s]\u001b[A\n",
            "3390it [04:16, 13.62it/s]\u001b[A\n",
            "3392it [04:17, 13.61it/s]\u001b[A\n",
            "3394it [04:17, 12.83it/s]\u001b[A\n",
            "3396it [04:17, 12.63it/s]\u001b[A\n",
            "3398it [04:17, 12.39it/s]\u001b[A\n",
            "3400it [04:17, 12.91it/s]\u001b[A\n",
            "3402it [04:17, 12.99it/s]\u001b[A\n",
            "3404it [04:18, 13.34it/s]\u001b[A\n",
            "3406it [04:18, 12.84it/s]\u001b[A\n",
            "3408it [04:18, 12.70it/s]\u001b[A\n",
            "3410it [04:18, 12.26it/s]\u001b[A\n",
            "3412it [04:18, 12.24it/s]\u001b[A\n",
            "3414it [04:18, 11.84it/s]\u001b[A\n",
            "3416it [04:19, 11.98it/s]\u001b[A\n",
            "3418it [04:19, 11.79it/s]\u001b[A\n",
            "3420it [04:19, 11.83it/s]\u001b[A\n",
            "3422it [04:19, 12.19it/s]\u001b[A\n",
            "3424it [04:19, 12.58it/s]\u001b[A\n",
            "3426it [04:19, 12.66it/s]\u001b[A\n",
            "3428it [04:20, 13.06it/s]\u001b[A\n",
            "3430it [04:20, 13.04it/s]\u001b[A\n",
            "3432it [04:20, 12.80it/s]\u001b[A\n",
            "3434it [04:20, 13.19it/s]\u001b[A\n",
            "3436it [04:20, 13.20it/s]\u001b[A\n",
            "3438it [04:20, 13.55it/s]\u001b[A\n",
            "3440it [04:20, 13.53it/s]\u001b[A\n",
            "3442it [04:21, 13.58it/s]\u001b[A\n",
            "3444it [04:21, 13.64it/s]\u001b[A\n",
            "3446it [04:21, 13.14it/s]\u001b[A\n",
            "3448it [04:21, 13.15it/s]\u001b[A\n",
            "3450it [04:21, 13.19it/s]\u001b[A\n",
            "3452it [04:21, 13.10it/s]\u001b[A\n",
            "3454it [04:21, 12.54it/s]\u001b[A\n",
            "3456it [04:22, 12.51it/s]\u001b[A\n",
            "3458it [04:22, 12.67it/s]\u001b[A\n",
            "3460it [04:22, 12.60it/s]\u001b[A\n",
            "3462it [04:22, 12.77it/s]\u001b[A\n",
            "3464it [04:22, 12.84it/s]\u001b[A\n",
            "3466it [04:22, 12.95it/s]\u001b[A\n",
            "3468it [04:23, 12.71it/s]\u001b[A\n",
            "3470it [04:23, 12.53it/s]\u001b[A\n",
            "3472it [04:23, 12.28it/s]\u001b[A\n",
            "3474it [04:23, 12.22it/s]\u001b[A\n",
            "3476it [04:23, 12.30it/s]\u001b[A\n",
            "3478it [04:23, 12.39it/s]\u001b[A\n",
            "3480it [04:24, 12.12it/s]\u001b[A\n",
            "3482it [04:24, 11.95it/s]\u001b[A\n",
            "3484it [04:24, 11.77it/s]\u001b[A\n",
            "3486it [04:24, 11.65it/s]\u001b[A\n",
            "3488it [04:24, 11.54it/s]\u001b[A\n",
            "3490it [04:24, 11.46it/s]\u001b[A\n",
            "3492it [04:25, 11.48it/s]\u001b[A\n",
            "3494it [04:25, 11.67it/s]\u001b[A\n",
            "3496it [04:25, 11.95it/s]\u001b[A\n",
            "3498it [04:25, 12.51it/s]\u001b[A\n",
            "3500it [04:25, 12.75it/s]\u001b[A\n",
            "3502it [04:25, 12.97it/s]\u001b[A\n",
            "3504it [04:26, 12.37it/s]\u001b[A\n",
            "3506it [04:26, 11.72it/s]\u001b[A\n",
            "3508it [04:26, 12.05it/s]\u001b[A\n",
            "3510it [04:26, 12.15it/s]\u001b[A\n",
            "3512it [04:26, 12.48it/s]\u001b[A\n",
            "3514it [04:26, 12.10it/s]\u001b[A\n",
            "3516it [04:27, 12.03it/s]\u001b[A\n",
            "3518it [04:27, 11.88it/s]\u001b[A\n",
            "3520it [04:27, 11.92it/s]\u001b[A\n",
            "3522it [04:27, 12.44it/s]\u001b[A\n",
            "3524it [04:27, 12.60it/s]\u001b[A\n",
            "3526it [04:27, 12.84it/s]\u001b[A\n",
            "3528it [04:28, 12.48it/s]\u001b[A\n",
            "3530it [04:28, 12.74it/s]\u001b[A\n",
            "3532it [04:28, 12.58it/s]\u001b[A\n",
            "3534it [04:28, 12.60it/s]\u001b[A\n",
            "3536it [04:28, 12.97it/s]\u001b[A\n",
            "3538it [04:28, 12.75it/s]\u001b[A\n",
            "3540it [04:28, 12.98it/s]\u001b[A\n",
            "3542it [04:29, 13.23it/s]\u001b[A\n",
            "3544it [04:29, 12.73it/s]\u001b[A\n",
            "3546it [04:29, 12.14it/s]\u001b[A\n",
            "3548it [04:29, 11.75it/s]\u001b[A\n",
            "3550it [04:29, 11.74it/s]\u001b[A\n",
            "3552it [04:29, 11.56it/s]\u001b[A\n",
            "3554it [04:30, 11.53it/s]\u001b[A\n",
            "3556it [04:30, 11.68it/s]\u001b[A\n",
            "3558it [04:30, 11.69it/s]\u001b[A\n",
            "3560it [04:30, 11.52it/s]\u001b[A\n",
            "3562it [04:30, 11.48it/s]\u001b[A\n",
            "3564it [04:31, 11.56it/s]\u001b[A\n",
            "3566it [04:31, 11.31it/s]\u001b[A\n",
            "3568it [04:31, 11.44it/s]\u001b[A\n",
            "3570it [04:31, 11.31it/s]\u001b[A\n",
            "3572it [04:31, 11.64it/s]\u001b[A\n",
            "3574it [04:31, 12.16it/s]\u001b[A\n",
            "3576it [04:32, 12.49it/s]\u001b[A\n",
            "3578it [04:32, 12.64it/s]\u001b[A\n",
            "3580it [04:32, 12.74it/s]\u001b[A\n",
            "3582it [04:32, 12.78it/s]\u001b[A\n",
            "3584it [04:32, 12.94it/s]\u001b[A\n",
            "3586it [04:32, 13.15it/s]\u001b[A\n",
            "3588it [04:32, 13.10it/s]\u001b[A\n",
            "3590it [04:33, 13.17it/s]\u001b[A\n",
            "3592it [04:33, 12.96it/s]\u001b[A\n",
            "3594it [04:33, 13.04it/s]\u001b[A\n",
            "3596it [04:33, 13.17it/s]\u001b[A\n",
            "3598it [04:33, 13.16it/s]\u001b[A\n",
            "3600it [04:33, 13.21it/s]\u001b[A\n",
            "3602it [04:33, 13.29it/s]\u001b[A\n",
            "3604it [04:34, 12.78it/s]\u001b[A\n",
            "3606it [04:34, 12.63it/s]\u001b[A\n",
            "3608it [04:34, 12.68it/s]\u001b[A\n",
            "3610it [04:34, 12.49it/s]\u001b[A\n",
            "3612it [04:34, 12.85it/s]\u001b[A\n",
            "3614it [04:34, 12.80it/s]\u001b[A\n",
            "3616it [04:35, 12.91it/s]\u001b[A\n",
            "3618it [04:35, 13.04it/s]\u001b[A\n",
            "3620it [04:35, 13.13it/s]\u001b[A\n",
            "3622it [04:35, 13.13it/s]\u001b[A\n",
            "3624it [04:35, 13.44it/s]\u001b[A\n",
            "3626it [04:35, 13.42it/s]\u001b[A\n",
            "3628it [04:36, 13.43it/s]\u001b[A\n",
            "3630it [04:36, 13.33it/s]\u001b[A\n",
            "3632it [04:36, 12.78it/s]\u001b[A\n",
            "3634it [04:36, 12.10it/s]\u001b[A\n",
            "3636it [04:36, 11.99it/s]\u001b[A\n",
            "3638it [04:36, 12.03it/s]\u001b[A\n",
            "3640it [04:37, 11.84it/s]\u001b[A\n",
            "3642it [04:37, 11.77it/s]\u001b[A\n",
            "3644it [04:37, 12.04it/s]\u001b[A\n",
            "3646it [04:37, 12.28it/s]\u001b[A\n",
            "3648it [04:37, 12.47it/s]\u001b[A\n",
            "3650it [04:37, 12.87it/s]\u001b[A\n",
            "3652it [04:37, 12.98it/s]\u001b[A\n",
            "3654it [04:38, 13.20it/s]\u001b[A\n",
            "3656it [04:38, 13.21it/s]\u001b[A\n",
            "3658it [04:38, 13.16it/s]\u001b[A\n",
            "3660it [04:38, 13.29it/s]\u001b[A\n",
            "3662it [04:38, 13.01it/s]\u001b[A\n",
            "3664it [04:38, 13.24it/s]\u001b[A\n",
            "3666it [04:39, 13.17it/s]\u001b[A\n",
            "3668it [04:39, 13.38it/s]\u001b[A\n",
            "3670it [04:39, 13.13it/s]\u001b[A\n",
            "3672it [04:39, 13.01it/s]\u001b[A\n",
            "3674it [04:39, 13.10it/s]\u001b[A\n",
            "3676it [04:39, 13.04it/s]\u001b[A\n",
            "3678it [04:39, 13.03it/s]\u001b[A\n",
            "3680it [04:40, 13.12it/s]\u001b[A\n",
            "3682it [04:40, 12.93it/s]\u001b[A\n",
            "3684it [04:40, 12.83it/s]\u001b[A\n",
            "3686it [04:40, 12.68it/s]\u001b[A\n",
            "3688it [04:40, 12.97it/s]\u001b[A\n",
            "3690it [04:40, 13.00it/s]\u001b[A\n",
            "3692it [04:40, 13.38it/s]\u001b[A\n",
            "3694it [04:41, 13.38it/s]\u001b[A\n",
            "3696it [04:41, 13.17it/s]\u001b[A\n",
            "3698it [04:41, 13.38it/s]\u001b[A\n",
            "3700it [04:41, 13.59it/s]\u001b[A\n",
            "3702it [04:41, 13.28it/s]\u001b[A\n",
            "3704it [04:41, 13.26it/s]\u001b[A\n",
            "3706it [04:42, 13.34it/s]\u001b[A\n",
            "3708it [04:42, 13.26it/s]\u001b[A\n",
            "3710it [04:42, 13.00it/s]\u001b[A\n",
            "3712it [04:42, 13.22it/s]\u001b[A\n",
            "3714it [04:42, 13.10it/s]\u001b[A\n",
            "3716it [04:42, 13.20it/s]\u001b[A\n",
            "3718it [04:42, 13.23it/s]\u001b[A\n",
            "3720it [04:43, 13.40it/s]\u001b[A\n",
            "3722it [04:43, 13.19it/s]\u001b[A\n",
            "3724it [04:43, 12.79it/s]\u001b[A\n",
            "3726it [04:43, 12.40it/s]\u001b[A\n",
            "3728it [04:43, 12.16it/s]\u001b[A\n",
            "3730it [04:43, 12.17it/s]\u001b[A\n",
            "3732it [04:44, 12.59it/s]\u001b[A\n",
            "3734it [04:44, 12.71it/s]\u001b[A\n",
            "3736it [04:44, 12.87it/s]\u001b[A\n",
            "3738it [04:44, 12.96it/s]\u001b[A\n",
            "3740it [04:44, 13.08it/s]\u001b[A\n",
            "3742it [04:44, 12.97it/s]\u001b[A\n",
            "3744it [04:44, 13.13it/s]\u001b[A\n",
            "3746it [04:45, 13.41it/s]\u001b[A\n",
            "3748it [04:45, 13.38it/s]\u001b[A\n",
            "3750it [04:45, 13.66it/s]\u001b[A\n",
            "3752it [04:45, 13.56it/s]\u001b[A\n",
            "3754it [04:45, 13.55it/s]\u001b[A\n",
            "3756it [04:45, 13.39it/s]\u001b[A\n",
            "3758it [04:46, 13.23it/s]\u001b[A\n",
            "3760it [04:46, 13.14it/s]\u001b[A\n",
            "3762it [04:46, 12.68it/s]\u001b[A\n",
            "3764it [04:46, 12.76it/s]\u001b[A\n",
            "3766it [04:46, 12.54it/s]\u001b[A\n",
            "3768it [04:46, 12.65it/s]\u001b[A\n",
            "3770it [04:47, 12.54it/s]\u001b[A\n",
            "3772it [04:47, 12.70it/s]\u001b[A\n",
            "3774it [04:47, 12.89it/s]\u001b[A\n",
            "3776it [04:47, 12.64it/s]\u001b[A\n",
            "3778it [04:47, 12.38it/s]\u001b[A\n",
            "3780it [04:47, 11.99it/s]\u001b[A\n",
            "3782it [04:47, 11.94it/s]\u001b[A\n",
            "3784it [04:48, 12.08it/s]\u001b[A\n",
            "3786it [04:48, 12.58it/s]\u001b[A\n",
            "3788it [04:48, 12.59it/s]\u001b[A\n",
            "3790it [04:48, 13.03it/s]\u001b[A\n",
            "3792it [04:48, 12.93it/s]\u001b[A\n",
            "3794it [04:48, 13.13it/s]\u001b[A\n",
            "3796it [04:49, 13.13it/s]\u001b[A\n",
            "3798it [04:49, 13.40it/s]\u001b[A\n",
            "3800it [04:49, 13.22it/s]\u001b[A\n",
            "3802it [04:49, 13.35it/s]\u001b[A\n",
            "3804it [04:49, 13.37it/s]\u001b[A\n",
            "3806it [04:49, 13.17it/s]\u001b[A\n",
            "3808it [04:49, 13.46it/s]\u001b[A\n",
            "3810it [04:50, 13.07it/s]\u001b[A\n",
            "3812it [04:50, 13.35it/s]\u001b[A\n",
            "3814it [04:50, 13.36it/s]\u001b[A\n",
            "3816it [04:50, 13.28it/s]\u001b[A\n",
            "3818it [04:50, 13.50it/s]\u001b[A\n",
            "3820it [04:50, 13.31it/s]\u001b[A\n",
            "3822it [04:50, 13.44it/s]\u001b[A\n",
            "3824it [04:51, 13.57it/s]\u001b[A\n",
            "3826it [04:51, 12.98it/s]\u001b[A\n",
            "3828it [04:51, 12.81it/s]\u001b[A\n",
            "3830it [04:51, 13.14it/s]\u001b[A\n",
            "3832it [04:51, 12.93it/s]\u001b[A\n",
            "3834it [04:51, 13.01it/s]\u001b[A\n",
            "3836it [04:52, 13.11it/s]\u001b[A\n",
            "3838it [04:52, 12.97it/s]\u001b[A\n",
            "3840it [04:52, 13.22it/s]\u001b[A\n",
            "3842it [04:52, 12.70it/s]\u001b[A\n",
            "3844it [04:52, 12.49it/s]\u001b[A\n",
            "3846it [04:52, 12.07it/s]\u001b[A\n",
            "3848it [04:53, 11.80it/s]\u001b[A\n",
            "3850it [04:53, 12.35it/s]\u001b[A\n",
            "3852it [04:53, 12.79it/s]\u001b[A\n",
            "3854it [04:53, 13.02it/s]\u001b[A\n",
            "3856it [04:53, 12.95it/s]\u001b[A\n",
            "3858it [04:53, 12.83it/s]\u001b[A\n",
            "3860it [04:53, 13.06it/s]\u001b[A\n",
            "3862it [04:54, 12.98it/s]\u001b[A\n",
            "3864it [04:54, 13.22it/s]\u001b[A\n",
            "3866it [04:54, 12.89it/s]\u001b[A\n",
            "3868it [04:54, 12.60it/s]\u001b[A\n",
            "3870it [04:54, 12.26it/s]\u001b[A\n",
            "3872it [04:54, 11.90it/s]\u001b[A\n",
            "3874it [04:55, 11.77it/s]\u001b[A\n",
            "3876it [04:55, 11.67it/s]\u001b[A\n",
            "3878it [04:55, 11.76it/s]\u001b[A\n",
            "3880it [04:55, 11.75it/s]\u001b[A\n",
            "3882it [04:55, 12.25it/s]\u001b[A\n",
            "3884it [04:55, 12.48it/s]\u001b[A\n",
            "3886it [04:56, 12.42it/s]\u001b[A\n",
            "3888it [04:56, 12.78it/s]\u001b[A\n",
            "3890it [04:56, 12.92it/s]\u001b[A\n",
            "3892it [04:56, 12.38it/s]\u001b[A\n",
            "3894it [04:56, 12.24it/s]\u001b[A\n",
            "3896it [04:56, 12.08it/s]\u001b[A\n",
            "3898it [04:57, 12.00it/s]\u001b[A\n",
            "3900it [04:57, 12.34it/s]\u001b[A\n",
            "3902it [04:57, 12.23it/s]\u001b[A\n",
            "3904it [04:57, 12.00it/s]\u001b[A\n",
            "3906it [04:57, 12.16it/s]\u001b[A\n",
            "3908it [04:57, 12.34it/s]\u001b[A\n",
            "3910it [04:58, 12.75it/s]\u001b[A\n",
            "3912it [04:58, 13.00it/s]\u001b[A\n",
            "3914it [04:58, 13.10it/s]\u001b[A\n",
            "3916it [04:58, 13.29it/s]\u001b[A\n",
            "3918it [04:58, 13.41it/s]\u001b[A\n",
            "3920it [04:58, 13.38it/s]\u001b[A\n",
            "3922it [04:58, 13.15it/s]\u001b[A\n",
            "3924it [04:59, 13.34it/s]\u001b[A\n",
            "3926it [04:59, 12.62it/s]\u001b[A\n",
            "3928it [04:59, 12.65it/s]\u001b[A\n",
            "3930it [04:59, 12.97it/s]\u001b[A\n",
            "3932it [04:59, 12.86it/s]\u001b[A\n",
            "3934it [04:59, 12.30it/s]\u001b[A\n",
            "3936it [05:00, 12.16it/s]\u001b[A\n",
            "3938it [05:00, 11.84it/s]\u001b[A\n",
            "3940it [05:00, 12.32it/s]\u001b[A\n",
            "3942it [05:00, 12.13it/s]\u001b[A\n",
            "3944it [05:00, 12.15it/s]\u001b[A\n",
            "3946it [05:00, 11.76it/s]\u001b[A\n",
            "3948it [05:01, 11.64it/s]\u001b[A\n",
            "3950it [05:01, 11.55it/s]\u001b[A\n",
            "3952it [05:01, 11.91it/s]\u001b[A\n",
            "3954it [05:01, 12.44it/s]\u001b[A\n",
            "3956it [05:01, 12.70it/s]\u001b[A\n",
            "3958it [05:01, 12.89it/s]\u001b[A\n",
            "3960it [05:02, 13.12it/s]\u001b[A\n",
            "3962it [05:02, 12.88it/s]\u001b[A\n",
            "3964it [05:02, 13.05it/s]\u001b[A\n",
            "3966it [05:02, 13.02it/s]\u001b[A\n",
            "3968it [05:02, 12.98it/s]\u001b[A\n",
            "3970it [05:02, 12.81it/s]\u001b[A\n",
            "3972it [05:02, 12.97it/s]\u001b[A\n",
            "3974it [05:03, 12.94it/s]\u001b[A\n",
            "3976it [05:03, 12.89it/s]\u001b[A\n",
            "3978it [05:03, 12.44it/s]\u001b[A\n",
            "3980it [05:03, 12.34it/s]\u001b[A\n",
            "3982it [05:03, 12.50it/s]\u001b[A\n",
            "3984it [05:03, 12.73it/s]\u001b[A\n",
            "3986it [05:04, 12.42it/s]\u001b[A\n",
            "3988it [05:04, 12.26it/s]\u001b[A\n",
            "3990it [05:04, 12.20it/s]\u001b[A\n",
            "3992it [05:04, 12.55it/s]\u001b[A\n",
            "3994it [05:04, 12.87it/s]\u001b[A\n",
            "3996it [05:04, 12.89it/s]\u001b[A\n",
            "3998it [05:05, 12.80it/s]\u001b[A\n",
            "4000it [05:05, 12.72it/s]\u001b[A\n",
            "4002it [05:05, 12.55it/s]\u001b[A\n",
            "4004it [05:05, 12.62it/s]\u001b[A\n",
            "4006it [05:05, 13.02it/s]\u001b[A\n",
            "4008it [05:05, 12.92it/s]\u001b[A\n",
            "4010it [05:05, 13.00it/s]\u001b[A\n",
            "4012it [05:06, 13.12it/s]\u001b[A\n",
            "4014it [05:06, 12.61it/s]\u001b[A\n",
            "4016it [05:06, 12.47it/s]\u001b[A\n",
            "4018it [05:06, 12.24it/s]\u001b[A\n",
            "4020it [05:06, 12.13it/s]\u001b[A\n",
            "4022it [05:06, 12.08it/s]\u001b[A\n",
            "4024it [05:07, 11.73it/s]\u001b[A\n",
            "4026it [05:07, 11.86it/s]\u001b[A\n",
            "4028it [05:07, 11.77it/s]\u001b[A\n",
            "4030it [05:07, 11.57it/s]\u001b[A\n",
            "4032it [05:07, 11.75it/s]\u001b[A\n",
            "4034it [05:07, 11.74it/s]\u001b[A\n",
            "4036it [05:08, 11.91it/s]\u001b[A\n",
            "4038it [05:08, 12.19it/s]\u001b[A\n",
            "4040it [05:08, 12.52it/s]\u001b[A\n",
            "4042it [05:08, 12.73it/s]\u001b[A\n",
            "4044it [05:08, 13.11it/s]\u001b[A\n",
            "4046it [05:08, 13.23it/s]\u001b[A\n",
            "4048it [05:09, 13.37it/s]\u001b[A\n",
            "4050it [05:09, 13.17it/s]\u001b[A\n",
            "4052it [05:09, 13.00it/s]\u001b[A\n",
            "4054it [05:09, 13.12it/s]\u001b[A\n",
            "4056it [05:09, 13.07it/s]\u001b[A\n",
            "4058it [05:09, 13.07it/s]\u001b[A\n",
            "4060it [05:09, 13.25it/s]\u001b[A\n",
            "4062it [05:10, 13.15it/s]\u001b[A\n",
            "4064it [05:10, 13.15it/s]\u001b[A\n",
            "4066it [05:10, 12.77it/s]\u001b[A\n",
            "4068it [05:10, 12.45it/s]\u001b[A\n",
            "4070it [05:10, 12.47it/s]\u001b[A\n",
            "4072it [05:10, 12.68it/s]\u001b[A\n",
            "4074it [05:11, 12.83it/s]\u001b[A\n",
            "4076it [05:11, 12.93it/s]\u001b[A\n",
            "4078it [05:11, 12.73it/s]\u001b[A\n",
            "4080it [05:11, 12.45it/s]\u001b[A\n",
            "4082it [05:11, 12.19it/s]\u001b[A\n",
            "4084it [05:11, 11.97it/s]\u001b[A\n",
            "4086it [05:12, 12.35it/s]\u001b[A\n",
            "4088it [05:12, 11.89it/s]\u001b[A\n",
            "4090it [05:12, 11.96it/s]\u001b[A\n",
            "4092it [05:12, 11.97it/s]\u001b[A\n",
            "4094it [05:12, 11.85it/s]\u001b[A\n",
            "4096it [05:12, 12.38it/s]\u001b[A\n",
            "4098it [05:12, 12.73it/s]\u001b[A\n",
            "4100it [05:13, 12.82it/s]\u001b[A\n",
            "4102it [05:13, 12.86it/s]\u001b[A\n",
            "4104it [05:13, 12.55it/s]\u001b[A\n",
            "4106it [05:13, 12.74it/s]\u001b[A\n",
            "4108it [05:13, 13.12it/s]\u001b[A\n",
            "4110it [05:13, 13.16it/s]\u001b[A\n",
            "4112it [05:14, 13.08it/s]\u001b[A\n",
            "4114it [05:14, 12.80it/s]\u001b[A\n",
            "4116it [05:14, 12.54it/s]\u001b[A\n",
            "4118it [05:14, 12.90it/s]\u001b[A\n",
            "4120it [05:14, 13.09it/s]\u001b[A\n",
            "4122it [05:14, 13.20it/s]\u001b[A\n",
            "4124it [05:14, 13.46it/s]\u001b[A\n",
            "4126it [05:15, 13.28it/s]\u001b[A\n",
            "4128it [05:15, 13.21it/s]\u001b[A\n",
            "4130it [05:15, 12.86it/s]\u001b[A\n",
            "4132it [05:15, 12.30it/s]\u001b[A\n",
            "4134it [05:15, 12.10it/s]\u001b[A\n",
            "4136it [05:15, 12.08it/s]\u001b[A\n",
            "4138it [05:16, 11.87it/s]\u001b[A\n",
            "4140it [05:16, 12.42it/s]\u001b[A\n",
            "4142it [05:16, 12.62it/s]\u001b[A\n",
            "4144it [05:16, 12.63it/s]\u001b[A\n",
            "4146it [05:16, 12.51it/s]\u001b[A\n",
            "4148it [05:16, 12.39it/s]\u001b[A\n",
            "4150it [05:17, 11.77it/s]\u001b[A\n",
            "4152it [05:17, 11.63it/s]\u001b[A\n",
            "4154it [05:17, 11.81it/s]\u001b[A\n",
            "4156it [05:17, 11.69it/s]\u001b[A\n",
            "4158it [05:17, 11.92it/s]\u001b[A\n",
            "4160it [05:17, 12.14it/s]\u001b[A\n",
            "4162it [05:18, 11.94it/s]\u001b[A\n",
            "4164it [05:18, 12.40it/s]\u001b[A\n",
            "4166it [05:18, 12.05it/s]\u001b[A\n",
            "4168it [05:18, 11.81it/s]\u001b[A\n",
            "4170it [05:18, 11.96it/s]\u001b[A\n",
            "4172it [05:18, 11.79it/s]\u001b[A\n",
            "4174it [05:19, 11.52it/s]\u001b[A\n",
            "4176it [05:19, 11.61it/s]\u001b[A\n",
            "4178it [05:19, 12.20it/s]\u001b[A\n",
            "4180it [05:19, 12.55it/s]\u001b[A\n",
            "4182it [05:19, 13.01it/s]\u001b[A\n",
            "4184it [05:19, 13.12it/s]\u001b[A\n",
            "4186it [05:20, 13.30it/s]\u001b[A\n",
            "4188it [05:20, 13.23it/s]\u001b[A\n",
            "4190it [05:20, 13.04it/s]\u001b[A\n",
            "4192it [05:20, 12.99it/s]\u001b[A\n",
            "4194it [05:20, 13.32it/s]\u001b[A\n",
            "4196it [05:20, 13.33it/s]\u001b[A\n",
            "4198it [05:20, 13.35it/s]\u001b[A\n",
            "4200it [05:21, 13.55it/s]\u001b[A\n",
            "4202it [05:21, 13.31it/s]\u001b[A\n",
            "4204it [05:21, 13.27it/s]\u001b[A\n",
            "4206it [05:21, 13.37it/s]\u001b[A\n",
            "4208it [05:21, 13.38it/s]\u001b[A\n",
            "4210it [05:21, 13.16it/s]\u001b[A\n",
            "4212it [05:22, 13.12it/s]\u001b[A\n",
            "4214it [05:22, 13.02it/s]\u001b[A\n",
            "4216it [05:22, 13.26it/s]\u001b[A\n",
            "4218it [05:22, 13.54it/s]\u001b[A\n",
            "4220it [05:22, 13.73it/s]\u001b[A\n",
            "4222it [05:22, 13.65it/s]\u001b[A\n",
            "4224it [05:22, 13.59it/s]\u001b[A\n",
            "4226it [05:23, 13.59it/s]\u001b[A\n",
            "4228it [05:23, 13.56it/s]\u001b[A\n",
            "4230it [05:23, 13.13it/s]\u001b[A\n",
            "4232it [05:23, 12.94it/s]\u001b[A\n",
            "4234it [05:23, 13.11it/s]\u001b[A\n",
            "4236it [05:23, 13.06it/s]\u001b[A\n",
            "4238it [05:23, 13.05it/s]\u001b[A\n",
            "4240it [05:24, 12.92it/s]\u001b[A\n",
            "4242it [05:24, 12.68it/s]\u001b[A\n",
            "4244it [05:24, 12.96it/s]\u001b[A\n",
            "4246it [05:24, 13.04it/s]\u001b[A\n",
            "4248it [05:24, 13.19it/s]\u001b[A\n",
            "4250it [05:24, 13.09it/s]\u001b[A\n",
            "4252it [05:25, 12.87it/s]\u001b[A\n",
            "4254it [05:25, 12.55it/s]\u001b[A\n",
            "4256it [05:25, 12.63it/s]\u001b[A\n",
            "4258it [05:25, 12.66it/s]\u001b[A\n",
            "4260it [05:25, 12.83it/s]\u001b[A\n",
            "4262it [05:25, 13.08it/s]\u001b[A\n",
            "4264it [05:25, 13.33it/s]\u001b[A\n",
            "4266it [05:26, 13.21it/s]\u001b[A\n",
            "4268it [05:26, 13.00it/s]\u001b[A\n",
            "4270it [05:26, 13.28it/s]\u001b[A\n",
            "4272it [05:26, 13.09it/s]\u001b[A\n",
            "4274it [05:26, 13.10it/s]\u001b[A\n",
            "4276it [05:26, 12.88it/s]\u001b[A\n",
            "4278it [05:27, 12.90it/s]\u001b[A\n",
            "4280it [05:27, 12.32it/s]\u001b[A\n",
            "4282it [05:27, 12.38it/s]\u001b[A\n",
            "4284it [05:27, 12.86it/s]\u001b[A\n",
            "4286it [05:27, 12.99it/s]\u001b[A\n",
            "4288it [05:27, 13.30it/s]\u001b[A\n",
            "4290it [05:27, 13.04it/s]\u001b[A\n",
            "4292it [05:28, 12.63it/s]\u001b[A\n",
            "4294it [05:28, 12.53it/s]\u001b[A\n",
            "4296it [05:28, 12.66it/s]\u001b[A\n",
            "4298it [05:28, 12.48it/s]\u001b[A\n",
            "4300it [05:28, 12.93it/s]\u001b[A\n",
            "4302it [05:28, 12.91it/s]\u001b[A\n",
            "4304it [05:29, 13.10it/s]\u001b[A\n",
            "4306it [05:29, 13.27it/s]\u001b[A\n",
            "4308it [05:29, 13.21it/s]\u001b[A\n",
            "4310it [05:29, 13.24it/s]\u001b[A\n",
            "4312it [05:29, 13.25it/s]\u001b[A\n",
            "4314it [05:29, 13.22it/s]\u001b[A\n",
            "4316it [05:30, 12.84it/s]\u001b[A\n",
            "4318it [05:30, 12.52it/s]\u001b[A\n",
            "4320it [05:30, 11.85it/s]\u001b[A\n",
            "4322it [05:30, 12.36it/s]\u001b[A\n",
            "4324it [05:30, 12.78it/s]\u001b[A\n",
            "4326it [05:30, 12.93it/s]\u001b[A\n",
            "4328it [05:30, 13.06it/s]\u001b[A\n",
            "4330it [05:31, 13.28it/s]\u001b[A\n",
            "4332it [05:31, 13.22it/s]\u001b[A\n",
            "4334it [05:31, 13.06it/s]\u001b[A\n",
            "4336it [05:31, 12.97it/s]\u001b[A\n",
            "4338it [05:31, 13.18it/s]\u001b[A\n",
            "4340it [05:31, 12.57it/s]\u001b[A\n",
            "4342it [05:32, 12.20it/s]\u001b[A\n",
            "4344it [05:32, 12.03it/s]\u001b[A\n",
            "4346it [05:32, 12.23it/s]\u001b[A\n",
            "4348it [05:32, 12.08it/s]\u001b[A\n",
            "4350it [05:32, 11.79it/s]\u001b[A\n",
            "4352it [05:32, 11.74it/s]\u001b[A\n",
            "4354it [05:33, 11.80it/s]\u001b[A\n",
            "4356it [05:33, 12.14it/s]\u001b[A\n",
            "4358it [05:33, 12.29it/s]\u001b[A\n",
            "4360it [05:33, 12.60it/s]\u001b[A\n",
            "4362it [05:33, 12.71it/s]\u001b[A\n",
            "4364it [05:33, 13.04it/s]\u001b[A\n",
            "4366it [05:34, 12.74it/s]\u001b[A\n",
            "4368it [05:34, 12.86it/s]\u001b[A\n",
            "4370it [05:34, 12.94it/s]\u001b[A\n",
            "4372it [05:34, 12.82it/s]\u001b[A\n",
            "4374it [05:34, 12.88it/s]\u001b[A\n",
            "4376it [05:34, 13.08it/s]\u001b[A\n",
            "4378it [05:34, 13.14it/s]\u001b[A\n",
            "4380it [05:35, 13.13it/s]\u001b[A\n",
            "4382it [05:35, 13.24it/s]\u001b[A\n",
            "4384it [05:35, 13.13it/s]\u001b[A\n",
            "4386it [05:35, 13.26it/s]\u001b[A\n",
            "4388it [05:35, 13.45it/s]\u001b[A\n",
            "4390it [05:35, 13.23it/s]\u001b[A\n",
            "4392it [05:35, 13.40it/s]\u001b[A\n",
            "4394it [05:36, 13.36it/s]\u001b[A\n",
            "4396it [05:36, 13.18it/s]\u001b[A\n",
            "4398it [05:36, 13.01it/s]\u001b[A\n",
            "4400it [05:36, 13.06it/s]\u001b[A\n",
            "4402it [05:36, 13.30it/s]\u001b[A\n",
            "4404it [05:36, 13.44it/s]\u001b[A\n",
            "4406it [05:37, 13.31it/s]\u001b[A\n",
            "4408it [05:37, 13.39it/s]\u001b[A\n",
            "4410it [05:37, 13.04it/s]\u001b[A\n",
            "4412it [05:37, 12.60it/s]\u001b[A\n",
            "4414it [05:37, 12.25it/s]\u001b[A\n",
            "4416it [05:37, 11.95it/s]\u001b[A\n",
            "4418it [05:38, 12.13it/s]\u001b[A\n",
            "4420it [05:38, 12.49it/s]\u001b[A\n",
            "4422it [05:38, 12.59it/s]\u001b[A\n",
            "4424it [05:38, 12.64it/s]\u001b[A\n",
            "4426it [05:38, 13.01it/s]\u001b[A\n",
            "4428it [05:38, 13.12it/s]\u001b[A\n",
            "4430it [05:38, 13.22it/s]\u001b[A\n",
            "4432it [05:39, 13.14it/s]\u001b[A\n",
            "4434it [05:39, 13.02it/s]\u001b[A\n",
            "4436it [05:39, 12.97it/s]\u001b[A\n",
            "4438it [05:39, 12.97it/s]\u001b[A\n",
            "4440it [05:39, 12.80it/s]\u001b[A\n",
            "4442it [05:39, 12.94it/s]\u001b[A\n",
            "4444it [05:40, 13.03it/s]\u001b[A\n",
            "4446it [05:40, 13.25it/s]\u001b[A\n",
            "4448it [05:40, 13.21it/s]\u001b[A\n",
            "4450it [05:40, 13.03it/s]\u001b[A\n",
            "4452it [05:40, 12.99it/s]\u001b[A\n",
            "4454it [05:40, 13.02it/s]\u001b[A\n",
            "4456it [05:40, 13.26it/s]\u001b[A\n",
            "4458it [05:41, 13.29it/s]\u001b[A\n",
            "4460it [05:41, 13.35it/s]\u001b[A\n",
            "4462it [05:41, 13.44it/s]\u001b[A\n",
            "4464it [05:41, 13.13it/s]\u001b[A\n",
            "4466it [05:41, 13.17it/s]\u001b[A\n",
            "4468it [05:41, 13.38it/s]\u001b[A\n",
            "4470it [05:41, 13.33it/s]\u001b[A\n",
            "4472it [05:42, 13.27it/s]\u001b[A\n",
            "4474it [05:42, 13.18it/s]\u001b[A\n",
            "4476it [05:42, 13.29it/s]\u001b[A\n",
            "4478it [05:42, 13.41it/s]\u001b[A\n",
            "4480it [05:42, 13.58it/s]\u001b[A\n",
            "4482it [05:42, 13.42it/s]\u001b[A\n",
            "4484it [05:43, 13.43it/s]\u001b[A\n",
            "4486it [05:43, 13.56it/s]\u001b[A\n",
            "4488it [05:43, 13.43it/s]\u001b[A\n",
            "4490it [05:43, 12.80it/s]\u001b[A\n",
            "4492it [05:43, 12.29it/s]\u001b[A\n",
            "4494it [05:43, 12.10it/s]\u001b[A\n",
            "4496it [05:44, 11.92it/s]\u001b[A\n",
            "4498it [05:44, 11.99it/s]\u001b[A\n",
            "4500it [05:44, 12.25it/s]\u001b[A\n",
            "4502it [05:44, 11.78it/s]\u001b[A\n",
            "4504it [05:44, 11.72it/s]\u001b[A\n",
            "4506it [05:44, 11.52it/s]\u001b[A\n",
            "4508it [05:45, 11.62it/s]\u001b[A\n",
            "4510it [05:45, 11.51it/s]\u001b[A\n",
            "4512it [05:45, 11.51it/s]\u001b[A\n",
            "4514it [05:45, 11.34it/s]\u001b[A\n",
            "4516it [05:45, 11.56it/s]\u001b[A\n",
            "4518it [05:45, 11.43it/s]\u001b[A\n",
            "4520it [05:46, 11.52it/s]\u001b[A\n",
            "4522it [05:46, 11.77it/s]\u001b[A\n",
            "4524it [05:46, 11.77it/s]\u001b[A\n",
            "4526it [05:46, 11.20it/s]\u001b[A\n",
            "4528it [05:46, 11.29it/s]\u001b[A\n",
            "4530it [05:46, 11.14it/s]\u001b[A\n",
            "4532it [05:47, 11.27it/s]\u001b[A\n",
            "4534it [05:47, 11.52it/s]\u001b[A\n",
            "4536it [05:47, 12.05it/s]\u001b[A\n",
            "4538it [05:47, 12.28it/s]\u001b[A\n",
            "4540it [05:47, 12.54it/s]\u001b[A\n",
            "4542it [05:47, 12.84it/s]\u001b[A\n",
            "4544it [05:48, 13.00it/s]\u001b[A\n",
            "4546it [05:48, 12.98it/s]\u001b[A\n",
            "4548it [05:48, 12.83it/s]\u001b[A\n",
            "4550it [05:48, 12.90it/s]\u001b[A\n",
            "4552it [05:48, 12.96it/s]\u001b[A\n",
            "4554it [05:48, 13.22it/s]\u001b[A\n",
            "4556it [05:48, 13.27it/s]\u001b[A\n",
            "4558it [05:49, 13.26it/s]\u001b[A\n",
            "4560it [05:49, 13.25it/s]\u001b[A\n",
            "4562it [05:49, 13.37it/s]\u001b[A\n",
            "4564it [05:49, 13.01it/s]\u001b[A\n",
            "4566it [05:49, 12.98it/s]\u001b[A\n",
            "4568it [05:49, 13.05it/s]\u001b[A\n",
            "4570it [05:50, 13.36it/s]\u001b[A\n",
            "4572it [05:50, 13.16it/s]\u001b[A\n",
            "4574it [05:50, 12.77it/s]\u001b[A\n",
            "4576it [05:50, 12.46it/s]\u001b[A\n",
            "4578it [05:50, 12.24it/s]\u001b[A\n",
            "4580it [05:50, 12.44it/s]\u001b[A\n",
            "4582it [05:50, 12.82it/s]\u001b[A\n",
            "4584it [05:51, 12.93it/s]\u001b[A\n",
            "4586it [05:51, 12.95it/s]\u001b[A\n",
            "4588it [05:51, 13.15it/s]\u001b[A\n",
            "4590it [05:51, 12.37it/s]\u001b[A\n",
            "4592it [05:51, 12.53it/s]\u001b[A\n",
            "4594it [05:51, 12.67it/s]\u001b[A\n",
            "4596it [05:52, 12.82it/s]\u001b[A\n",
            "4598it [05:52, 13.16it/s]\u001b[A\n",
            "4600it [05:52, 13.17it/s]\u001b[A\n",
            "4602it [05:52, 13.19it/s]\u001b[A\n",
            "4604it [05:52, 13.18it/s]\u001b[A\n",
            "4606it [05:52, 13.42it/s]\u001b[A\n",
            "4608it [05:52, 13.40it/s]\u001b[A\n",
            "4610it [05:53, 13.38it/s]\u001b[A\n",
            "4612it [05:53, 12.81it/s]\u001b[A\n",
            "4614it [05:53, 12.76it/s]\u001b[A\n",
            "4616it [05:53, 12.91it/s]\u001b[A\n",
            "4618it [05:53, 12.91it/s]\u001b[A\n",
            "4620it [05:53, 12.95it/s]\u001b[A\n",
            "4622it [05:54, 12.99it/s]\u001b[A\n",
            "4624it [05:54, 13.04it/s]\u001b[A\n",
            "4626it [05:54, 13.15it/s]\u001b[A\n",
            "4628it [05:54, 12.85it/s]\u001b[A\n",
            "4630it [05:54, 12.65it/s]\u001b[A\n",
            "4632it [05:54, 12.53it/s]\u001b[A\n",
            "4634it [05:55, 12.36it/s]\u001b[A\n",
            "4636it [05:55, 12.03it/s]\u001b[A\n",
            "4638it [05:55, 11.89it/s]\u001b[A\n",
            "4640it [05:55, 11.92it/s]\u001b[A\n",
            "4642it [05:55, 11.61it/s]\u001b[A\n",
            "4644it [05:55, 11.77it/s]\u001b[A\n",
            "4646it [05:56, 11.62it/s]\u001b[A\n",
            "4648it [05:56, 11.67it/s]\u001b[A\n",
            "4650it [05:56, 11.93it/s]\u001b[A\n",
            "4652it [05:56, 12.29it/s]\u001b[A\n",
            "4654it [05:56, 12.36it/s]\u001b[A\n",
            "4656it [05:56, 12.48it/s]\u001b[A\n",
            "4658it [05:57, 12.75it/s]\u001b[A\n",
            "4660it [05:57, 12.83it/s]\u001b[A\n",
            "4662it [05:57, 13.08it/s]\u001b[A\n",
            "4664it [05:57, 13.10it/s]\u001b[A\n",
            "4666it [05:57, 12.18it/s]\u001b[A\n",
            "4668it [05:57, 12.33it/s]\u001b[A\n",
            "4670it [05:57, 12.73it/s]\u001b[A\n",
            "4672it [05:58, 12.26it/s]\u001b[A\n",
            "4674it [05:58, 12.48it/s]\u001b[A\n",
            "4676it [05:58, 12.57it/s]\u001b[A\n",
            "4678it [05:58, 12.59it/s]\u001b[A\n",
            "4680it [05:58, 12.61it/s]\u001b[A\n",
            "4682it [05:58, 12.82it/s]\u001b[A\n",
            "4684it [05:59, 12.78it/s]\u001b[A\n",
            "4686it [05:59, 12.92it/s]\u001b[A\n",
            "4688it [05:59, 12.90it/s]\u001b[A\n",
            "4690it [05:59, 12.96it/s]\u001b[A\n",
            "4692it [05:59, 12.74it/s]\u001b[A\n",
            "4694it [05:59, 12.74it/s]\u001b[A\n",
            "4696it [06:00, 12.75it/s]\u001b[A\n",
            "4698it [06:00, 12.87it/s]\u001b[A\n",
            "4700it [06:00, 12.65it/s]\u001b[A\n",
            "4702it [06:00, 12.74it/s]\u001b[A\n",
            "4704it [06:00, 12.96it/s]\u001b[A\n",
            "4706it [06:00, 12.90it/s]\u001b[A\n",
            "4708it [06:00, 13.14it/s]\u001b[A\n",
            "4710it [06:01, 13.09it/s]\u001b[A\n",
            "4712it [06:01, 13.31it/s]\u001b[A\n",
            "4714it [06:01, 13.14it/s]\u001b[A\n",
            "4716it [06:01, 12.91it/s]\u001b[A\n",
            "4718it [06:01, 12.28it/s]\u001b[A\n",
            "4720it [06:01, 12.23it/s]\u001b[A\n",
            "4722it [06:02, 12.01it/s]\u001b[A\n",
            "4724it [06:02, 11.71it/s]\u001b[A\n",
            "4726it [06:02, 11.77it/s]\u001b[A\n",
            "4728it [06:02, 11.82it/s]\u001b[A\n",
            "4730it [06:02, 11.71it/s]\u001b[A\n",
            "4732it [06:02, 11.60it/s]\u001b[A\n",
            "4734it [06:03, 11.64it/s]\u001b[A\n",
            "4736it [06:03, 11.47it/s]\u001b[A\n",
            "4738it [06:03, 11.32it/s]\u001b[A\n",
            "4740it [06:03, 11.52it/s]\u001b[A\n",
            "4742it [06:03, 11.68it/s]\u001b[A\n",
            "4744it [06:03, 11.99it/s]\u001b[A\n",
            "4746it [06:04, 12.38it/s]\u001b[A\n",
            "4748it [06:04, 12.52it/s]\u001b[A\n",
            "4750it [06:04, 12.39it/s]\u001b[A\n",
            "4752it [06:04, 12.70it/s]\u001b[A\n",
            "4754it [06:04, 12.65it/s]\u001b[A\n",
            "4756it [06:04, 12.43it/s]\u001b[A\n",
            "4758it [06:05, 12.13it/s]\u001b[A\n",
            "4760it [06:05, 11.81it/s]\u001b[A\n",
            "4762it [06:05, 11.73it/s]\u001b[A\n",
            "4764it [06:05, 11.86it/s]\u001b[A\n",
            "4766it [06:05, 12.08it/s]\u001b[A\n",
            "4768it [06:05, 12.33it/s]\u001b[A\n",
            "4770it [06:06, 12.86it/s]\u001b[A\n",
            "4772it [06:06, 12.62it/s]\u001b[A\n",
            "4774it [06:06, 12.57it/s]\u001b[A\n",
            "4776it [06:06, 12.81it/s]\u001b[A\n",
            "4778it [06:06, 12.74it/s]\u001b[A\n",
            "4780it [06:06, 12.71it/s]\u001b[A\n",
            "4782it [06:06, 12.72it/s]\u001b[A\n",
            "4784it [06:07, 12.90it/s]\u001b[A\n",
            "4786it [06:07, 12.96it/s]\u001b[A\n",
            "4788it [06:07, 12.92it/s]\u001b[A\n",
            "4790it [06:07, 12.71it/s]\u001b[A\n",
            "4792it [06:07, 13.15it/s]\u001b[A\n",
            "4794it [06:07, 12.99it/s]\u001b[A\n",
            "4796it [06:08, 13.12it/s]\u001b[A\n",
            "4798it [06:08, 12.94it/s]\u001b[A\n",
            "4800it [06:08, 12.95it/s]\u001b[A\n",
            "4802it [06:08, 12.88it/s]\u001b[A\n",
            "4804it [06:08, 13.33it/s]\u001b[A\n",
            "4806it [06:08, 13.25it/s]\u001b[A\n",
            "4808it [06:08, 13.39it/s]\u001b[A\n",
            "4810it [06:09, 13.64it/s]\u001b[A\n",
            "4812it [06:09, 13.43it/s]\u001b[A\n",
            "4814it [06:09, 13.15it/s]\u001b[A\n",
            "4816it [06:09, 12.95it/s]\u001b[A\n",
            "4818it [06:09, 12.84it/s]\u001b[A\n",
            "4820it [06:09, 12.72it/s]\u001b[A\n",
            "4822it [06:10, 12.90it/s]\u001b[A\n",
            "4824it [06:10, 12.97it/s]\u001b[A\n",
            "4826it [06:10, 12.75it/s]\u001b[A\n",
            "4828it [06:10, 12.35it/s]\u001b[A\n",
            "4830it [06:10, 12.15it/s]\u001b[A\n",
            "4832it [06:10, 12.39it/s]\u001b[A\n",
            "4834it [06:11, 12.83it/s]\u001b[A\n",
            "4836it [06:11, 12.68it/s]\u001b[A\n",
            "4838it [06:11, 12.93it/s]\u001b[A\n",
            "4840it [06:11, 12.87it/s]\u001b[A\n",
            "4842it [06:11, 12.52it/s]\u001b[A\n",
            "4844it [06:11, 12.49it/s]\u001b[A\n",
            "4846it [06:11, 12.64it/s]\u001b[A\n",
            "4848it [06:12, 12.82it/s]\u001b[A\n",
            "4850it [06:12, 12.85it/s]\u001b[A\n",
            "4852it [06:12, 12.58it/s]\u001b[A\n",
            "4854it [06:12, 11.97it/s]\u001b[A\n",
            "4856it [06:12, 11.65it/s]\u001b[A\n",
            "4858it [06:12, 11.65it/s]\u001b[A\n",
            "4860it [06:13, 11.32it/s]\u001b[A\n",
            "4862it [06:13, 11.46it/s]\u001b[A\n",
            "4864it [06:13, 11.56it/s]\u001b[A\n",
            "4866it [06:13, 11.60it/s]\u001b[A\n",
            "4868it [06:13, 11.87it/s]\u001b[A\n",
            "4870it [06:14, 11.97it/s]\u001b[A\n",
            "4872it [06:14, 12.39it/s]\u001b[A\n",
            "4874it [06:14, 12.38it/s]\u001b[A\n",
            "4876it [06:14, 12.30it/s]\u001b[A\n",
            "4878it [06:14, 12.48it/s]\u001b[A\n",
            "4880it [06:14, 12.59it/s]\u001b[A\n",
            "4882it [06:14, 12.70it/s]\u001b[A\n",
            "4884it [06:15, 12.61it/s]\u001b[A\n",
            "4886it [06:15, 12.22it/s]\u001b[A\n",
            "4888it [06:15, 12.69it/s]\u001b[A\n",
            "4890it [06:15, 12.94it/s]\u001b[A\n",
            "4892it [06:15, 13.24it/s]\u001b[A\n",
            "4894it [06:15, 13.23it/s]\u001b[A\n",
            "4896it [06:16, 13.02it/s]\u001b[A\n",
            "4898it [06:16, 13.04it/s]\u001b[A\n",
            "4900it [06:16, 12.68it/s]\u001b[A\n",
            "4902it [06:16, 12.47it/s]\u001b[A\n",
            "4904it [06:16, 12.24it/s]\u001b[A\n",
            "4906it [06:16, 11.96it/s]\u001b[A\n",
            "4908it [06:17, 11.73it/s]\u001b[A\n",
            "4910it [06:17, 11.62it/s]\u001b[A\n",
            "4912it [06:17, 11.88it/s]\u001b[A\n",
            "4914it [06:17, 12.00it/s]\u001b[A\n",
            "4916it [06:17, 12.36it/s]\u001b[A\n",
            "4918it [06:17, 12.49it/s]\u001b[A\n",
            "4920it [06:17, 12.65it/s]\u001b[A\n",
            "4922it [06:18, 13.09it/s]\u001b[A\n",
            "4924it [06:18, 13.17it/s]\u001b[A\n",
            "4926it [06:18, 13.16it/s]\u001b[A\n",
            "4928it [06:18, 13.09it/s]\u001b[A\n",
            "4930it [06:18, 13.32it/s]\u001b[A\n",
            "4932it [06:18, 13.26it/s]\u001b[A\n",
            "4934it [06:19, 13.23it/s]\u001b[A\n",
            "4936it [06:19, 13.46it/s]\u001b[A\n",
            "4938it [06:19, 13.22it/s]\u001b[A\n",
            "4940it [06:19, 13.09it/s]\u001b[A\n",
            "4942it [06:19, 13.13it/s]\u001b[A\n",
            "4944it [06:19, 13.38it/s]\u001b[A\n",
            "4946it [06:19, 13.37it/s]\u001b[A\n",
            "4948it [06:20, 13.25it/s]\u001b[A\n",
            "4950it [06:20, 13.19it/s]\u001b[A\n",
            "4952it [06:20, 13.34it/s]\u001b[A\n",
            "4954it [06:20, 13.18it/s]\u001b[A\n",
            "4956it [06:20, 12.82it/s]\u001b[A\n",
            "4958it [06:20, 12.97it/s]\u001b[A\n",
            "4960it [06:21, 12.53it/s]\u001b[A\n",
            "4962it [06:21, 12.70it/s]\u001b[A\n",
            "4964it [06:21, 13.05it/s]\u001b[A\n",
            "4966it [06:21, 13.17it/s]\u001b[A\n",
            "4968it [06:21, 13.18it/s]\u001b[A\n",
            "4970it [06:21, 13.23it/s]\u001b[A\n",
            "4972it [06:21, 13.43it/s]\u001b[A\n",
            "4974it [06:22, 13.30it/s]\u001b[A\n",
            "4976it [06:22, 13.51it/s]\u001b[A\n",
            "4978it [06:22, 12.92it/s]\u001b[A\n",
            "4980it [06:22, 12.39it/s]\u001b[A\n",
            "4982it [06:22, 12.20it/s]\u001b[A\n",
            "4984it [06:22, 12.68it/s]\u001b[A\n",
            "4986it [06:23, 12.62it/s]\u001b[A\n",
            "4988it [06:23, 12.73it/s]\u001b[A\n",
            "4990it [06:23, 12.63it/s]\u001b[A\n",
            "4992it [06:23, 12.06it/s]\u001b[A\n",
            "4994it [06:23, 12.04it/s]\u001b[A\n",
            "4996it [06:23, 11.97it/s]\u001b[A\n",
            "4998it [06:24, 12.04it/s]\u001b[A\n",
            "5000it [06:24, 12.23it/s]\u001b[A\n",
            "5002it [06:24, 12.65it/s]\u001b[A\n",
            "5004it [06:24, 12.79it/s]\u001b[A\n",
            "5006it [06:24, 12.93it/s]\u001b[A\n",
            "5008it [06:24, 12.75it/s]\u001b[A\n",
            "5010it [06:24, 13.01it/s]\u001b[A\n",
            "5012it [06:25, 12.83it/s]\u001b[A\n",
            "5014it [06:25, 13.01it/s]\u001b[A\n",
            "5016it [06:25, 12.54it/s]\u001b[A\n",
            "5018it [06:25, 12.15it/s]\u001b[A\n",
            "5020it [06:25, 12.21it/s]\u001b[A\n",
            "5022it [06:25, 12.63it/s]\u001b[A\n",
            "5024it [06:26, 12.55it/s]\u001b[A\n",
            "5026it [06:26, 12.46it/s]\u001b[A\n",
            "5028it [06:26, 12.64it/s]\u001b[A\n",
            "5030it [06:26, 12.89it/s]\u001b[A\n",
            "5032it [06:26, 12.88it/s]\u001b[A\n",
            "5034it [06:26, 12.69it/s]\u001b[A\n",
            "5036it [06:27, 12.46it/s]\u001b[A\n",
            "5038it [06:27, 11.96it/s]\u001b[A\n",
            "5040it [06:27, 12.07it/s]\u001b[A\n",
            "5042it [06:27, 11.93it/s]\u001b[A\n",
            "5044it [06:27, 11.82it/s]\u001b[A\n",
            "5046it [06:27, 11.84it/s]\u001b[A\n",
            "5048it [06:28, 12.41it/s]\u001b[A\n",
            "5050it [06:28, 11.92it/s]\u001b[A\n",
            "5052it [06:28, 11.95it/s]\u001b[A\n",
            "5054it [06:28, 12.34it/s]\u001b[A\n",
            "5056it [06:28, 12.30it/s]\u001b[A\n",
            "5058it [06:28, 12.70it/s]\u001b[A\n",
            "5060it [06:28, 12.94it/s]\u001b[A\n",
            "5062it [06:29, 12.86it/s]\u001b[A\n",
            "5064it [06:29, 12.80it/s]\u001b[A\n",
            "5066it [06:29, 13.03it/s]\u001b[A\n",
            "5068it [06:29, 12.99it/s]\u001b[A\n",
            "5070it [06:29, 12.96it/s]\u001b[A\n",
            "5072it [06:29, 13.09it/s]\u001b[A\n",
            "5074it [06:30, 13.23it/s]\u001b[A\n",
            "5076it [06:30, 12.98it/s]\u001b[A\n",
            "5078it [06:30, 13.11it/s]\u001b[A\n",
            "5080it [06:30, 12.71it/s]\u001b[A\n",
            "5082it [06:30, 12.28it/s]\u001b[A\n",
            "5084it [06:30, 11.94it/s]\u001b[A\n",
            "5086it [06:31, 11.87it/s]\u001b[A\n",
            "5088it [06:31, 11.42it/s]\u001b[A\n",
            "5090it [06:31, 11.69it/s]\u001b[A\n",
            "5092it [06:31, 12.06it/s]\u001b[A\n",
            "5094it [06:31, 12.37it/s]\u001b[A\n",
            "5096it [06:31, 12.46it/s]\u001b[A\n",
            "5098it [06:32, 12.52it/s]\u001b[A\n",
            "5100it [06:32, 12.66it/s]\u001b[A\n",
            "5102it [06:32, 12.83it/s]\u001b[A\n",
            "5104it [06:32, 12.98it/s]\u001b[A\n",
            "5106it [06:32, 13.02it/s]\u001b[A\n",
            "5108it [06:32, 13.10it/s]\u001b[A\n",
            "5110it [06:32, 13.45it/s]\u001b[A\n",
            "5112it [06:33, 13.37it/s]\u001b[A\n",
            "5114it [06:33, 13.14it/s]\u001b[A\n",
            "5116it [06:33, 13.19it/s]\u001b[A\n",
            "5118it [06:33, 12.81it/s]\u001b[A\n",
            "5120it [06:33, 12.70it/s]\u001b[A\n",
            "5122it [06:33, 12.32it/s]\u001b[A\n",
            "5124it [06:34, 11.87it/s]\u001b[A\n",
            "5126it [06:34, 12.07it/s]\u001b[A\n",
            "5128it [06:34, 12.22it/s]\u001b[A\n",
            "5130it [06:34, 12.51it/s]\u001b[A\n",
            "5132it [06:34, 12.85it/s]\u001b[A\n",
            "5134it [06:34, 12.75it/s]\u001b[A\n",
            "5136it [06:35, 12.42it/s]\u001b[A\n",
            "5138it [06:35, 12.58it/s]\u001b[A\n",
            "5140it [06:35, 12.79it/s]\u001b[A\n",
            "5142it [06:35, 12.99it/s]\u001b[A\n",
            "5144it [06:35, 12.99it/s]\u001b[A\n",
            "5146it [06:35, 13.09it/s]\u001b[A\n",
            "5148it [06:35, 13.28it/s]\u001b[A\n",
            "5150it [06:36, 13.30it/s]\u001b[A\n",
            "5152it [06:36, 13.00it/s]\u001b[A\n",
            "5154it [06:36, 12.84it/s]\u001b[A\n",
            "5156it [06:36, 12.97it/s]\u001b[A\n",
            "5158it [06:36, 13.03it/s]\u001b[A\n",
            "5160it [06:36, 12.86it/s]\u001b[A\n",
            "5162it [06:37, 12.95it/s]\u001b[A\n",
            "5164it [06:37, 13.23it/s]\u001b[A\n",
            "5166it [06:37, 13.01it/s]\u001b[A\n",
            "5168it [06:37, 12.97it/s]\u001b[A\n",
            "5170it [06:37, 12.96it/s]\u001b[A\n",
            "5172it [06:37, 13.00it/s]\u001b[A\n",
            "5174it [06:37, 13.14it/s]\u001b[A\n",
            "5176it [06:38, 12.98it/s]\u001b[A\n",
            "5178it [06:38, 12.84it/s]\u001b[A\n",
            "5180it [06:38, 12.97it/s]\u001b[A\n",
            "5182it [06:38, 13.04it/s]\u001b[A\n",
            "5184it [06:38, 12.82it/s]\u001b[A\n",
            "5186it [06:38, 12.44it/s]\u001b[A\n",
            "5188it [06:39, 12.09it/s]\u001b[A\n",
            "5190it [06:39, 11.72it/s]\u001b[A\n",
            "5192it [06:39, 11.65it/s]\u001b[A\n",
            "5194it [06:39, 11.63it/s]\u001b[A\n",
            "5196it [06:39, 12.02it/s]\u001b[A\n",
            "5198it [06:39, 12.45it/s]\u001b[A\n",
            "5200it [06:40, 11.86it/s]\u001b[A\n",
            "5202it [06:40, 12.02it/s]\u001b[A\n",
            "5204it [06:40, 12.03it/s]\u001b[A\n",
            "5206it [06:40, 12.33it/s]\u001b[A\n",
            "5208it [06:40, 12.61it/s]\u001b[A\n",
            "5210it [06:40, 12.82it/s]\u001b[A\n",
            "5212it [06:41, 13.03it/s]\u001b[A\n",
            "5214it [06:41, 13.00it/s]\u001b[A\n",
            "5216it [06:41, 12.71it/s]\u001b[A\n",
            "5218it [06:41, 12.72it/s]\u001b[A\n",
            "5220it [06:41, 12.96it/s]\u001b[A\n",
            "5222it [06:41, 13.25it/s]\u001b[A\n",
            "5224it [06:41, 13.21it/s]\u001b[A\n",
            "5226it [06:42, 12.89it/s]\u001b[A\n",
            "5228it [06:42, 13.02it/s]\u001b[A\n",
            "5230it [06:42, 12.88it/s]\u001b[A\n",
            "5232it [06:42, 13.03it/s]\u001b[A\n",
            "5234it [06:42, 13.14it/s]\u001b[A\n",
            "5236it [06:42, 13.18it/s]\u001b[A\n",
            "5238it [06:42, 13.19it/s]\u001b[A\n",
            "5240it [06:43, 12.89it/s]\u001b[A\n",
            "5242it [06:43, 12.40it/s]\u001b[A\n",
            "5244it [06:43, 12.55it/s]\u001b[A\n",
            "5246it [06:43, 12.81it/s]\u001b[A\n",
            "5248it [06:43, 13.04it/s]\u001b[A\n",
            "5250it [06:43, 12.98it/s]\u001b[A\n",
            "5252it [06:44, 12.99it/s]\u001b[A\n",
            "5254it [06:44, 12.63it/s]\u001b[A\n",
            "5256it [06:44, 12.67it/s]\u001b[A\n",
            "5258it [06:44, 12.74it/s]\u001b[A\n",
            "5260it [06:44, 12.95it/s]\u001b[A\n",
            "5262it [06:44, 13.20it/s]\u001b[A\n",
            "5264it [06:45, 13.15it/s]\u001b[A\n",
            "5266it [06:45, 13.37it/s]\u001b[A\n",
            "5268it [06:45, 13.16it/s]\u001b[A\n",
            "5270it [06:45, 13.15it/s]\u001b[A\n",
            "5272it [06:45, 13.13it/s]\u001b[A\n",
            "5274it [06:45, 13.00it/s]\u001b[A\n",
            "5276it [06:45, 12.85it/s]\u001b[A\n",
            "5278it [06:46, 12.65it/s]\u001b[A\n",
            "5280it [06:46, 12.35it/s]\u001b[A\n",
            "5282it [06:46, 11.62it/s]\u001b[A\n",
            "5284it [06:46, 11.42it/s]\u001b[A\n",
            "5286it [06:46, 11.60it/s]\u001b[A\n",
            "5288it [06:46, 11.81it/s]\u001b[A\n",
            "5290it [06:47, 11.61it/s]\u001b[A\n",
            "5292it [06:47, 11.98it/s]\u001b[A\n",
            "5294it [06:47, 12.11it/s]\u001b[A\n",
            "5296it [06:47, 12.28it/s]\u001b[A\n",
            "5298it [06:47, 12.41it/s]\u001b[A\n",
            "5300it [06:47, 12.46it/s]\u001b[A\n",
            "5302it [06:48, 12.29it/s]\u001b[A\n",
            "5304it [06:48, 12.01it/s]\u001b[A\n",
            "5306it [06:48, 11.59it/s]\u001b[A\n",
            "5308it [06:48, 11.57it/s]\u001b[A\n",
            "5310it [06:48, 11.93it/s]\u001b[A\n",
            "5312it [06:48, 12.25it/s]\u001b[A\n",
            "5314it [06:49, 12.36it/s]\u001b[A\n",
            "5316it [06:49, 12.52it/s]\u001b[A\n",
            "5318it [06:49, 12.52it/s]\u001b[A\n",
            "5320it [06:49, 12.67it/s]\u001b[A\n",
            "5322it [06:49, 12.78it/s]\u001b[A\n",
            "5324it [06:49, 13.10it/s]\u001b[A\n",
            "5326it [06:50, 13.04it/s]\u001b[A\n",
            "5328it [06:50, 12.88it/s]\u001b[A\n",
            "5330it [06:50, 12.77it/s]\u001b[A\n",
            "5332it [06:50, 12.66it/s]\u001b[A\n",
            "5334it [06:50, 12.93it/s]\u001b[A\n",
            "5336it [06:50, 12.82it/s]\u001b[A\n",
            "5338it [06:50, 13.01it/s]\u001b[A\n",
            "5340it [06:51, 12.69it/s]\u001b[A\n",
            "5342it [06:51, 12.38it/s]\u001b[A\n",
            "5344it [06:51, 12.39it/s]\u001b[A\n",
            "5346it [06:51, 12.79it/s]\u001b[A\n",
            "5348it [06:51, 12.75it/s]\u001b[A\n",
            "5350it [06:51, 12.34it/s]\u001b[A\n",
            "5352it [06:52, 12.17it/s]\u001b[A\n",
            "5354it [06:52, 12.56it/s]\u001b[A\n",
            "5356it [06:52, 12.02it/s]\u001b[A\n",
            "5358it [06:52, 11.98it/s]\u001b[A\n",
            "5360it [06:52, 11.65it/s]\u001b[A\n",
            "5362it [06:52, 11.92it/s]\u001b[A\n",
            "5364it [06:53, 12.23it/s]\u001b[A\n",
            "5366it [06:53, 12.21it/s]\u001b[A\n",
            "5368it [06:53, 11.84it/s]\u001b[A\n",
            "5370it [06:53, 11.78it/s]\u001b[A\n",
            "5372it [06:53, 11.72it/s]\u001b[A\n",
            "5374it [06:53, 11.69it/s]\u001b[A\n",
            "5376it [06:54, 11.57it/s]\u001b[A\n",
            "5378it [06:54, 11.91it/s]\u001b[A\n",
            "5380it [06:54, 11.72it/s]\u001b[A\n",
            "5382it [06:54, 11.57it/s]\u001b[A\n",
            "5384it [06:54, 11.90it/s]\u001b[A\n",
            "5386it [06:55, 11.62it/s]\u001b[A\n",
            "5388it [06:55, 11.72it/s]\u001b[A\n",
            "5390it [06:55, 11.73it/s]\u001b[A\n",
            "5392it [06:55, 11.95it/s]\u001b[A\n",
            "5394it [06:55, 12.30it/s]\u001b[A\n",
            "5396it [06:55, 12.68it/s]\u001b[A\n",
            "5398it [06:55, 12.73it/s]\u001b[A\n",
            "5400it [06:56, 12.68it/s]\u001b[A\n",
            "5402it [06:56, 12.81it/s]\u001b[A\n",
            "5404it [06:56, 12.87it/s]\u001b[A\n",
            "5406it [06:56, 12.74it/s]\u001b[A\n",
            "5408it [06:56, 12.92it/s]\u001b[A\n",
            "5410it [06:56, 12.93it/s]\u001b[A\n",
            "5412it [06:57, 13.10it/s]\u001b[A\n",
            "5414it [06:57, 13.05it/s]\u001b[A\n",
            "5416it [06:57, 13.08it/s]\u001b[A\n",
            "5418it [06:57, 12.37it/s]\u001b[A\n",
            "5420it [06:57, 12.26it/s]\u001b[A\n",
            "5422it [06:57, 12.01it/s]\u001b[A\n",
            "5424it [06:58, 11.81it/s]\u001b[A\n",
            "5426it [06:58, 11.95it/s]\u001b[A\n",
            "5428it [06:58, 12.32it/s]\u001b[A\n",
            "5430it [06:58, 12.13it/s]\u001b[A\n",
            "5432it [06:58, 12.16it/s]\u001b[A\n",
            "5434it [06:58, 12.35it/s]\u001b[A\n",
            "5436it [06:59, 12.51it/s]\u001b[A\n",
            "5438it [06:59, 12.87it/s]\u001b[A\n",
            "5440it [06:59, 12.55it/s]\u001b[A\n",
            "5442it [06:59, 12.21it/s]\u001b[A\n",
            "5444it [06:59, 11.76it/s]\u001b[A\n",
            "5446it [06:59, 11.69it/s]\u001b[A\n",
            "5448it [07:00, 11.76it/s]\u001b[A\n",
            "5450it [07:00, 11.93it/s]\u001b[A\n",
            "5452it [07:00, 12.05it/s]\u001b[A\n",
            "5454it [07:00, 12.43it/s]\u001b[A\n",
            "5456it [07:00, 12.80it/s]\u001b[A\n",
            "5458it [07:00, 12.89it/s]\u001b[A\n",
            "5460it [07:00, 12.93it/s]\u001b[A\n",
            "5462it [07:01, 13.04it/s]\u001b[A\n",
            "5464it [07:01, 12.88it/s]\u001b[A\n",
            "5466it [07:01, 12.80it/s]\u001b[A\n",
            "5468it [07:01, 12.66it/s]\u001b[A\n",
            "5470it [07:01, 12.79it/s]\u001b[A\n",
            "5472it [07:01, 12.99it/s]\u001b[A\n",
            "5474it [07:02, 13.09it/s]\u001b[A\n",
            "5476it [07:02, 12.65it/s]\u001b[A\n",
            "5478it [07:02, 12.46it/s]\u001b[A\n",
            "5480it [07:02, 12.69it/s]\u001b[A\n",
            "5482it [07:02, 12.69it/s]\u001b[A\n",
            "5484it [07:02, 12.70it/s]\u001b[A\n",
            "5486it [07:02, 12.89it/s]\u001b[A\n",
            "5488it [07:03, 12.93it/s]\u001b[A\n",
            "5490it [07:03, 13.07it/s]\u001b[A\n",
            "5492it [07:03, 13.14it/s]\u001b[A\n",
            "5494it [07:03, 13.01it/s]\u001b[A\n",
            "5496it [07:03, 12.86it/s]\u001b[A\n",
            "5498it [07:03, 13.14it/s]\u001b[A\n",
            "5500it [07:04, 12.98it/s]\u001b[A\n",
            "5502it [07:04, 12.77it/s]\u001b[A\n",
            "5504it [07:04, 12.77it/s]\u001b[A\n",
            "5506it [07:04, 12.85it/s]\u001b[A\n",
            "5508it [07:04, 12.56it/s]\u001b[A\n",
            "5510it [07:04, 12.43it/s]\u001b[A\n",
            "5512it [07:05, 12.48it/s]\u001b[A\n",
            "5514it [07:05, 12.64it/s]\u001b[A\n",
            "5516it [07:05, 12.79it/s]\u001b[A\n",
            "5518it [07:05, 12.79it/s]\u001b[A\n",
            "5520it [07:05, 12.86it/s]\u001b[A\n",
            "5522it [07:05, 13.08it/s]\u001b[A\n",
            "5524it [07:05, 13.03it/s]\u001b[A\n",
            "5526it [07:06, 13.06it/s]\u001b[A\n",
            "5528it [07:06, 12.94it/s]\u001b[A\n",
            "5530it [07:06, 12.73it/s]\u001b[A\n",
            "5532it [07:06, 12.87it/s]\u001b[A\n",
            "5534it [07:06, 12.79it/s]\u001b[A\n",
            "5536it [07:06, 12.95it/s]\u001b[A\n",
            "5538it [07:07, 12.93it/s]\u001b[A\n",
            "5540it [07:07, 12.92it/s]\u001b[A\n",
            "5542it [07:07, 12.89it/s]\u001b[A\n",
            "5544it [07:07, 12.73it/s]\u001b[A\n",
            "5546it [07:07, 12.68it/s]\u001b[A\n",
            "5548it [07:07, 12.87it/s]\u001b[A\n",
            "5550it [07:07, 13.16it/s]\u001b[A\n",
            "5552it [07:08, 12.92it/s]\u001b[A\n",
            "5554it [07:08, 12.85it/s]\u001b[A\n",
            "5556it [07:08, 12.41it/s]\u001b[A\n",
            "5558it [07:08, 12.87it/s]\u001b[A\n",
            "5560it [07:08, 12.84it/s]\u001b[A\n",
            "5562it [07:08, 12.88it/s]\u001b[A\n",
            "5564it [07:09, 12.82it/s]\u001b[A\n",
            "5566it [07:09, 12.81it/s]\u001b[A\n",
            "5568it [07:09, 12.72it/s]\u001b[A\n",
            "5570it [07:09, 12.70it/s]\u001b[A\n",
            "5572it [07:09, 12.77it/s]\u001b[A\n",
            "5574it [07:09, 12.93it/s]\u001b[A\n",
            "5576it [07:09, 12.67it/s]\u001b[A\n",
            "5578it [07:10, 12.21it/s]\u001b[A\n",
            "5580it [07:10, 12.62it/s]\u001b[A\n",
            "5582it [07:10, 12.70it/s]\u001b[A\n",
            "5584it [07:10, 12.70it/s]\u001b[A\n",
            "5586it [07:10, 12.71it/s]\u001b[A\n",
            "5588it [07:10, 12.85it/s]\u001b[A\n",
            "5590it [07:11, 12.92it/s]\u001b[A\n",
            "5592it [07:11, 12.42it/s]\u001b[A\n",
            "5594it [07:11, 12.36it/s]\u001b[A\n",
            "5596it [07:11, 12.70it/s]\u001b[A\n",
            "5598it [07:11, 12.77it/s]\u001b[A\n",
            "5600it [07:11, 12.86it/s]\u001b[A\n",
            "5602it [07:12, 12.99it/s]\u001b[A\n",
            "5604it [07:12, 13.03it/s]\u001b[A\n",
            "5606it [07:12, 12.89it/s]\u001b[A\n",
            "5608it [07:12, 12.41it/s]\u001b[A\n",
            "5610it [07:12, 11.97it/s]\u001b[A\n",
            "5612it [07:12, 11.83it/s]\u001b[A\n",
            "5614it [07:13, 11.72it/s]\u001b[A\n",
            "5616it [07:13, 11.83it/s]\u001b[A\n",
            "5618it [07:13, 12.11it/s]\u001b[A\n",
            "5620it [07:13, 12.30it/s]\u001b[A\n",
            "5622it [07:13, 12.38it/s]\u001b[A\n",
            "5624it [07:13, 12.69it/s]\u001b[A\n",
            "5626it [07:13, 12.95it/s]\u001b[A\n",
            "5628it [07:14, 13.01it/s]\u001b[A\n",
            "5630it [07:14, 13.02it/s]\u001b[A\n",
            "5632it [07:14, 12.75it/s]\u001b[A\n",
            "5634it [07:14, 12.64it/s]\u001b[A\n",
            "5636it [07:14, 12.64it/s]\u001b[A\n",
            "5638it [07:14, 12.77it/s]\u001b[A\n",
            "5640it [07:15, 12.73it/s]\u001b[A\n",
            "5642it [07:15, 13.00it/s]\u001b[A\n",
            "5644it [07:15, 12.77it/s]\u001b[A\n",
            "5646it [07:15, 12.32it/s]\u001b[A\n",
            "5648it [07:15, 12.29it/s]\u001b[A\n",
            "5650it [07:15, 11.94it/s]\u001b[A\n",
            "5652it [07:16, 11.76it/s]\u001b[A\n",
            "5654it [07:16, 12.18it/s]\u001b[A\n",
            "5656it [07:16, 12.38it/s]\u001b[A\n",
            "5658it [07:16, 12.52it/s]\u001b[A\n",
            "5660it [07:16, 12.78it/s]\u001b[A\n",
            "5662it [07:16, 12.42it/s]\u001b[A\n",
            "5664it [07:17, 12.02it/s]\u001b[A\n",
            "5666it [07:17, 11.85it/s]\u001b[A\n",
            "5668it [07:17, 12.03it/s]\u001b[A\n",
            "5670it [07:17, 12.30it/s]\u001b[A\n",
            "5672it [07:17, 12.49it/s]\u001b[A\n",
            "5674it [07:17, 12.77it/s]\u001b[A\n",
            "5676it [07:17, 12.89it/s]\u001b[A\n",
            "5678it [07:18, 12.80it/s]\u001b[A\n",
            "5680it [07:18, 12.88it/s]\u001b[A\n",
            "5682it [07:18, 12.44it/s]\u001b[A\n",
            "5684it [07:18, 12.21it/s]\u001b[A\n",
            "5686it [07:18, 12.14it/s]\u001b[A\n",
            "5688it [07:18, 12.43it/s]\u001b[A\n",
            "5690it [07:19, 12.62it/s]\u001b[A\n",
            "5692it [07:19, 12.66it/s]\u001b[A\n",
            "5694it [07:19, 12.76it/s]\u001b[A\n",
            "5696it [07:19, 13.06it/s]\u001b[A\n",
            "5698it [07:19, 13.00it/s]\u001b[A\n",
            "5700it [07:19, 12.94it/s]\u001b[A\n",
            "5702it [07:20, 13.03it/s]\u001b[A\n",
            "5704it [07:20, 13.08it/s]\u001b[A\n",
            "5706it [07:20, 12.92it/s]\u001b[A\n",
            "5708it [07:20, 13.06it/s]\u001b[A\n",
            "5710it [07:20, 12.94it/s]\u001b[A\n",
            "5712it [07:20, 12.95it/s]\u001b[A\n",
            "5714it [07:20, 12.91it/s]\u001b[A\n",
            "5716it [07:21, 12.85it/s]\u001b[A\n",
            "5718it [07:21, 12.50it/s]\u001b[A\n",
            "5720it [07:21, 12.56it/s]\u001b[A\n",
            "5722it [07:21, 12.75it/s]\u001b[A\n",
            "5724it [07:21, 13.02it/s]\u001b[A\n",
            "5726it [07:21, 12.99it/s]\u001b[A\n",
            "5728it [07:22, 13.20it/s]\u001b[A\n",
            "5730it [07:22, 13.02it/s]\u001b[A\n",
            "5732it [07:22, 12.83it/s]\u001b[A\n",
            "5734it [07:22, 12.92it/s]\u001b[A\n",
            "5736it [07:22, 12.94it/s]\u001b[A\n",
            "5738it [07:22, 13.15it/s]\u001b[A\n",
            "5740it [07:22, 12.96it/s]\u001b[A\n",
            "5742it [07:23, 13.03it/s]\u001b[A\n",
            "5744it [07:23, 12.94it/s]\u001b[A\n",
            "5746it [07:23, 13.02it/s]\u001b[A\n",
            "5748it [07:23, 12.95it/s]\u001b[A\n",
            "5750it [07:23, 12.85it/s]\u001b[A\n",
            "5752it [07:23, 12.59it/s]\u001b[A\n",
            "5754it [07:24, 12.43it/s]\u001b[A\n",
            "5756it [07:24, 12.67it/s]\u001b[A\n",
            "5758it [07:24, 12.83it/s]\u001b[A\n",
            "5760it [07:24, 13.00it/s]\u001b[A\n",
            "5762it [07:24, 13.03it/s]\u001b[A\n",
            "5764it [07:24, 13.09it/s]\u001b[A\n",
            "5766it [07:25, 12.79it/s]\u001b[A\n",
            "5768it [07:25, 13.02it/s]\u001b[A\n",
            "5770it [07:25, 13.10it/s]\u001b[A\n",
            "5772it [07:25, 12.98it/s]\u001b[A\n",
            "5774it [07:25, 12.25it/s]\u001b[A\n",
            "5776it [07:25, 12.03it/s]\u001b[A\n",
            "5778it [07:25, 11.78it/s]\u001b[A\n",
            "5780it [07:26, 11.75it/s]\u001b[A\n",
            "5782it [07:26, 12.05it/s]\u001b[A\n",
            "5784it [07:26, 12.24it/s]\u001b[A\n",
            "5786it [07:26, 12.32it/s]\u001b[A\n",
            "5788it [07:26, 12.33it/s]\u001b[A\n",
            "5790it [07:26, 12.40it/s]\u001b[A\n",
            "5792it [07:27, 12.47it/s]\u001b[A\n",
            "5794it [07:27, 12.59it/s]\u001b[A\n",
            "5796it [07:27, 12.76it/s]\u001b[A\n",
            "5798it [07:27, 12.72it/s]\u001b[A\n",
            "5800it [07:27, 12.86it/s]\u001b[A\n",
            "5802it [07:27, 13.01it/s]\u001b[A\n",
            "5804it [07:28, 12.71it/s]\u001b[A\n",
            "5806it [07:28, 12.70it/s]\u001b[A\n",
            "5808it [07:28, 12.85it/s]\u001b[A\n",
            "5810it [07:28, 12.46it/s]\u001b[A\n",
            "5812it [07:28, 12.14it/s]\u001b[A\n",
            "5814it [07:28, 11.97it/s]\u001b[A\n",
            "5816it [07:29, 11.71it/s]\u001b[A\n",
            "5818it [07:29, 11.58it/s]\u001b[A\n",
            "5820it [07:29, 11.93it/s]\u001b[A\n",
            "5822it [07:29, 12.23it/s]\u001b[A\n",
            "5824it [07:29, 12.20it/s]\u001b[A\n",
            "5826it [07:29, 12.22it/s]\u001b[A\n",
            "5828it [07:30, 12.57it/s]\u001b[A\n",
            "5830it [07:30, 12.77it/s]\u001b[A\n",
            "5832it [07:30, 12.64it/s]\u001b[A\n",
            "5834it [07:30, 12.69it/s]\u001b[A\n",
            "5836it [07:30, 12.30it/s]\u001b[A\n",
            "5838it [07:30, 12.00it/s]\u001b[A\n",
            "5840it [07:31, 11.62it/s]\u001b[A\n",
            "5842it [07:31, 11.39it/s]\u001b[A\n",
            "5844it [07:31, 11.25it/s]\u001b[A\n",
            "5846it [07:31, 11.24it/s]\u001b[A\n",
            "5848it [07:31, 11.36it/s]\u001b[A\n",
            "5850it [07:31, 11.38it/s]\u001b[A\n",
            "5852it [07:32, 11.46it/s]\u001b[A\n",
            "5854it [07:32, 11.51it/s]\u001b[A\n",
            "5856it [07:32, 11.59it/s]\u001b[A\n",
            "5858it [07:32, 11.96it/s]\u001b[A\n",
            "5860it [07:32, 12.36it/s]\u001b[A\n",
            "5862it [07:32, 12.55it/s]\u001b[A\n",
            "5864it [07:33, 12.56it/s]\u001b[A\n",
            "5866it [07:33, 12.72it/s]\u001b[A\n",
            "5868it [07:33, 13.09it/s]\u001b[A\n",
            "5870it [07:33, 13.26it/s]\u001b[A\n",
            "5872it [07:33, 13.20it/s]\u001b[A\n",
            "5874it [07:33, 13.02it/s]\u001b[A\n",
            "5876it [07:33, 12.94it/s]\u001b[A\n",
            "5878it [07:34, 12.15it/s]\u001b[A\n",
            "5880it [07:34, 12.34it/s]\u001b[A\n",
            "5882it [07:34, 12.24it/s]\u001b[A\n",
            "5884it [07:34, 11.96it/s]\u001b[A\n",
            "5886it [07:34, 12.47it/s]\u001b[A\n",
            "5888it [07:34, 12.42it/s]\u001b[A\n",
            "5890it [07:35, 12.53it/s]\u001b[A\n",
            "5892it [07:35, 12.77it/s]\u001b[A\n",
            "5894it [07:35, 12.83it/s]\u001b[A\n",
            "5896it [07:35, 13.05it/s]\u001b[A\n",
            "5898it [07:35, 13.17it/s]\u001b[A\n",
            "5900it [07:35, 12.91it/s]\u001b[A\n",
            "5902it [07:36, 12.45it/s]\u001b[A\n",
            "5904it [07:36, 12.49it/s]\u001b[A\n",
            "5906it [07:36, 12.44it/s]\u001b[A\n",
            "5908it [07:36, 11.71it/s]\u001b[A\n",
            "5910it [07:36, 11.48it/s]\u001b[A\n",
            "5912it [07:36, 11.39it/s]\u001b[A\n",
            "5914it [07:37, 11.53it/s]\u001b[A\n",
            "5916it [07:37, 11.92it/s]\u001b[A\n",
            "5918it [07:37, 11.74it/s]\u001b[A\n",
            "5920it [07:37, 11.54it/s]\u001b[A\n",
            "5922it [07:37, 11.99it/s]\u001b[A\n",
            "5924it [07:37, 12.30it/s]\u001b[A\n",
            "5926it [07:38, 12.52it/s]\u001b[A\n",
            "5928it [07:38, 12.38it/s]\u001b[A\n",
            "5930it [07:38, 12.65it/s]\u001b[A\n",
            "5932it [07:38, 12.81it/s]\u001b[A\n",
            "5934it [07:38, 12.80it/s]\u001b[A\n",
            "5936it [07:38, 12.89it/s]\u001b[A\n",
            "5938it [07:38, 12.66it/s]\u001b[A\n",
            "5940it [07:39, 12.10it/s]\u001b[A\n",
            "5942it [07:39, 12.13it/s]\u001b[A\n",
            "5944it [07:39, 12.26it/s]\u001b[A\n",
            "5946it [07:39, 12.46it/s]\u001b[A\n",
            "5948it [07:39, 12.64it/s]\u001b[A\n",
            "5950it [07:39, 12.97it/s]\u001b[A\n",
            "5952it [07:40, 12.60it/s]\u001b[A\n",
            "5954it [07:40, 12.26it/s]\u001b[A\n",
            "5956it [07:40, 12.52it/s]\u001b[A\n",
            "5958it [07:40, 12.45it/s]\u001b[A\n",
            "5960it [07:40, 12.62it/s]\u001b[A\n",
            "5962it [07:40, 12.68it/s]\u001b[A\n",
            "5964it [07:41, 12.97it/s]\u001b[A\n",
            "5966it [07:41, 12.93it/s]\u001b[A\n",
            "5968it [07:41, 12.80it/s]\u001b[A\n",
            "5970it [07:41, 12.83it/s]\u001b[A\n",
            "5972it [07:41, 13.00it/s]\u001b[A\n",
            "5974it [07:41, 12.98it/s]\u001b[A\n",
            "5976it [07:41, 13.12it/s]\u001b[A\n",
            "5978it [07:42, 12.95it/s]\u001b[A\n",
            "5980it [07:42, 12.91it/s]\u001b[A\n",
            "5982it [07:42, 12.70it/s]\u001b[A\n",
            "5984it [07:42, 12.75it/s]\u001b[A\n",
            "5986it [07:42, 12.97it/s]\u001b[A\n",
            "5988it [07:42, 13.02it/s]\u001b[A\n",
            "5990it [07:43, 13.06it/s]\u001b[A\n",
            "5992it [07:43, 12.96it/s]\u001b[A\n",
            "5994it [07:43, 13.04it/s]\u001b[A\n",
            "5996it [07:43, 13.16it/s]\u001b[A\n",
            "5998it [07:43, 13.31it/s]\u001b[A\n",
            "6000it [07:43, 13.57it/s]\u001b[A\n",
            "6002it [07:43, 13.41it/s]\u001b[A\n",
            "6004it [07:44, 13.40it/s]\u001b[A\n",
            "6006it [07:44, 13.02it/s]\u001b[A\n",
            "6008it [07:44, 12.91it/s]\u001b[A\n",
            "6010it [07:44, 13.08it/s]\u001b[A\n",
            "6012it [07:44, 13.24it/s]\u001b[A\n",
            "6014it [07:44, 13.20it/s]\u001b[A\n",
            "6016it [07:45, 13.16it/s]\u001b[A\n",
            "6018it [07:45, 13.11it/s]\u001b[A\n",
            "6020it [07:45, 13.18it/s]\u001b[A\n",
            "6022it [07:45, 13.20it/s]\u001b[A\n",
            "6024it [07:45, 13.19it/s]\u001b[A\n",
            "6026it [07:45, 13.25it/s]\u001b[A\n",
            "6028it [07:45, 13.32it/s]\u001b[A\n",
            "6030it [07:46, 13.12it/s]\u001b[A\n",
            "6032it [07:46, 12.45it/s]\u001b[A\n",
            "6034it [07:46, 12.24it/s]\u001b[A\n",
            "6036it [07:46, 12.11it/s]\u001b[A\n",
            "6038it [07:46, 12.28it/s]\u001b[A\n",
            "6040it [07:46, 12.43it/s]\u001b[A\n",
            "6042it [07:47, 12.45it/s]\u001b[A\n",
            "6044it [07:47, 12.50it/s]\u001b[A\n",
            "6046it [07:47, 12.40it/s]\u001b[A\n",
            "6048it [07:47, 12.03it/s]\u001b[A\n",
            "6050it [07:47, 11.88it/s]\u001b[A\n",
            "6052it [07:47, 12.25it/s]\u001b[A\n",
            "6054it [07:48, 12.06it/s]\u001b[A\n",
            "6056it [07:48, 11.68it/s]\u001b[A\n",
            "6058it [07:48, 11.66it/s]\u001b[A\n",
            "6060it [07:48, 11.68it/s]\u001b[A\n",
            "6062it [07:48, 11.91it/s]\u001b[A\n",
            "6064it [07:48, 12.36it/s]\u001b[A\n",
            "6066it [07:49, 12.48it/s]\u001b[A\n",
            "6068it [07:49, 12.28it/s]\u001b[A\n",
            "6070it [07:49, 12.56it/s]\u001b[A\n",
            "6072it [07:49, 12.92it/s]\u001b[A\n",
            "6074it [07:49, 13.02it/s]\u001b[A\n",
            "6076it [07:49, 13.15it/s]\u001b[A\n",
            "6078it [07:50, 13.11it/s]\u001b[A\n",
            "6080it [07:50, 13.17it/s]\u001b[A\n",
            "6082it [07:50, 12.53it/s]\u001b[A\n",
            "6084it [07:50, 12.33it/s]\u001b[A\n",
            "6086it [07:50, 12.54it/s]\u001b[A\n",
            "6088it [07:50, 12.59it/s]\u001b[A\n",
            "6090it [07:50, 12.80it/s]\u001b[A\n",
            "6092it [07:51, 12.69it/s]\u001b[A\n",
            "6094it [07:51, 12.11it/s]\u001b[A\n",
            "6096it [07:51, 11.89it/s]\u001b[A\n",
            "6098it [07:51, 11.67it/s]\u001b[A\n",
            "6100it [07:51, 11.61it/s]\u001b[A\n",
            "6102it [07:52, 11.61it/s]\u001b[A\n",
            "6104it [07:52, 11.43it/s]\u001b[A\n",
            "6106it [07:52, 11.63it/s]\u001b[A\n",
            "6108it [07:52, 12.07it/s]\u001b[A\n",
            "6110it [07:52, 12.62it/s]\u001b[A\n",
            "6112it [07:52, 12.92it/s]\u001b[A\n",
            "6114it [07:52, 12.88it/s]\u001b[A\n",
            "6116it [07:53, 12.89it/s]\u001b[A\n",
            "6118it [07:53, 12.96it/s]\u001b[A\n",
            "6120it [07:53, 12.77it/s]\u001b[A\n",
            "6122it [07:53, 12.40it/s]\u001b[A\n",
            "6124it [07:53, 12.20it/s]\u001b[A\n",
            "6126it [07:53, 12.45it/s]\u001b[A\n",
            "6128it [07:54, 12.62it/s]\u001b[A\n",
            "6130it [07:54, 12.36it/s]\u001b[A\n",
            "6132it [07:54, 12.24it/s]\u001b[A\n",
            "6134it [07:54, 12.39it/s]\u001b[A\n",
            "6136it [07:54, 12.59it/s]\u001b[A\n",
            "6138it [07:54, 12.75it/s]\u001b[A\n",
            "6140it [07:55, 12.37it/s]\u001b[A\n",
            "6142it [07:55, 12.16it/s]\u001b[A\n",
            "6144it [07:55, 11.83it/s]\u001b[A\n",
            "6146it [07:55, 11.66it/s]\u001b[A\n",
            "6148it [07:55, 11.58it/s]\u001b[A\n",
            "6150it [07:55, 11.89it/s]\u001b[A\n",
            "6152it [07:56, 12.18it/s]\u001b[A\n",
            "6154it [07:56, 12.43it/s]\u001b[A\n",
            "6156it [07:56, 12.30it/s]\u001b[A\n",
            "6158it [07:56, 12.31it/s]\u001b[A\n",
            "6160it [07:56, 12.59it/s]\u001b[A\n",
            "6162it [07:56, 12.80it/s]\u001b[A\n",
            "6164it [07:56, 12.92it/s]\u001b[A\n",
            "6166it [07:57, 13.06it/s]\u001b[A\n",
            "6168it [07:57, 12.41it/s]\u001b[A\n",
            "6170it [07:57, 12.25it/s]\u001b[A\n",
            "6172it [07:57, 12.07it/s]\u001b[A\n",
            "6174it [07:57, 12.13it/s]\u001b[A\n",
            "6176it [07:57, 12.32it/s]\u001b[A\n",
            "6178it [07:58, 12.51it/s]\u001b[A\n",
            "6180it [07:58, 12.48it/s]\u001b[A\n",
            "6182it [07:58, 12.18it/s]\u001b[A\n",
            "6184it [07:58, 12.29it/s]\u001b[A\n",
            "6186it [07:58, 12.42it/s]\u001b[A\n",
            "6188it [07:58, 12.51it/s]\u001b[A\n",
            "6190it [07:59, 12.37it/s]\u001b[A\n",
            "6192it [07:59, 12.58it/s]\u001b[A\n",
            "6194it [07:59, 12.61it/s]\u001b[A\n",
            "6196it [07:59, 12.67it/s]\u001b[A\n",
            "6198it [07:59, 12.63it/s]\u001b[A\n",
            "6200it [07:59, 12.65it/s]\u001b[A\n",
            "6202it [08:00, 12.04it/s]\u001b[A\n",
            "6204it [08:00, 11.86it/s]\u001b[A\n",
            "6206it [08:00, 12.08it/s]\u001b[A\n",
            "6208it [08:00, 12.42it/s]\u001b[A\n",
            "6210it [08:00, 12.65it/s]\u001b[A\n",
            "6212it [08:00, 12.65it/s]\u001b[A\n",
            "6214it [08:01, 12.72it/s]\u001b[A\n",
            "6216it [08:01, 12.97it/s]\u001b[A\n",
            "6218it [08:01, 12.81it/s]\u001b[A\n",
            "6220it [08:01, 12.63it/s]\u001b[A\n",
            "6222it [08:01, 12.65it/s]\u001b[A\n",
            "6224it [08:01, 12.60it/s]\u001b[A\n",
            "6226it [08:01, 12.78it/s]\u001b[A\n",
            "6228it [08:02, 13.08it/s]\u001b[A\n",
            "6230it [08:02, 12.49it/s]\u001b[A\n",
            "6232it [08:02, 12.17it/s]\u001b[A\n",
            "6234it [08:02, 12.08it/s]\u001b[A\n",
            "6236it [08:02, 11.81it/s]\u001b[A\n",
            "6238it [08:02, 11.49it/s]\u001b[A\n",
            "6240it [08:03, 11.31it/s]\u001b[A\n",
            "6242it [08:03, 11.25it/s]\u001b[A\n",
            "6244it [08:03, 10.95it/s]\u001b[A\n",
            "6246it [08:03, 10.99it/s]\u001b[A\n",
            "6248it [08:03, 11.03it/s]\u001b[A\n",
            "6250it [08:04, 11.56it/s]\u001b[A\n",
            "6252it [08:04, 12.04it/s]\u001b[A\n",
            "6254it [08:04, 12.13it/s]\u001b[A\n",
            "6256it [08:04, 12.42it/s]\u001b[A\n",
            "6258it [08:04, 12.61it/s]\u001b[A\n",
            "6260it [08:04, 12.64it/s]\u001b[A\n",
            "6262it [08:05, 12.14it/s]\u001b[A\n",
            "6264it [08:05, 11.87it/s]\u001b[A\n",
            "6266it [08:05, 11.89it/s]\u001b[A\n",
            "6268it [08:05, 12.13it/s]\u001b[A\n",
            "6270it [08:05, 11.92it/s]\u001b[A\n",
            "6272it [08:05, 12.06it/s]\u001b[A\n",
            "6274it [08:06, 12.35it/s]\u001b[A\n",
            "6276it [08:06, 12.75it/s]\u001b[A\n",
            "6278it [08:06, 12.36it/s]\u001b[A\n",
            "6280it [08:06, 11.96it/s]\u001b[A\n",
            "6282it [08:06, 11.94it/s]\u001b[A\n",
            "6284it [08:06, 11.72it/s]\u001b[A\n",
            "6286it [08:07, 11.78it/s]\u001b[A\n",
            "6288it [08:07, 12.13it/s]\u001b[A\n",
            "6290it [08:07, 12.39it/s]\u001b[A\n",
            "6292it [08:07, 12.55it/s]\u001b[A\n",
            "6294it [08:07, 12.70it/s]\u001b[A\n",
            "6296it [08:07, 12.91it/s]\u001b[A\n",
            "6298it [08:07, 12.74it/s]\u001b[A\n",
            "6300it [08:08, 12.27it/s]\u001b[A\n",
            "6302it [08:08, 12.56it/s]\u001b[A\n",
            "6304it [08:08, 12.61it/s]\u001b[A\n",
            "6306it [08:08, 12.46it/s]\u001b[A\n",
            "6308it [08:08, 12.46it/s]\u001b[A\n",
            "6310it [08:08, 12.57it/s]\u001b[A\n",
            "6312it [08:09, 12.67it/s]\u001b[A\n",
            "6314it [08:09, 12.31it/s]\u001b[A\n",
            "6316it [08:09, 12.44it/s]\u001b[A\n",
            "6318it [08:09, 12.64it/s]\u001b[A\n",
            "6320it [08:09, 12.79it/s]\u001b[A\n",
            "6322it [08:09, 12.87it/s]\u001b[A\n",
            "6324it [08:09, 12.99it/s]\u001b[A\n",
            "6326it [08:10, 12.86it/s]\u001b[A\n",
            "6328it [08:10, 12.58it/s]\u001b[A\n",
            "6330it [08:10, 12.78it/s]\u001b[A\n",
            "6332it [08:10, 12.61it/s]\u001b[A\n",
            "6334it [08:10, 12.92it/s]\u001b[A\n",
            "6336it [08:10, 12.93it/s]\u001b[A\n",
            "6338it [08:11, 12.98it/s]\u001b[A\n",
            "6340it [08:11, 13.12it/s]\u001b[A\n",
            "6342it [08:11, 13.10it/s]\u001b[A\n",
            "6344it [08:11, 13.00it/s]\u001b[A\n",
            "6346it [08:11, 12.90it/s]\u001b[A\n",
            "6348it [08:11, 12.89it/s]\u001b[A\n",
            "6350it [08:12, 12.82it/s]\u001b[A\n",
            "6352it [08:12, 12.81it/s]\u001b[A\n",
            "6354it [08:12, 12.69it/s]\u001b[A\n",
            "6356it [08:12, 12.86it/s]\u001b[A\n",
            "6358it [08:12, 12.93it/s]\u001b[A\n",
            "6360it [08:12, 13.06it/s]\u001b[A\n",
            "6362it [08:12, 13.15it/s]\u001b[A\n",
            "6364it [08:13, 13.32it/s]\u001b[A\n",
            "6366it [08:13, 13.24it/s]\u001b[A\n",
            "6368it [08:13, 13.07it/s]\u001b[A\n",
            "6370it [08:13, 13.13it/s]\u001b[A\n",
            "6372it [08:13, 12.82it/s]\u001b[A\n",
            "6374it [08:13, 12.44it/s]\u001b[A\n",
            "6376it [08:14, 12.04it/s]\u001b[A\n",
            "6378it [08:14, 12.20it/s]\u001b[A\n",
            "6380it [08:14, 12.05it/s]\u001b[A\n",
            "6382it [08:14, 11.69it/s]\u001b[A\n",
            "6384it [08:14, 11.81it/s]\u001b[A\n",
            "6386it [08:14, 12.20it/s]\u001b[A\n",
            "6388it [08:15, 11.89it/s]\u001b[A\n",
            "6390it [08:15, 11.69it/s]\u001b[A\n",
            "6392it [08:15, 11.83it/s]\u001b[A\n",
            "6394it [08:15, 12.02it/s]\u001b[A\n",
            "6396it [08:15, 12.19it/s]\u001b[A\n",
            "6398it [08:15, 12.02it/s]\u001b[A\n",
            "6400it [08:16, 11.59it/s]\u001b[A\n",
            "6402it [08:16, 11.70it/s]\u001b[A\n",
            "6404it [08:16, 12.06it/s]\u001b[A\n",
            "6406it [08:16, 12.41it/s]\u001b[A\n",
            "6408it [08:16, 12.56it/s]\u001b[A\n",
            "6410it [08:16, 12.88it/s]\u001b[A\n",
            "6412it [08:17, 13.01it/s]\u001b[A\n",
            "6414it [08:17, 12.97it/s]\u001b[A\n",
            "6416it [08:17, 12.85it/s]\u001b[A\n",
            "6418it [08:17, 12.71it/s]\u001b[A\n",
            "6420it [08:17, 12.57it/s]\u001b[A\n",
            "6422it [08:17, 12.78it/s]\u001b[A\n",
            "6424it [08:17, 12.83it/s]\u001b[A\n",
            "6426it [08:18, 12.78it/s]\u001b[A\n",
            "6428it [08:18, 12.36it/s]\u001b[A\n",
            "6430it [08:18, 12.58it/s]\u001b[A\n",
            "6432it [08:18, 12.52it/s]\u001b[A\n",
            "6434it [08:18, 12.49it/s]\u001b[A\n",
            "6436it [08:18, 12.74it/s]\u001b[A\n",
            "6438it [08:19, 12.90it/s]\u001b[A\n",
            "6440it [08:19, 12.50it/s]\u001b[A\n",
            "6442it [08:19, 12.08it/s]\u001b[A\n",
            "6444it [08:19, 12.00it/s]\u001b[A\n",
            "6446it [08:19, 11.77it/s]\u001b[A\n",
            "6448it [08:19, 12.18it/s]\u001b[A\n",
            "6450it [08:20, 12.33it/s]\u001b[A\n",
            "6452it [08:20, 12.07it/s]\u001b[A\n",
            "6454it [08:20, 12.17it/s]\u001b[A\n",
            "6456it [08:20, 12.50it/s]\u001b[A\n",
            "6458it [08:20, 12.64it/s]\u001b[A\n",
            "6460it [08:20, 12.67it/s]\u001b[A\n",
            "6462it [08:21, 12.93it/s]\u001b[A\n",
            "6464it [08:21, 12.99it/s]\u001b[A\n",
            "6466it [08:21, 12.90it/s]\u001b[A\n",
            "6468it [08:21, 12.91it/s]\u001b[A\n",
            "6470it [08:21, 13.07it/s]\u001b[A\n",
            "6472it [08:21, 12.91it/s]\u001b[A\n",
            "6474it [08:21, 13.05it/s]\u001b[A\n",
            "6476it [08:22, 13.08it/s]\u001b[A\n",
            "6478it [08:22, 12.99it/s]\u001b[A\n",
            "6480it [08:22, 12.51it/s]\u001b[A\n",
            "6482it [08:22, 12.09it/s]\u001b[A\n",
            "6484it [08:22, 11.61it/s]\u001b[A\n",
            "6486it [08:22, 11.58it/s]\u001b[A\n",
            "6488it [08:23, 11.46it/s]\u001b[A\n",
            "6490it [08:23, 11.42it/s]\u001b[A\n",
            "6492it [08:23, 11.57it/s]\u001b[A\n",
            "6494it [08:23, 11.45it/s]\u001b[A\n",
            "6496it [08:23, 11.24it/s]\u001b[A\n",
            "6498it [08:24, 11.27it/s]\u001b[A\n",
            "6500it [08:24, 11.46it/s]\u001b[A\n",
            "6502it [08:24, 11.85it/s]\u001b[A\n",
            "6504it [08:24, 11.70it/s]\u001b[A\n",
            "6506it [08:24, 11.71it/s]\u001b[A\n",
            "6508it [08:24, 11.59it/s]\u001b[A\n",
            "6510it [08:25, 11.41it/s]\u001b[A\n",
            "6512it [08:25, 11.46it/s]\u001b[A\n",
            "6514it [08:25, 11.80it/s]\u001b[A\n",
            "6516it [08:25, 12.13it/s]\u001b[A\n",
            "6518it [08:25, 12.16it/s]\u001b[A\n",
            "6520it [08:25, 12.31it/s]\u001b[A\n",
            "6522it [08:26, 12.49it/s]\u001b[A\n",
            "6524it [08:26, 12.22it/s]\u001b[A\n",
            "6526it [08:26, 11.98it/s]\u001b[A\n",
            "6528it [08:26, 12.24it/s]\u001b[A\n",
            "6530it [08:26, 12.49it/s]\u001b[A\n",
            "6532it [08:26, 12.65it/s]\u001b[A\n",
            "6534it [08:26, 12.81it/s]\u001b[A\n",
            "6536it [08:27, 12.81it/s]\u001b[A\n",
            "6538it [08:27, 12.94it/s]\u001b[A\n",
            "6540it [08:27, 13.19it/s]\u001b[A\n",
            "6542it [08:27, 13.25it/s]\u001b[A\n",
            "6544it [08:27, 13.30it/s]\u001b[A\n",
            "6546it [08:27, 13.35it/s]\u001b[A\n",
            "6548it [08:28, 13.33it/s]\u001b[A\n",
            "6550it [08:28, 13.12it/s]\u001b[A\n",
            "6552it [08:28, 13.09it/s]\u001b[A\n",
            "6554it [08:28, 12.93it/s]\u001b[A\n",
            "6556it [08:28, 12.91it/s]\u001b[A\n",
            "6558it [08:28, 12.78it/s]\u001b[A\n",
            "6560it [08:28, 12.95it/s]\u001b[A\n",
            "6562it [08:29, 13.00it/s]\u001b[A\n",
            "6564it [08:29, 12.93it/s]\u001b[A\n",
            "6566it [08:29, 12.31it/s]\u001b[A\n",
            "6568it [08:29, 11.91it/s]\u001b[A\n",
            "6570it [08:29, 11.98it/s]\u001b[A\n",
            "6572it [08:29, 11.95it/s]\u001b[A\n",
            "6574it [08:30, 11.70it/s]\u001b[A\n",
            "6576it [08:30, 11.91it/s]\u001b[A\n",
            "6578it [08:30, 11.94it/s]\u001b[A\n",
            "6580it [08:30, 12.33it/s]\u001b[A\n",
            "6582it [08:30, 12.60it/s]\u001b[A\n",
            "6584it [08:30, 12.53it/s]\u001b[A\n",
            "6586it [08:31, 12.62it/s]\u001b[A\n",
            "6588it [08:31, 12.76it/s]\u001b[A\n",
            "6590it [08:31, 12.54it/s]\u001b[A\n",
            "6592it [08:31, 12.17it/s]\u001b[A\n",
            "6594it [08:31, 12.13it/s]\u001b[A\n",
            "6596it [08:31, 12.29it/s]\u001b[A\n",
            "6598it [08:32, 12.67it/s]\u001b[A\n",
            "6600it [08:32, 12.75it/s]\u001b[A\n",
            "6602it [08:32, 12.31it/s]\u001b[A\n",
            "6604it [08:32, 11.85it/s]\u001b[A\n",
            "6606it [08:32, 11.77it/s]\u001b[A\n",
            "6608it [08:32, 11.55it/s]\u001b[A\n",
            "6610it [08:33, 11.53it/s]\u001b[A\n",
            "6612it [08:33, 11.48it/s]\u001b[A\n",
            "6614it [08:33, 11.57it/s]\u001b[A\n",
            "6616it [08:33, 11.42it/s]\u001b[A\n",
            "6618it [08:33, 11.39it/s]\u001b[A\n",
            "6620it [08:33, 11.09it/s]\u001b[A\n",
            "6622it [08:34, 11.20it/s]\u001b[A\n",
            "6624it [08:34, 11.47it/s]\u001b[A\n",
            "6626it [08:34, 11.89it/s]\u001b[A\n",
            "6628it [08:34, 12.01it/s]\u001b[A\n",
            "6630it [08:34, 12.39it/s]\u001b[A\n",
            "6632it [08:34, 12.31it/s]\u001b[A\n",
            "6634it [08:35, 12.60it/s]\u001b[A\n",
            "6636it [08:35, 12.67it/s]\u001b[A\n",
            "6638it [08:35, 12.67it/s]\u001b[A\n",
            "6640it [08:35, 12.65it/s]\u001b[A\n",
            "6642it [08:35, 12.78it/s]\u001b[A\n",
            "6644it [08:35, 12.75it/s]\u001b[A\n",
            "6646it [08:36, 12.89it/s]\u001b[A\n",
            "6648it [08:36, 12.74it/s]\u001b[A\n",
            "6650it [08:36, 12.68it/s]\u001b[A\n",
            "6652it [08:36, 12.77it/s]\u001b[A\n",
            "6654it [08:36, 12.64it/s]\u001b[A\n",
            "6656it [08:36, 12.43it/s]\u001b[A\n",
            "6658it [08:37, 12.00it/s]\u001b[A\n",
            "6660it [08:37, 11.73it/s]\u001b[A\n",
            "6662it [08:37, 11.80it/s]\u001b[A\n",
            "6664it [08:37, 12.14it/s]\u001b[A\n",
            "6666it [08:37, 12.48it/s]\u001b[A\n",
            "6668it [08:37, 12.57it/s]\u001b[A\n",
            "6670it [08:37, 12.50it/s]\u001b[A\n",
            "6672it [08:38, 12.56it/s]\u001b[A\n",
            "6674it [08:38, 12.73it/s]\u001b[A\n",
            "6676it [08:38, 12.91it/s]\u001b[A\n",
            "6678it [08:38, 12.97it/s]\u001b[A\n",
            "6680it [08:38, 13.09it/s]\u001b[A\n",
            "6682it [08:38, 12.96it/s]\u001b[A\n",
            "6684it [08:39, 13.02it/s]\u001b[A\n",
            "6686it [08:39, 12.93it/s]\u001b[A\n",
            "6688it [08:39, 13.06it/s]\u001b[A\n",
            "6690it [08:39, 12.44it/s]\u001b[A\n",
            "6692it [08:39, 12.15it/s]\u001b[A\n",
            "6694it [08:39, 12.46it/s]\u001b[A\n",
            "6696it [08:40, 12.63it/s]\u001b[A\n",
            "6698it [08:40, 12.63it/s]\u001b[A\n",
            "6700it [08:40, 12.32it/s]\u001b[A\n",
            "6702it [08:40, 12.55it/s]\u001b[A\n",
            "6704it [08:40, 12.24it/s]\u001b[A\n",
            "6706it [08:40, 11.97it/s]\u001b[A\n",
            "6708it [08:41, 11.89it/s]\u001b[A\n",
            "6710it [08:41, 11.94it/s]\u001b[A\n",
            "6712it [08:41, 12.20it/s]\u001b[A\n",
            "6714it [08:41, 12.41it/s]\u001b[A\n",
            "6716it [08:41, 12.46it/s]\u001b[A\n",
            "6718it [08:41, 12.61it/s]\u001b[A\n",
            "6720it [08:41, 12.32it/s]\u001b[A\n",
            "6722it [08:42, 12.13it/s]\u001b[A\n",
            "6724it [08:42, 11.99it/s]\u001b[A\n",
            "6726it [08:42, 12.11it/s]\u001b[A\n",
            "6728it [08:42, 12.40it/s]\u001b[A\n",
            "6730it [08:42, 12.48it/s]\u001b[A\n",
            "6732it [08:42, 12.45it/s]\u001b[A\n",
            "6734it [08:43, 12.55it/s]\u001b[A\n",
            "6736it [08:43, 12.63it/s]\u001b[A\n",
            "6738it [08:43, 12.82it/s]\u001b[A\n",
            "6740it [08:43, 12.88it/s]\u001b[A\n",
            "6742it [08:43, 13.04it/s]\u001b[A\n",
            "6744it [08:43, 13.23it/s]\u001b[A\n",
            "6746it [08:44, 12.94it/s]\u001b[A\n",
            "6748it [08:44, 12.91it/s]\u001b[A\n",
            "6750it [08:44, 13.08it/s]\u001b[A\n",
            "6752it [08:44, 13.12it/s]\u001b[A\n",
            "6754it [08:44, 13.07it/s]\u001b[A\n",
            "6756it [08:44, 13.32it/s]\u001b[A\n",
            "6758it [08:44, 13.32it/s]\u001b[A\n",
            "6760it [08:45, 13.05it/s]\u001b[A\n",
            "6762it [08:45, 12.80it/s]\u001b[A\n",
            "6764it [08:45, 12.96it/s]\u001b[A\n",
            "6766it [08:45, 13.06it/s]\u001b[A\n",
            "6768it [08:45, 13.07it/s]\u001b[A\n",
            "6770it [08:45, 13.12it/s]\u001b[A\n",
            "6772it [08:46, 12.77it/s]\u001b[A\n",
            "6774it [08:46, 12.26it/s]\u001b[A\n",
            "6776it [08:46, 12.02it/s]\u001b[A\n",
            "6778it [08:46, 11.95it/s]\u001b[A\n",
            "6780it [08:46, 11.87it/s]\u001b[A\n",
            "6782it [08:46, 11.85it/s]\u001b[A\n",
            "6784it [08:47, 11.92it/s]\u001b[A\n",
            "6786it [08:47, 12.24it/s]\u001b[A\n",
            "6788it [08:47, 12.61it/s]\u001b[A\n",
            "6790it [08:47, 12.73it/s]\u001b[A\n",
            "6792it [08:47, 12.81it/s]\u001b[A\n",
            "6794it [08:47, 12.98it/s]\u001b[A\n",
            "6796it [08:47, 12.45it/s]\u001b[A\n",
            "6798it [08:48, 12.20it/s]\u001b[A\n",
            "6800it [08:48, 12.25it/s]\u001b[A\n",
            "6802it [08:48, 12.20it/s]\u001b[A\n",
            "6804it [08:48, 11.87it/s]\u001b[A\n",
            "6806it [08:48, 11.70it/s]\u001b[A\n",
            "6808it [08:49, 11.66it/s]\u001b[A\n",
            "6810it [08:49, 11.46it/s]\u001b[A\n",
            "6812it [08:49, 11.30it/s]\u001b[A\n",
            "6814it [08:49, 11.29it/s]\u001b[A\n",
            "6816it [08:49, 11.36it/s]\u001b[A\n",
            "6818it [08:49, 11.89it/s]\u001b[A\n",
            "6820it [08:50, 12.28it/s]\u001b[A\n",
            "6822it [08:50, 12.20it/s]\u001b[A\n",
            "6824it [08:50, 12.24it/s]\u001b[A\n",
            "6826it [08:50, 12.49it/s]\u001b[A\n",
            "6828it [08:50, 12.67it/s]\u001b[A\n",
            "6830it [08:50, 12.61it/s]\u001b[A\n",
            "6832it [08:50, 12.77it/s]\u001b[A\n",
            "6834it [08:51, 12.82it/s]\u001b[A\n",
            "6836it [08:51, 13.06it/s]\u001b[A\n",
            "6838it [08:51, 12.99it/s]\u001b[A\n",
            "6840it [08:51, 13.14it/s]\u001b[A\n",
            "6842it [08:51, 13.19it/s]\u001b[A\n",
            "6844it [08:51, 13.03it/s]\u001b[A\n",
            "6846it [08:52, 12.85it/s]\u001b[A\n",
            "6848it [08:52, 12.67it/s]\u001b[A\n",
            "6850it [08:52, 12.44it/s]\u001b[A\n",
            "6852it [08:52, 12.23it/s]\u001b[A\n",
            "6854it [08:52, 11.87it/s]\u001b[A\n",
            "6856it [08:52, 12.00it/s]\u001b[A\n",
            "6858it [08:53, 11.74it/s]\u001b[A\n",
            "6860it [08:53, 11.41it/s]\u001b[A\n",
            "6862it [08:53, 11.75it/s]\u001b[A\n",
            "6864it [08:53, 11.67it/s]\u001b[A\n",
            "6866it [08:53, 11.70it/s]\u001b[A\n",
            "6868it [08:53, 11.63it/s]\u001b[A\n",
            "6870it [08:54, 11.48it/s]\u001b[A\n",
            "6872it [08:54, 11.98it/s]\u001b[A\n",
            "6874it [08:54, 12.45it/s]\u001b[A\n",
            "6876it [08:54, 12.68it/s]\u001b[A\n",
            "6878it [08:54, 12.86it/s]\u001b[A\n",
            "6880it [08:54, 13.03it/s]\u001b[A\n",
            "6882it [08:55, 12.97it/s]\u001b[A\n",
            "6884it [08:55, 12.84it/s]\u001b[A\n",
            "6886it [08:55, 12.96it/s]\u001b[A\n",
            "6888it [08:55, 12.86it/s]\u001b[A\n",
            "6890it [08:55, 12.39it/s]\u001b[A\n",
            "6892it [08:55, 12.60it/s]\u001b[A\n",
            "6894it [08:55, 12.67it/s]\u001b[A\n",
            "6896it [08:56, 12.39it/s]\u001b[A\n",
            "6898it [08:56, 12.22it/s]\u001b[A\n",
            "6900it [08:56, 12.01it/s]\u001b[A\n",
            "6902it [08:56, 11.80it/s]\u001b[A\n",
            "6904it [08:56, 11.68it/s]\u001b[A\n",
            "6906it [08:57, 11.49it/s]\u001b[A\n",
            "6908it [08:57, 11.40it/s]\u001b[A\n",
            "6910it [08:57, 11.33it/s]\u001b[A\n",
            "6912it [08:57, 11.42it/s]\u001b[A\n",
            "6914it [08:57, 11.28it/s]\u001b[A\n",
            "6916it [08:57, 11.14it/s]\u001b[A\n",
            "6918it [08:58, 11.05it/s]\u001b[A\n",
            "6920it [08:58, 11.13it/s]\u001b[A\n",
            "6922it [08:58, 11.69it/s]\u001b[A\n",
            "6924it [08:58, 12.23it/s]\u001b[A\n",
            "6926it [08:58, 12.65it/s]\u001b[A\n",
            "6928it [08:58, 12.78it/s]\u001b[A\n",
            "6930it [08:59, 12.90it/s]\u001b[A\n",
            "6932it [08:59, 13.05it/s]\u001b[A\n",
            "6934it [08:59, 12.53it/s]\u001b[A\n",
            "6936it [08:59, 12.07it/s]\u001b[A\n",
            "6938it [08:59, 11.96it/s]\u001b[A\n",
            "6940it [08:59, 12.20it/s]\u001b[A\n",
            "6942it [09:00, 12.35it/s]\u001b[A\n",
            "6944it [09:00, 12.44it/s]\u001b[A\n",
            "6946it [09:00, 12.58it/s]\u001b[A\n",
            "6948it [09:00, 12.87it/s]\u001b[A\n",
            "6950it [09:00, 12.80it/s]\u001b[A\n",
            "6952it [09:00, 13.16it/s]\u001b[A\n",
            "6954it [09:00, 13.18it/s]\u001b[A\n",
            "6956it [09:01, 13.06it/s]\u001b[A\n",
            "6958it [09:01, 12.98it/s]\u001b[A\n",
            "6960it [09:01, 12.78it/s]\u001b[A\n",
            "6962it [09:01, 12.96it/s]\u001b[A\n",
            "6964it [09:01, 12.98it/s]\u001b[A\n",
            "6966it [09:01, 12.90it/s]\u001b[A\n",
            "6968it [09:02, 13.06it/s]\u001b[A\n",
            "6970it [09:02, 12.98it/s]\u001b[A\n",
            "6972it [09:02, 12.49it/s]\u001b[A\n",
            "6974it [09:02, 12.31it/s]\u001b[A\n",
            "6976it [09:02, 11.97it/s]\u001b[A\n",
            "6978it [09:02, 12.06it/s]\u001b[A\n",
            "6980it [09:03, 12.31it/s]\u001b[A\n",
            "6982it [09:03, 12.51it/s]\u001b[A\n",
            "6984it [09:03, 12.03it/s]\u001b[A\n",
            "6986it [09:03, 11.72it/s]\u001b[A\n",
            "6988it [09:03, 11.49it/s]\u001b[A\n",
            "6990it [09:03, 11.76it/s]\u001b[A\n",
            "6992it [09:04, 11.80it/s]\u001b[A\n",
            "6994it [09:04, 12.14it/s]\u001b[A\n",
            "6996it [09:04, 12.00it/s]\u001b[A\n",
            "6998it [09:04, 12.24it/s]\u001b[A\n",
            "7000it [09:04, 12.27it/s]\u001b[A\n",
            "7002it [09:04, 12.23it/s]\u001b[A\n",
            "7004it [09:05, 12.14it/s]\u001b[A\n",
            "7006it [09:05, 11.88it/s]\u001b[A\n",
            "7008it [09:05, 11.72it/s]\u001b[A\n",
            "7010it [09:05, 12.04it/s]\u001b[A\n",
            "7012it [09:05, 12.23it/s]\u001b[A\n",
            "7014it [09:05, 12.29it/s]\u001b[A\n",
            "7016it [09:05, 12.52it/s]\u001b[A\n",
            "7018it [09:06, 12.58it/s]\u001b[A\n",
            "7020it [09:06, 12.11it/s]\u001b[A\n",
            "7022it [09:06, 12.21it/s]\u001b[A\n",
            "7024it [09:06, 12.10it/s]\u001b[A\n",
            "7026it [09:06, 11.95it/s]\u001b[A\n",
            "7028it [09:06, 11.82it/s]\u001b[A\n",
            "7030it [09:07, 11.42it/s]\u001b[A\n",
            "7032it [09:07, 11.15it/s]\u001b[A\n",
            "7034it [09:07, 11.09it/s]\u001b[A\n",
            "7036it [09:07, 11.11it/s]\u001b[A\n",
            "7038it [09:07, 11.33it/s]\u001b[A\n",
            "7040it [09:08, 11.68it/s]\u001b[A\n",
            "7042it [09:08, 11.70it/s]\u001b[A\n",
            "7044it [09:08, 11.50it/s]\u001b[A\n",
            "7046it [09:08, 11.23it/s]\u001b[A\n",
            "7048it [09:08, 11.27it/s]\u001b[A\n",
            "7050it [09:08, 11.20it/s]\u001b[A\n",
            "7052it [09:09, 10.93it/s]\u001b[A\n",
            "7054it [09:09, 11.03it/s]\u001b[A\n",
            "7056it [09:09, 11.13it/s]\u001b[A\n",
            "7058it [09:09, 11.61it/s]\u001b[A\n",
            "7060it [09:09, 11.73it/s]\u001b[A\n",
            "7062it [09:09, 11.88it/s]\u001b[A\n",
            "7064it [09:10, 11.70it/s]\u001b[A\n",
            "7066it [09:10, 11.86it/s]\u001b[A\n",
            "7068it [09:10, 12.04it/s]\u001b[A\n",
            "7070it [09:10, 12.20it/s]\u001b[A\n",
            "7072it [09:10, 12.32it/s]\u001b[A\n",
            "7074it [09:10, 12.40it/s]\u001b[A\n",
            "7076it [09:11, 12.41it/s]\u001b[A\n",
            "7078it [09:11, 12.52it/s]\u001b[A\n",
            "7080it [09:11, 12.09it/s]\u001b[A\n",
            "7082it [09:11, 11.88it/s]\u001b[A\n",
            "7084it [09:11, 11.96it/s]\u001b[A\n",
            "7086it [09:11, 12.21it/s]\u001b[A\n",
            "7088it [09:12, 12.63it/s]\u001b[A\n",
            "7090it [09:12, 12.61it/s]\u001b[A\n",
            "7092it [09:12, 12.41it/s]\u001b[A\n",
            "7094it [09:12, 12.50it/s]\u001b[A\n",
            "7096it [09:12, 12.12it/s]\u001b[A\n",
            "7098it [09:12, 12.35it/s]\u001b[A\n",
            "7100it [09:13, 12.46it/s]\u001b[A\n",
            "7102it [09:13, 12.63it/s]\u001b[A\n",
            "7104it [09:13, 12.64it/s]\u001b[A\n",
            "7106it [09:13, 12.34it/s]\u001b[A\n",
            "7108it [09:13, 12.51it/s]\u001b[A\n",
            "7110it [09:13, 12.91it/s]\u001b[A\n",
            "7112it [09:14, 13.00it/s]\u001b[A\n",
            "7114it [09:14, 12.73it/s]\u001b[A\n",
            "7116it [09:14, 12.39it/s]\u001b[A\n",
            "7118it [09:14, 12.45it/s]\u001b[A\n",
            "7120it [09:14, 12.55it/s]\u001b[A\n",
            "7122it [09:14, 12.63it/s]\u001b[A\n",
            "7124it [09:14, 12.75it/s]\u001b[A\n",
            "7126it [09:15, 12.84it/s]\u001b[A\n",
            "7128it [09:15, 12.94it/s]\u001b[A\n",
            "7130it [09:15, 12.95it/s]\u001b[A\n",
            "7132it [09:15, 12.73it/s]\u001b[A\n",
            "7134it [09:15, 12.80it/s]\u001b[A\n",
            "7136it [09:15, 12.84it/s]\u001b[A\n",
            "7138it [09:16, 13.01it/s]\u001b[A\n",
            "7140it [09:16, 12.52it/s]\u001b[A\n",
            "7142it [09:16, 12.38it/s]\u001b[A\n",
            "7144it [09:16, 12.29it/s]\u001b[A\n",
            "7146it [09:16, 12.65it/s]\u001b[A\n",
            "7148it [09:16, 12.14it/s]\u001b[A\n",
            "7150it [09:17, 11.98it/s]\u001b[A\n",
            "7152it [09:17, 11.82it/s]\u001b[A\n",
            "7154it [09:17, 11.94it/s]\u001b[A\n",
            "7156it [09:17, 12.11it/s]\u001b[A\n",
            "7158it [09:17, 12.48it/s]\u001b[A\n",
            "7160it [09:17, 12.59it/s]\u001b[A\n",
            "7162it [09:18, 12.80it/s]\u001b[A\n",
            "7164it [09:18, 12.92it/s]\u001b[A\n",
            "7166it [09:18, 13.06it/s]\u001b[A\n",
            "7168it [09:18, 13.11it/s]\u001b[A\n",
            "7170it [09:18, 12.99it/s]\u001b[A\n",
            "7172it [09:18, 12.90it/s]\u001b[A\n",
            "7174it [09:18, 12.96it/s]\u001b[A\n",
            "7176it [09:19, 13.03it/s]\u001b[A\n",
            "7178it [09:19, 13.03it/s]\u001b[A\n",
            "7180it [09:19, 12.88it/s]\u001b[A\n",
            "7182it [09:19, 12.66it/s]\u001b[A\n",
            "7184it [09:19, 12.62it/s]\u001b[A\n",
            "7186it [09:19, 12.66it/s]\u001b[A\n",
            "7188it [09:20, 12.48it/s]\u001b[A\n",
            "7190it [09:20, 12.26it/s]\u001b[A\n",
            "7192it [09:20, 12.48it/s]\u001b[A\n",
            "7194it [09:20, 12.56it/s]\u001b[A\n",
            "7196it [09:20, 12.75it/s]\u001b[A\n",
            "7198it [09:20, 12.89it/s]\u001b[A\n",
            "7200it [09:20, 12.99it/s]\u001b[A\n",
            "7202it [09:21, 12.98it/s]\u001b[A\n",
            "7204it [09:21, 13.00it/s]\u001b[A\n",
            "7206it [09:21, 13.03it/s]\u001b[A\n",
            "7208it [09:21, 12.89it/s]\u001b[A\n",
            "7210it [09:21, 13.04it/s]\u001b[A\n",
            "7212it [09:21, 13.07it/s]\u001b[A\n",
            "7214it [09:22, 12.99it/s]\u001b[A\n",
            "7216it [09:22, 13.01it/s]\u001b[A\n",
            "7218it [09:22, 13.00it/s]\u001b[A\n",
            "7220it [09:22, 12.44it/s]\u001b[A\n",
            "7222it [09:22, 11.97it/s]\u001b[A\n",
            "7224it [09:22, 12.25it/s]\u001b[A\n",
            "7226it [09:23, 12.42it/s]\u001b[A\n",
            "7228it [09:23, 12.43it/s]\u001b[A\n",
            "7230it [09:23, 12.45it/s]\u001b[A\n",
            "7232it [09:23, 12.58it/s]\u001b[A\n",
            "7234it [09:23, 12.48it/s]\u001b[A\n",
            "7236it [09:23, 12.83it/s]\u001b[A\n",
            "7238it [09:23, 12.97it/s]\u001b[A\n",
            "7240it [09:24, 12.94it/s]\u001b[A\n",
            "7242it [09:24, 12.95it/s]\u001b[A\n",
            "7244it [09:24, 12.87it/s]\u001b[A\n",
            "7246it [09:24, 12.71it/s]\u001b[A\n",
            "7248it [09:24, 12.75it/s]\u001b[A\n",
            "7250it [09:24, 12.77it/s]\u001b[A\n",
            "7252it [09:25, 12.88it/s]\u001b[A\n",
            "7254it [09:25, 12.99it/s]\u001b[A\n",
            "7256it [09:25, 12.78it/s]\u001b[A\n",
            "7258it [09:25, 13.07it/s]\u001b[A\n",
            "7260it [09:25, 12.95it/s]\u001b[A\n",
            "7262it [09:25, 13.01it/s]\u001b[A\n",
            "7264it [09:25, 13.06it/s]\u001b[A\n",
            "7266it [09:26, 12.81it/s]\u001b[A\n",
            "7268it [09:26, 12.37it/s]\u001b[A\n",
            "7270it [09:26, 12.36it/s]\u001b[A\n",
            "7272it [09:26, 12.47it/s]\u001b[A\n",
            "7274it [09:26, 12.63it/s]\u001b[A\n",
            "7276it [09:26, 12.25it/s]\u001b[A\n",
            "7278it [09:27, 12.23it/s]\u001b[A\n",
            "7280it [09:27, 11.99it/s]\u001b[A\n",
            "7282it [09:27, 12.32it/s]\u001b[A\n",
            "7284it [09:27, 12.58it/s]\u001b[A\n",
            "7286it [09:27, 12.42it/s]\u001b[A\n",
            "7288it [09:27, 12.23it/s]\u001b[A\n",
            "7290it [09:28, 12.14it/s]\u001b[A\n",
            "7292it [09:28, 12.41it/s]\u001b[A\n",
            "7294it [09:28, 12.60it/s]\u001b[A\n",
            "7296it [09:28, 12.70it/s]\u001b[A\n",
            "7298it [09:28, 12.64it/s]\u001b[A\n",
            "7300it [09:28, 12.84it/s]\u001b[A\n",
            "7302it [09:29, 12.91it/s]\u001b[A\n",
            "7304it [09:29, 12.78it/s]\u001b[A\n",
            "7306it [09:29, 12.63it/s]\u001b[A\n",
            "7308it [09:29, 12.69it/s]\u001b[A\n",
            "7310it [09:29, 12.55it/s]\u001b[A\n",
            "7312it [09:29, 12.67it/s]\u001b[A\n",
            "7314it [09:29, 12.82it/s]\u001b[A\n",
            "7316it [09:30, 12.85it/s]\u001b[A\n",
            "7318it [09:30, 12.31it/s]\u001b[A\n",
            "7320it [09:30, 12.05it/s]\u001b[A\n",
            "7322it [09:30, 11.76it/s]\u001b[A\n",
            "7324it [09:30, 11.95it/s]\u001b[A\n",
            "7326it [09:30, 12.17it/s]\u001b[A\n",
            "7328it [09:31, 12.23it/s]\u001b[A\n",
            "7330it [09:31, 11.64it/s]\u001b[A\n",
            "7332it [09:31, 11.44it/s]\u001b[A\n",
            "7334it [09:31, 11.56it/s]\u001b[A\n",
            "7336it [09:31, 11.92it/s]\u001b[A\n",
            "7338it [09:31, 12.24it/s]\u001b[A\n",
            "7340it [09:32, 12.12it/s]\u001b[A\n",
            "7342it [09:32, 12.28it/s]\u001b[A\n",
            "7344it [09:32, 12.39it/s]\u001b[A\n",
            "7346it [09:32, 12.48it/s]\u001b[A\n",
            "7348it [09:32, 12.25it/s]\u001b[A\n",
            "7350it [09:32, 12.47it/s]\u001b[A\n",
            "7352it [09:33, 12.65it/s]\u001b[A\n",
            "7354it [09:33, 12.62it/s]\u001b[A\n",
            "7356it [09:33, 12.55it/s]\u001b[A\n",
            "7358it [09:33, 12.56it/s]\u001b[A\n",
            "7360it [09:33, 12.43it/s]\u001b[A\n",
            "7362it [09:33, 12.27it/s]\u001b[A\n",
            "7364it [09:34, 12.26it/s]\u001b[A\n",
            "7366it [09:34, 12.25it/s]\u001b[A\n",
            "7368it [09:34, 12.19it/s]\u001b[A\n",
            "7370it [09:34, 12.37it/s]\u001b[A\n",
            "7372it [09:34, 12.16it/s]\u001b[A\n",
            "7374it [09:34, 12.34it/s]\u001b[A\n",
            "7376it [09:35, 11.97it/s]\u001b[A\n",
            "7378it [09:35, 11.58it/s]\u001b[A\n",
            "7380it [09:35, 11.79it/s]\u001b[A\n",
            "7382it [09:35, 11.85it/s]\u001b[A\n",
            "7384it [09:35, 11.90it/s]\u001b[A\n",
            "7386it [09:35, 12.09it/s]\u001b[A\n",
            "7388it [09:36, 12.13it/s]\u001b[A\n",
            "7390it [09:36, 12.34it/s]\u001b[A\n",
            "7392it [09:36, 12.14it/s]\u001b[A\n",
            "7394it [09:36, 12.23it/s]\u001b[A\n",
            "7396it [09:36, 12.39it/s]\u001b[A\n",
            "7398it [09:36, 12.58it/s]\u001b[A\n",
            "7400it [09:37, 12.82it/s]\u001b[A\n",
            "7402it [09:37, 12.42it/s]\u001b[A\n",
            "7404it [09:37, 12.21it/s]\u001b[A\n",
            "7406it [09:37, 12.25it/s]\u001b[A\n",
            "7408it [09:37, 12.44it/s]\u001b[A\n",
            "7410it [09:37, 12.51it/s]\u001b[A\n",
            "7412it [09:38, 12.55it/s]\u001b[A\n",
            "7414it [09:38, 12.67it/s]\u001b[A\n",
            "7416it [09:38, 12.46it/s]\u001b[A\n",
            "7418it [09:38, 12.59it/s]\u001b[A\n",
            "7420it [09:38, 12.65it/s]\u001b[A\n",
            "7422it [09:38, 12.70it/s]\u001b[A\n",
            "7424it [09:38, 12.72it/s]\u001b[A\n",
            "7426it [09:39, 13.06it/s]\u001b[A\n",
            "7428it [09:39, 13.07it/s]\u001b[A\n",
            "7430it [09:39, 12.58it/s]\u001b[A\n",
            "7432it [09:39, 12.75it/s]\u001b[A\n",
            "7434it [09:39, 12.94it/s]\u001b[A\n",
            "7436it [09:39, 12.81it/s]\u001b[A\n",
            "7438it [09:40, 12.80it/s]\u001b[A\n",
            "7440it [09:40, 12.76it/s]\u001b[A\n",
            "7442it [09:40, 12.64it/s]\u001b[A\n",
            "7444it [09:40, 12.57it/s]\u001b[A\n",
            "7446it [09:40, 12.72it/s]\u001b[A\n",
            "7448it [09:40, 12.59it/s]\u001b[A\n",
            "7450it [09:40, 12.62it/s]\u001b[A\n",
            "7452it [09:41, 12.36it/s]\u001b[A\n",
            "7454it [09:41, 12.07it/s]\u001b[A\n",
            "7456it [09:41, 11.82it/s]\u001b[A\n",
            "7458it [09:41, 11.66it/s]\u001b[A\n",
            "7460it [09:41, 11.63it/s]\u001b[A\n",
            "7462it [09:42, 11.88it/s]\u001b[A\n",
            "7464it [09:42, 12.10it/s]\u001b[A\n",
            "7466it [09:42, 12.23it/s]\u001b[A\n",
            "7468it [09:42, 11.97it/s]\u001b[A\n",
            "7470it [09:42, 11.78it/s]\u001b[A\n",
            "7472it [09:42, 11.53it/s]\u001b[A\n",
            "7474it [09:43, 11.45it/s]\u001b[A\n",
            "7476it [09:43, 11.36it/s]\u001b[A\n",
            "7478it [09:43, 11.50it/s]\u001b[A\n",
            "7480it [09:43, 11.48it/s]\u001b[A\n",
            "7482it [09:43, 11.62it/s]\u001b[A\n",
            "7484it [09:43, 11.95it/s]\u001b[A\n",
            "7486it [09:44, 12.25it/s]\u001b[A\n",
            "7488it [09:44, 12.26it/s]\u001b[A\n",
            "7490it [09:44, 11.96it/s]\u001b[A\n",
            "7492it [09:44, 11.93it/s]\u001b[A\n",
            "7494it [09:44, 11.73it/s]\u001b[A\n",
            "7496it [09:44, 11.93it/s]\u001b[A\n",
            "7498it [09:45, 11.72it/s]\u001b[A\n",
            "7500it [09:45, 11.75it/s]\u001b[A\n",
            "7502it [09:45, 11.99it/s]\u001b[A\n",
            "7504it [09:45, 12.30it/s]\u001b[A\n",
            "7506it [09:45, 12.52it/s]\u001b[A\n",
            "7508it [09:45, 12.78it/s]\u001b[A\n",
            "7510it [09:46, 12.86it/s]\u001b[A\n",
            "7512it [09:46, 12.67it/s]\u001b[A\n",
            "7514it [09:46, 12.43it/s]\u001b[A\n",
            "7516it [09:46, 12.38it/s]\u001b[A\n",
            "7518it [09:46, 12.15it/s]\u001b[A\n",
            "7520it [09:46, 12.02it/s]\u001b[A\n",
            "7522it [09:47, 11.94it/s]\u001b[A\n",
            "7524it [09:47, 12.16it/s]\u001b[A\n",
            "7526it [09:47, 12.34it/s]\u001b[A\n",
            "7528it [09:47, 12.54it/s]\u001b[A\n",
            "7530it [09:47, 12.50it/s]\u001b[A\n",
            "7532it [09:47, 12.59it/s]\u001b[A\n",
            "7534it [09:47, 12.17it/s]\u001b[A\n",
            "7536it [09:48, 11.98it/s]\u001b[A\n",
            "7538it [09:48, 12.32it/s]\u001b[A\n",
            "7540it [09:48, 12.41it/s]\u001b[A\n",
            "7542it [09:48, 12.57it/s]\u001b[A\n",
            "7544it [09:48, 12.69it/s]\u001b[A\n",
            "7546it [09:48, 12.62it/s]\u001b[A\n",
            "7548it [09:49, 12.36it/s]\u001b[A\n",
            "7550it [09:49, 12.52it/s]\u001b[A\n",
            "7552it [09:49, 12.90it/s]\u001b[A\n",
            "7554it [09:49, 12.84it/s]\u001b[A\n",
            "7556it [09:49, 12.79it/s]\u001b[A\n",
            "7558it [09:49, 12.85it/s]\u001b[A\n",
            "7560it [09:50, 12.61it/s]\u001b[A\n",
            "7562it [09:50, 12.62it/s]\u001b[A\n",
            "7564it [09:50, 12.57it/s]\u001b[A\n",
            "7566it [09:50, 12.51it/s]\u001b[A\n",
            "7568it [09:50, 12.09it/s]\u001b[A\n",
            "7570it [09:50, 11.82it/s]\u001b[A\n",
            "7572it [09:51, 11.49it/s]\u001b[A\n",
            "7574it [09:51, 11.37it/s]\u001b[A\n",
            "7576it [09:51, 11.61it/s]\u001b[A\n",
            "7578it [09:51, 11.53it/s]\u001b[A\n",
            "7580it [09:51, 11.43it/s]\u001b[A\n",
            "7582it [09:51, 11.44it/s]\u001b[A\n",
            "7584it [09:52, 11.34it/s]\u001b[A\n",
            "7586it [09:52, 11.63it/s]\u001b[A\n",
            "7588it [09:52, 12.05it/s]\u001b[A\n",
            "7590it [09:52, 12.18it/s]\u001b[A\n",
            "7592it [09:52, 12.19it/s]\u001b[A\n",
            "7594it [09:52, 12.27it/s]\u001b[A\n",
            "7596it [09:53, 12.35it/s]\u001b[A\n",
            "7598it [09:53, 12.24it/s]\u001b[A\n",
            "7600it [09:53, 12.61it/s]\u001b[A\n",
            "7602it [09:53, 12.71it/s]\u001b[A\n",
            "7604it [09:53, 13.05it/s]\u001b[A\n",
            "7606it [09:53, 12.93it/s]\u001b[A\n",
            "7608it [09:53, 12.67it/s]\u001b[A\n",
            "7610it [09:54, 12.66it/s]\u001b[A\n",
            "7612it [09:54, 12.72it/s]\u001b[A\n",
            "7614it [09:54, 12.64it/s]\u001b[A\n",
            "7616it [09:54, 12.78it/s]\u001b[A\n",
            "7618it [09:54, 12.86it/s]\u001b[A\n",
            "7620it [09:54, 12.88it/s]\u001b[A\n",
            "7622it [09:55, 12.74it/s]\u001b[A\n",
            "7624it [09:55, 12.74it/s]\u001b[A\n",
            "7626it [09:55, 12.62it/s]\u001b[A\n",
            "7628it [09:55, 12.72it/s]\u001b[A\n",
            "7630it [09:55, 12.83it/s]\u001b[A\n",
            "7632it [09:55, 12.80it/s]\u001b[A\n",
            "7634it [09:56, 12.79it/s]\u001b[A\n",
            "7636it [09:56, 12.72it/s]\u001b[A\n",
            "7638it [09:56, 12.71it/s]\u001b[A\n",
            "7640it [09:56, 12.56it/s]\u001b[A\n",
            "7642it [09:56, 12.65it/s]\u001b[A\n",
            "7644it [09:56, 12.70it/s]\u001b[A\n",
            "7646it [09:56, 12.87it/s]\u001b[A\n",
            "7648it [09:57, 12.77it/s]\u001b[A\n",
            "7650it [09:57, 12.70it/s]\u001b[A\n",
            "7652it [09:57, 12.20it/s]\u001b[A\n",
            "7654it [09:57, 11.85it/s]\u001b[A\n",
            "7656it [09:57, 11.94it/s]\u001b[A\n",
            "7658it [09:57, 12.38it/s]\u001b[A\n",
            "7660it [09:58, 12.23it/s]\u001b[A\n",
            "7662it [09:58, 12.40it/s]\u001b[A\n",
            "7664it [09:58, 12.67it/s]\u001b[A\n",
            "7666it [09:58, 12.75it/s]\u001b[A\n",
            "7668it [09:58, 13.09it/s]\u001b[A\n",
            "7670it [09:58, 13.16it/s]\u001b[A\n",
            "7672it [09:59, 12.91it/s]\u001b[A\n",
            "7674it [09:59, 12.64it/s]\u001b[A\n",
            "7676it [09:59, 12.66it/s]\u001b[A\n",
            "7678it [09:59, 12.71it/s]\u001b[A\n",
            "7680it [09:59, 12.80it/s]\u001b[A\n",
            "7682it [09:59, 12.77it/s]\u001b[A\n",
            "7684it [10:00, 12.20it/s]\u001b[A\n",
            "7686it [10:00, 12.10it/s]\u001b[A\n",
            "7688it [10:00, 12.22it/s]\u001b[A\n",
            "7690it [10:00, 11.93it/s]\u001b[A\n",
            "7692it [10:00, 11.80it/s]\u001b[A\n",
            "7694it [10:00, 12.16it/s]\u001b[A\n",
            "7696it [10:01, 11.97it/s]\u001b[A\n",
            "7698it [10:01, 12.03it/s]\u001b[A\n",
            "7700it [10:01, 12.10it/s]\u001b[A\n",
            "7702it [10:01, 12.23it/s]\u001b[A\n",
            "7704it [10:01, 12.33it/s]\u001b[A\n",
            "7706it [10:01, 12.24it/s]\u001b[A\n",
            "7708it [10:01, 12.50it/s]\u001b[A\n",
            "7710it [10:02, 12.48it/s]\u001b[A\n",
            "7712it [10:02, 12.70it/s]\u001b[A\n",
            "7714it [10:02, 12.81it/s]\u001b[A\n",
            "7716it [10:02, 12.91it/s]\u001b[A\n",
            "7718it [10:02, 12.96it/s]\u001b[A\n",
            "7720it [10:02, 13.00it/s]\u001b[A\n",
            "7722it [10:03, 13.06it/s]\u001b[A\n",
            "7724it [10:03, 12.90it/s]\u001b[A\n",
            "7726it [10:03, 12.19it/s]\u001b[A\n",
            "7728it [10:03, 11.99it/s]\u001b[A\n",
            "7730it [10:03, 11.92it/s]\u001b[A\n",
            "7732it [10:03, 11.81it/s]\u001b[A\n",
            "7734it [10:04, 11.65it/s]\u001b[A\n",
            "7736it [10:04, 11.41it/s]\u001b[A\n",
            "7738it [10:04, 11.45it/s]\u001b[A\n",
            "7740it [10:04, 11.41it/s]\u001b[A\n",
            "7742it [10:04, 11.57it/s]\u001b[A\n",
            "7744it [10:04, 11.62it/s]\u001b[A\n",
            "7746it [10:05, 11.40it/s]\u001b[A\n",
            "7748it [10:05, 11.39it/s]\u001b[A\n",
            "7750it [10:05, 11.43it/s]\u001b[A\n",
            "7752it [10:05, 11.35it/s]\u001b[A\n",
            "7754it [10:05, 11.32it/s]\u001b[A\n",
            "7756it [10:06, 11.24it/s]\u001b[A\n",
            "7758it [10:06, 11.46it/s]\u001b[A\n",
            "7760it [10:06, 11.76it/s]\u001b[A\n",
            "7762it [10:06, 12.00it/s]\u001b[A\n",
            "7764it [10:06, 12.27it/s]\u001b[A\n",
            "7766it [10:06, 12.47it/s]\u001b[A\n",
            "7768it [10:06, 12.64it/s]\u001b[A\n",
            "7770it [10:07, 12.83it/s]\u001b[A\n",
            "7772it [10:07, 12.65it/s]\u001b[A\n",
            "7774it [10:07, 12.67it/s]\u001b[A\n",
            "7776it [10:07, 12.81it/s]\u001b[A\n",
            "7778it [10:07, 12.68it/s]\u001b[A\n",
            "7780it [10:07, 12.70it/s]\u001b[A\n",
            "7782it [10:08, 12.68it/s]\u001b[A\n",
            "7784it [10:08, 12.27it/s]\u001b[A\n",
            "7786it [10:08, 11.99it/s]\u001b[A\n",
            "7788it [10:08, 11.68it/s]\u001b[A\n",
            "7790it [10:08, 11.84it/s]\u001b[A\n",
            "7792it [10:08, 11.63it/s]\u001b[A\n",
            "7794it [10:09, 11.72it/s]\u001b[A\n",
            "7796it [10:09, 11.95it/s]\u001b[A\n",
            "7798it [10:09, 12.07it/s]\u001b[A\n",
            "7800it [10:09, 12.28it/s]\u001b[A\n",
            "7802it [10:09, 12.31it/s]\u001b[A\n",
            "7804it [10:09, 12.38it/s]\u001b[A\n",
            "7806it [10:10, 12.68it/s]\u001b[A\n",
            "7808it [10:10, 12.40it/s]\u001b[A\n",
            "7810it [10:10, 12.41it/s]\u001b[A\n",
            "7812it [10:10, 12.84it/s]\u001b[A\n",
            "7814it [10:10, 13.13it/s]\u001b[A\n",
            "7816it [10:10, 13.10it/s]\u001b[A\n",
            "7818it [10:11, 13.16it/s]\u001b[A\n",
            "7820it [10:11, 13.20it/s]\u001b[A\n",
            "7822it [10:11, 12.90it/s]\u001b[A\n",
            "7824it [10:11, 12.87it/s]\u001b[A\n",
            "7826it [10:11, 12.98it/s]\u001b[A\n",
            "7828it [10:11, 13.19it/s]\u001b[A\n",
            "7830it [10:11, 13.24it/s]\u001b[A\n",
            "7832it [10:12, 13.37it/s]\u001b[A\n",
            "7834it [10:12, 12.65it/s]\u001b[A\n",
            "7836it [10:12, 12.65it/s]\u001b[A\n",
            "7838it [10:12, 12.59it/s]\u001b[A\n",
            "7840it [10:12, 12.64it/s]\u001b[A\n",
            "7842it [10:12, 12.77it/s]\u001b[A\n",
            "7844it [10:13, 12.62it/s]\u001b[A\n",
            "7846it [10:13, 12.61it/s]\u001b[A\n",
            "7848it [10:13, 12.64it/s]\u001b[A\n",
            "7850it [10:13, 12.64it/s]\u001b[A\n",
            "7852it [10:13, 12.66it/s]\u001b[A\n",
            "7854it [10:13, 12.72it/s]\u001b[A\n",
            "7856it [10:13, 12.81it/s]\u001b[A\n",
            "7858it [10:14, 12.59it/s]\u001b[A\n",
            "7860it [10:14, 12.47it/s]\u001b[A\n",
            "7862it [10:14, 12.37it/s]\u001b[A\n",
            "7864it [10:14, 12.53it/s]\u001b[A\n",
            "7866it [10:14, 12.28it/s]\u001b[A\n",
            "7868it [10:14, 11.70it/s]\u001b[A\n",
            "7870it [10:15, 11.76it/s]\u001b[A\n",
            "7872it [10:15, 11.71it/s]\u001b[A\n",
            "7874it [10:15, 11.51it/s]\u001b[A\n",
            "7876it [10:15, 11.52it/s]\u001b[A\n",
            "7878it [10:15, 11.86it/s]\u001b[A\n",
            "7880it [10:15, 12.15it/s]\u001b[A\n",
            "7882it [10:16, 12.33it/s]\u001b[A\n",
            "7884it [10:16, 12.39it/s]\u001b[A\n",
            "7886it [10:16, 12.01it/s]\u001b[A\n",
            "7888it [10:16, 11.58it/s]\u001b[A\n",
            "7890it [10:16, 11.96it/s]\u001b[A\n",
            "7892it [10:16, 12.20it/s]\u001b[A\n",
            "7894it [10:17, 12.53it/s]\u001b[A\n",
            "7896it [10:17, 12.56it/s]\u001b[A\n",
            "7898it [10:17, 11.93it/s]\u001b[A\n",
            "7900it [10:17, 11.76it/s]\u001b[A\n",
            "7902it [10:17, 11.98it/s]\u001b[A\n",
            "7904it [10:17, 12.53it/s]\u001b[A\n",
            "7906it [10:18, 12.91it/s]\u001b[A\n",
            "7908it [10:18, 12.91it/s]\u001b[A\n",
            "7910it [10:18, 12.65it/s]\u001b[A\n",
            "7912it [10:18, 12.85it/s]\u001b[A\n",
            "7914it [10:18, 12.86it/s]\u001b[A\n",
            "7916it [10:18, 12.95it/s]\u001b[A\n",
            "7918it [10:19, 13.03it/s]\u001b[A\n",
            "7920it [10:19, 13.07it/s]\u001b[A\n",
            "7922it [10:19, 12.98it/s]\u001b[A\n",
            "7924it [10:19, 13.04it/s]\u001b[A\n",
            "7926it [10:19, 13.15it/s]\u001b[A\n",
            "7928it [10:19, 13.19it/s]\u001b[A\n",
            "7930it [10:19, 13.23it/s]\u001b[A\n",
            "7932it [10:20, 13.13it/s]\u001b[A\n",
            "7934it [10:20, 13.11it/s]\u001b[A\n",
            "7936it [10:20, 12.74it/s]\u001b[A\n",
            "7938it [10:20, 12.01it/s]\u001b[A\n",
            "7940it [10:20, 11.93it/s]\u001b[A\n",
            "7942it [10:20, 12.22it/s]\u001b[A\n",
            "7944it [10:21, 12.37it/s]\u001b[A\n",
            "7946it [10:21, 12.72it/s]\u001b[A\n",
            "7948it [10:21, 12.14it/s]\u001b[A\n",
            "7950it [10:21, 11.78it/s]\u001b[A\n",
            "7952it [10:21, 11.65it/s]\u001b[A\n",
            "7954it [10:21, 11.60it/s]\u001b[A\n",
            "7956it [10:22, 11.57it/s]\u001b[A\n",
            "7958it [10:22, 12.07it/s]\u001b[A\n",
            "7960it [10:22, 12.24it/s]\u001b[A\n",
            "7962it [10:22, 12.35it/s]\u001b[A\n",
            "7964it [10:22, 12.47it/s]\u001b[A\n",
            "7966it [10:22, 12.77it/s]\u001b[A\n",
            "7968it [10:23, 12.79it/s]\u001b[A\n",
            "7970it [10:23, 12.75it/s]\u001b[A\n",
            "7972it [10:23, 12.80it/s]\u001b[A\n",
            "7974it [10:23, 12.59it/s]\u001b[A\n",
            "7976it [10:23, 12.92it/s]\u001b[A\n",
            "7978it [10:23, 12.98it/s]\u001b[A\n",
            "7980it [10:23, 13.00it/s]\u001b[A\n",
            "7982it [10:24, 13.00it/s]\u001b[A\n",
            "7984it [10:24, 12.94it/s]\u001b[A\n",
            "7986it [10:24, 12.82it/s]\u001b[A\n",
            "7988it [10:24, 12.95it/s]\u001b[A\n",
            "7990it [10:24, 13.04it/s]\u001b[A\n",
            "7992it [10:24, 12.97it/s]\u001b[A\n",
            "7994it [10:25, 12.97it/s]\u001b[A\n",
            "7996it [10:25, 12.67it/s]\u001b[A\n",
            "7998it [10:25, 12.37it/s]\u001b[A\n",
            "8000it [10:25, 12.52it/s]\u001b[A\n",
            "8002it [10:25, 12.69it/s]\u001b[A\n",
            "8004it [10:25, 12.78it/s]\u001b[A\n",
            "8006it [10:26, 12.87it/s]\u001b[A\n",
            "8008it [10:26, 12.78it/s]\u001b[A\n",
            "8010it [10:26, 12.47it/s]\u001b[A\n",
            "8012it [10:26, 11.94it/s]\u001b[A\n",
            "8014it [10:26, 12.12it/s]\u001b[A\n",
            "8016it [10:26, 11.98it/s]\u001b[A\n",
            "8018it [10:27, 11.85it/s]\u001b[A\n",
            "8020it [10:27, 11.66it/s]\u001b[A\n",
            "8022it [10:27, 11.69it/s]\u001b[A\n",
            "8024it [10:27, 11.55it/s]\u001b[A\n",
            "8026it [10:27, 11.54it/s]\u001b[A\n",
            "8028it [10:27, 11.95it/s]\u001b[A\n",
            "8030it [10:28, 11.80it/s]\u001b[A\n",
            "8032it [10:28, 12.06it/s]\u001b[A\n",
            "8034it [10:28, 12.28it/s]\u001b[A\n",
            "8036it [10:28, 12.22it/s]\u001b[A\n",
            "8038it [10:28, 12.45it/s]\u001b[A\n",
            "8040it [10:28, 12.61it/s]\u001b[A\n",
            "8042it [10:29, 12.44it/s]\u001b[A\n",
            "8044it [10:29, 12.53it/s]\u001b[A\n",
            "8046it [10:29, 12.61it/s]\u001b[A\n",
            "8048it [10:29, 12.32it/s]\u001b[A\n",
            "8050it [10:29, 12.04it/s]\u001b[A\n",
            "8052it [10:29, 12.14it/s]\u001b[A\n",
            "8054it [10:29, 12.47it/s]\u001b[A\n",
            "8056it [10:30, 12.52it/s]\u001b[A\n",
            "8058it [10:30, 12.90it/s]\u001b[A\n",
            "8060it [10:30, 12.88it/s]\u001b[A\n",
            "8062it [10:30, 12.23it/s]\u001b[A\n",
            "8064it [10:30, 11.88it/s]\u001b[A\n",
            "8066it [10:30, 11.68it/s]\u001b[A\n",
            "8068it [10:31, 11.42it/s]\u001b[A\n",
            "8070it [10:31, 11.49it/s]\u001b[A\n",
            "8072it [10:31, 11.89it/s]\u001b[A\n",
            "8074it [10:31, 12.10it/s]\u001b[A\n",
            "8076it [10:31, 12.21it/s]\u001b[A\n",
            "8078it [10:31, 12.48it/s]\u001b[A\n",
            "8080it [10:32, 12.72it/s]\u001b[A\n",
            "8082it [10:32, 12.55it/s]\u001b[A\n",
            "8084it [10:32, 12.62it/s]\u001b[A\n",
            "8086it [10:32, 11.96it/s]\u001b[A\n",
            "8088it [10:32, 12.02it/s]\u001b[A\n",
            "8090it [10:32, 12.22it/s]\u001b[A\n",
            "8092it [10:33, 12.26it/s]\u001b[A\n",
            "8094it [10:33, 12.19it/s]\u001b[A\n",
            "8096it [10:33, 12.19it/s]\u001b[A\n",
            "8098it [10:33, 11.84it/s]\u001b[A\n",
            "8100it [10:33, 11.96it/s]\u001b[A\n",
            "8102it [10:33, 12.22it/s]\u001b[A\n",
            "8104it [10:34, 12.46it/s]\u001b[A\n",
            "8106it [10:34, 12.56it/s]\u001b[A\n",
            "8108it [10:34, 12.59it/s]\u001b[A\n",
            "8110it [10:34, 12.44it/s]\u001b[A\n",
            "8112it [10:34, 12.61it/s]\u001b[A\n",
            "8114it [10:34, 12.69it/s]\u001b[A\n",
            "8116it [10:35, 12.30it/s]\u001b[A\n",
            "8118it [10:35, 11.81it/s]\u001b[A\n",
            "8120it [10:35, 11.99it/s]\u001b[A\n",
            "8122it [10:35, 12.07it/s]\u001b[A\n",
            "8124it [10:35, 12.25it/s]\u001b[A\n",
            "8126it [10:35, 12.44it/s]\u001b[A\n",
            "8128it [10:36, 12.64it/s]\u001b[A\n",
            "8130it [10:36, 12.71it/s]\u001b[A\n",
            "8132it [10:36, 12.72it/s]\u001b[A\n",
            "8134it [10:36, 12.87it/s]\u001b[A\n",
            "8136it [10:36, 13.03it/s]\u001b[A\n",
            "8138it [10:36, 12.91it/s]\u001b[A\n",
            "8140it [10:36, 13.10it/s]\u001b[A\n",
            "8142it [10:37, 13.15it/s]\u001b[A\n",
            "8144it [10:37, 13.23it/s]\u001b[A\n",
            "8146it [10:37, 12.98it/s]\u001b[A\n",
            "8148it [10:37, 12.92it/s]\u001b[A\n",
            "8150it [10:37, 12.72it/s]\u001b[A\n",
            "8152it [10:37, 12.90it/s]\u001b[A\n",
            "8154it [10:38, 12.97it/s]\u001b[A\n",
            "8156it [10:38, 12.84it/s]\u001b[A\n",
            "8158it [10:38, 12.86it/s]\u001b[A\n",
            "8160it [10:38, 12.83it/s]\u001b[A\n",
            "8162it [10:38, 12.86it/s]\u001b[A\n",
            "8164it [10:38, 12.69it/s]\u001b[A\n",
            "8166it [10:38, 12.21it/s]\u001b[A\n",
            "8168it [10:39, 11.97it/s]\u001b[A\n",
            "8170it [10:39, 11.76it/s]\u001b[A\n",
            "8172it [10:39, 12.03it/s]\u001b[A\n",
            "8174it [10:39, 12.10it/s]\u001b[A\n",
            "8176it [10:39, 12.35it/s]\u001b[A\n",
            "8178it [10:39, 12.12it/s]\u001b[A\n",
            "8180it [10:40, 11.78it/s]\u001b[A\n",
            "8182it [10:40, 12.08it/s]\u001b[A\n",
            "8184it [10:40, 11.81it/s]\u001b[A\n",
            "8186it [10:40, 11.53it/s]\u001b[A\n",
            "8188it [10:40, 11.41it/s]\u001b[A\n",
            "8190it [10:41, 11.46it/s]\u001b[A\n",
            "8192it [10:41, 11.42it/s]\u001b[A\n",
            "8194it [10:41, 11.32it/s]\u001b[A\n",
            "8196it [10:41, 11.42it/s]\u001b[A\n",
            "8198it [10:41, 11.56it/s]\u001b[A\n",
            "8200it [10:41, 11.70it/s]\u001b[A\n",
            "8202it [10:42, 11.88it/s]\u001b[A\n",
            "8204it [10:42, 12.25it/s]\u001b[A\n",
            "8206it [10:42, 12.41it/s]\u001b[A\n",
            "8208it [10:42, 11.92it/s]\u001b[A\n",
            "8210it [10:42, 11.76it/s]\u001b[A\n",
            "8212it [10:42, 11.72it/s]\u001b[A\n",
            "8214it [10:43, 11.50it/s]\u001b[A\n",
            "8216it [10:43, 11.53it/s]\u001b[A\n",
            "8218it [10:43, 11.58it/s]\u001b[A\n",
            "8220it [10:43, 11.52it/s]\u001b[A\n",
            "8222it [10:43, 11.52it/s]\u001b[A\n",
            "8224it [10:43, 11.92it/s]\u001b[A\n",
            "8226it [10:44, 12.08it/s]\u001b[A\n",
            "8228it [10:44, 11.79it/s]\u001b[A\n",
            "8230it [10:44, 12.05it/s]\u001b[A\n",
            "8232it [10:44, 11.86it/s]\u001b[A\n",
            "8234it [10:44, 11.80it/s]\u001b[A\n",
            "8236it [10:44, 11.88it/s]\u001b[A\n",
            "8238it [10:45, 12.01it/s]\u001b[A\n",
            "8240it [10:45, 12.22it/s]\u001b[A\n",
            "8242it [10:45, 12.53it/s]\u001b[A\n",
            "8244it [10:45, 12.86it/s]\u001b[A\n",
            "8246it [10:45, 12.87it/s]\u001b[A\n",
            "8248it [10:45, 12.89it/s]\u001b[A\n",
            "8250it [10:46, 13.07it/s]\u001b[A\n",
            "8252it [10:46, 12.65it/s]\u001b[A\n",
            "8254it [10:46, 12.40it/s]\u001b[A\n",
            "8256it [10:46, 11.99it/s]\u001b[A\n",
            "8258it [10:46, 11.76it/s]\u001b[A\n",
            "8260it [10:46, 11.67it/s]\u001b[A\n",
            "8262it [10:47, 11.39it/s]\u001b[A\n",
            "8264it [10:47, 11.36it/s]\u001b[A\n",
            "8266it [10:47, 11.36it/s]\u001b[A\n",
            "8268it [10:47, 11.37it/s]\u001b[A\n",
            "8270it [10:47, 11.42it/s]\u001b[A\n",
            "8272it [10:47, 11.87it/s]\u001b[A\n",
            "8274it [10:48, 12.16it/s]\u001b[A\n",
            "8276it [10:48, 12.20it/s]\u001b[A\n",
            "8278it [10:48, 12.31it/s]\u001b[A\n",
            "8280it [10:48, 12.48it/s]\u001b[A\n",
            "8282it [10:48, 12.78it/s]\u001b[A\n",
            "8284it [10:48, 12.63it/s]\u001b[A\n",
            "8286it [10:49, 12.59it/s]\u001b[A\n",
            "8288it [10:49, 12.84it/s]\u001b[A\n",
            "8290it [10:49, 13.09it/s]\u001b[A\n",
            "8292it [10:49, 13.10it/s]\u001b[A\n",
            "8294it [10:49, 13.24it/s]\u001b[A\n",
            "8296it [10:49, 13.06it/s]\u001b[A\n",
            "8298it [10:49, 12.55it/s]\u001b[A\n",
            "8300it [10:50, 12.31it/s]\u001b[A\n",
            "8302it [10:50, 11.97it/s]\u001b[A\n",
            "8304it [10:50, 11.85it/s]\u001b[A\n",
            "8306it [10:50, 12.13it/s]\u001b[A\n",
            "8308it [10:50, 12.29it/s]\u001b[A\n",
            "8310it [10:50, 12.35it/s]\u001b[A\n",
            "8312it [10:51, 12.43it/s]\u001b[A\n",
            "8314it [10:51, 12.64it/s]\u001b[A\n",
            "8316it [10:51, 12.72it/s]\u001b[A\n",
            "8318it [10:51, 12.65it/s]\u001b[A\n",
            "8320it [10:51, 12.54it/s]\u001b[A\n",
            "8322it [10:51, 12.57it/s]\u001b[A\n",
            "8324it [10:52, 12.38it/s]\u001b[A\n",
            "8326it [10:52, 12.66it/s]\u001b[A\n",
            "8328it [10:52, 12.50it/s]\u001b[A\n",
            "8330it [10:52, 12.05it/s]\u001b[A\n",
            "8332it [10:52, 11.97it/s]\u001b[A\n",
            "8334it [10:52, 11.67it/s]\u001b[A\n",
            "8336it [10:53, 11.56it/s]\u001b[A\n",
            "8338it [10:53, 11.66it/s]\u001b[A\n",
            "8340it [10:53, 11.83it/s]\u001b[A\n",
            "8342it [10:53, 12.08it/s]\u001b[A\n",
            "8344it [10:53, 12.38it/s]\u001b[A\n",
            "8346it [10:53, 12.30it/s]\u001b[A\n",
            "8348it [10:54, 12.33it/s]\u001b[A\n",
            "8350it [10:54, 12.56it/s]\u001b[A\n",
            "8352it [10:54, 12.61it/s]\u001b[A\n",
            "8354it [10:54, 12.70it/s]\u001b[A\n",
            "8356it [10:54, 12.72it/s]\u001b[A\n",
            "8358it [10:54, 12.69it/s]\u001b[A\n",
            "8360it [10:54, 12.55it/s]\u001b[A\n",
            "8362it [10:55, 12.17it/s]\u001b[A\n",
            "8364it [10:55, 12.22it/s]\u001b[A\n",
            "8366it [10:55, 12.48it/s]\u001b[A\n",
            "8368it [10:55, 12.50it/s]\u001b[A\n",
            "8370it [10:55, 12.60it/s]\u001b[A\n",
            "8372it [10:55, 12.52it/s]\u001b[A\n",
            "8374it [10:56, 12.72it/s]\u001b[A\n",
            "8376it [10:56, 12.35it/s]\u001b[A\n",
            "8378it [10:56, 12.59it/s]\u001b[A\n",
            "8380it [10:56, 12.60it/s]\u001b[A\n",
            "8382it [10:56, 12.85it/s]\u001b[A\n",
            "8384it [10:56, 13.14it/s]\u001b[A\n",
            "8386it [10:57, 13.13it/s]\u001b[A\n",
            "8388it [10:57, 13.09it/s]\u001b[A\n",
            "8390it [10:57, 13.17it/s]\u001b[A\n",
            "8392it [10:57, 12.70it/s]\u001b[A\n",
            "8394it [10:57, 12.82it/s]\u001b[A\n",
            "8396it [10:57, 12.94it/s]\u001b[A\n",
            "8398it [10:57, 12.85it/s]\u001b[A\n",
            "8400it [10:58, 13.07it/s]\u001b[A\n",
            "8402it [10:58, 12.94it/s]\u001b[A\n",
            "8404it [10:58, 13.01it/s]\u001b[A\n",
            "8406it [10:58, 13.14it/s]\u001b[A\n",
            "8408it [10:58, 13.16it/s]\u001b[A\n",
            "8410it [10:58, 13.03it/s]\u001b[A\n",
            "8412it [10:59, 12.93it/s]\u001b[A\n",
            "8414it [10:59, 12.70it/s]\u001b[A\n",
            "8416it [10:59, 12.71it/s]\u001b[A\n",
            "8418it [10:59, 12.77it/s]\u001b[A\n",
            "8420it [10:59, 13.02it/s]\u001b[A\n",
            "8422it [10:59, 12.89it/s]\u001b[A\n",
            "8424it [10:59, 12.78it/s]\u001b[A\n",
            "8426it [11:00, 12.40it/s]\u001b[A\n",
            "8428it [11:00, 12.25it/s]\u001b[A\n",
            "8430it [11:00, 12.58it/s]\u001b[A\n",
            "8432it [11:00, 12.83it/s]\u001b[A\n",
            "8434it [11:00, 13.00it/s]\u001b[A\n",
            "8436it [11:00, 13.04it/s]\u001b[A\n",
            "8438it [11:01, 12.92it/s]\u001b[A\n",
            "8440it [11:01, 12.64it/s]\u001b[A\n",
            "8442it [11:01, 12.60it/s]\u001b[A\n",
            "8444it [11:01, 12.47it/s]\u001b[A\n",
            "8446it [11:01, 12.62it/s]\u001b[A\n",
            "8448it [11:01, 12.91it/s]\u001b[A\n",
            "8450it [11:02, 12.73it/s]\u001b[A\n",
            "8452it [11:02, 12.81it/s]\u001b[A\n",
            "8454it [11:02, 12.76it/s]\u001b[A\n",
            "8456it [11:02, 12.90it/s]\u001b[A\n",
            "8458it [11:02, 12.96it/s]\u001b[A\n",
            "8460it [11:02, 13.25it/s]\u001b[A\n",
            "8462it [11:02, 13.19it/s]\u001b[A\n",
            "8464it [11:03, 13.21it/s]\u001b[A\n",
            "8466it [11:03, 13.06it/s]\u001b[A\n",
            "8468it [11:03, 12.85it/s]\u001b[A\n",
            "8470it [11:03, 12.77it/s]\u001b[A\n",
            "8472it [11:03, 12.77it/s]\u001b[A\n",
            "8474it [11:03, 12.58it/s]\u001b[A\n",
            "8476it [11:04, 12.12it/s]\u001b[A\n",
            "8478it [11:04, 12.20it/s]\u001b[A\n",
            "8480it [11:04, 12.34it/s]\u001b[A\n",
            "8482it [11:04, 12.35it/s]\u001b[A\n",
            "8484it [11:04, 12.10it/s]\u001b[A\n",
            "8486it [11:04, 12.30it/s]\u001b[A\n",
            "8488it [11:05, 12.18it/s]\u001b[A\n",
            "8490it [11:05, 12.48it/s]\u001b[A\n",
            "8492it [11:05, 12.05it/s]\u001b[A\n",
            "8494it [11:05, 12.39it/s]\u001b[A\n",
            "8496it [11:05, 12.81it/s]\u001b[A\n",
            "8498it [11:05, 12.66it/s]\u001b[A\n",
            "8500it [11:05, 12.99it/s]\u001b[A\n",
            "8502it [11:06, 12.66it/s]\u001b[A\n",
            "8504it [11:06, 12.34it/s]\u001b[A\n",
            "8506it [11:06, 12.38it/s]\u001b[A\n",
            "8508it [11:06, 12.17it/s]\u001b[A\n",
            "8510it [11:06, 12.20it/s]\u001b[A\n",
            "8512it [11:06, 12.64it/s]\u001b[A\n",
            "8514it [11:07, 12.68it/s]\u001b[A\n",
            "8516it [11:07, 12.73it/s]\u001b[A\n",
            "8518it [11:07, 12.82it/s]\u001b[A\n",
            "8520it [11:07, 13.04it/s]\u001b[A\n",
            "8522it [11:07, 13.10it/s]\u001b[A\n",
            "8524it [11:07, 13.07it/s]\u001b[A\n",
            "8526it [11:08, 13.01it/s]\u001b[A\n",
            "8528it [11:08, 12.57it/s]\u001b[A\n",
            "8530it [11:08, 12.24it/s]\u001b[A\n",
            "8532it [11:08, 11.93it/s]\u001b[A\n",
            "8534it [11:08, 11.83it/s]\u001b[A\n",
            "8536it [11:08, 12.10it/s]\u001b[A\n",
            "8538it [11:09, 12.42it/s]\u001b[A\n",
            "8540it [11:09, 12.46it/s]\u001b[A\n",
            "8542it [11:09, 12.52it/s]\u001b[A\n",
            "8544it [11:09, 12.46it/s]\u001b[A\n",
            "8546it [11:09, 12.44it/s]\u001b[A\n",
            "8548it [11:09, 12.65it/s]\u001b[A\n",
            "8550it [11:09, 12.90it/s]\u001b[A\n",
            "8552it [11:10, 12.69it/s]\u001b[A\n",
            "8554it [11:10, 12.75it/s]\u001b[A\n",
            "8556it [11:10, 12.40it/s]\u001b[A\n",
            "8558it [11:10, 12.18it/s]\u001b[A\n",
            "8560it [11:10, 12.39it/s]\u001b[A\n",
            "8562it [11:10, 12.52it/s]\u001b[A\n",
            "8564it [11:11, 12.55it/s]\u001b[A\n",
            "8566it [11:11, 12.80it/s]\u001b[A\n",
            "8568it [11:11, 12.36it/s]\u001b[A\n",
            "8570it [11:11, 12.16it/s]\u001b[A\n",
            "8572it [11:11, 11.79it/s]\u001b[A\n",
            "8574it [11:11, 11.44it/s]\u001b[A\n",
            "8576it [11:12, 11.46it/s]\u001b[A\n",
            "8578it [11:12, 11.90it/s]\u001b[A\n",
            "8580it [11:12, 11.97it/s]\u001b[A\n",
            "8582it [11:12, 11.72it/s]\u001b[A\n",
            "8584it [11:12, 12.01it/s]\u001b[A\n",
            "8586it [11:12, 12.23it/s]\u001b[A\n",
            "8588it [11:13, 12.25it/s]\u001b[A\n",
            "8590it [11:13, 12.44it/s]\u001b[A\n",
            "8592it [11:13, 12.56it/s]\u001b[A\n",
            "8594it [11:13, 12.86it/s]\u001b[A\n",
            "8596it [11:13, 12.93it/s]\u001b[A\n",
            "8598it [11:13, 13.06it/s]\u001b[A\n",
            "8600it [11:14, 13.24it/s]\u001b[A\n",
            "8602it [11:14, 12.77it/s]\u001b[A\n",
            "8604it [11:14, 12.84it/s]\u001b[A\n",
            "8606it [11:14, 12.32it/s]\u001b[A\n",
            "8608it [11:14, 11.99it/s]\u001b[A\n",
            "8610it [11:14, 11.83it/s]\u001b[A\n",
            "8612it [11:15, 11.59it/s]\u001b[A\n",
            "8614it [11:15, 11.30it/s]\u001b[A\n",
            "8616it [11:15, 11.75it/s]\u001b[A\n",
            "8618it [11:15, 12.08it/s]\u001b[A\n",
            "8620it [11:15, 12.18it/s]\u001b[A\n",
            "8622it [11:15, 12.33it/s]\u001b[A\n",
            "8624it [11:16, 12.45it/s]\u001b[A\n",
            "8626it [11:16, 12.52it/s]\u001b[A\n",
            "8628it [11:16, 12.79it/s]\u001b[A\n",
            "8630it [11:16, 12.82it/s]\u001b[A\n",
            "8632it [11:16, 12.85it/s]\u001b[A\n",
            "8634it [11:16, 12.71it/s]\u001b[A\n",
            "8636it [11:16, 12.39it/s]\u001b[A\n",
            "8638it [11:17, 12.03it/s]\u001b[A\n",
            "8640it [11:17, 11.92it/s]\u001b[A\n",
            "8642it [11:17, 11.81it/s]\u001b[A\n",
            "8644it [11:17, 11.82it/s]\u001b[A\n",
            "8646it [11:17, 12.12it/s]\u001b[A\n",
            "8648it [11:17, 12.32it/s]\u001b[A\n",
            "8650it [11:18, 12.36it/s]\u001b[A\n",
            "8652it [11:18, 12.39it/s]\u001b[A\n",
            "8654it [11:18, 12.68it/s]\u001b[A\n",
            "8656it [11:18, 12.72it/s]\u001b[A\n",
            "8658it [11:18, 12.82it/s]\u001b[A\n",
            "8660it [11:18, 12.91it/s]\u001b[A\n",
            "8662it [11:19, 13.02it/s]\u001b[A\n",
            "8664it [11:19, 12.66it/s]\u001b[A\n",
            "8666it [11:19, 12.74it/s]\u001b[A\n",
            "8668it [11:19, 12.88it/s]\u001b[A\n",
            "8670it [11:19, 13.11it/s]\u001b[A\n",
            "8672it [11:19, 13.22it/s]\u001b[A\n",
            "8674it [11:19, 13.15it/s]\u001b[A\n",
            "8676it [11:20, 13.00it/s]\u001b[A\n",
            "8678it [11:20, 12.65it/s]\u001b[A\n",
            "8680it [11:20, 12.75it/s]\u001b[A\n",
            "8682it [11:20, 12.78it/s]\u001b[A\n",
            "8684it [11:20, 12.81it/s]\u001b[A\n",
            "8686it [11:20, 12.94it/s]\u001b[A\n",
            "8688it [11:21, 13.14it/s]\u001b[A\n",
            "8690it [11:21, 13.10it/s]\u001b[A\n",
            "8692it [11:21, 12.87it/s]\u001b[A\n",
            "8694it [11:21, 12.80it/s]\u001b[A\n",
            "8696it [11:21, 12.89it/s]\u001b[A\n",
            "8698it [11:21, 12.85it/s]\u001b[A\n",
            "8700it [11:22, 12.85it/s]\u001b[A\n",
            "8702it [11:22, 12.82it/s]\u001b[A\n",
            "8704it [11:22, 12.75it/s]\u001b[A\n",
            "8706it [11:22, 12.80it/s]\u001b[A\n",
            "8708it [11:22, 12.88it/s]\u001b[A\n",
            "8710it [11:22, 12.97it/s]\u001b[A\n",
            "8712it [11:22, 12.94it/s]\u001b[A\n",
            "8714it [11:23, 13.00it/s]\u001b[A\n",
            "8716it [11:23, 13.05it/s]\u001b[A\n",
            "8718it [11:23, 12.81it/s]\u001b[A\n",
            "8720it [11:23, 12.87it/s]\u001b[A\n",
            "8722it [11:23, 12.93it/s]\u001b[A\n",
            "8724it [11:23, 13.06it/s]\u001b[A\n",
            "8726it [11:24, 13.09it/s]\u001b[A\n",
            "8728it [11:24, 13.18it/s]\u001b[A\n",
            "8730it [11:24, 12.84it/s]\u001b[A\n",
            "8732it [11:24, 12.54it/s]\u001b[A\n",
            "8734it [11:24, 12.83it/s]\u001b[A\n",
            "8736it [11:24, 12.89it/s]\u001b[A\n",
            "8738it [11:24, 13.03it/s]\u001b[A\n",
            "8740it [11:25, 12.93it/s]\u001b[A\n",
            "8742it [11:25, 12.91it/s]\u001b[A\n",
            "8744it [11:25, 12.50it/s]\u001b[A\n",
            "8746it [11:25, 12.70it/s]\u001b[A\n",
            "8748it [11:25, 13.01it/s]\u001b[A\n",
            "8750it [11:25, 13.01it/s]\u001b[A\n",
            "8752it [11:26, 13.13it/s]\u001b[A\n",
            "8754it [11:26, 12.61it/s]\u001b[A\n",
            "8756it [11:26, 12.52it/s]\u001b[A\n",
            "8758it [11:26, 12.83it/s]\u001b[A\n",
            "8760it [11:26, 12.94it/s]\u001b[A\n",
            "8762it [11:26, 13.04it/s]\u001b[A\n",
            "8764it [11:26, 13.21it/s]\u001b[A\n",
            "8766it [11:27, 13.06it/s]\u001b[A\n",
            "8768it [11:27, 13.16it/s]\u001b[A\n",
            "8770it [11:27, 12.89it/s]\u001b[A\n",
            "8772it [11:27, 13.01it/s]\u001b[A\n",
            "8774it [11:27, 13.11it/s]\u001b[A\n",
            "8776it [11:27, 12.99it/s]\u001b[A\n",
            "8778it [11:28, 12.32it/s]\u001b[A\n",
            "8780it [11:28, 12.12it/s]\u001b[A\n",
            "8782it [11:28, 12.12it/s]\u001b[A\n",
            "8784it [11:28, 11.88it/s]\u001b[A\n",
            "8786it [11:28, 12.34it/s]\u001b[A\n",
            "8788it [11:28, 12.53it/s]\u001b[A\n",
            "8790it [11:29, 12.61it/s]\u001b[A\n",
            "8792it [11:29, 12.55it/s]\u001b[A\n",
            "8794it [11:29, 12.24it/s]\u001b[A\n",
            "8796it [11:29, 12.39it/s]\u001b[A\n",
            "8798it [11:29, 12.56it/s]\u001b[A\n",
            "8800it [11:29, 12.81it/s]\u001b[A\n",
            "8802it [11:30, 12.45it/s]\u001b[A\n",
            "8804it [11:30, 12.48it/s]\u001b[A\n",
            "8806it [11:30, 12.66it/s]\u001b[A\n",
            "8808it [11:30, 12.63it/s]\u001b[A\n",
            "8810it [11:30, 12.77it/s]\u001b[A\n",
            "8812it [11:30, 12.94it/s]\u001b[A\n",
            "8814it [11:30, 12.98it/s]\u001b[A\n",
            "8816it [11:31, 13.27it/s]\u001b[A\n",
            "8818it [11:31, 13.29it/s]\u001b[A\n",
            "8820it [11:31, 13.17it/s]\u001b[A\n",
            "8822it [11:31, 13.19it/s]\u001b[A\n",
            "8824it [11:31, 13.22it/s]\u001b[A\n",
            "8826it [11:31, 13.27it/s]\u001b[A\n",
            "8828it [11:31, 13.26it/s]\u001b[A\n",
            "8830it [11:32, 13.02it/s]\u001b[A\n",
            "8832it [11:32, 13.10it/s]\u001b[A\n",
            "8834it [11:32, 12.54it/s]\u001b[A\n",
            "8836it [11:32, 12.34it/s]\u001b[A\n",
            "8838it [11:32, 12.47it/s]\u001b[A\n",
            "8840it [11:32, 12.47it/s]\u001b[A\n",
            "8842it [11:33, 12.88it/s]\u001b[A\n",
            "8844it [11:33, 12.84it/s]\u001b[A\n",
            "8846it [11:33, 12.39it/s]\u001b[A\n",
            "8848it [11:33, 12.76it/s]\u001b[A\n",
            "8850it [11:33, 12.72it/s]\u001b[A\n",
            "8852it [11:33, 12.81it/s]\u001b[A\n",
            "8854it [11:34, 12.73it/s]\u001b[A\n",
            "8856it [11:34, 12.15it/s]\u001b[A\n",
            "8858it [11:34, 11.87it/s]\u001b[A\n",
            "8860it [11:34, 12.20it/s]\u001b[A\n",
            "8862it [11:34, 12.18it/s]\u001b[A\n",
            "8864it [11:34, 12.26it/s]\u001b[A\n",
            "8866it [11:35, 12.52it/s]\u001b[A\n",
            "8868it [11:35, 12.74it/s]\u001b[A\n",
            "8870it [11:35, 12.41it/s]\u001b[A\n",
            "8872it [11:35, 12.47it/s]\u001b[A\n",
            "8874it [11:35, 12.63it/s]\u001b[A\n",
            "8876it [11:35, 12.61it/s]\u001b[A\n",
            "8878it [11:35, 12.86it/s]\u001b[A\n",
            "8880it [11:36, 12.77it/s]\u001b[A\n",
            "8882it [11:36, 12.74it/s]\u001b[A\n",
            "8884it [11:36, 12.67it/s]\u001b[A\n",
            "8886it [11:36, 12.74it/s]\u001b[A\n",
            "8888it [11:36, 12.59it/s]\u001b[A\n",
            "8890it [11:36, 12.58it/s]\u001b[A\n",
            "8892it [11:37, 12.81it/s]\u001b[A\n",
            "8894it [11:37, 12.74it/s]\u001b[A\n",
            "8896it [11:37, 12.97it/s]\u001b[A\n",
            "8898it [11:37, 13.01it/s]\u001b[A\n",
            "8900it [11:37, 13.05it/s]\u001b[A\n",
            "8902it [11:37, 13.08it/s]\u001b[A\n",
            "8904it [11:38, 12.95it/s]\u001b[A\n",
            "8906it [11:38, 12.62it/s]\u001b[A\n",
            "8908it [11:38, 12.30it/s]\u001b[A\n",
            "8910it [11:38, 11.94it/s]\u001b[A\n",
            "8912it [11:38, 11.93it/s]\u001b[A\n",
            "8914it [11:38, 12.08it/s]\u001b[A\n",
            "8916it [11:39, 12.34it/s]\u001b[A\n",
            "8918it [11:39, 12.61it/s]\u001b[A\n",
            "8920it [11:39, 12.89it/s]\u001b[A\n",
            "8922it [11:39, 12.82it/s]\u001b[A\n",
            "8924it [11:39, 12.74it/s]\u001b[A\n",
            "8926it [11:39, 12.89it/s]\u001b[A\n",
            "8928it [11:39, 12.45it/s]\u001b[A\n",
            "8930it [11:40, 12.11it/s]\u001b[A\n",
            "8932it [11:40, 11.89it/s]\u001b[A\n",
            "8934it [11:40, 12.23it/s]\u001b[A\n",
            "8936it [11:40, 12.14it/s]\u001b[A\n",
            "8938it [11:40, 12.47it/s]\u001b[A\n",
            "8940it [11:40, 12.63it/s]\u001b[A\n",
            "8942it [11:41, 12.58it/s]\u001b[A\n",
            "8944it [11:41, 12.24it/s]\u001b[A\n",
            "8946it [11:41, 12.11it/s]\u001b[A\n",
            "8948it [11:41, 12.17it/s]\u001b[A\n",
            "8950it [11:41, 12.55it/s]\u001b[A\n",
            "8952it [11:41, 12.62it/s]\u001b[A\n",
            "8954it [11:42, 12.37it/s]\u001b[A\n",
            "8956it [11:42, 12.44it/s]\u001b[A\n",
            "8958it [11:42, 11.96it/s]\u001b[A\n",
            "8960it [11:42, 12.26it/s]\u001b[A\n",
            "8962it [11:42, 12.39it/s]\u001b[A\n",
            "8964it [11:42, 12.76it/s]\u001b[A\n",
            "8966it [11:43, 12.65it/s]\u001b[A\n",
            "8968it [11:43, 12.67it/s]\u001b[A\n",
            "8970it [11:43, 12.86it/s]\u001b[A\n",
            "8972it [11:43, 13.01it/s]\u001b[A\n",
            "8974it [11:43, 12.95it/s]\u001b[A\n",
            "8976it [11:43, 12.47it/s]\u001b[A\n",
            "8978it [11:43, 12.10it/s]\u001b[A\n",
            "8980it [11:44, 12.01it/s]\u001b[A\n",
            "8982it [11:44, 12.21it/s]\u001b[A\n",
            "8984it [11:44, 12.41it/s]\u001b[A\n",
            "8986it [11:44, 12.46it/s]\u001b[A\n",
            "8988it [11:44, 12.65it/s]\u001b[A\n",
            "8990it [11:44, 12.74it/s]\u001b[A\n",
            "8992it [11:45, 12.87it/s]\u001b[A\n",
            "8994it [11:45, 12.88it/s]\u001b[A\n",
            "8996it [11:45, 12.45it/s]\u001b[A\n",
            "8998it [11:45, 12.60it/s]\u001b[A\n",
            "9000it [11:45, 12.72it/s]\u001b[A\n",
            "9002it [11:45, 12.69it/s]\u001b[A\n",
            "9004it [11:46, 12.74it/s]\u001b[A\n",
            "9006it [11:46, 12.49it/s]\u001b[A\n",
            "9008it [11:46, 11.97it/s]\u001b[A\n",
            "9010it [11:46, 11.93it/s]\u001b[A\n",
            "9012it [11:46, 11.74it/s]\u001b[A\n",
            "9014it [11:46, 11.63it/s]\u001b[A\n",
            "9016it [11:47, 11.64it/s]\u001b[A\n",
            "9018it [11:47, 11.84it/s]\u001b[A\n",
            "9020it [11:47, 11.88it/s]\u001b[A\n",
            "9022it [11:47, 11.69it/s]\u001b[A\n",
            "9024it [11:47, 11.57it/s]\u001b[A\n",
            "9026it [11:47, 11.60it/s]\u001b[A\n",
            "9028it [11:48, 11.47it/s]\u001b[A\n",
            "9030it [11:48, 11.85it/s]\u001b[A\n",
            "9032it [11:48, 12.06it/s]\u001b[A\n",
            "9034it [11:48, 12.39it/s]\u001b[A\n",
            "9036it [11:48, 12.55it/s]\u001b[A\n",
            "9038it [11:48, 12.97it/s]\u001b[A\n",
            "9040it [11:49, 12.97it/s]\u001b[A\n",
            "9042it [11:49, 12.97it/s]\u001b[A\n",
            "9044it [11:49, 13.03it/s]\u001b[A\n",
            "9046it [11:49, 12.76it/s]\u001b[A\n",
            "9048it [11:49, 12.69it/s]\u001b[A\n",
            "9050it [11:49, 12.74it/s]\u001b[A\n",
            "9052it [11:49, 12.67it/s]\u001b[A\n",
            "9054it [11:50, 12.85it/s]\u001b[A\n",
            "9056it [11:50, 12.79it/s]\u001b[A\n",
            "9058it [11:50, 12.83it/s]\u001b[A\n",
            "9060it [11:50, 12.70it/s]\u001b[A\n",
            "9062it [11:50, 12.62it/s]\u001b[A\n",
            "9064it [11:50, 12.56it/s]\u001b[A\n",
            "9066it [11:51, 12.72it/s]\u001b[A\n",
            "9068it [11:51, 12.86it/s]\u001b[A\n",
            "9070it [11:51, 12.72it/s]\u001b[A\n",
            "9072it [11:51, 13.03it/s]\u001b[A\n",
            "9074it [11:51, 12.88it/s]\u001b[A\n",
            "9076it [11:51, 12.95it/s]\u001b[A\n",
            "9078it [11:51, 12.95it/s]\u001b[A\n",
            "9080it [11:52, 13.01it/s]\u001b[A\n",
            "9082it [11:52, 12.64it/s]\u001b[A\n",
            "9084it [11:52, 12.08it/s]\u001b[A\n",
            "9086it [11:52, 12.00it/s]\u001b[A\n",
            "9088it [11:52, 11.62it/s]\u001b[A\n",
            "9090it [11:53, 11.56it/s]\u001b[A\n",
            "9092it [11:53, 11.78it/s]\u001b[A\n",
            "9094it [11:53, 12.20it/s]\u001b[A\n",
            "9096it [11:53, 12.58it/s]\u001b[A\n",
            "9098it [11:53, 12.72it/s]\u001b[A\n",
            "9100it [11:53, 12.35it/s]\u001b[A\n",
            "9102it [11:53, 12.43it/s]\u001b[A\n",
            "9104it [11:54, 12.55it/s]\u001b[A\n",
            "9106it [11:54, 12.43it/s]\u001b[A\n",
            "9108it [11:54, 12.41it/s]\u001b[A\n",
            "9110it [11:54, 12.59it/s]\u001b[A\n",
            "9112it [11:54, 12.46it/s]\u001b[A\n",
            "9114it [11:54, 12.38it/s]\u001b[A\n",
            "9116it [11:55, 11.95it/s]\u001b[A\n",
            "9118it [11:55, 12.01it/s]\u001b[A\n",
            "9120it [11:55, 11.70it/s]\u001b[A\n",
            "9122it [11:55, 11.25it/s]\u001b[A\n",
            "9124it [11:55, 11.36it/s]\u001b[A\n",
            "9126it [11:55, 11.80it/s]\u001b[A\n",
            "9128it [11:56, 12.07it/s]\u001b[A\n",
            "9130it [11:56, 12.36it/s]\u001b[A\n",
            "9132it [11:56, 12.53it/s]\u001b[A\n",
            "9134it [11:56, 12.78it/s]\u001b[A\n",
            "9136it [11:56, 12.56it/s]\u001b[A\n",
            "9138it [11:56, 12.31it/s]\u001b[A\n",
            "9140it [11:57, 11.99it/s]\u001b[A\n",
            "9142it [11:57, 11.76it/s]\u001b[A\n",
            "9144it [11:57, 11.92it/s]\u001b[A\n",
            "9146it [11:57, 11.73it/s]\u001b[A\n",
            "9148it [11:57, 11.75it/s]\u001b[A\n",
            "9150it [11:57, 12.21it/s]\u001b[A\n",
            "9152it [11:58, 11.88it/s]\u001b[A\n",
            "9154it [11:58, 12.07it/s]\u001b[A\n",
            "9156it [11:58, 12.51it/s]\u001b[A\n",
            "9158it [11:58, 12.57it/s]\u001b[A\n",
            "9160it [11:58, 12.69it/s]\u001b[A\n",
            "9162it [11:58, 12.53it/s]\u001b[A\n",
            "9164it [11:59, 12.69it/s]\u001b[A\n",
            "9166it [11:59, 12.41it/s]\u001b[A\n",
            "9168it [11:59, 12.69it/s]\u001b[A\n",
            "9170it [11:59, 12.58it/s]\u001b[A\n",
            "9172it [11:59, 12.70it/s]\u001b[A\n",
            "9174it [11:59, 12.49it/s]\u001b[A\n",
            "9176it [12:00, 12.31it/s]\u001b[A\n",
            "9178it [12:00, 11.88it/s]\u001b[A\n",
            "9180it [12:00, 11.83it/s]\u001b[A\n",
            "9182it [12:00, 11.60it/s]\u001b[A\n",
            "9184it [12:00, 11.57it/s]\u001b[A\n",
            "9186it [12:00, 11.75it/s]\u001b[A\n",
            "9188it [12:01, 12.07it/s]\u001b[A\n",
            "9190it [12:01, 11.98it/s]\u001b[A\n",
            "9192it [12:01, 12.12it/s]\u001b[A\n",
            "9194it [12:01, 12.50it/s]\u001b[A\n",
            "9196it [12:01, 12.55it/s]\u001b[A\n",
            "9198it [12:01, 12.56it/s]\u001b[A\n",
            "9200it [12:01, 12.91it/s]\u001b[A\n",
            "9202it [12:02, 12.87it/s]\u001b[A\n",
            "9204it [12:02, 12.84it/s]\u001b[A\n",
            "9206it [12:02, 12.75it/s]\u001b[A\n",
            "9208it [12:02, 12.55it/s]\u001b[A\n",
            "9210it [12:02, 12.56it/s]\u001b[A\n",
            "9212it [12:02, 12.43it/s]\u001b[A\n",
            "9214it [12:03, 12.51it/s]\u001b[A\n",
            "9216it [12:03, 12.32it/s]\u001b[A\n",
            "9218it [12:03, 12.19it/s]\u001b[A\n",
            "9220it [12:03, 11.72it/s]\u001b[A\n",
            "9222it [12:03, 11.81it/s]\u001b[A\n",
            "9224it [12:03, 11.95it/s]\u001b[A\n",
            "9226it [12:04, 11.91it/s]\u001b[A\n",
            "9228it [12:04, 12.19it/s]\u001b[A\n",
            "9230it [12:04, 12.13it/s]\u001b[A\n",
            "9232it [12:04, 11.77it/s]\u001b[A\n",
            "9234it [12:04, 11.86it/s]\u001b[A\n",
            "9236it [12:04, 11.84it/s]\u001b[A\n",
            "9238it [12:05, 12.26it/s]\u001b[A\n",
            "9240it [12:05, 12.50it/s]\u001b[A\n",
            "9242it [12:05, 12.11it/s]\u001b[A\n",
            "9244it [12:05, 12.19it/s]\u001b[A\n",
            "9246it [12:05, 12.10it/s]\u001b[A\n",
            "9248it [12:05, 12.21it/s]\u001b[A\n",
            "9250it [12:06, 12.56it/s]\u001b[A\n",
            "9252it [12:06, 12.36it/s]\u001b[A\n",
            "9254it [12:06, 12.54it/s]\u001b[A\n",
            "9256it [12:06, 12.72it/s]\u001b[A\n",
            "9258it [12:06, 12.61it/s]\u001b[A\n",
            "9260it [12:06, 12.60it/s]\u001b[A\n",
            "9262it [12:07, 12.79it/s]\u001b[A\n",
            "9264it [12:07, 12.78it/s]\u001b[A\n",
            "9266it [12:07, 12.41it/s]\u001b[A\n",
            "9268it [12:07, 12.08it/s]\u001b[A\n",
            "9270it [12:07, 11.77it/s]\u001b[A\n",
            "9272it [12:07, 11.68it/s]\u001b[A\n",
            "9274it [12:08, 11.89it/s]\u001b[A\n",
            "9276it [12:08, 12.03it/s]\u001b[A\n",
            "9278it [12:08, 12.24it/s]\u001b[A\n",
            "9280it [12:08, 12.30it/s]\u001b[A\n",
            "9282it [12:08, 12.55it/s]\u001b[A\n",
            "9284it [12:08, 12.84it/s]\u001b[A\n",
            "9286it [12:08, 12.73it/s]\u001b[A\n",
            "9288it [12:09, 12.92it/s]\u001b[A\n",
            "9290it [12:09, 12.97it/s]\u001b[A\n",
            "9292it [12:09, 12.57it/s]\u001b[A\n",
            "9294it [12:09, 12.12it/s]\u001b[A\n",
            "9296it [12:09, 12.26it/s]\u001b[A\n",
            "9298it [12:09, 12.26it/s]\u001b[A\n",
            "9300it [12:10, 12.41it/s]\u001b[A\n",
            "9302it [12:10, 12.56it/s]\u001b[A\n",
            "9304it [12:10, 12.59it/s]\u001b[A\n",
            "9306it [12:10, 12.83it/s]\u001b[A\n",
            "9308it [12:10, 13.03it/s]\u001b[A\n",
            "9310it [12:10, 12.82it/s]\u001b[A\n",
            "9312it [12:11, 12.70it/s]\u001b[A\n",
            "9314it [12:11, 12.71it/s]\u001b[A\n",
            "9316it [12:11, 12.74it/s]\u001b[A\n",
            "9318it [12:11, 12.26it/s]\u001b[A\n",
            "9320it [12:11, 11.98it/s]\u001b[A\n",
            "9322it [12:11, 11.64it/s]\u001b[A\n",
            "9324it [12:12, 11.35it/s]\u001b[A\n",
            "9326it [12:12, 11.75it/s]\u001b[A\n",
            "9328it [12:12, 11.99it/s]\u001b[A\n",
            "9330it [12:12, 12.19it/s]\u001b[A\n",
            "9332it [12:12, 12.55it/s]\u001b[A\n",
            "9334it [12:12, 12.62it/s]\u001b[A\n",
            "9336it [12:13, 12.56it/s]\u001b[A\n",
            "9338it [12:13, 12.38it/s]\u001b[A\n",
            "9340it [12:13, 12.20it/s]\u001b[A\n",
            "9342it [12:13, 11.91it/s]\u001b[A\n",
            "9344it [12:13, 11.77it/s]\u001b[A\n",
            "9346it [12:13, 11.69it/s]\u001b[A\n",
            "9348it [12:14, 11.42it/s]\u001b[A\n",
            "9350it [12:14, 11.59it/s]\u001b[A\n",
            "9352it [12:14, 12.02it/s]\u001b[A\n",
            "9354it [12:14, 12.25it/s]\u001b[A\n",
            "9356it [12:14, 12.31it/s]\u001b[A\n",
            "9358it [12:14, 12.60it/s]\u001b[A\n",
            "9360it [12:15, 12.35it/s]\u001b[A\n",
            "9362it [12:15, 12.05it/s]\u001b[A\n",
            "9364it [12:15, 11.95it/s]\u001b[A\n",
            "9366it [12:15, 11.82it/s]\u001b[A\n",
            "9368it [12:15, 11.84it/s]\u001b[A\n",
            "9370it [12:15, 12.13it/s]\u001b[A\n",
            "9372it [12:16, 11.51it/s]\u001b[A\n",
            "9374it [12:16, 11.62it/s]\u001b[A\n",
            "9376it [12:16, 12.10it/s]\u001b[A\n",
            "9378it [12:16, 11.71it/s]\u001b[A\n",
            "9380it [12:16, 11.73it/s]\u001b[A\n",
            "9382it [12:16, 12.04it/s]\u001b[A\n",
            "9384it [12:17, 11.79it/s]\u001b[A\n",
            "9386it [12:17, 11.60it/s]\u001b[A\n",
            "9388it [12:17, 12.10it/s]\u001b[A\n",
            "9390it [12:17, 12.30it/s]\u001b[A\n",
            "9392it [12:17, 12.42it/s]\u001b[A\n",
            "9394it [12:17, 12.59it/s]\u001b[A\n",
            "9396it [12:18, 12.61it/s]\u001b[A\n",
            "9398it [12:18, 12.49it/s]\u001b[A\n",
            "9400it [12:18, 12.31it/s]\u001b[A\n",
            "9402it [12:18, 12.38it/s]\u001b[A\n",
            "9404it [12:18, 12.67it/s]\u001b[A\n",
            "9406it [12:18, 12.65it/s]\u001b[A\n",
            "9408it [12:18, 12.72it/s]\u001b[A\n",
            "9410it [12:19, 12.55it/s]\u001b[A\n",
            "9412it [12:19, 12.44it/s]\u001b[A\n",
            "9414it [12:19, 12.49it/s]\u001b[A\n",
            "9416it [12:19, 12.58it/s]\u001b[A\n",
            "9418it [12:19, 12.73it/s]\u001b[A\n",
            "9420it [12:19, 12.73it/s]\u001b[A\n",
            "9422it [12:20, 12.18it/s]\u001b[A\n",
            "9424it [12:20, 12.28it/s]\u001b[A\n",
            "9426it [12:20, 12.51it/s]\u001b[A\n",
            "9428it [12:20, 12.38it/s]\u001b[A\n",
            "9430it [12:20, 12.17it/s]\u001b[A\n",
            "9432it [12:20, 12.15it/s]\u001b[A\n",
            "9434it [12:21, 12.39it/s]\u001b[A\n",
            "9436it [12:21, 11.97it/s]\u001b[A\n",
            "9438it [12:21, 11.74it/s]\u001b[A\n",
            "9440it [12:21, 12.17it/s]\u001b[A\n",
            "9442it [12:21, 12.49it/s]\u001b[A\n",
            "9444it [12:21, 12.12it/s]\u001b[A\n",
            "9446it [12:22, 11.92it/s]\u001b[A\n",
            "9448it [12:22, 11.91it/s]\u001b[A\n",
            "9450it [12:22, 12.21it/s]\u001b[A\n",
            "9452it [12:22, 12.31it/s]\u001b[A\n",
            "9454it [12:22, 12.64it/s]\u001b[A\n",
            "9456it [12:22, 12.76it/s]\u001b[A\n",
            "9458it [12:23, 12.66it/s]\u001b[A\n",
            "9460it [12:23, 12.71it/s]\u001b[A\n",
            "9462it [12:23, 12.72it/s]\u001b[A\n",
            "9464it [12:23, 12.80it/s]\u001b[A\n",
            "9466it [12:23, 12.95it/s]\u001b[A\n",
            "9468it [12:23, 12.97it/s]\u001b[A\n",
            "9470it [12:23, 12.94it/s]\u001b[A\n",
            "9472it [12:24, 13.02it/s]\u001b[A\n",
            "9474it [12:24, 12.88it/s]\u001b[A\n",
            "9476it [12:24, 12.82it/s]\u001b[A\n",
            "9478it [12:24, 12.98it/s]\u001b[A\n",
            "9480it [12:24, 13.13it/s]\u001b[A\n",
            "9482it [12:24, 13.18it/s]\u001b[A\n",
            "9484it [12:25, 13.18it/s]\u001b[A\n",
            "9486it [12:25, 13.06it/s]\u001b[A\n",
            "9488it [12:25, 12.85it/s]\u001b[A\n",
            "9490it [12:25, 12.26it/s]\u001b[A\n",
            "9492it [12:25, 11.90it/s]\u001b[A\n",
            "9494it [12:25, 12.23it/s]\u001b[A\n",
            "9496it [12:26, 12.46it/s]\u001b[A\n",
            "9498it [12:26, 12.12it/s]\u001b[A\n",
            "9500it [12:26, 12.28it/s]\u001b[A\n",
            "9502it [12:26, 12.42it/s]\u001b[A\n",
            "9504it [12:26, 12.67it/s]\u001b[A\n",
            "9506it [12:26, 12.63it/s]\u001b[A\n",
            "9508it [12:26, 12.72it/s]\u001b[A\n",
            "9510it [12:27, 12.61it/s]\u001b[A\n",
            "9512it [12:27, 12.59it/s]\u001b[A\n",
            "9514it [12:27, 12.37it/s]\u001b[A\n",
            "9516it [12:27, 12.17it/s]\u001b[A\n",
            "9518it [12:27, 12.10it/s]\u001b[A\n",
            "9520it [12:27, 11.90it/s]\u001b[A\n",
            "9522it [12:28, 11.83it/s]\u001b[A\n",
            "9524it [12:28, 11.39it/s]\u001b[A\n",
            "9526it [12:28, 11.57it/s]\u001b[A\n",
            "9528it [12:28, 11.92it/s]\u001b[A\n",
            "9530it [12:28, 12.19it/s]\u001b[A\n",
            "9532it [12:28, 12.49it/s]\u001b[A\n",
            "9534it [12:29, 12.67it/s]\u001b[A\n",
            "9536it [12:29, 12.07it/s]\u001b[A\n",
            "9538it [12:29, 12.25it/s]\u001b[A\n",
            "9540it [12:29, 12.38it/s]\u001b[A\n",
            "9542it [12:29, 12.52it/s]\u001b[A\n",
            "9544it [12:29, 12.64it/s]\u001b[A\n",
            "9546it [12:30, 12.66it/s]\u001b[A\n",
            "9548it [12:30, 12.83it/s]\u001b[A\n",
            "9550it [12:30, 12.90it/s]\u001b[A\n",
            "9552it [12:30, 12.94it/s]\u001b[A\n",
            "9554it [12:30, 12.97it/s]\u001b[A\n",
            "9556it [12:30, 12.95it/s]\u001b[A\n",
            "9558it [12:31, 12.92it/s]\u001b[A\n",
            "9560it [12:31, 13.06it/s]\u001b[A\n",
            "9562it [12:31, 12.93it/s]\u001b[A\n",
            "9564it [12:31, 12.76it/s]\u001b[A\n",
            "9566it [12:31, 12.76it/s]\u001b[A\n",
            "9568it [12:31, 12.95it/s]\u001b[A\n",
            "9570it [12:31, 12.87it/s]\u001b[A\n",
            "9572it [12:32, 12.88it/s]\u001b[A\n",
            "9574it [12:32, 12.84it/s]\u001b[A\n",
            "9576it [12:32, 12.99it/s]\u001b[A\n",
            "9578it [12:32, 13.09it/s]\u001b[A\n",
            "9580it [12:32, 13.03it/s]\u001b[A\n",
            "9582it [12:32, 13.07it/s]\u001b[A\n",
            "9584it [12:33, 13.12it/s]\u001b[A\n",
            "9586it [12:33, 12.14it/s]\u001b[A\n",
            "9588it [12:33, 11.99it/s]\u001b[A\n",
            "9590it [12:33, 12.40it/s]\u001b[A\n",
            "9592it [12:33, 12.64it/s]\u001b[A\n",
            "9594it [12:33, 12.74it/s]\u001b[A\n",
            "9596it [12:33, 12.55it/s]\u001b[A\n",
            "9598it [12:34, 12.58it/s]\u001b[A\n",
            "9600it [12:34, 12.65it/s]\u001b[A\n",
            "9602it [12:34, 12.65it/s]\u001b[A\n",
            "9604it [12:34, 12.69it/s]\u001b[A\n",
            "9606it [12:34, 12.69it/s]\u001b[A\n",
            "9608it [12:34, 12.56it/s]\u001b[A\n",
            "9610it [12:35, 12.32it/s]\u001b[A\n",
            "9612it [12:35, 12.03it/s]\u001b[A\n",
            "9614it [12:35, 11.90it/s]\u001b[A\n",
            "9616it [12:35, 12.23it/s]\u001b[A\n",
            "9618it [12:35, 12.50it/s]\u001b[A\n",
            "9620it [12:35, 12.57it/s]\u001b[A\n",
            "9622it [12:36, 12.48it/s]\u001b[A\n",
            "9624it [12:36, 12.55it/s]\u001b[A\n",
            "9626it [12:36, 12.20it/s]\u001b[A\n",
            "9628it [12:36, 12.07it/s]\u001b[A\n",
            "9630it [12:36, 11.94it/s]\u001b[A\n",
            "9632it [12:36, 11.89it/s]\u001b[A\n",
            "9634it [12:37, 11.96it/s]\u001b[A\n",
            "9636it [12:37, 11.98it/s]\u001b[A\n",
            "9638it [12:37, 11.97it/s]\u001b[A\n",
            "9640it [12:37, 11.79it/s]\u001b[A\n",
            "9642it [12:37, 12.02it/s]\u001b[A\n",
            "9644it [12:37, 12.35it/s]\u001b[A\n",
            "9646it [12:38, 12.32it/s]\u001b[A\n",
            "9648it [12:38, 12.42it/s]\u001b[A\n",
            "9650it [12:38, 11.46it/s]\u001b[A\n",
            "9652it [12:38, 11.54it/s]\u001b[A\n",
            "9654it [12:38, 12.06it/s]\u001b[A\n",
            "9656it [12:38, 12.14it/s]\u001b[A\n",
            "9658it [12:39, 12.34it/s]\u001b[A\n",
            "9660it [12:39, 12.67it/s]\u001b[A\n",
            "9662it [12:39, 12.66it/s]\u001b[A\n",
            "9664it [12:39, 12.76it/s]\u001b[A\n",
            "9666it [12:39, 12.89it/s]\u001b[A\n",
            "9668it [12:39, 12.82it/s]\u001b[A\n",
            "9670it [12:40, 12.57it/s]\u001b[A\n",
            "9672it [12:40, 12.76it/s]\u001b[A\n",
            "9674it [12:40, 13.01it/s]\u001b[A\n",
            "9676it [12:40, 12.67it/s]\u001b[A\n",
            "9678it [12:40, 12.65it/s]\u001b[A\n",
            "9680it [12:40, 12.46it/s]\u001b[A\n",
            "9682it [12:40, 12.55it/s]\u001b[A\n",
            "9684it [12:41, 12.78it/s]\u001b[A\n",
            "9686it [12:41, 12.35it/s]\u001b[A\n",
            "9688it [12:41, 12.50it/s]\u001b[A\n",
            "9690it [12:41, 12.69it/s]\u001b[A\n",
            "9692it [12:41, 12.69it/s]\u001b[A\n",
            "9694it [12:41, 12.97it/s]\u001b[A\n",
            "9696it [12:42, 13.04it/s]\u001b[A\n",
            "9698it [12:42, 12.83it/s]\u001b[A\n",
            "9700it [12:42, 12.81it/s]\u001b[A\n",
            "9702it [12:42, 12.82it/s]\u001b[A\n",
            "9704it [12:42, 12.73it/s]\u001b[A\n",
            "9706it [12:42, 12.77it/s]\u001b[A\n",
            "9708it [12:42, 12.87it/s]\u001b[A\n",
            "9710it [12:43, 13.00it/s]\u001b[A\n",
            "9712it [12:43, 12.78it/s]\u001b[A\n",
            "9714it [12:43, 12.66it/s]\u001b[A\n",
            "9716it [12:43, 12.89it/s]\u001b[A\n",
            "9718it [12:43, 12.97it/s]\u001b[A\n",
            "9720it [12:43, 12.99it/s]\u001b[A\n",
            "9722it [12:44, 12.97it/s]\u001b[A\n",
            "9724it [12:44, 13.02it/s]\u001b[A\n",
            "9726it [12:44, 13.20it/s]\u001b[A\n",
            "9728it [12:44, 12.96it/s]\u001b[A\n",
            "9730it [12:44, 13.08it/s]\u001b[A\n",
            "9732it [12:44, 13.29it/s]\u001b[A\n",
            "9734it [12:44, 13.10it/s]\u001b[A\n",
            "9736it [12:45, 13.06it/s]\u001b[A\n",
            "9738it [12:45, 12.62it/s]\u001b[A\n",
            "9740it [12:45, 12.33it/s]\u001b[A\n",
            "9742it [12:45, 12.27it/s]\u001b[A\n",
            "9744it [12:45, 12.17it/s]\u001b[A\n",
            "9746it [12:45, 12.42it/s]\u001b[A\n",
            "9748it [12:46, 12.52it/s]\u001b[A\n",
            "9750it [12:46, 12.28it/s]\u001b[A\n",
            "9752it [12:46, 11.99it/s]\u001b[A\n",
            "9754it [12:46, 11.76it/s]\u001b[A\n",
            "9756it [12:46, 11.35it/s]\u001b[A\n",
            "9758it [12:47, 11.14it/s]\u001b[A\n",
            "9760it [12:47, 11.07it/s]\u001b[A\n",
            "9762it [12:47, 11.51it/s]\u001b[A\n",
            "9764it [12:47, 11.83it/s]\u001b[A\n",
            "9766it [12:47, 12.21it/s]\u001b[A\n",
            "9768it [12:47, 12.19it/s]\u001b[A\n",
            "9770it [12:47, 12.38it/s]\u001b[A\n",
            "9772it [12:48, 12.35it/s]\u001b[A\n",
            "9774it [12:48, 12.18it/s]\u001b[A\n",
            "9776it [12:48, 12.41it/s]\u001b[A\n",
            "9778it [12:48, 12.36it/s]\u001b[A\n",
            "9780it [12:48, 12.65it/s]\u001b[A\n",
            "9782it [12:48, 12.70it/s]\u001b[A\n",
            "9784it [12:49, 12.75it/s]\u001b[A\n",
            "9786it [12:49, 12.82it/s]\u001b[A\n",
            "9788it [12:49, 13.08it/s]\u001b[A\n",
            "9790it [12:49, 13.01it/s]\u001b[A\n",
            "9792it [12:49, 13.02it/s]\u001b[A\n",
            "9794it [12:49, 13.18it/s]\u001b[A\n",
            "9796it [12:50, 13.03it/s]\u001b[A\n",
            "9798it [12:50, 13.05it/s]\u001b[A\n",
            "9800it [12:50, 12.85it/s]\u001b[A\n",
            "9802it [12:50, 12.78it/s]\u001b[A\n",
            "9804it [12:50, 12.69it/s]\u001b[A\n",
            "9806it [12:50, 12.72it/s]\u001b[A\n",
            "9808it [12:50, 12.91it/s]\u001b[A\n",
            "9810it [12:51, 12.58it/s]\u001b[A\n",
            "9812it [12:51, 12.67it/s]\u001b[A\n",
            "9814it [12:51, 12.73it/s]\u001b[A\n",
            "9816it [12:51, 12.64it/s]\u001b[A\n",
            "9818it [12:51, 12.85it/s]\u001b[A\n",
            "9820it [12:51, 12.28it/s]\u001b[A\n",
            "9822it [12:52, 11.71it/s]\u001b[A\n",
            "9824it [12:52, 11.58it/s]\u001b[A\n",
            "9826it [12:52, 11.91it/s]\u001b[A\n",
            "9828it [12:52, 12.28it/s]\u001b[A\n",
            "9830it [12:52, 12.45it/s]\u001b[A\n",
            "9832it [12:52, 12.74it/s]\u001b[A\n",
            "9834it [12:53, 12.81it/s]\u001b[A\n",
            "9836it [12:53, 12.83it/s]\u001b[A\n",
            "9838it [12:53, 12.82it/s]\u001b[A\n",
            "9840it [12:53, 12.60it/s]\u001b[A\n",
            "9842it [12:53, 12.60it/s]\u001b[A\n",
            "9844it [12:53, 12.51it/s]\u001b[A\n",
            "9846it [12:54, 12.75it/s]\u001b[A\n",
            "9848it [12:54, 12.77it/s]\u001b[A\n",
            "9850it [12:54, 12.77it/s]\u001b[A\n",
            "9852it [12:54, 12.75it/s]\u001b[A\n",
            "9854it [12:54, 12.72it/s]\u001b[A\n",
            "9856it [12:54, 12.80it/s]\u001b[A\n",
            "9858it [12:54, 12.99it/s]\u001b[A\n",
            "9860it [12:55, 12.82it/s]\u001b[A\n",
            "9862it [12:55, 12.67it/s]\u001b[A\n",
            "9864it [12:55, 12.59it/s]\u001b[A\n",
            "9866it [12:55, 12.28it/s]\u001b[A\n",
            "9868it [12:55, 12.29it/s]\u001b[A\n",
            "9870it [12:55, 12.35it/s]\u001b[A\n",
            "9872it [12:56, 12.28it/s]\u001b[A\n",
            "9874it [12:56, 12.16it/s]\u001b[A\n",
            "9876it [12:56, 11.88it/s]\u001b[A\n",
            "9878it [12:56, 11.85it/s]\u001b[A\n",
            "9880it [12:56, 11.52it/s]\u001b[A\n",
            "9882it [12:56, 11.33it/s]\u001b[A\n",
            "9884it [12:57, 11.19it/s]\u001b[A\n",
            "9886it [12:57, 11.28it/s]\u001b[A\n",
            "9888it [12:57, 11.84it/s]\u001b[A\n",
            "9890it [12:57, 12.25it/s]\u001b[A\n",
            "9892it [12:57, 12.46it/s]\u001b[A\n",
            "9894it [12:57, 12.67it/s]\u001b[A\n",
            "9896it [12:58, 12.63it/s]\u001b[A\n",
            "9898it [12:58, 12.77it/s]\u001b[A\n",
            "9900it [12:58, 12.59it/s]\u001b[A\n",
            "9902it [12:58, 12.75it/s]\u001b[A\n",
            "9904it [12:58, 12.81it/s]\u001b[A\n",
            "9906it [12:58, 12.77it/s]\u001b[A\n",
            "9908it [12:59, 12.79it/s]\u001b[A\n",
            "9910it [12:59, 12.87it/s]\u001b[A\n",
            "9912it [12:59, 12.30it/s]\u001b[A\n",
            "9914it [12:59, 12.41it/s]\u001b[A\n",
            "9916it [12:59, 12.16it/s]\u001b[A\n",
            "9918it [12:59, 12.25it/s]\u001b[A\n",
            "9920it [13:00, 11.86it/s]\u001b[A\n",
            "9922it [13:00, 12.19it/s]\u001b[A\n",
            "9924it [13:00, 12.37it/s]\u001b[A\n",
            "9926it [13:00, 12.48it/s]\u001b[A\n",
            "9928it [13:00, 12.62it/s]\u001b[A\n",
            "9930it [13:00, 12.64it/s]\u001b[A\n",
            "9932it [13:00, 12.80it/s]\u001b[A\n",
            "9934it [13:01, 12.86it/s]\u001b[A\n",
            "9936it [13:01, 12.35it/s]\u001b[A\n",
            "9938it [13:01, 12.19it/s]\u001b[A\n",
            "9940it [13:01, 12.40it/s]\u001b[A\n",
            "9942it [13:01, 12.63it/s]\u001b[A\n",
            "9944it [13:01, 12.53it/s]\u001b[A\n",
            "9946it [13:02, 12.67it/s]\u001b[A\n",
            "9948it [13:02, 12.57it/s]\u001b[A\n",
            "9950it [13:02, 12.26it/s]\u001b[A\n",
            "9952it [13:02, 11.98it/s]\u001b[A\n",
            "9954it [13:02, 11.92it/s]\u001b[A\n",
            "9956it [13:02, 12.09it/s]\u001b[A\n",
            "9958it [13:03, 11.90it/s]\u001b[A\n",
            "9960it [13:03, 12.12it/s]\u001b[A\n",
            "9962it [13:03, 12.22it/s]\u001b[A\n",
            "9964it [13:03, 11.98it/s]\u001b[A\n",
            "9966it [13:03, 11.85it/s]\u001b[A\n",
            "9968it [13:03, 11.93it/s]\u001b[A\n",
            "9970it [13:04, 12.06it/s]\u001b[A\n",
            "9972it [13:04, 12.28it/s]\u001b[A\n",
            "9974it [13:04, 11.85it/s]\u001b[A\n",
            "9976it [13:04, 11.77it/s]\u001b[A\n",
            "9978it [13:04, 11.68it/s]\u001b[A\n",
            "9980it [13:04, 11.91it/s]\u001b[A\n",
            "9982it [13:05, 12.05it/s]\u001b[A\n",
            "9984it [13:05, 11.58it/s]\u001b[A\n",
            "9986it [13:05, 11.55it/s]\u001b[A\n",
            "9988it [13:05, 11.53it/s]\u001b[A\n",
            "9990it [13:05, 11.33it/s]\u001b[A\n",
            "9992it [13:05, 11.44it/s]\u001b[A\n",
            "9994it [13:06, 11.48it/s]\u001b[A\n",
            "9996it [13:06, 11.66it/s]\u001b[A\n",
            "9998it [13:06, 11.61it/s]\u001b[A\n",
            "10000it [13:06, 11.56it/s]\u001b[A\n",
            "10002it [13:06, 11.45it/s]\u001b[A\n",
            "10004it [13:07, 11.50it/s]\u001b[A\n",
            "10006it [13:07, 11.41it/s]\u001b[A\n",
            "10008it [13:07, 11.43it/s]\u001b[A\n",
            "10010it [13:07, 11.36it/s]\u001b[A\n",
            "10012it [13:07, 11.39it/s]\u001b[A\n",
            "10014it [13:07, 11.28it/s]\u001b[A\n",
            "10016it [13:08, 11.30it/s]\u001b[A\n",
            "10018it [13:08, 11.80it/s]\u001b[A\n",
            "10020it [13:08, 11.98it/s]\u001b[A\n",
            "10022it [13:08, 12.20it/s]\u001b[A\n",
            "10024it [13:08, 12.43it/s]\u001b[A\n",
            "10026it [13:08, 12.58it/s]\u001b[A\n",
            "10028it [13:09, 12.67it/s]\u001b[A\n",
            "10030it [13:09, 12.77it/s]\u001b[A\n",
            "10032it [13:09, 12.79it/s]\u001b[A\n",
            "10034it [13:09, 12.92it/s]\u001b[A\n",
            "10036it [13:09, 13.02it/s]\u001b[A\n",
            "10038it [13:09, 13.02it/s]\u001b[A\n",
            "10040it [13:09, 12.72it/s]\u001b[A\n",
            "10042it [13:10, 12.80it/s]\u001b[A\n",
            "10044it [13:10, 12.95it/s]\u001b[A\n",
            "10046it [13:10, 13.08it/s]\u001b[A\n",
            "10048it [13:10, 13.04it/s]\u001b[A\n",
            "10050it [13:10, 13.11it/s]\u001b[A\n",
            "10052it [13:10, 12.92it/s]\u001b[A\n",
            "10054it [13:11, 12.83it/s]\u001b[A\n",
            "10056it [13:11, 12.72it/s]\u001b[A\n",
            "10058it [13:11, 12.27it/s]\u001b[A\n",
            "10060it [13:11, 11.87it/s]\u001b[A\n",
            "10062it [13:11, 11.74it/s]\u001b[A\n",
            "10064it [13:11, 11.92it/s]\u001b[A\n",
            "10066it [13:12, 12.18it/s]\u001b[A\n",
            "10068it [13:12, 12.35it/s]\u001b[A\n",
            "10070it [13:12, 12.05it/s]\u001b[A\n",
            "10072it [13:12, 11.90it/s]\u001b[A\n",
            "10074it [13:12, 11.60it/s]\u001b[A\n",
            "10076it [13:12, 11.52it/s]\u001b[A\n",
            "10078it [13:13, 11.39it/s]\u001b[A\n",
            "10080it [13:13, 11.42it/s]\u001b[A\n",
            "10082it [13:13, 11.42it/s]\u001b[A\n",
            "10084it [13:13, 11.36it/s]\u001b[A\n",
            "10086it [13:13, 11.58it/s]\u001b[A\n",
            "10088it [13:13, 11.93it/s]\u001b[A\n",
            "10090it [13:14, 11.93it/s]\u001b[A\n",
            "10092it [13:14, 11.72it/s]\u001b[A\n",
            "10094it [13:14, 12.08it/s]\u001b[A\n",
            "10096it [13:14, 12.29it/s]\u001b[A\n",
            "10098it [13:14, 12.60it/s]\u001b[A\n",
            "10100it [13:14, 12.31it/s]\u001b[A\n",
            "10102it [13:15, 11.97it/s]\u001b[A\n",
            "10104it [13:15, 11.72it/s]\u001b[A\n",
            "10106it [13:15, 12.09it/s]\u001b[A\n",
            "10108it [13:15, 12.38it/s]\u001b[A\n",
            "10110it [13:15, 12.76it/s]\u001b[A\n",
            "10112it [13:15, 12.66it/s]\u001b[A\n",
            "10114it [13:16, 12.65it/s]\u001b[A\n",
            "10116it [13:16, 12.95it/s]\u001b[A\n",
            "10118it [13:16, 12.72it/s]\u001b[A\n",
            "10120it [13:16, 12.69it/s]\u001b[A\n",
            "10122it [13:16, 12.89it/s]\u001b[A\n",
            "10124it [13:16, 13.11it/s]\u001b[A\n",
            "10126it [13:16, 12.94it/s]\u001b[A\n",
            "10128it [13:17, 13.06it/s]\u001b[A\n",
            "10130it [13:17, 12.90it/s]\u001b[A\n",
            "10132it [13:17, 12.67it/s]\u001b[A\n",
            "10134it [13:17, 12.34it/s]\u001b[A\n",
            "10136it [13:17, 12.42it/s]\u001b[A\n",
            "10138it [13:17, 12.65it/s]\u001b[A\n",
            "10140it [13:18, 12.42it/s]\u001b[A\n",
            "10142it [13:18, 12.62it/s]\u001b[A\n",
            "10144it [13:18, 12.21it/s]\u001b[A\n",
            "10146it [13:18, 12.01it/s]\u001b[A\n",
            "10148it [13:18, 11.79it/s]\u001b[A\n",
            "10150it [13:18, 12.00it/s]\u001b[A\n",
            "10152it [13:19, 11.90it/s]\u001b[A\n",
            "10154it [13:19, 12.07it/s]\u001b[A\n",
            "10156it [13:19, 12.30it/s]\u001b[A\n",
            "10158it [13:19, 12.48it/s]\u001b[A\n",
            "10160it [13:19, 12.50it/s]\u001b[A\n",
            "10162it [13:19, 12.63it/s]\u001b[A\n",
            "10164it [13:20, 11.93it/s]\u001b[A\n",
            "10166it [13:20, 12.06it/s]\u001b[A\n",
            "10168it [13:20, 12.12it/s]\u001b[A\n",
            "10170it [13:20, 12.30it/s]\u001b[A\n",
            "10172it [13:20, 12.69it/s]\u001b[A\n",
            "10174it [13:20, 12.69it/s]\u001b[A\n",
            "10176it [13:21, 12.80it/s]\u001b[A\n",
            "10178it [13:21, 12.71it/s]\u001b[A\n",
            "10180it [13:21, 12.54it/s]\u001b[A\n",
            "10182it [13:21, 12.20it/s]\u001b[A\n",
            "10184it [13:21, 11.95it/s]\u001b[A\n",
            "10186it [13:21, 12.28it/s]\u001b[A\n",
            "10188it [13:21, 12.30it/s]\u001b[A\n",
            "10190it [13:22, 12.48it/s]\u001b[A\n",
            "10192it [13:22, 12.52it/s]\u001b[A\n",
            "10194it [13:22, 12.17it/s]\u001b[A\n",
            "10196it [13:22, 11.79it/s]\u001b[A\n",
            "10198it [13:22, 12.00it/s]\u001b[A\n",
            "10200it [13:22, 12.47it/s]\u001b[A\n",
            "10202it [13:23, 12.47it/s]\u001b[A\n",
            "10204it [13:23, 12.70it/s]\u001b[A\n",
            "10206it [13:23, 12.78it/s]\u001b[A\n",
            "10208it [13:23, 12.66it/s]\u001b[A\n",
            "10210it [13:23, 12.67it/s]\u001b[A\n",
            "10212it [13:23, 12.65it/s]\u001b[A\n",
            "10214it [13:24, 12.58it/s]\u001b[A\n",
            "10216it [13:24, 12.61it/s]\u001b[A\n",
            "10218it [13:24, 12.86it/s]\u001b[A\n",
            "10220it [13:24, 12.98it/s]\u001b[A\n",
            "10222it [13:24, 12.89it/s]\u001b[A\n",
            "10224it [13:24, 12.84it/s]\u001b[A\n",
            "10226it [13:24, 13.08it/s]\u001b[A\n",
            "10228it [13:25, 12.75it/s]\u001b[A\n",
            "10230it [13:25, 12.81it/s]\u001b[A\n",
            "10232it [13:25, 12.68it/s]\u001b[A\n",
            "10234it [13:25, 12.58it/s]\u001b[A\n",
            "10236it [13:25, 12.67it/s]\u001b[A\n",
            "10238it [13:25, 12.74it/s]\u001b[A\n",
            "10240it [13:26, 12.43it/s]\u001b[A\n",
            "10242it [13:26, 12.58it/s]\u001b[A\n",
            "10244it [13:26, 12.75it/s]\u001b[A\n",
            "10246it [13:26, 12.79it/s]\u001b[A\n",
            "10248it [13:26, 12.72it/s]\u001b[A\n",
            "10250it [13:26, 12.28it/s]\u001b[A\n",
            "10252it [13:27, 12.33it/s]\u001b[A\n",
            "10254it [13:27, 12.38it/s]\u001b[A\n",
            "10256it [13:27, 12.52it/s]\u001b[A\n",
            "10258it [13:27, 12.21it/s]\u001b[A\n",
            "10260it [13:27, 12.15it/s]\u001b[A\n",
            "10262it [13:27, 12.35it/s]\u001b[A\n",
            "10264it [13:28, 11.72it/s]\u001b[A\n",
            "10266it [13:28, 11.74it/s]\u001b[A\n",
            "10268it [13:28, 11.87it/s]\u001b[A\n",
            "10270it [13:28, 12.06it/s]\u001b[A\n",
            "10272it [13:28, 12.48it/s]\u001b[A\n",
            "10274it [13:28, 12.64it/s]\u001b[A\n",
            "10276it [13:29, 12.68it/s]\u001b[A\n",
            "10278it [13:29, 12.63it/s]\u001b[A\n",
            "10280it [13:29, 12.79it/s]\u001b[A\n",
            "10282it [13:29, 12.75it/s]\u001b[A\n",
            "10284it [13:29, 12.91it/s]\u001b[A\n",
            "10286it [13:29, 12.78it/s]\u001b[A\n",
            "10288it [13:29, 12.89it/s]\u001b[A\n",
            "10290it [13:30, 12.70it/s]\u001b[A\n",
            "10292it [13:30, 12.43it/s]\u001b[A\n",
            "10294it [13:30, 12.24it/s]\u001b[A\n",
            "10296it [13:30, 11.82it/s]\u001b[A\n",
            "10298it [13:30, 11.65it/s]\u001b[A\n",
            "10300it [13:30, 11.51it/s]\u001b[A\n",
            "10302it [13:31, 11.24it/s]\u001b[A\n",
            "10304it [13:31, 11.31it/s]\u001b[A\n",
            "10306it [13:31, 11.85it/s]\u001b[A\n",
            "10308it [13:31, 12.21it/s]\u001b[A\n",
            "10310it [13:31, 12.68it/s]\u001b[A\n",
            "10312it [13:31, 12.85it/s]\u001b[A\n",
            "10314it [13:32, 13.01it/s]\u001b[A\n",
            "10316it [13:32, 12.78it/s]\u001b[A\n",
            "10318it [13:32, 12.74it/s]\u001b[A\n",
            "10320it [13:32, 12.86it/s]\u001b[A\n",
            "10322it [13:32, 12.88it/s]\u001b[A\n",
            "10324it [13:32, 12.73it/s]\u001b[A\n",
            "10326it [13:33, 12.91it/s]\u001b[A\n",
            "10328it [13:33, 12.85it/s]\u001b[A\n",
            "10330it [13:33, 12.44it/s]\u001b[A\n",
            "10332it [13:33, 12.43it/s]\u001b[A\n",
            "10334it [13:33, 12.63it/s]\u001b[A\n",
            "10336it [13:33, 12.61it/s]\u001b[A\n",
            "10338it [13:34, 12.55it/s]\u001b[A\n",
            "10340it [13:34, 12.36it/s]\u001b[A\n",
            "10342it [13:34, 12.18it/s]\u001b[A\n",
            "10344it [13:34, 12.23it/s]\u001b[A\n",
            "10346it [13:34, 12.36it/s]\u001b[A\n",
            "10348it [13:34, 12.38it/s]\u001b[A\n",
            "10350it [13:34, 12.59it/s]\u001b[A\n",
            "10352it [13:35, 12.65it/s]\u001b[A\n",
            "10354it [13:35, 12.27it/s]\u001b[A\n",
            "10356it [13:35, 11.89it/s]\u001b[A\n",
            "10358it [13:35, 11.54it/s]\u001b[A\n",
            "10360it [13:35, 11.35it/s]\u001b[A\n",
            "10362it [13:36, 11.35it/s]\u001b[A\n",
            "10364it [13:36, 11.43it/s]\u001b[A\n",
            "10366it [13:36, 11.74it/s]\u001b[A\n",
            "10368it [13:36, 11.74it/s]\u001b[A\n",
            "10370it [13:36, 11.60it/s]\u001b[A\n",
            "10372it [13:36, 11.63it/s]\u001b[A\n",
            "10374it [13:37, 11.53it/s]\u001b[A\n",
            "10376it [13:37, 11.44it/s]\u001b[A\n",
            "10378it [13:37, 11.50it/s]\u001b[A\n",
            "10380it [13:37, 11.40it/s]\u001b[A\n",
            "10382it [13:37, 11.44it/s]\u001b[A\n",
            "10384it [13:37, 11.36it/s]\u001b[A\n",
            "10386it [13:38, 11.39it/s]\u001b[A\n",
            "10388it [13:38, 11.72it/s]\u001b[A\n",
            "10390it [13:38, 11.97it/s]\u001b[A\n",
            "10392it [13:38, 12.22it/s]\u001b[A\n",
            "10394it [13:38, 12.49it/s]\u001b[A\n",
            "10396it [13:38, 12.57it/s]\u001b[A\n",
            "10398it [13:39, 12.74it/s]\u001b[A\n",
            "10400it [13:39, 12.78it/s]\u001b[A\n",
            "10402it [13:39, 12.66it/s]\u001b[A\n",
            "10404it [13:39, 12.73it/s]\u001b[A\n",
            "10406it [13:39, 12.77it/s]\u001b[A\n",
            "10408it [13:39, 12.90it/s]\u001b[A\n",
            "10410it [13:39, 12.81it/s]\u001b[A\n",
            "10412it [13:40, 12.78it/s]\u001b[A\n",
            "10414it [13:40, 12.64it/s]\u001b[A\n",
            "10416it [13:40, 12.82it/s]\u001b[A\n",
            "10418it [13:40, 13.01it/s]\u001b[A\n",
            "10420it [13:40, 13.04it/s]\u001b[A\n",
            "10422it [13:40, 13.06it/s]\u001b[A\n",
            "10424it [13:41, 13.13it/s]\u001b[A\n",
            "10426it [13:41, 13.00it/s]\u001b[A\n",
            "10428it [13:41, 12.18it/s]\u001b[A\n",
            "10430it [13:41, 11.72it/s]\u001b[A\n",
            "10432it [13:41, 12.01it/s]\u001b[A\n",
            "10434it [13:41, 12.01it/s]\u001b[A\n",
            "10436it [13:42, 11.86it/s]\u001b[A\n",
            "10438it [13:42, 12.10it/s]\u001b[A\n",
            "10440it [13:42, 11.56it/s]\u001b[A\n",
            "10442it [13:42, 12.03it/s]\u001b[A\n",
            "10444it [13:42, 12.29it/s]\u001b[A\n",
            "10446it [13:42, 12.47it/s]\u001b[A\n",
            "10448it [13:43, 12.27it/s]\u001b[A\n",
            "10450it [13:43, 11.94it/s]\u001b[A\n",
            "10452it [13:43, 11.69it/s]\u001b[A\n",
            "10454it [13:43, 11.53it/s]\u001b[A\n",
            "10456it [13:43, 11.47it/s]\u001b[A\n",
            "10458it [13:43, 11.33it/s]\u001b[A\n",
            "10460it [13:44, 11.47it/s]\u001b[A\n",
            "10462it [13:44, 11.90it/s]\u001b[A\n",
            "10464it [13:44, 12.11it/s]\u001b[A\n",
            "10466it [13:44, 12.18it/s]\u001b[A\n",
            "10468it [13:44, 12.48it/s]\u001b[A\n",
            "10470it [13:44, 12.63it/s]\u001b[A\n",
            "10472it [13:45, 12.75it/s]\u001b[A\n",
            "10474it [13:45, 12.78it/s]\u001b[A\n",
            "10476it [13:45, 12.68it/s]\u001b[A\n",
            "10478it [13:45, 12.75it/s]\u001b[A\n",
            "10480it [13:45, 12.62it/s]\u001b[A\n",
            "10482it [13:45, 12.53it/s]\u001b[A\n",
            "10484it [13:46, 12.60it/s]\u001b[A\n",
            "10486it [13:46, 12.45it/s]\u001b[A\n",
            "10488it [13:46, 12.08it/s]\u001b[A\n",
            "10490it [13:46, 12.01it/s]\u001b[A\n",
            "10492it [13:46, 11.76it/s]\u001b[A\n",
            "10494it [13:46, 11.74it/s]\u001b[A\n",
            "10496it [13:47, 11.88it/s]\u001b[A\n",
            "10498it [13:47, 11.99it/s]\u001b[A\n",
            "10500it [13:47, 11.88it/s]\u001b[A\n",
            "10502it [13:47, 11.86it/s]\u001b[A\n",
            "10504it [13:47, 11.54it/s]\u001b[A\n",
            "10506it [13:47, 11.40it/s]\u001b[A\n",
            "10508it [13:48, 11.31it/s]\u001b[A\n",
            "10510it [13:48, 11.72it/s]\u001b[A\n",
            "10512it [13:48, 11.87it/s]\u001b[A\n",
            "10514it [13:48, 12.31it/s]\u001b[A\n",
            "10516it [13:48, 12.64it/s]\u001b[A\n",
            "10518it [13:48, 12.73it/s]\u001b[A\n",
            "10520it [13:49, 12.89it/s]\u001b[A\n",
            "10522it [13:49, 12.83it/s]\u001b[A\n",
            "10524it [13:49, 12.98it/s]\u001b[A\n",
            "10526it [13:49, 12.79it/s]\u001b[A\n",
            "10528it [13:49, 12.69it/s]\u001b[A\n",
            "10530it [13:49, 12.49it/s]\u001b[A\n",
            "10532it [13:49, 12.68it/s]\u001b[A\n",
            "10534it [13:50, 12.73it/s]\u001b[A\n",
            "10536it [13:50, 12.95it/s]\u001b[A\n",
            "10538it [13:50, 12.37it/s]\u001b[A\n",
            "10540it [13:50, 11.72it/s]\u001b[A\n",
            "10542it [13:50, 11.85it/s]\u001b[A\n",
            "10544it [13:50, 12.18it/s]\u001b[A\n",
            "10546it [13:51, 12.04it/s]\u001b[A\n",
            "10548it [13:51, 11.90it/s]\u001b[A\n",
            "10550it [13:51, 11.89it/s]\u001b[A\n",
            "10552it [13:51, 12.14it/s]\u001b[A\n",
            "10554it [13:51, 12.32it/s]\u001b[A\n",
            "10556it [13:51, 12.39it/s]\u001b[A\n",
            "10558it [13:52, 12.55it/s]\u001b[A\n",
            "10560it [13:52, 12.21it/s]\u001b[A\n",
            "10562it [13:52, 12.10it/s]\u001b[A\n",
            "10564it [13:52, 12.32it/s]\u001b[A\n",
            "10566it [13:52, 12.55it/s]\u001b[A\n",
            "10568it [13:52, 12.62it/s]\u001b[A\n",
            "10570it [13:53, 12.86it/s]\u001b[A\n",
            "10572it [13:53, 12.62it/s]\u001b[A\n",
            "10574it [13:53, 12.71it/s]\u001b[A\n",
            "10576it [13:53, 12.41it/s]\u001b[A\n",
            "10578it [13:53, 12.55it/s]\u001b[A\n",
            "10580it [13:53, 12.67it/s]\u001b[A\n",
            "10582it [13:53, 12.78it/s]\u001b[A\n",
            "10584it [13:54, 12.75it/s]\u001b[A\n",
            "10586it [13:54, 12.80it/s]\u001b[A\n",
            "10588it [13:54, 12.07it/s]\u001b[A\n",
            "10590it [13:54, 11.78it/s]\u001b[A\n",
            "10592it [13:54, 12.09it/s]\u001b[A\n",
            "10594it [13:54, 12.40it/s]\u001b[A\n",
            "10596it [13:55, 12.41it/s]\u001b[A\n",
            "10598it [13:55, 11.99it/s]\u001b[A\n",
            "10600it [13:55, 11.74it/s]\u001b[A\n",
            "10602it [13:55, 11.56it/s]\u001b[A\n",
            "10604it [13:55, 11.41it/s]\u001b[A\n",
            "10606it [13:56, 11.23it/s]\u001b[A\n",
            "10608it [13:56, 11.14it/s]\u001b[A\n",
            "10610it [13:56, 11.47it/s]\u001b[A\n",
            "10612it [13:56, 11.70it/s]\u001b[A\n",
            "10614it [13:56, 11.97it/s]\u001b[A\n",
            "10616it [13:56, 12.15it/s]\u001b[A\n",
            "10618it [13:57, 12.20it/s]\u001b[A\n",
            "10620it [13:57, 11.87it/s]\u001b[A\n",
            "10622it [13:57, 11.91it/s]\u001b[A\n",
            "10624it [13:57, 12.06it/s]\u001b[A\n",
            "10626it [13:57, 12.42it/s]\u001b[A\n",
            "10628it [13:57, 12.61it/s]\u001b[A\n",
            "10630it [13:58, 12.62it/s]\u001b[A\n",
            "10632it [13:58, 12.47it/s]\u001b[A\n",
            "10634it [13:58, 12.24it/s]\u001b[A\n",
            "10636it [13:58, 11.74it/s]\u001b[A\n",
            "10638it [13:58, 11.50it/s]\u001b[A\n",
            "10640it [13:58, 11.80it/s]\u001b[A\n",
            "10642it [13:59, 12.04it/s]\u001b[A\n",
            "10644it [13:59, 12.25it/s]\u001b[A\n",
            "10646it [13:59, 12.15it/s]\u001b[A\n",
            "10648it [13:59, 11.94it/s]\u001b[A\n",
            "10650it [13:59, 12.25it/s]\u001b[A\n",
            "10652it [13:59, 12.31it/s]\u001b[A\n",
            "10654it [13:59, 12.39it/s]\u001b[A\n",
            "10656it [14:00, 12.38it/s]\u001b[A\n",
            "10658it [14:00, 12.53it/s]\u001b[A\n",
            "10660it [14:00, 12.66it/s]\u001b[A\n",
            "10662it [14:00, 12.72it/s]\u001b[A\n",
            "10664it [14:00, 12.83it/s]\u001b[A\n",
            "10666it [14:00, 12.73it/s]\u001b[A\n",
            "10668it [14:01, 12.75it/s]\u001b[A\n",
            "10670it [14:01, 12.84it/s]\u001b[A\n",
            "10672it [14:01, 12.43it/s]\u001b[A\n",
            "10674it [14:01, 11.72it/s]\u001b[A\n",
            "10676it [14:01, 11.92it/s]\u001b[A\n",
            "10678it [14:01, 11.70it/s]\u001b[A\n",
            "10680it [14:02, 11.68it/s]\u001b[A\n",
            "10682it [14:02, 11.98it/s]\u001b[A\n",
            "10684it [14:02, 12.05it/s]\u001b[A\n",
            "10686it [14:02, 11.77it/s]\u001b[A\n",
            "10688it [14:02, 11.93it/s]\u001b[A\n",
            "10690it [14:02, 12.18it/s]\u001b[A\n",
            "10692it [14:03, 12.34it/s]\u001b[A\n",
            "10694it [14:03, 12.52it/s]\u001b[A\n",
            "10696it [14:03, 12.63it/s]\u001b[A\n",
            "10698it [14:03, 12.57it/s]\u001b[A\n",
            "10700it [14:03, 12.51it/s]\u001b[A\n",
            "10702it [14:03, 12.68it/s]\u001b[A\n",
            "10704it [14:04, 12.60it/s]\u001b[A\n",
            "10706it [14:04, 12.37it/s]\u001b[A\n",
            "10708it [14:04, 12.39it/s]\u001b[A\n",
            "10710it [14:04, 12.52it/s]\u001b[A\n",
            "10712it [14:04, 12.36it/s]\u001b[A\n",
            "10714it [14:04, 12.30it/s]\u001b[A\n",
            "10716it [14:05, 12.38it/s]\u001b[A\n",
            "10718it [14:05, 12.39it/s]\u001b[A\n",
            "10720it [14:05, 12.49it/s]\u001b[A\n",
            "10722it [14:05, 12.06it/s]\u001b[A\n",
            "10724it [14:05, 11.63it/s]\u001b[A\n",
            "10726it [14:05, 11.87it/s]\u001b[A\n",
            "10728it [14:06, 12.05it/s]\u001b[A\n",
            "10730it [14:06, 12.08it/s]\u001b[A\n",
            "10732it [14:06, 12.18it/s]\u001b[A\n",
            "10734it [14:06, 12.25it/s]\u001b[A\n",
            "10736it [14:06, 11.94it/s]\u001b[A\n",
            "10738it [14:06, 11.66it/s]\u001b[A\n",
            "10740it [14:07, 11.45it/s]\u001b[A\n",
            "10742it [14:07, 11.26it/s]\u001b[A\n",
            "10744it [14:07, 11.17it/s]\u001b[A\n",
            "10746it [14:07, 11.21it/s]\u001b[A\n",
            "10748it [14:07, 11.30it/s]\u001b[A\n",
            "10750it [14:07, 11.42it/s]\u001b[A\n",
            "10752it [14:08, 11.54it/s]\u001b[A\n",
            "10754it [14:08, 11.83it/s]\u001b[A\n",
            "10756it [14:08, 11.66it/s]\u001b[A\n",
            "10758it [14:08, 12.12it/s]\u001b[A\n",
            "10760it [14:08, 12.23it/s]\u001b[A\n",
            "10762it [14:08, 12.54it/s]\u001b[A\n",
            "10764it [14:09, 12.80it/s]\u001b[A\n",
            "10766it [14:09, 12.82it/s]\u001b[A\n",
            "10768it [14:09, 13.05it/s]\u001b[A\n",
            "10770it [14:09, 13.09it/s]\u001b[A\n",
            "10772it [14:09, 13.18it/s]\u001b[A\n",
            "10774it [14:09, 13.20it/s]\u001b[A\n",
            "10776it [14:09, 13.19it/s]\u001b[A\n",
            "10778it [14:10, 13.02it/s]\u001b[A\n",
            "10780it [14:10, 12.83it/s]\u001b[A\n",
            "10782it [14:10, 12.84it/s]\u001b[A\n",
            "10784it [14:10, 12.78it/s]\u001b[A\n",
            "10786it [14:10, 12.83it/s]\u001b[A\n",
            "10788it [14:10, 12.83it/s]\u001b[A\n",
            "10790it [14:11, 13.05it/s]\u001b[A\n",
            "10792it [14:11, 12.70it/s]\u001b[A\n",
            "10794it [14:11, 12.56it/s]\u001b[A\n",
            "10796it [14:11, 12.61it/s]\u001b[A\n",
            "10798it [14:11, 12.56it/s]\u001b[A\n",
            "10800it [14:11, 12.60it/s]\u001b[A\n",
            "10802it [14:12, 12.65it/s]\u001b[A\n",
            "10804it [14:12, 12.80it/s]\u001b[A\n",
            "10806it [14:12, 12.57it/s]\u001b[A\n",
            "10808it [14:12, 12.55it/s]\u001b[A\n",
            "10810it [14:12, 12.58it/s]\u001b[A\n",
            "10812it [14:12, 11.98it/s]\u001b[A\n",
            "10814it [14:13, 11.68it/s]\u001b[A\n",
            "10816it [14:13, 11.02it/s]\u001b[A\n",
            "10818it [14:13, 11.00it/s]\u001b[A\n",
            "10820it [14:13, 11.32it/s]\u001b[A\n",
            "10822it [14:13, 11.57it/s]\u001b[A\n",
            "10825it [14:13, 12.68it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[9357.497582048178, 9446.468951970339, 9378.525211721659, 9479.95735681057, 9535.449575036764, 9510.309046983719, 9289.561259806156, 9530.35733640194, 9517.998938679695]\n",
            "[9503, 9651, 9606, 9649, 9721, 9648, 9526, 9665, 9631]\n",
            "[448.41239222848185, 637.2631376257617, 684.1313679411988, 512.6794190745065, 558.3709353026475, 448.10474678606613, 734.9538882930817, 437.2487093207777, 359.9448776579988]\n",
            "Entropy: 0.05569118810380174\n",
            "Each Classifier Average:  [0.9846887911236639, 0.9788072688809801, 0.9763195098606765, 0.9824808121888869, 0.9809124138500941, 0.9857285496459078, 0.9751796409622251, 0.9860690467048049, 0.988266944105461]\n",
            "Threshold: 0.9820503308136335\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8VI9suKmr2Te",
        "outputId": "e082aa8d-4d33-4f38-a0c6-7c0c922a3149"
      },
      "source": [
        "ref_vect_in_0an = []\n",
        "ref_vect_in_0an.append(classifier_avg_t)\n",
        "\n",
        "threshold_in_0an = []\n",
        "threshold_in_0an.append(treshold_t)\n",
        "\n",
        "entropy_in_0an = []\n",
        "entropy_in_0an.append(entropy_t)\n",
        "\n",
        "print(entropy_in_0an)\n",
        "print(ref_vect_in_0an)\n",
        "print(threshold_in_0an)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.05569118810380174]\n",
            "[[0.9846887911236639, 0.9788072688809801, 0.9763195098606765, 0.9824808121888869, 0.9809124138500941, 0.9857285496459078, 0.9751796409622251, 0.9860690467048049, 0.988266944105461]]\n",
            "[0.9820503308136335]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "muAYeth2nOkF"
      },
      "source": [
        "entropy_in_0an = [0.05569118810380174]\n",
        "ref_vect_in_0an = [[0.9846887911236639, 0.9788072688809801, 0.9763195098606765, 0.9824808121888869, 0.9809124138500941, 0.9857285496459078, 0.9751796409622251, 0.9860690467048049, 0.988266944105461]]\n",
        "threshold_in_0an = [0.9820503308136335]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PhKqXodasPxB",
        "outputId": "ecca9eba-1768-47b2-d0b0-76967286173f"
      },
      "source": [
        "from tqdm import tqdm\n",
        "avg = [0,0,0,0,0,0,0,0,0]\n",
        "count = [0,0,0,0,0,0,0,0,0]\n",
        "entropy_list = [0,0,0,0,0,0,0,0,0]\n",
        "\n",
        "for img, lbl in tqdm(zip(new_val_images,new_val_labels)):\n",
        "  img = img.reshape([-1, 28, 28, 1])\n",
        "  if lbl == 1:\n",
        "    logits = model_dict[0](img)\n",
        "    logits = tf.math.divide(logits, temp_val[0])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e0 = entropy(pred[0])\n",
        "    entropy_list[0] = entropy_list[0] + e0\n",
        "    max_val0 = np.max(pred)\n",
        "    avg[0] = avg[0] + max_val0\n",
        "    count[0] = count[0] + 1\n",
        "  if lbl == 2:\n",
        "    logits = model_dict[1](img)\n",
        "    logits = tf.math.divide(logits, temp_val[1])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e1 = entropy(pred[0])\n",
        "    entropy_list[1] = entropy_list[1] + e1\n",
        "    max_val1 = np.max(pred)\n",
        "    avg[1] = avg[1] + max_val1\n",
        "    count[1] = count[1] + 1\n",
        "  if lbl == 3:\n",
        "    logits = model_dict[2](img)\n",
        "    logits = tf.math.divide(logits, temp_val[2])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e2 = entropy(pred[0])\n",
        "    entropy_list[2] = entropy_list[2] + e2\n",
        "    max_val2 = np.max(pred)\n",
        "    avg[2] = avg[2] + max_val2\n",
        "    count[2] = count[2] + 1\n",
        "  if lbl == 4:\n",
        "    logits = model_dict[3](img)\n",
        "    logits = tf.math.divide(logits, temp_val[3])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e3 = entropy(pred[0])\n",
        "    entropy_list[3] = entropy_list[3] + e3\n",
        "    max_val3 = np.max(pred)  \n",
        "    avg[3] = avg[3] + max_val3\n",
        "    count[3] = count[3] + 1\n",
        "  if lbl == 5:\n",
        "    logits = model_dict[4](img)\n",
        "    logits = tf.math.divide(logits, temp_val[4])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e4 = entropy(pred[0])\n",
        "    entropy_list[4] = entropy_list[4] + e4\n",
        "    max_val4 = np.max(pred)\n",
        "    avg[4] = avg[4] + max_val4\n",
        "    count[4] = count[4] + 1\n",
        "  if lbl == 6:\n",
        "    logits = model_dict[5](img)\n",
        "    logits = tf.math.divide(logits, temp_val[5])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e5 = entropy(pred[0])\n",
        "    entropy_list[5] = entropy_list[5] + e5\n",
        "    max_val5 = np.max(pred)\n",
        "    avg[5] = avg[5] + max_val5\n",
        "    count[5] = count[5] + 1\n",
        "  if lbl == 7:\n",
        "    logits = model_dict[6](img)\n",
        "    logits = tf.math.divide(logits, temp_val[6])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e6 = entropy(pred[0])\n",
        "    entropy_list[6] = entropy_list[6] + e6\n",
        "    max_val6 = np.max(pred)\n",
        "    avg[6] = avg[6] + max_val6\n",
        "    count[6] = count[6] + 1\n",
        "  if lbl == 8:\n",
        "    logits = model_dict[7](img)\n",
        "    logits = tf.math.divide(logits, temp_val[7])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e7 = entropy(pred[0])\n",
        "    entropy_list[7] = entropy_list[7] + e7\n",
        "    max_val7 = np.max(pred)\n",
        "    avg[7] = avg[7] + max_val7\n",
        "    count[7] = count[7] + 1\n",
        "  if lbl == 9:\n",
        "    logits = model_dict[8](img)\n",
        "    logits = tf.math.divide(logits, temp_val[8])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e8 = entropy(pred[0])\n",
        "    entropy_list[8] = entropy_list[8] + e8\n",
        "    max_val8 = np.max(pred)\n",
        "    avg[8] = avg[8] + max_val8\n",
        "    count[8] = count[8] + 1\n",
        "\n",
        "print(avg)\n",
        "print(count)\n",
        "print(entropy_list)\n",
        "\n",
        "entropy_avg_t = [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]\n",
        "for i in range(9):\n",
        "  entropy_avg_t[i] = entropy_list[i]/count[i]\n",
        "\n",
        "entropy_value_t = 0.0\n",
        "for i in range(9):\n",
        "  entropy_value_t = entropy_value_t + entropy_avg_t[i]\n",
        "\n",
        "entropy_t = entropy_value_t/len(entropy_avg_t)\n",
        "\n",
        "print('Entropy:', entropy_t)\n",
        "\n",
        "classifier_avg_t = [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]\n",
        "for i in range(9):\n",
        "  classifier_avg_t[i] = avg[i]/count[i]\n",
        "\n",
        "print('Each Classifier Average: ',classifier_avg_t)\n",
        "\n",
        "treshold_value = 0.0\n",
        "for i in range(9):\n",
        "  treshold_value = treshold_value + classifier_avg_t[i]\n",
        "\n",
        "treshold_t = treshold_value/len(classifier_avg_t)\n",
        "\n",
        "print('Threshold:', treshold_t)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "0it [00:00, ?it/s]\u001b[A\n",
            "12it [00:00, 116.56it/s]\u001b[A\n",
            "24it [00:00, 114.83it/s]\u001b[A\n",
            "36it [00:00, 113.79it/s]\u001b[A\n",
            "48it [00:00, 112.99it/s]\u001b[A\n",
            "60it [00:00, 112.31it/s]\u001b[A\n",
            "72it [00:00, 112.22it/s]\u001b[A\n",
            "83it [00:00, 111.04it/s]\u001b[A\n",
            "95it [00:00, 110.92it/s]\u001b[A\n",
            "106it [00:00, 108.37it/s]\u001b[A\n",
            "117it [00:01, 107.39it/s]\u001b[A\n",
            "128it [00:01, 105.91it/s]\u001b[A\n",
            "139it [00:01, 106.60it/s]\u001b[A\n",
            "150it [00:01, 107.46it/s]\u001b[A\n",
            "162it [00:01, 109.86it/s]\u001b[A\n",
            "174it [00:01, 110.56it/s]\u001b[A\n",
            "186it [00:01, 108.11it/s]\u001b[A\n",
            "197it [00:01, 104.92it/s]\u001b[A\n",
            "208it [00:01, 101.83it/s]\u001b[A\n",
            "219it [00:02, 102.39it/s]\u001b[A\n",
            "230it [00:02, 103.54it/s]\u001b[A\n",
            "242it [00:02, 105.64it/s]\u001b[A\n",
            "253it [00:02, 106.37it/s]\u001b[A\n",
            "264it [00:02, 104.32it/s]\u001b[A\n",
            "275it [00:02, 98.84it/s] \u001b[A\n",
            "285it [00:02, 97.50it/s]\u001b[A\n",
            "295it [00:02, 97.03it/s]\u001b[A\n",
            "305it [00:02, 96.00it/s]\u001b[A\n",
            "315it [00:03, 94.17it/s]\u001b[A\n",
            "325it [00:03, 93.97it/s]\u001b[A\n",
            "336it [00:03, 96.80it/s]\u001b[A\n",
            "347it [00:03, 99.96it/s]\u001b[A\n",
            "359it [00:03, 103.11it/s]\u001b[A\n",
            "370it [00:03, 104.37it/s]\u001b[A\n",
            "382it [00:03, 106.45it/s]\u001b[A\n",
            "393it [00:03, 106.92it/s]\u001b[A\n",
            "405it [00:03, 108.38it/s]\u001b[A\n",
            "416it [00:03, 107.81it/s]\u001b[A\n",
            "427it [00:04, 106.02it/s]\u001b[A\n",
            "438it [00:04, 107.11it/s]\u001b[A\n",
            "450it [00:04, 108.47it/s]\u001b[A\n",
            "462it [00:04, 110.44it/s]\u001b[A\n",
            "474it [00:04, 112.03it/s]\u001b[A\n",
            "486it [00:04, 111.97it/s]\u001b[A\n",
            "498it [00:04, 111.84it/s]\u001b[A\n",
            "510it [00:04, 112.27it/s]\u001b[A\n",
            "522it [00:04, 113.44it/s]\u001b[A\n",
            "534it [00:05, 112.16it/s]\u001b[A\n",
            "546it [00:05, 110.78it/s]\u001b[A\n",
            "558it [00:05, 111.03it/s]\u001b[A\n",
            "570it [00:05, 110.92it/s]\u001b[A\n",
            "582it [00:05, 110.21it/s]\u001b[A\n",
            "594it [00:05, 107.90it/s]\u001b[A\n",
            "606it [00:05, 109.15it/s]\u001b[A\n",
            "617it [00:05, 109.32it/s]\u001b[A\n",
            "629it [00:05, 109.86it/s]\u001b[A\n",
            "640it [00:05, 108.07it/s]\u001b[A\n",
            "652it [00:06, 109.77it/s]\u001b[A\n",
            "664it [00:06, 110.07it/s]\u001b[A\n",
            "676it [00:06, 111.43it/s]\u001b[A\n",
            "688it [00:06, 111.67it/s]\u001b[A\n",
            "700it [00:06, 109.17it/s]\u001b[A\n",
            "711it [00:06, 108.88it/s]\u001b[A\n",
            "723it [00:06, 109.71it/s]\u001b[A\n",
            "734it [00:06, 108.43it/s]\u001b[A\n",
            "746it [00:06, 109.68it/s]\u001b[A\n",
            "757it [00:07, 105.55it/s]\u001b[A\n",
            "768it [00:07, 106.65it/s]\u001b[A\n",
            "780it [00:07, 107.81it/s]\u001b[A\n",
            "791it [00:07, 107.28it/s]\u001b[A\n",
            "802it [00:07, 106.31it/s]\u001b[A\n",
            "813it [00:07, 103.00it/s]\u001b[A\n",
            "824it [00:07, 98.87it/s] \u001b[A\n",
            "834it [00:07, 96.79it/s]\u001b[A\n",
            "844it [00:07, 95.00it/s]\u001b[A\n",
            "854it [00:08, 93.98it/s]\u001b[A\n",
            "864it [00:08, 93.71it/s]\u001b[A\n",
            "876it [00:08, 98.35it/s]\u001b[A\n",
            "886it [00:08, 97.84it/s]\u001b[A\n",
            "897it [00:08, 100.14it/s]\u001b[A\n",
            "909it [00:08, 104.39it/s]\u001b[A\n",
            "920it [00:08, 105.47it/s]\u001b[A\n",
            "932it [00:08, 107.42it/s]\u001b[A\n",
            "944it [00:08, 109.05it/s]\u001b[A\n",
            "955it [00:08, 108.15it/s]\u001b[A\n",
            "966it [00:09, 107.85it/s]\u001b[A\n",
            "977it [00:09, 108.05it/s]\u001b[A\n",
            "989it [00:09, 109.53it/s]\u001b[A\n",
            "1001it [00:09, 110.57it/s]\u001b[A\n",
            "1013it [00:09, 103.47it/s]\u001b[A\n",
            "1024it [00:09, 104.28it/s]\u001b[A\n",
            "1035it [00:09, 105.85it/s]\u001b[A\n",
            "1047it [00:09, 107.85it/s]\u001b[A\n",
            "1058it [00:09, 106.21it/s]\u001b[A\n",
            "1069it [00:10, 101.73it/s]\u001b[A\n",
            "1080it [00:10, 102.06it/s]\u001b[A\n",
            "1091it [00:10, 103.60it/s]\u001b[A\n",
            "1102it [00:10, 103.44it/s]\u001b[A\n",
            "1113it [00:10, 102.69it/s]\u001b[A\n",
            "1124it [00:10, 101.90it/s]\u001b[A\n",
            "1135it [00:10, 99.66it/s] \u001b[A\n",
            "1145it [00:10, 98.95it/s]\u001b[A\n",
            "1155it [00:10, 97.57it/s]\u001b[A\n",
            "1165it [00:11, 93.35it/s]\u001b[A\n",
            "1176it [00:11, 96.31it/s]\u001b[A\n",
            "1188it [00:11, 100.44it/s]\u001b[A\n",
            "1199it [00:11, 102.75it/s]\u001b[A\n",
            "1211it [00:11, 105.41it/s]\u001b[A\n",
            "1223it [00:11, 107.95it/s]\u001b[A\n",
            "1234it [00:11, 105.41it/s]\u001b[A\n",
            "1245it [00:11, 102.61it/s]\u001b[A\n",
            "1256it [00:11, 104.48it/s]\u001b[A\n",
            "1267it [00:12, 104.05it/s]\u001b[A\n",
            "1278it [00:12, 104.08it/s]\u001b[A\n",
            "1290it [00:12, 106.89it/s]\u001b[A\n",
            "1302it [00:12, 109.35it/s]\u001b[A\n",
            "1314it [00:12, 110.37it/s]\u001b[A\n",
            "1326it [00:12, 111.88it/s]\u001b[A\n",
            "1338it [00:12, 112.14it/s]\u001b[A\n",
            "1350it [00:12, 113.01it/s]\u001b[A\n",
            "1362it [00:12, 113.85it/s]\u001b[A\n",
            "1374it [00:12, 109.69it/s]\u001b[A\n",
            "1386it [00:13, 108.45it/s]\u001b[A\n",
            "1397it [00:13, 105.64it/s]\u001b[A\n",
            "1408it [00:13, 103.38it/s]\u001b[A\n",
            "1419it [00:13, 101.22it/s]\u001b[A\n",
            "1430it [00:13, 100.13it/s]\u001b[A\n",
            "1441it [00:13, 98.31it/s] \u001b[A\n",
            "1451it [00:13, 97.54it/s]\u001b[A\n",
            "1461it [00:13, 97.09it/s]\u001b[A\n",
            "1472it [00:13, 98.64it/s]\u001b[A\n",
            "1483it [00:14, 100.30it/s]\u001b[A\n",
            "1494it [00:14, 95.20it/s] \u001b[A\n",
            "1504it [00:14, 92.06it/s]\u001b[A\n",
            "1514it [00:14, 91.17it/s]\u001b[A\n",
            "1525it [00:14, 94.63it/s]\u001b[A\n",
            "1537it [00:14, 99.30it/s]\u001b[A\n",
            "1548it [00:14, 101.82it/s]\u001b[A\n",
            "1560it [00:14, 104.68it/s]\u001b[A\n",
            "1572it [00:14, 107.16it/s]\u001b[A\n",
            "1583it [00:15, 106.68it/s]\u001b[A\n",
            "1594it [00:15, 104.32it/s]\u001b[A\n",
            "1605it [00:15, 105.90it/s]\u001b[A\n",
            "1616it [00:15, 106.80it/s]\u001b[A\n",
            "1628it [00:15, 109.29it/s]\u001b[A\n",
            "1639it [00:15, 109.10it/s]\u001b[A\n",
            "1651it [00:15, 110.25it/s]\u001b[A\n",
            "1663it [00:15, 110.74it/s]\u001b[A\n",
            "1675it [00:15, 106.25it/s]\u001b[A\n",
            "1686it [00:16, 103.90it/s]\u001b[A\n",
            "1697it [00:16, 104.16it/s]\u001b[A\n",
            "1708it [00:16, 101.74it/s]\u001b[A\n",
            "1719it [00:16, 101.55it/s]\u001b[A\n",
            "1730it [00:16, 103.63it/s]\u001b[A\n",
            "1741it [00:16, 101.44it/s]\u001b[A\n",
            "1752it [00:16, 99.24it/s] \u001b[A\n",
            "1762it [00:16, 98.20it/s]\u001b[A\n",
            "1772it [00:16, 98.50it/s]\u001b[A\n",
            "1783it [00:16, 100.81it/s]\u001b[A\n",
            "1794it [00:17, 102.32it/s]\u001b[A\n",
            "1805it [00:17, 103.55it/s]\u001b[A\n",
            "1817it [00:17, 106.43it/s]\u001b[A\n",
            "1828it [00:17, 106.92it/s]\u001b[A\n",
            "1840it [00:17, 109.33it/s]\u001b[A\n",
            "1851it [00:17, 109.44it/s]\u001b[A\n",
            "1862it [00:17, 106.78it/s]\u001b[A\n",
            "1873it [00:17, 106.06it/s]\u001b[A\n",
            "1884it [00:17, 106.93it/s]\u001b[A\n",
            "1896it [00:18, 108.28it/s]\u001b[A\n",
            "1907it [00:18, 104.42it/s]\u001b[A\n",
            "1918it [00:18, 103.82it/s]\u001b[A\n",
            "1929it [00:18, 102.27it/s]\u001b[A\n",
            "1941it [00:18, 105.33it/s]\u001b[A\n",
            "1953it [00:18, 106.66it/s]\u001b[A\n",
            "1965it [00:18, 108.30it/s]\u001b[A\n",
            "1977it [00:18, 109.52it/s]\u001b[A\n",
            "1988it [00:18, 109.24it/s]\u001b[A\n",
            "2000it [00:19, 109.60it/s]\u001b[A\n",
            "2012it [00:19, 110.43it/s]\u001b[A\n",
            "2024it [00:19, 106.63it/s]\u001b[A\n",
            "2035it [00:19, 107.16it/s]\u001b[A\n",
            "2047it [00:19, 108.69it/s]\u001b[A\n",
            "2059it [00:19, 109.33it/s]\u001b[A\n",
            "2070it [00:19, 109.17it/s]\u001b[A\n",
            "2081it [00:19, 107.50it/s]\u001b[A\n",
            "2092it [00:19, 106.65it/s]\u001b[A\n",
            "2103it [00:19, 105.15it/s]\u001b[A\n",
            "2114it [00:20, 103.76it/s]\u001b[A\n",
            "2125it [00:20, 103.93it/s]\u001b[A\n",
            "2137it [00:20, 106.44it/s]\u001b[A\n",
            "2148it [00:20, 107.36it/s]\u001b[A\n",
            "2160it [00:20, 109.12it/s]\u001b[A\n",
            "2172it [00:20, 110.10it/s]\u001b[A\n",
            "2184it [00:20, 111.40it/s]\u001b[A\n",
            "2196it [00:20, 110.57it/s]\u001b[A\n",
            "2208it [00:20, 106.88it/s]\u001b[A\n",
            "2219it [00:21, 103.28it/s]\u001b[A\n",
            "2230it [00:21, 102.79it/s]\u001b[A\n",
            "2241it [00:21, 99.19it/s] \u001b[A\n",
            "2251it [00:21, 95.24it/s]\u001b[A\n",
            "2261it [00:21, 96.55it/s]\u001b[A\n",
            "2271it [00:21, 97.56it/s]\u001b[A\n",
            "2281it [00:21, 96.34it/s]\u001b[A\n",
            "2291it [00:21, 95.93it/s]\u001b[A\n",
            "2301it [00:21, 95.76it/s]\u001b[A\n",
            "2313it [00:22, 100.22it/s]\u001b[A\n",
            "2324it [00:22, 98.53it/s] \u001b[A\n",
            "2334it [00:22, 98.95it/s]\u001b[A\n",
            "2345it [00:22, 100.22it/s]\u001b[A\n",
            "2356it [00:22, 100.08it/s]\u001b[A\n",
            "2367it [00:22, 99.26it/s] \u001b[A\n",
            "2377it [00:22, 97.71it/s]\u001b[A\n",
            "2387it [00:22, 97.40it/s]\u001b[A\n",
            "2397it [00:22, 95.71it/s]\u001b[A\n",
            "2407it [00:22, 92.57it/s]\u001b[A\n",
            "2417it [00:23, 92.70it/s]\u001b[A\n",
            "2428it [00:23, 95.77it/s]\u001b[A\n",
            "2439it [00:23, 98.66it/s]\u001b[A\n",
            "2451it [00:23, 102.38it/s]\u001b[A\n",
            "2463it [00:23, 105.27it/s]\u001b[A\n",
            "2474it [00:23, 105.88it/s]\u001b[A\n",
            "2485it [00:23, 106.08it/s]\u001b[A\n",
            "2496it [00:23, 105.57it/s]\u001b[A\n",
            "2507it [00:23, 106.56it/s]\u001b[A\n",
            "2518it [00:24, 107.29it/s]\u001b[A\n",
            "2529it [00:24, 106.04it/s]\u001b[A\n",
            "2540it [00:24, 98.66it/s] \u001b[A\n",
            "2550it [00:24, 96.41it/s]\u001b[A\n",
            "2560it [00:24, 96.40it/s]\u001b[A\n",
            "2570it [00:24, 96.94it/s]\u001b[A\n",
            "2580it [00:24, 95.18it/s]\u001b[A\n",
            "2590it [00:24, 96.22it/s]\u001b[A\n",
            "2600it [00:24, 95.84it/s]\u001b[A\n",
            "2610it [00:25, 95.71it/s]\u001b[A\n",
            "2620it [00:25, 96.32it/s]\u001b[A\n",
            "2630it [00:25, 96.15it/s]\u001b[A\n",
            "2640it [00:25, 94.81it/s]\u001b[A\n",
            "2652it [00:25, 99.72it/s]\u001b[A\n",
            "2664it [00:25, 103.70it/s]\u001b[A\n",
            "2675it [00:25, 102.30it/s]\u001b[A\n",
            "2687it [00:25, 105.06it/s]\u001b[A\n",
            "2699it [00:25, 107.82it/s]\u001b[A\n",
            "2710it [00:25, 103.50it/s]\u001b[A\n",
            "2721it [00:26, 103.11it/s]\u001b[A\n",
            "2732it [00:26, 104.99it/s]\u001b[A\n",
            "2743it [00:26, 104.79it/s]\u001b[A\n",
            "2755it [00:26, 107.42it/s]\u001b[A\n",
            "2767it [00:26, 108.72it/s]\u001b[A\n",
            "2779it [00:26, 110.43it/s]\u001b[A\n",
            "2791it [00:26, 111.91it/s]\u001b[A\n",
            "2803it [00:26, 112.12it/s]\u001b[A\n",
            "2815it [00:26, 110.27it/s]\u001b[A\n",
            "2827it [00:27, 108.48it/s]\u001b[A\n",
            "2838it [00:27, 108.05it/s]\u001b[A\n",
            "2849it [00:27, 108.33it/s]\u001b[A\n",
            "2860it [00:27, 108.47it/s]\u001b[A\n",
            "2871it [00:27, 106.14it/s]\u001b[A\n",
            "2882it [00:27, 106.39it/s]\u001b[A\n",
            "2894it [00:27, 107.72it/s]\u001b[A\n",
            "2905it [00:27, 107.75it/s]\u001b[A\n",
            "2917it [00:27, 108.64it/s]\u001b[A\n",
            "2928it [00:27, 108.03it/s]\u001b[A\n",
            "2939it [00:28, 108.57it/s]\u001b[A\n",
            "2950it [00:28, 106.23it/s]\u001b[A\n",
            "2961it [00:28, 103.42it/s]\u001b[A\n",
            "2973it [00:28, 105.86it/s]\u001b[A\n",
            "2984it [00:28, 106.61it/s]\u001b[A\n",
            "2996it [00:28, 107.98it/s]\u001b[A\n",
            "3008it [00:28, 109.44it/s]\u001b[A\n",
            "3019it [00:28, 106.89it/s]\u001b[A\n",
            "3030it [00:28, 105.63it/s]\u001b[A\n",
            "3041it [00:29, 105.14it/s]\u001b[A\n",
            "3052it [00:29, 104.28it/s]\u001b[A\n",
            "3063it [00:29, 100.12it/s]\u001b[A\n",
            "3074it [00:29, 97.38it/s] \u001b[A\n",
            "3085it [00:29, 99.21it/s]\u001b[A\n",
            "3095it [00:29, 98.92it/s]\u001b[A\n",
            "3105it [00:29, 97.19it/s]\u001b[A\n",
            "3115it [00:29, 96.87it/s]\u001b[A\n",
            "3126it [00:29, 98.29it/s]\u001b[A\n",
            "3137it [00:30, 100.57it/s]\u001b[A\n",
            "3148it [00:30, 99.09it/s] \u001b[A\n",
            "3158it [00:30, 97.29it/s]\u001b[A\n",
            "3168it [00:30, 93.31it/s]\u001b[A\n",
            "3178it [00:30, 93.40it/s]\u001b[A\n",
            "3190it [00:30, 98.30it/s]\u001b[A\n",
            "3201it [00:30, 99.52it/s]\u001b[A\n",
            "3212it [00:30, 102.26it/s]\u001b[A\n",
            "3223it [00:30, 103.96it/s]\u001b[A\n",
            "3234it [00:30, 105.50it/s]\u001b[A\n",
            "3246it [00:31, 107.57it/s]\u001b[A\n",
            "3257it [00:31, 107.85it/s]\u001b[A\n",
            "3268it [00:31, 106.30it/s]\u001b[A\n",
            "3279it [00:31, 106.64it/s]\u001b[A\n",
            "3290it [00:31, 103.63it/s]\u001b[A\n",
            "3301it [00:31, 102.09it/s]\u001b[A\n",
            "3312it [00:31, 99.67it/s] \u001b[A\n",
            "3322it [00:31, 97.78it/s]\u001b[A\n",
            "3333it [00:31, 99.06it/s]\u001b[A\n",
            "3344it [00:32, 101.64it/s]\u001b[A\n",
            "3355it [00:32, 103.08it/s]\u001b[A\n",
            "3366it [00:32, 104.41it/s]\u001b[A\n",
            "3377it [00:32, 102.58it/s]\u001b[A\n",
            "3389it [00:32, 105.97it/s]\u001b[A\n",
            "3401it [00:32, 107.58it/s]\u001b[A\n",
            "3413it [00:32, 109.25it/s]\u001b[A\n",
            "3425it [00:32, 110.02it/s]\u001b[A\n",
            "3437it [00:32, 111.17it/s]\u001b[A\n",
            "3449it [00:33, 111.66it/s]\u001b[A\n",
            "3461it [00:33, 107.90it/s]\u001b[A\n",
            "3473it [00:33, 108.96it/s]\u001b[A\n",
            "3484it [00:33, 107.03it/s]\u001b[A\n",
            "3496it [00:33, 108.14it/s]\u001b[A\n",
            "3507it [00:33, 107.11it/s]\u001b[A\n",
            "3519it [00:33, 108.42it/s]\u001b[A\n",
            "3531it [00:33, 110.00it/s]\u001b[A\n",
            "3543it [00:33, 111.31it/s]\u001b[A\n",
            "3555it [00:34, 109.89it/s]\u001b[A\n",
            "3567it [00:34, 110.62it/s]\u001b[A\n",
            "3579it [00:34, 112.00it/s]\u001b[A\n",
            "3591it [00:34, 111.84it/s]\u001b[A\n",
            "3603it [00:34, 110.10it/s]\u001b[A\n",
            "3615it [00:34, 110.58it/s]\u001b[A\n",
            "3627it [00:34, 108.91it/s]\u001b[A\n",
            "3639it [00:34, 109.64it/s]\u001b[A\n",
            "3651it [00:34, 110.96it/s]\u001b[A\n",
            "3663it [00:34, 110.93it/s]\u001b[A\n",
            "3675it [00:35, 106.96it/s]\u001b[A\n",
            "3686it [00:35, 102.82it/s]\u001b[A\n",
            "3697it [00:35, 101.57it/s]\u001b[A\n",
            "3708it [00:35, 96.21it/s] \u001b[A\n",
            "3718it [00:35, 94.73it/s]\u001b[A\n",
            "3728it [00:35, 94.77it/s]\u001b[A\n",
            "3738it [00:35, 92.59it/s]\u001b[A\n",
            "3749it [00:35, 95.54it/s]\u001b[A\n",
            "3761it [00:35, 100.40it/s]\u001b[A\n",
            "3772it [00:36, 101.13it/s]\u001b[A\n",
            "3783it [00:36, 101.48it/s]\u001b[A\n",
            "3794it [00:36, 100.45it/s]\u001b[A\n",
            "3805it [00:36, 97.67it/s] \u001b[A\n",
            "3815it [00:36, 97.00it/s]\u001b[A\n",
            "3825it [00:36, 96.86it/s]\u001b[A\n",
            "3835it [00:36, 95.91it/s]\u001b[A\n",
            "3845it [00:36, 94.49it/s]\u001b[A\n",
            "3855it [00:36, 93.83it/s]\u001b[A\n",
            "3865it [00:37, 93.83it/s]\u001b[A\n",
            "3876it [00:37, 95.98it/s]\u001b[A\n",
            "3887it [00:37, 99.23it/s]\u001b[A\n",
            "3899it [00:37, 102.01it/s]\u001b[A\n",
            "3910it [00:37, 103.49it/s]\u001b[A\n",
            "3922it [00:37, 105.82it/s]\u001b[A\n",
            "3933it [00:37, 102.26it/s]\u001b[A\n",
            "3944it [00:37, 99.77it/s] \u001b[A\n",
            "3955it [00:37, 100.99it/s]\u001b[A\n",
            "3966it [00:38, 103.05it/s]\u001b[A\n",
            "3978it [00:38, 105.28it/s]\u001b[A\n",
            "3989it [00:38, 102.59it/s]\u001b[A\n",
            "4000it [00:38, 100.70it/s]\u001b[A\n",
            "4011it [00:38, 99.36it/s] \u001b[A\n",
            "4021it [00:38, 97.24it/s]\u001b[A\n",
            "4031it [00:38, 96.97it/s]\u001b[A\n",
            "4041it [00:38, 94.30it/s]\u001b[A\n",
            "4051it [00:38, 94.93it/s]\u001b[A\n",
            "4061it [00:39, 92.49it/s]\u001b[A\n",
            "4072it [00:39, 95.14it/s]\u001b[A\n",
            "4084it [00:39, 99.29it/s]\u001b[A\n",
            "4096it [00:39, 103.34it/s]\u001b[A\n",
            "4107it [00:39, 103.75it/s]\u001b[A\n",
            "4118it [00:39, 103.77it/s]\u001b[A\n",
            "4129it [00:39, 104.22it/s]\u001b[A\n",
            "4141it [00:39, 106.27it/s]\u001b[A\n",
            "4153it [00:39, 108.25it/s]\u001b[A\n",
            "4164it [00:40, 102.73it/s]\u001b[A\n",
            "4175it [00:40, 103.34it/s]\u001b[A\n",
            "4186it [00:40, 104.95it/s]\u001b[A\n",
            "4197it [00:40, 105.70it/s]\u001b[A\n",
            "4209it [00:40, 107.22it/s]\u001b[A\n",
            "4220it [00:40, 104.58it/s]\u001b[A\n",
            "4231it [00:40, 105.67it/s]\u001b[A\n",
            "4243it [00:40, 107.31it/s]\u001b[A\n",
            "4254it [00:40, 104.09it/s]\u001b[A\n",
            "4265it [00:40, 101.04it/s]\u001b[A\n",
            "4276it [00:41, 98.13it/s] \u001b[A\n",
            "4286it [00:41, 97.49it/s]\u001b[A\n",
            "4296it [00:41, 97.32it/s]\u001b[A\n",
            "4306it [00:41, 96.31it/s]\u001b[A\n",
            "4316it [00:41, 92.35it/s]\u001b[A\n",
            "4326it [00:41, 91.52it/s]\u001b[A\n",
            "4336it [00:41, 90.59it/s]\u001b[A\n",
            "4346it [00:41, 90.96it/s]\u001b[A\n",
            "4357it [00:41, 95.72it/s]\u001b[A\n",
            "4369it [00:42, 100.06it/s]\u001b[A\n",
            "4380it [00:42, 99.28it/s] \u001b[A\n",
            "4391it [00:42, 98.79it/s]\u001b[A\n",
            "4401it [00:42, 97.17it/s]\u001b[A\n",
            "4411it [00:42, 95.62it/s]\u001b[A\n",
            "4422it [00:42, 98.82it/s]\u001b[A\n",
            "4433it [00:42, 99.90it/s]\u001b[A\n",
            "4444it [00:42, 101.50it/s]\u001b[A\n",
            "4455it [00:42, 103.18it/s]\u001b[A\n",
            "4466it [00:43, 103.84it/s]\u001b[A\n",
            "4477it [00:43, 104.80it/s]\u001b[A\n",
            "4488it [00:43, 101.36it/s]\u001b[A\n",
            "4499it [00:43, 100.47it/s]\u001b[A\n",
            "4510it [00:43, 99.67it/s] \u001b[A\n",
            "4520it [00:43, 97.60it/s]\u001b[A\n",
            "4530it [00:43, 97.58it/s]\u001b[A\n",
            "4540it [00:43, 96.13it/s]\u001b[A\n",
            "4551it [00:43, 98.41it/s]\u001b[A\n",
            "4562it [00:44, 101.43it/s]\u001b[A\n",
            "4574it [00:44, 104.33it/s]\u001b[A\n",
            "4586it [00:44, 106.99it/s]\u001b[A\n",
            "4597it [00:44, 106.90it/s]\u001b[A\n",
            "4608it [00:44, 104.85it/s]\u001b[A\n",
            "4619it [00:44, 105.46it/s]\u001b[A\n",
            "4631it [00:44, 107.27it/s]\u001b[A\n",
            "4643it [00:44, 109.67it/s]\u001b[A\n",
            "4655it [00:44, 110.41it/s]\u001b[A\n",
            "4667it [00:44, 110.57it/s]\u001b[A\n",
            "4679it [00:45, 110.47it/s]\u001b[A\n",
            "4691it [00:45, 110.56it/s]\u001b[A\n",
            "4703it [00:45, 107.42it/s]\u001b[A\n",
            "4715it [00:45, 109.58it/s]\u001b[A\n",
            "4727it [00:45, 110.84it/s]\u001b[A\n",
            "4739it [00:45, 109.19it/s]\u001b[A\n",
            "4751it [00:45, 110.77it/s]\u001b[A\n",
            "4763it [00:45, 111.11it/s]\u001b[A\n",
            "4775it [00:45, 111.40it/s]\u001b[A\n",
            "4787it [00:46, 109.81it/s]\u001b[A\n",
            "4798it [00:46, 103.24it/s]\u001b[A\n",
            "4809it [00:46, 105.06it/s]\u001b[A\n",
            "4821it [00:46, 107.17it/s]\u001b[A\n",
            "4833it [00:46, 108.52it/s]\u001b[A\n",
            "4844it [00:46, 107.15it/s]\u001b[A\n",
            "4856it [00:46, 108.57it/s]\u001b[A\n",
            "4868it [00:46, 109.37it/s]\u001b[A\n",
            "4879it [00:46, 103.43it/s]\u001b[A\n",
            "4890it [00:47, 99.13it/s] \u001b[A\n",
            "4902it [00:47, 102.85it/s]\u001b[A\n",
            "4914it [00:47, 105.36it/s]\u001b[A\n",
            "4926it [00:47, 107.88it/s]\u001b[A\n",
            "4938it [00:47, 109.79it/s]\u001b[A\n",
            "4950it [00:47, 108.55it/s]\u001b[A\n",
            "4962it [00:47, 110.08it/s]\u001b[A\n",
            "4974it [00:47, 109.29it/s]\u001b[A\n",
            "4985it [00:47, 109.37it/s]\u001b[A\n",
            "4997it [00:48, 110.28it/s]\u001b[A\n",
            "5009it [00:48, 110.86it/s]\u001b[A\n",
            "5021it [00:48, 110.75it/s]\u001b[A\n",
            "5033it [00:48, 111.58it/s]\u001b[A\n",
            "5045it [00:48, 112.79it/s]\u001b[A\n",
            "5057it [00:48, 112.78it/s]\u001b[A\n",
            "5069it [00:48, 109.89it/s]\u001b[A\n",
            "5081it [00:48, 111.22it/s]\u001b[A\n",
            "5093it [00:48, 112.46it/s]\u001b[A\n",
            "5105it [00:48, 111.68it/s]\u001b[A\n",
            "5117it [00:49, 109.38it/s]\u001b[A\n",
            "5128it [00:49, 105.39it/s]\u001b[A\n",
            "5139it [00:49, 106.48it/s]\u001b[A\n",
            "5150it [00:49, 104.47it/s]\u001b[A\n",
            "5161it [00:49, 103.02it/s]\u001b[A\n",
            "5172it [00:49, 102.93it/s]\u001b[A\n",
            "5183it [00:49, 104.13it/s]\u001b[A\n",
            "5194it [00:49, 103.75it/s]\u001b[A\n",
            "5205it [00:49, 101.18it/s]\u001b[A\n",
            "5216it [00:50, 98.07it/s] \u001b[A\n",
            "5226it [00:50, 94.58it/s]\u001b[A\n",
            "5237it [00:50, 96.89it/s]\u001b[A\n",
            "5247it [00:50, 97.66it/s]\u001b[A\n",
            "5257it [00:50, 96.74it/s]\u001b[A\n",
            "5267it [00:50, 95.73it/s]\u001b[A\n",
            "5278it [00:50, 97.44it/s]\u001b[A\n",
            "5289it [00:50, 99.23it/s]\u001b[A\n",
            "5300it [00:50, 101.57it/s]\u001b[A\n",
            "5312it [00:51, 104.10it/s]\u001b[A\n",
            "5324it [00:51, 105.97it/s]\u001b[A\n",
            "5335it [00:51, 103.63it/s]\u001b[A\n",
            "5347it [00:51, 106.20it/s]\u001b[A\n",
            "5359it [00:51, 108.55it/s]\u001b[A\n",
            "5371it [00:51, 110.24it/s]\u001b[A\n",
            "5383it [00:51, 107.95it/s]\u001b[A\n",
            "5394it [00:51, 108.05it/s]\u001b[A\n",
            "5405it [00:51, 107.77it/s]\u001b[A\n",
            "5416it [00:51, 107.07it/s]\u001b[A\n",
            "5427it [00:52, 104.75it/s]\u001b[A\n",
            "5438it [00:52, 100.79it/s]\u001b[A\n",
            "5449it [00:52, 97.32it/s] \u001b[A\n",
            "5459it [00:52, 96.57it/s]\u001b[A\n",
            "5470it [00:52, 98.94it/s]\u001b[A\n",
            "5481it [00:52, 100.99it/s]\u001b[A\n",
            "5493it [00:52, 104.53it/s]\u001b[A\n",
            "5504it [00:52, 103.45it/s]\u001b[A\n",
            "5516it [00:52, 106.19it/s]\u001b[A\n",
            "5527it [00:53, 103.99it/s]\u001b[A\n",
            "5539it [00:53, 106.25it/s]\u001b[A\n",
            "5550it [00:53, 106.96it/s]\u001b[A\n",
            "5562it [00:53, 108.90it/s]\u001b[A\n",
            "5574it [00:53, 110.40it/s]\u001b[A\n",
            "5586it [00:53, 109.88it/s]\u001b[A\n",
            "5598it [00:53, 106.67it/s]\u001b[A\n",
            "5609it [00:53, 105.88it/s]\u001b[A\n",
            "5620it [00:53, 104.71it/s]\u001b[A\n",
            "5631it [00:54, 104.41it/s]\u001b[A\n",
            "5642it [00:54, 101.77it/s]\u001b[A\n",
            "5653it [00:54, 98.86it/s] \u001b[A\n",
            "5663it [00:54, 96.11it/s]\u001b[A\n",
            "5673it [00:54, 93.90it/s]\u001b[A\n",
            "5683it [00:54, 91.23it/s]\u001b[A\n",
            "5693it [00:54, 89.70it/s]\u001b[A\n",
            "5703it [00:54, 90.52it/s]\u001b[A\n",
            "5713it [00:54, 91.92it/s]\u001b[A\n",
            "5723it [00:55, 92.55it/s]\u001b[A\n",
            "5733it [00:55, 92.42it/s]\u001b[A\n",
            "5743it [00:55, 90.73it/s]\u001b[A\n",
            "5753it [00:55, 90.07it/s]\u001b[A\n",
            "5764it [00:55, 93.62it/s]\u001b[A\n",
            "5774it [00:55, 94.56it/s]\u001b[A\n",
            "5784it [00:55, 92.61it/s]\u001b[A\n",
            "5794it [00:55, 93.45it/s]\u001b[A\n",
            "5804it [00:55, 95.00it/s]\u001b[A\n",
            "5814it [00:56, 95.08it/s]\u001b[A\n",
            "5825it [00:56, 98.94it/s]\u001b[A\n",
            "5836it [00:56, 101.71it/s]\u001b[A\n",
            "5847it [00:56, 104.01it/s]\u001b[A\n",
            "5859it [00:56, 106.03it/s]\u001b[A\n",
            "5870it [00:56, 104.68it/s]\u001b[A\n",
            "5881it [00:56, 99.17it/s] \u001b[A\n",
            "5892it [00:56, 97.24it/s]\u001b[A\n",
            "5902it [00:56, 96.80it/s]\u001b[A\n",
            "5912it [00:57, 96.28it/s]\u001b[A\n",
            "5923it [00:57, 98.96it/s]\u001b[A\n",
            "5934it [00:57, 100.78it/s]\u001b[A\n",
            "5945it [00:57, 101.88it/s]\u001b[A\n",
            "5956it [00:57, 102.19it/s]\u001b[A\n",
            "5967it [00:57, 104.20it/s]\u001b[A\n",
            "5978it [00:57, 104.89it/s]\u001b[A\n",
            "5989it [00:57, 104.49it/s]\u001b[A\n",
            "6000it [00:57, 105.97it/s]\u001b[A\n",
            "6011it [00:57, 103.90it/s]\u001b[A\n",
            "6022it [00:58, 103.18it/s]\u001b[A\n",
            "6034it [00:58, 105.76it/s]\u001b[A\n",
            "6045it [00:58, 106.44it/s]\u001b[A\n",
            "6057it [00:58, 108.29it/s]\u001b[A\n",
            "6069it [00:58, 110.26it/s]\u001b[A\n",
            "6081it [00:58, 104.45it/s]\u001b[A\n",
            "6092it [00:58, 100.21it/s]\u001b[A\n",
            "6103it [00:58, 99.09it/s] \u001b[A\n",
            "6113it [00:58, 97.46it/s]\u001b[A\n",
            "6124it [00:59, 99.00it/s]\u001b[A\n",
            "6136it [00:59, 102.20it/s]\u001b[A\n",
            "6147it [00:59, 102.08it/s]\u001b[A\n",
            "6158it [00:59, 101.22it/s]\u001b[A\n",
            "6169it [00:59, 103.02it/s]\u001b[A\n",
            "6180it [00:59, 104.88it/s]\u001b[A\n",
            "6191it [00:59, 103.92it/s]\u001b[A\n",
            "6202it [00:59, 102.84it/s]\u001b[A\n",
            "6213it [00:59, 101.06it/s]\u001b[A\n",
            "6224it [01:00, 102.56it/s]\u001b[A\n",
            "6235it [01:00, 104.46it/s]\u001b[A\n",
            "6246it [01:00, 105.89it/s]\u001b[A\n",
            "6257it [01:00, 106.66it/s]\u001b[A\n",
            "6268it [01:00, 105.17it/s]\u001b[A\n",
            "6279it [01:00, 104.87it/s]\u001b[A\n",
            "6290it [01:00, 102.20it/s]\u001b[A\n",
            "6301it [01:00, 97.94it/s] \u001b[A\n",
            "6311it [01:00, 97.09it/s]\u001b[A\n",
            "6321it [01:00, 93.56it/s]\u001b[A\n",
            "6331it [01:01, 94.16it/s]\u001b[A\n",
            "6342it [01:01, 96.28it/s]\u001b[A\n",
            "6353it [01:01, 99.30it/s]\u001b[A\n",
            "6364it [01:01, 102.22it/s]\u001b[A\n",
            "6375it [01:01, 104.12it/s]\u001b[A\n",
            "6386it [01:01, 99.55it/s] \u001b[A\n",
            "6397it [01:01, 96.67it/s]\u001b[A\n",
            "6407it [01:01, 95.67it/s]\u001b[A\n",
            "6418it [01:01, 98.85it/s]\u001b[A\n",
            "6429it [01:02, 101.50it/s]\u001b[A\n",
            "6440it [01:02, 102.58it/s]\u001b[A\n",
            "6451it [01:02, 103.38it/s]\u001b[A\n",
            "6463it [01:02, 105.57it/s]\u001b[A\n",
            "6474it [01:02, 106.63it/s]\u001b[A\n",
            "6486it [01:02, 108.41it/s]\u001b[A\n",
            "6498it [01:02, 109.39it/s]\u001b[A\n",
            "6509it [01:02, 107.02it/s]\u001b[A\n",
            "6520it [01:02, 105.37it/s]\u001b[A\n",
            "6531it [01:03, 104.69it/s]\u001b[A\n",
            "6542it [01:03, 99.73it/s] \u001b[A\n",
            "6553it [01:03, 97.92it/s]\u001b[A\n",
            "6563it [01:03, 94.98it/s]\u001b[A\n",
            "6574it [01:03, 97.21it/s]\u001b[A\n",
            "6586it [01:03, 101.48it/s]\u001b[A\n",
            "6597it [01:03, 103.78it/s]\u001b[A\n",
            "6608it [01:03, 104.80it/s]\u001b[A\n",
            "6620it [01:03, 106.80it/s]\u001b[A\n",
            "6631it [01:04, 105.32it/s]\u001b[A\n",
            "6642it [01:04, 100.03it/s]\u001b[A\n",
            "6654it [01:04, 103.42it/s]\u001b[A\n",
            "6665it [01:04, 102.76it/s]\u001b[A\n",
            "6677it [01:04, 105.38it/s]\u001b[A\n",
            "6688it [01:04, 106.14it/s]\u001b[A\n",
            "6699it [01:04, 105.73it/s]\u001b[A\n",
            "6711it [01:04, 107.35it/s]\u001b[A\n",
            "6722it [01:04, 107.01it/s]\u001b[A\n",
            "6734it [01:04, 109.09it/s]\u001b[A\n",
            "6745it [01:05, 107.64it/s]\u001b[A\n",
            "6756it [01:05, 106.79it/s]\u001b[A\n",
            "6768it [01:05, 107.74it/s]\u001b[A\n",
            "6780it [01:05, 109.57it/s]\u001b[A\n",
            "6791it [01:05, 109.12it/s]\u001b[A\n",
            "6803it [01:05, 109.28it/s]\u001b[A\n",
            "6815it [01:05, 110.39it/s]\u001b[A\n",
            "6827it [01:05, 106.10it/s]\u001b[A\n",
            "6838it [01:05, 106.87it/s]\u001b[A\n",
            "6850it [01:06, 108.54it/s]\u001b[A\n",
            "6861it [01:06, 103.29it/s]\u001b[A\n",
            "6872it [01:06, 100.95it/s]\u001b[A\n",
            "6883it [01:06, 97.79it/s] \u001b[A\n",
            "6893it [01:06, 94.92it/s]\u001b[A\n",
            "6903it [01:06, 95.13it/s]\u001b[A\n",
            "6913it [01:06, 94.17it/s]\u001b[A\n",
            "6923it [01:06, 93.23it/s]\u001b[A\n",
            "6934it [01:06, 96.64it/s]\u001b[A\n",
            "6945it [01:07, 98.21it/s]\u001b[A\n",
            "6956it [01:07, 99.51it/s]\u001b[A\n",
            "6968it [01:07, 103.16it/s]\u001b[A\n",
            "6980it [01:07, 105.29it/s]\u001b[A\n",
            "6992it [01:07, 107.33it/s]\u001b[A\n",
            "7004it [01:07, 108.93it/s]\u001b[A\n",
            "7015it [01:07, 104.44it/s]\u001b[A\n",
            "7026it [01:07, 101.75it/s]\u001b[A\n",
            "7037it [01:07, 100.37it/s]\u001b[A\n",
            "7048it [01:08, 99.55it/s] \u001b[A\n",
            "7059it [01:08, 101.94it/s]\u001b[A\n",
            "7070it [01:08, 101.53it/s]\u001b[A\n",
            "7082it [01:08, 104.13it/s]\u001b[A\n",
            "7093it [01:08, 102.77it/s]\u001b[A\n",
            "7104it [01:08, 104.18it/s]\u001b[A\n",
            "7115it [01:08, 103.89it/s]\u001b[A\n",
            "7126it [01:08, 103.49it/s]\u001b[A\n",
            "7137it [01:08, 100.23it/s]\u001b[A\n",
            "7148it [01:09, 101.20it/s]\u001b[A\n",
            "7159it [01:09, 100.64it/s]\u001b[A\n",
            "7171it [01:09, 103.93it/s]\u001b[A\n",
            "7182it [01:09, 105.41it/s]\u001b[A\n",
            "7193it [01:09, 104.83it/s]\u001b[A\n",
            "7204it [01:09, 103.47it/s]\u001b[A\n",
            "7215it [01:09, 103.91it/s]\u001b[A\n",
            "7226it [01:09, 105.49it/s]\u001b[A\n",
            "7237it [01:09, 106.03it/s]\u001b[A\n",
            "7248it [01:09, 105.40it/s]\u001b[A\n",
            "7259it [01:10, 104.56it/s]\u001b[A\n",
            "7270it [01:10, 102.57it/s]\u001b[A\n",
            "7282it [01:10, 105.60it/s]\u001b[A\n",
            "7293it [01:10, 106.22it/s]\u001b[A\n",
            "7305it [01:10, 107.64it/s]\u001b[A\n",
            "7316it [01:10, 106.36it/s]\u001b[A\n",
            "7328it [01:10, 107.98it/s]\u001b[A\n",
            "7340it [01:10, 109.49it/s]\u001b[A\n",
            "7351it [01:10, 108.66it/s]\u001b[A\n",
            "7362it [01:11, 106.93it/s]\u001b[A\n",
            "7373it [01:11, 105.04it/s]\u001b[A\n",
            "7384it [01:11, 103.80it/s]\u001b[A\n",
            "7396it [01:11, 105.94it/s]\u001b[A\n",
            "7407it [01:11, 104.56it/s]\u001b[A\n",
            "7418it [01:11, 105.94it/s]\u001b[A\n",
            "7429it [01:11, 103.51it/s]\u001b[A\n",
            "7440it [01:11, 103.77it/s]\u001b[A\n",
            "7451it [01:11, 105.19it/s]\u001b[A\n",
            "7462it [01:11, 105.17it/s]\u001b[A\n",
            "7473it [01:12, 101.68it/s]\u001b[A\n",
            "7484it [01:12, 99.87it/s] \u001b[A\n",
            "7495it [01:12, 96.56it/s]\u001b[A\n",
            "7505it [01:12, 94.72it/s]\u001b[A\n",
            "7516it [01:12, 98.44it/s]\u001b[A\n",
            "7528it [01:12, 102.23it/s]\u001b[A\n",
            "7540it [01:12, 104.93it/s]\u001b[A\n",
            "7551it [01:12, 102.19it/s]\u001b[A\n",
            "7562it [01:12, 102.72it/s]\u001b[A\n",
            "7573it [01:13, 102.48it/s]\u001b[A\n",
            "7584it [01:13, 99.69it/s] \u001b[A\n",
            "7595it [01:13, 98.20it/s]\u001b[A\n",
            "7605it [01:13, 96.40it/s]\u001b[A\n",
            "7615it [01:13, 96.00it/s]\u001b[A\n",
            "7626it [01:13, 98.54it/s]\u001b[A\n",
            "7636it [01:13, 98.67it/s]\u001b[A\n",
            "7646it [01:13, 96.06it/s]\u001b[A\n",
            "7656it [01:13, 88.68it/s]\u001b[A\n",
            "7666it [01:14, 86.85it/s]\u001b[A\n",
            "7676it [01:14, 88.83it/s]\u001b[A\n",
            "7686it [01:14, 90.72it/s]\u001b[A\n",
            "7696it [01:14, 91.35it/s]\u001b[A\n",
            "7707it [01:14, 95.15it/s]\u001b[A\n",
            "7718it [01:14, 97.52it/s]\u001b[A\n",
            "7729it [01:14, 99.09it/s]\u001b[A\n",
            "7740it [01:14, 101.45it/s]\u001b[A\n",
            "7751it [01:14, 102.81it/s]\u001b[A\n",
            "7762it [01:15, 101.48it/s]\u001b[A\n",
            "7773it [01:15, 99.89it/s] \u001b[A\n",
            "7784it [01:15, 101.88it/s]\u001b[A\n",
            "7796it [01:15, 105.08it/s]\u001b[A\n",
            "7808it [01:15, 106.15it/s]\u001b[A\n",
            "7820it [01:15, 107.71it/s]\u001b[A\n",
            "7831it [01:15, 108.30it/s]\u001b[A\n",
            "7842it [01:15, 106.15it/s]\u001b[A\n",
            "7853it [01:15, 101.27it/s]\u001b[A\n",
            "7864it [01:16, 98.30it/s] \u001b[A\n",
            "7875it [01:16, 101.24it/s]\u001b[A\n",
            "7886it [01:16, 102.56it/s]\u001b[A\n",
            "7897it [01:16, 102.66it/s]\u001b[A\n",
            "7909it [01:16, 105.40it/s]\u001b[A\n",
            "7921it [01:16, 108.28it/s]\u001b[A\n",
            "7932it [01:16, 108.11it/s]\u001b[A\n",
            "7944it [01:16, 109.12it/s]\u001b[A\n",
            "7955it [01:16, 107.20it/s]\u001b[A\n",
            "7966it [01:16, 106.42it/s]\u001b[A\n",
            "7977it [01:17, 106.25it/s]\u001b[A\n",
            "7988it [01:17, 106.91it/s]\u001b[A\n",
            "7999it [01:17, 106.68it/s]\u001b[A\n",
            "8011it [01:17, 107.96it/s]\u001b[A\n",
            "8022it [01:17, 107.38it/s]\u001b[A\n",
            "8033it [01:17, 107.97it/s]\u001b[A\n",
            "8045it [01:17, 109.01it/s]\u001b[A\n",
            "8056it [01:17, 108.22it/s]\u001b[A\n",
            "8067it [01:17, 106.15it/s]\u001b[A\n",
            "8078it [01:18, 104.55it/s]\u001b[A\n",
            "8089it [01:18, 105.86it/s]\u001b[A\n",
            "8100it [01:18, 106.31it/s]\u001b[A\n",
            "8112it [01:18, 108.09it/s]\u001b[A\n",
            "8123it [01:18, 108.10it/s]\u001b[A\n",
            "8134it [01:18, 106.34it/s]\u001b[A\n",
            "8145it [01:18, 107.35it/s]\u001b[A\n",
            "8157it [01:18, 108.66it/s]\u001b[A\n",
            "8168it [01:18, 107.29it/s]\u001b[A\n",
            "8179it [01:19, 99.89it/s] \u001b[A\n",
            "8190it [01:19, 98.20it/s]\u001b[A\n",
            "8200it [01:19, 93.52it/s]\u001b[A\n",
            "8210it [01:19, 93.27it/s]\u001b[A\n",
            "8220it [01:19, 93.95it/s]\u001b[A\n",
            "8230it [01:19, 92.06it/s]\u001b[A\n",
            "8240it [01:19, 91.23it/s]\u001b[A\n",
            "8250it [01:19, 92.52it/s]\u001b[A\n",
            "8260it [01:19, 93.41it/s]\u001b[A\n",
            "8270it [01:19, 93.07it/s]\u001b[A\n",
            "8280it [01:20, 94.50it/s]\u001b[A\n",
            "8291it [01:20, 97.15it/s]\u001b[A\n",
            "8302it [01:20, 99.80it/s]\u001b[A\n",
            "8313it [01:20, 99.53it/s]\u001b[A\n",
            "8324it [01:20, 102.07it/s]\u001b[A\n",
            "8335it [01:20, 99.68it/s] \u001b[A\n",
            "8346it [01:20, 99.72it/s]\u001b[A\n",
            "8357it [01:20, 101.74it/s]\u001b[A\n",
            "8368it [01:20, 100.55it/s]\u001b[A\n",
            "8379it [01:21, 98.20it/s] \u001b[A\n",
            "8389it [01:21, 95.36it/s]\u001b[A\n",
            "8399it [01:21, 94.36it/s]\u001b[A\n",
            "8409it [01:21, 94.84it/s]\u001b[A\n",
            "8419it [01:21, 95.62it/s]\u001b[A\n",
            "8430it [01:21, 97.50it/s]\u001b[A\n",
            "8440it [01:21, 96.35it/s]\u001b[A\n",
            "8450it [01:21, 96.04it/s]\u001b[A\n",
            "8461it [01:21, 98.00it/s]\u001b[A\n",
            "8473it [01:22, 100.64it/s]\u001b[A\n",
            "8484it [01:22, 100.60it/s]\u001b[A\n",
            "8496it [01:22, 104.37it/s]\u001b[A\n",
            "8508it [01:22, 106.60it/s]\u001b[A\n",
            "8520it [01:22, 108.73it/s]\u001b[A\n",
            "8532it [01:22, 109.53it/s]\u001b[A\n",
            "8544it [01:22, 110.38it/s]\u001b[A\n",
            "8556it [01:22, 109.10it/s]\u001b[A\n",
            "8568it [01:22, 110.13it/s]\u001b[A\n",
            "8580it [01:23, 109.42it/s]\u001b[A\n",
            "8591it [01:23, 102.48it/s]\u001b[A\n",
            "8602it [01:23, 94.21it/s] \u001b[A\n",
            "8612it [01:23, 91.70it/s]\u001b[A\n",
            "8622it [01:23, 93.62it/s]\u001b[A\n",
            "8633it [01:23, 96.89it/s]\u001b[A\n",
            "8644it [01:23, 100.20it/s]\u001b[A\n",
            "8655it [01:23, 101.38it/s]\u001b[A\n",
            "8666it [01:23, 102.59it/s]\u001b[A\n",
            "8677it [01:24, 104.51it/s]\u001b[A\n",
            "8688it [01:24, 103.71it/s]\u001b[A\n",
            "8699it [01:24, 99.88it/s] \u001b[A\n",
            "8710it [01:24, 97.53it/s]\u001b[A\n",
            "8720it [01:24, 96.54it/s]\u001b[A\n",
            "8730it [01:24, 95.53it/s]\u001b[A\n",
            "8740it [01:24, 95.68it/s]\u001b[A\n",
            "8750it [01:24, 94.05it/s]\u001b[A\n",
            "8760it [01:24, 93.88it/s]\u001b[A\n",
            "8772it [01:24, 98.96it/s]\u001b[A\n",
            "8783it [01:25, 100.83it/s]\u001b[A\n",
            "8794it [01:25, 103.08it/s]\u001b[A\n",
            "8805it [01:25, 103.75it/s]\u001b[A\n",
            "8816it [01:25, 103.79it/s]\u001b[A\n",
            "8828it [01:25, 106.27it/s]\u001b[A\n",
            "8839it [01:25, 107.25it/s]\u001b[A\n",
            "8851it [01:25, 108.90it/s]\u001b[A\n",
            "8862it [01:25, 106.64it/s]\u001b[A\n",
            "8873it [01:25, 103.97it/s]\u001b[A\n",
            "8884it [01:26, 105.70it/s]\u001b[A\n",
            "8895it [01:26, 106.08it/s]\u001b[A\n",
            "8906it [01:26, 106.64it/s]\u001b[A\n",
            "8917it [01:26, 106.53it/s]\u001b[A\n",
            "8929it [01:26, 108.81it/s]\u001b[A\n",
            "8940it [01:26, 108.59it/s]\u001b[A\n",
            "8952it [01:26, 109.51it/s]\u001b[A\n",
            "8964it [01:26, 110.68it/s]\u001b[A\n",
            "8976it [01:26, 108.34it/s]\u001b[A\n",
            "8987it [01:26, 106.38it/s]\u001b[A\n",
            "8998it [01:27, 106.53it/s]\u001b[A\n",
            "9009it [01:27, 104.09it/s]\u001b[A\n",
            "9020it [01:27, 104.69it/s]\u001b[A\n",
            "9031it [01:27, 104.55it/s]\u001b[A\n",
            "9043it [01:27, 106.81it/s]\u001b[A\n",
            "9055it [01:27, 108.29it/s]\u001b[A\n",
            "9066it [01:27, 108.39it/s]\u001b[A\n",
            "9077it [01:27, 108.71it/s]\u001b[A\n",
            "9088it [01:27, 104.41it/s]\u001b[A\n",
            "9099it [01:28, 100.37it/s]\u001b[A\n",
            "9110it [01:28, 99.40it/s] \u001b[A\n",
            "9122it [01:28, 102.78it/s]\u001b[A\n",
            "9133it [01:28, 103.87it/s]\u001b[A\n",
            "9144it [01:28, 104.25it/s]\u001b[A\n",
            "9156it [01:28, 106.56it/s]\u001b[A\n",
            "9168it [01:28, 107.84it/s]\u001b[A\n",
            "9180it [01:28, 108.80it/s]\u001b[A\n",
            "9191it [01:28, 107.05it/s]\u001b[A\n",
            "9203it [01:29, 108.07it/s]\u001b[A\n",
            "9214it [01:29, 106.01it/s]\u001b[A\n",
            "9225it [01:29, 106.80it/s]\u001b[A\n",
            "9236it [01:29, 103.30it/s]\u001b[A\n",
            "9247it [01:29, 100.97it/s]\u001b[A\n",
            "9258it [01:29, 99.95it/s] \u001b[A\n",
            "9269it [01:29, 101.88it/s]\u001b[A\n",
            "9281it [01:29, 104.46it/s]\u001b[A\n",
            "9292it [01:29, 103.94it/s]\u001b[A\n",
            "9303it [01:30, 98.09it/s] \u001b[A\n",
            "9314it [01:30, 100.25it/s]\u001b[A\n",
            "9325it [01:30, 101.92it/s]\u001b[A\n",
            "9336it [01:30, 103.76it/s]\u001b[A\n",
            "9347it [01:30, 103.80it/s]\u001b[A\n",
            "9359it [01:30, 106.52it/s]\u001b[A\n",
            "9371it [01:30, 108.25it/s]\u001b[A\n",
            "9382it [01:30, 108.20it/s]\u001b[A\n",
            "9393it [01:30, 104.25it/s]\u001b[A\n",
            "9405it [01:30, 106.46it/s]\u001b[A\n",
            "9416it [01:31, 106.26it/s]\u001b[A\n",
            "9427it [01:31, 104.95it/s]\u001b[A\n",
            "9439it [01:31, 106.92it/s]\u001b[A\n",
            "9450it [01:31, 103.56it/s]\u001b[A\n",
            "9461it [01:31, 105.09it/s]\u001b[A\n",
            "9473it [01:31, 107.61it/s]\u001b[A\n",
            "9484it [01:31, 107.48it/s]\u001b[A\n",
            "9495it [01:31, 103.48it/s]\u001b[A\n",
            "9506it [01:31, 104.69it/s]\u001b[A\n",
            "9517it [01:32, 105.85it/s]\u001b[A\n",
            "9528it [01:32, 104.59it/s]\u001b[A\n",
            "9539it [01:32, 99.50it/s] \u001b[A\n",
            "9550it [01:32, 97.61it/s]\u001b[A\n",
            "9560it [01:32, 96.83it/s]\u001b[A\n",
            "9570it [01:32, 95.92it/s]\u001b[A\n",
            "9580it [01:32, 94.35it/s]\u001b[A\n",
            "9590it [01:32, 92.35it/s]\u001b[A\n",
            "9600it [01:32, 92.36it/s]\u001b[A\n",
            "9610it [01:33, 93.35it/s]\u001b[A\n",
            "9620it [01:33, 93.29it/s]\u001b[A\n",
            "9630it [01:33, 89.19it/s]\u001b[A\n",
            "9640it [01:33, 90.88it/s]\u001b[A\n",
            "9650it [01:33, 91.99it/s]\u001b[A\n",
            "9660it [01:33, 91.93it/s]\u001b[A\n",
            "9670it [01:33, 89.63it/s]\u001b[A\n",
            "9680it [01:33, 91.05it/s]\u001b[A\n",
            "9690it [01:33, 92.98it/s]\u001b[A\n",
            "9700it [01:34, 92.79it/s]\u001b[A\n",
            "9711it [01:34, 97.12it/s]\u001b[A\n",
            "9721it [01:34, 92.89it/s]\u001b[A\n",
            "9731it [01:34, 92.55it/s]\u001b[A\n",
            "9741it [01:34, 93.65it/s]\u001b[A\n",
            "9751it [01:34, 94.56it/s]\u001b[A\n",
            "9761it [01:34, 92.02it/s]\u001b[A\n",
            "9771it [01:34, 93.01it/s]\u001b[A\n",
            "9781it [01:34, 93.76it/s]\u001b[A\n",
            "9791it [01:34, 94.22it/s]\u001b[A\n",
            "9801it [01:35, 94.04it/s]\u001b[A\n",
            "9812it [01:35, 97.68it/s]\u001b[A\n",
            "9822it [01:35, 97.47it/s]\u001b[A\n",
            "9834it [01:35, 101.84it/s]\u001b[A\n",
            "9845it [01:35, 102.78it/s]\u001b[A\n",
            "9857it [01:35, 105.19it/s]\u001b[A\n",
            "9868it [01:35, 106.07it/s]\u001b[A\n",
            "9879it [01:35, 105.69it/s]\u001b[A\n",
            "9890it [01:35, 104.26it/s]\u001b[A\n",
            "9901it [01:36, 102.69it/s]\u001b[A\n",
            "9912it [01:36, 99.57it/s] \u001b[A\n",
            "9922it [01:36, 95.49it/s]\u001b[A\n",
            "9932it [01:36, 95.00it/s]\u001b[A\n",
            "9942it [01:36, 93.78it/s]\u001b[A\n",
            "9953it [01:36, 97.22it/s]\u001b[A\n",
            "9963it [01:36, 95.30it/s]\u001b[A\n",
            "9973it [01:36, 94.94it/s]\u001b[A\n",
            "9983it [01:36, 92.00it/s]\u001b[A\n",
            "9993it [01:37, 91.89it/s]\u001b[A\n",
            "10003it [01:37, 91.45it/s]\u001b[A\n",
            "10013it [01:37, 92.25it/s]\u001b[A\n",
            "10024it [01:37, 95.61it/s]\u001b[A\n",
            "10034it [01:37, 96.37it/s]\u001b[A\n",
            "10046it [01:37, 101.10it/s]\u001b[A\n",
            "10057it [01:37, 103.29it/s]\u001b[A\n",
            "10068it [01:37, 104.77it/s]\u001b[A\n",
            "10079it [01:37, 104.04it/s]\u001b[A\n",
            "10091it [01:37, 106.09it/s]\u001b[A\n",
            "10103it [01:38, 107.82it/s]\u001b[A\n",
            "10114it [01:38, 104.98it/s]\u001b[A\n",
            "10125it [01:38, 102.95it/s]\u001b[A\n",
            "10136it [01:38, 104.13it/s]\u001b[A\n",
            "10147it [01:38, 105.82it/s]\u001b[A\n",
            "10159it [01:38, 108.30it/s]\u001b[A\n",
            "10170it [01:38, 106.87it/s]\u001b[A\n",
            "10181it [01:38, 106.88it/s]\u001b[A\n",
            "10193it [01:38, 108.30it/s]\u001b[A\n",
            "10204it [01:39, 106.49it/s]\u001b[A\n",
            "10215it [01:39, 99.94it/s] \u001b[A\n",
            "10226it [01:39, 96.65it/s]\u001b[A\n",
            "10236it [01:39, 96.23it/s]\u001b[A\n",
            "10246it [01:39, 96.25it/s]\u001b[A\n",
            "10256it [01:39, 95.54it/s]\u001b[A\n",
            "10267it [01:39, 99.31it/s]\u001b[A\n",
            "10279it [01:39, 102.65it/s]\u001b[A\n",
            "10290it [01:39, 104.20it/s]\u001b[A\n",
            "10301it [01:40, 102.56it/s]\u001b[A\n",
            "10312it [01:40, 98.35it/s] \u001b[A\n",
            "10322it [01:40, 97.32it/s]\u001b[A\n",
            "10332it [01:40, 94.64it/s]\u001b[A\n",
            "10342it [01:40, 93.19it/s]\u001b[A\n",
            "10352it [01:40, 92.35it/s]\u001b[A\n",
            "10363it [01:40, 95.49it/s]\u001b[A\n",
            "10374it [01:40, 98.00it/s]\u001b[A\n",
            "10384it [01:40, 98.04it/s]\u001b[A\n",
            "10395it [01:41, 100.01it/s]\u001b[A\n",
            "10406it [01:41, 102.28it/s]\u001b[A\n",
            "10417it [01:41, 103.61it/s]\u001b[A\n",
            "10428it [01:41, 98.48it/s] \u001b[A\n",
            "10439it [01:41, 101.27it/s]\u001b[A\n",
            "10450it [01:41, 100.78it/s]\u001b[A\n",
            "10462it [01:41, 104.08it/s]\u001b[A\n",
            "10474it [01:41, 106.14it/s]\u001b[A\n",
            "10485it [01:41, 104.71it/s]\u001b[A\n",
            "10496it [01:41, 106.12it/s]\u001b[A\n",
            "10508it [01:42, 107.64it/s]\u001b[A\n",
            "10519it [01:42, 107.43it/s]\u001b[A\n",
            "10530it [01:42, 105.84it/s]\u001b[A\n",
            "10541it [01:42, 104.78it/s]\u001b[A\n",
            "10552it [01:42, 105.79it/s]\u001b[A\n",
            "10563it [01:42, 106.06it/s]\u001b[A\n",
            "10574it [01:42, 104.80it/s]\u001b[A\n",
            "10585it [01:42, 105.80it/s]\u001b[A\n",
            "10596it [01:42, 106.18it/s]\u001b[A\n",
            "10608it [01:43, 108.23it/s]\u001b[A\n",
            "10619it [01:43, 106.04it/s]\u001b[A\n",
            "10630it [01:43, 106.40it/s]\u001b[A\n",
            "10641it [01:43, 105.91it/s]\u001b[A\n",
            "10652it [01:43, 106.40it/s]\u001b[A\n",
            "10663it [01:43, 107.33it/s]\u001b[A\n",
            "10674it [01:43, 106.41it/s]\u001b[A\n",
            "10686it [01:43, 108.12it/s]\u001b[A\n",
            "10697it [01:43, 105.13it/s]\u001b[A\n",
            "10708it [01:43, 100.51it/s]\u001b[A\n",
            "10719it [01:44, 100.38it/s]\u001b[A\n",
            "10730it [01:44, 102.58it/s]\u001b[A\n",
            "10741it [01:44, 102.31it/s]\u001b[A\n",
            "10752it [01:44, 96.03it/s] \u001b[A\n",
            "10762it [01:44, 95.48it/s]\u001b[A\n",
            "10772it [01:44, 94.90it/s]\u001b[A\n",
            "10782it [01:44, 94.43it/s]\u001b[A\n",
            "10792it [01:44, 94.04it/s]\u001b[A\n",
            "10802it [01:44, 91.56it/s]\u001b[A\n",
            "10813it [01:45, 95.21it/s]\u001b[A\n",
            "10825it [01:45, 102.89it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[714.6198810487986, 982.1086966097355, 928.6873873472214, 927.3719318807125, 879.4890236258507, 993.4708969295025, 926.6441331803799, 911.2026011049747, 1013.5440234839916]\n",
            "[1322, 1174, 1219, 1176, 1104, 1177, 1299, 1160, 1194]\n",
            "[1573.1453399970196, 509.90413363599646, 757.7741318449798, 622.4137706265319, 573.614500436941, 476.6119991002597, 972.0077286690939, 658.5512278623064, 487.1469287318632]\n",
            "Entropy: 0.6026340201245685\n",
            "Each Classifier Average:  [0.5405596679642954, 0.8365491453234544, 0.7618436319501406, 0.788581574728497, 0.7966386083567488, 0.8440704306962638, 0.7133519116092224, 0.7855194837111851, 0.8488643412763749]\n",
            "Threshold: 0.768442088401798\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-rkvUJ3Esh1s",
        "outputId": "6b9051b7-371f-462d-e208-ccf12488f062"
      },
      "source": [
        "ref_vect_out_0an = []\n",
        "ref_vect_out_0an.append(classifier_avg_t)\n",
        "\n",
        "threshold_out_0an = []\n",
        "threshold_out_0an.append(treshold_t)\n",
        "\n",
        "entropy_out_0an = []\n",
        "entropy_out_0an.append(entropy_t)\n",
        "\n",
        "print(entropy_out_0an)\n",
        "print(ref_vect_out_0an)\n",
        "print(threshold_out_0an)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.6026340201245685]\n",
            "[[0.5405596679642954, 0.8365491453234544, 0.7618436319501406, 0.788581574728497, 0.7966386083567488, 0.8440704306962638, 0.7133519116092224, 0.7855194837111851, 0.8488643412763749]]\n",
            "[0.768442088401798]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "py_tdFIcnjjG"
      },
      "source": [
        "entropy_out_0an = [0.6026340201245685]\n",
        "ref_vect_out_0an = [[0.5405596679642954, 0.8365491453234544, 0.7618436319501406, 0.788581574728497, 0.7966386083567488, 0.8440704306962638, 0.7133519116092224, 0.7855194837111851, 0.8488643412763749]]\n",
        "threshold_out_0an = [0.768442088401798]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49pV4LYhvtiv"
      },
      "source": [
        "def get_max_pred_value(model, img, temp):\n",
        "  logits = model(img)\n",
        "  logits = tf.math.divide(logits, temp)\n",
        "  pred = tf.nn.softmax(logits)\n",
        "  e = entropy(pred[0])\n",
        "\n",
        "  return np.max(pred), tf.argmax(pred[0]).numpy(), e"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K8hQIP5L2gWL",
        "outputId": "a854c2e9-d33b-4010-c2e1-b770822627dc"
      },
      "source": [
        "set(train_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iv23n8dE2PQD"
      },
      "source": [
        "def get_mapping(leave_out_class, anomaly_class):\n",
        "  mapping = {}\n",
        "\n",
        "  labels = set(train_labels)\n",
        "  labels.remove(anomaly_class)\n",
        "  labels.remove(leave_out_class)\n",
        "  labels = sorted(labels)\n",
        "\n",
        "  for i,j in enumerate(labels):\n",
        "    mapping[i] = j\n",
        "\n",
        "  return mapping\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2sMg8hxovx8Q"
      },
      "source": [
        "ood = 0\n",
        "ind = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jeIuFWuDv0S6",
        "outputId": "6761a48c-bc6f-4a76-98d9-78c9d5222c2e"
      },
      "source": [
        "max_sm_all_wt_0an = []\n",
        "for data, label in tqdm(zip(test_imgs, test_lbls)):\n",
        "  img = data.reshape([-1, 28, 28, 1])\n",
        "  ref_value = []\n",
        "  \n",
        "  if label == 0:\n",
        "    lbl = ood\n",
        "  else:\n",
        "    lbl = ind\n",
        "\n",
        "\n",
        "  max0, pred_0, e0 = get_max_pred_value(model_dict[0], img, temp=temp_val[0])\n",
        "  map0 = get_mapping(1, 0)\n",
        "  pred_0 = map0[pred_0]\n",
        "\n",
        "  max1, pred_1, e1 = get_max_pred_value(model_dict[1], img, temp=temp_val[1])\n",
        "  map1 = get_mapping(2, 0)\n",
        "  pred_1 = map1[pred_1]\n",
        "\n",
        "  max2, pred_2, e2 = get_max_pred_value(model_dict[2], img, temp=temp_val[2])\n",
        "  map2 = get_mapping(3, 0)\n",
        "  pred_2 = map2[pred_2]\n",
        "\n",
        "  max3, pred_3, e3 = get_max_pred_value(model_dict[3], img, temp=temp_val[3])\n",
        "  map3 = get_mapping(4, 0)\n",
        "  pred_3 = map3[pred_3]\n",
        "\n",
        "  max4, pred_4, e4 = get_max_pred_value(model_dict[4], img, temp=temp_val[4])\n",
        "  map4 = get_mapping(5, 0)\n",
        "  pred_4 = map4[pred_4]\n",
        "\n",
        "  max5, pred_5, e5 = get_max_pred_value(model_dict[5], img, temp=temp_val[5])\n",
        "  map5 = get_mapping(6, 0)\n",
        "  pred_5 = map5[pred_5]\n",
        "\n",
        "  max6, pred_6, e6 = get_max_pred_value(model_dict[6], img, temp=temp_val[6])\n",
        "  map6 = get_mapping(7, 0)\n",
        "  pred_6 = map6[pred_6]\n",
        "\n",
        "  max7, pred_7, e7 = get_max_pred_value(model_dict[7], img, temp=temp_val[7])\n",
        "  map7 = get_mapping(8, 0)\n",
        "  pred_7 = map7[pred_7]\n",
        "\n",
        "  max8, pred_8, e8 = get_max_pred_value(model_dict[8], img, temp=temp_val[8])\n",
        "  map8 = get_mapping(9, 0)\n",
        "  pred_8 = map8[pred_8]\n",
        "\n",
        "  ref_value =[max0, max1, max2, max3, max4, max5, max6, max7, max8]\n",
        "  pred_value = [pred_0, pred_1, pred_2, pred_3, pred_4, pred_5, pred_6, pred_7, pred_8]\n",
        "  e_value = [e0, e1, e2, e3, e4, e5, e6, e7, e8]\n",
        "  e_ = 0.0\n",
        "  for  e in e_value:\n",
        "    e_ = e_ + e\n",
        "  e_ = e_/len(e_value)\n",
        "  max_sm_all_wt_0an.append([ref_value, lbl, pred_value, label, e_])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "5001it [11:38,  6.85it/s]\u001b[A\n",
            "5002it [11:38,  6.73it/s]\u001b[A\n",
            "5003it [11:38,  6.47it/s]\u001b[A\n",
            "5004it [11:38,  6.38it/s]\u001b[A\n",
            "5005it [11:38,  6.36it/s]\u001b[A\n",
            "5006it [11:39,  6.37it/s]\u001b[A\n",
            "5007it [11:39,  6.16it/s]\u001b[A\n",
            "5008it [11:39,  6.42it/s]\u001b[A\n",
            "5009it [11:39,  6.63it/s]\u001b[A\n",
            "5010it [11:39,  6.72it/s]\u001b[A\n",
            "5011it [11:39,  6.59it/s]\u001b[A\n",
            "5012it [11:39,  6.54it/s]\u001b[A\n",
            "5013it [11:40,  6.49it/s]\u001b[A\n",
            "5014it [11:40,  6.67it/s]\u001b[A\n",
            "5015it [11:40,  6.76it/s]\u001b[A\n",
            "5016it [11:40,  6.75it/s]\u001b[A\n",
            "5017it [11:40,  6.91it/s]\u001b[A\n",
            "5018it [11:40,  6.97it/s]\u001b[A\n",
            "5019it [11:40,  7.02it/s]\u001b[A\n",
            "5020it [11:41,  6.96it/s]\u001b[A\n",
            "5021it [11:41,  6.87it/s]\u001b[A\n",
            "5022it [11:41,  7.02it/s]\u001b[A\n",
            "5023it [11:41,  7.10it/s]\u001b[A\n",
            "5024it [11:41,  6.91it/s]\u001b[A\n",
            "5025it [11:41,  6.80it/s]\u001b[A\n",
            "5026it [11:42,  6.67it/s]\u001b[A\n",
            "5027it [11:42,  6.77it/s]\u001b[A\n",
            "5028it [11:42,  6.74it/s]\u001b[A\n",
            "5029it [11:42,  6.83it/s]\u001b[A\n",
            "5030it [11:42,  6.86it/s]\u001b[A\n",
            "5031it [11:42,  6.89it/s]\u001b[A\n",
            "5032it [11:42,  6.96it/s]\u001b[A\n",
            "5033it [11:43,  7.08it/s]\u001b[A\n",
            "5034it [11:43,  7.12it/s]\u001b[A\n",
            "5035it [11:43,  7.05it/s]\u001b[A\n",
            "5036it [11:43,  7.05it/s]\u001b[A\n",
            "5037it [11:43,  6.86it/s]\u001b[A\n",
            "5038it [11:43,  6.77it/s]\u001b[A\n",
            "5039it [11:43,  6.68it/s]\u001b[A\n",
            "5040it [11:44,  6.66it/s]\u001b[A\n",
            "5041it [11:44,  6.62it/s]\u001b[A\n",
            "5042it [11:44,  6.49it/s]\u001b[A\n",
            "5043it [11:44,  6.55it/s]\u001b[A\n",
            "5044it [11:44,  6.63it/s]\u001b[A\n",
            "5045it [11:44,  6.70it/s]\u001b[A\n",
            "5046it [11:44,  6.84it/s]\u001b[A\n",
            "5047it [11:45,  6.90it/s]\u001b[A\n",
            "5048it [11:45,  6.93it/s]\u001b[A\n",
            "5049it [11:45,  6.80it/s]\u001b[A\n",
            "5050it [11:45,  6.70it/s]\u001b[A\n",
            "5051it [11:45,  6.68it/s]\u001b[A\n",
            "5052it [11:45,  6.77it/s]\u001b[A\n",
            "5053it [11:45,  6.89it/s]\u001b[A\n",
            "5054it [11:46,  6.75it/s]\u001b[A\n",
            "5055it [11:46,  6.67it/s]\u001b[A\n",
            "5056it [11:46,  6.48it/s]\u001b[A\n",
            "5057it [11:46,  6.62it/s]\u001b[A\n",
            "5058it [11:46,  6.75it/s]\u001b[A\n",
            "5059it [11:46,  6.86it/s]\u001b[A\n",
            "5060it [11:47,  6.90it/s]\u001b[A\n",
            "5061it [11:47,  6.96it/s]\u001b[A\n",
            "5062it [11:47,  6.81it/s]\u001b[A\n",
            "5063it [11:47,  6.89it/s]\u001b[A\n",
            "5064it [11:47,  6.92it/s]\u001b[A\n",
            "5065it [11:47,  6.80it/s]\u001b[A\n",
            "5066it [11:47,  6.77it/s]\u001b[A\n",
            "5067it [11:48,  6.79it/s]\u001b[A\n",
            "5068it [11:48,  6.90it/s]\u001b[A\n",
            "5069it [11:48,  6.89it/s]\u001b[A\n",
            "5070it [11:48,  6.83it/s]\u001b[A\n",
            "5071it [11:48,  6.85it/s]\u001b[A\n",
            "5072it [11:48,  6.78it/s]\u001b[A\n",
            "5073it [11:48,  6.96it/s]\u001b[A\n",
            "5074it [11:49,  7.00it/s]\u001b[A\n",
            "5075it [11:49,  7.05it/s]\u001b[A\n",
            "5076it [11:49,  7.04it/s]\u001b[A\n",
            "5077it [11:49,  7.10it/s]\u001b[A\n",
            "5078it [11:49,  6.98it/s]\u001b[A\n",
            "5079it [11:49,  6.97it/s]\u001b[A\n",
            "5080it [11:49,  6.97it/s]\u001b[A\n",
            "5081it [11:50,  6.87it/s]\u001b[A\n",
            "5082it [11:50,  6.69it/s]\u001b[A\n",
            "5083it [11:50,  6.70it/s]\u001b[A\n",
            "5084it [11:50,  6.89it/s]\u001b[A\n",
            "5085it [11:50,  6.87it/s]\u001b[A\n",
            "5086it [11:50,  6.97it/s]\u001b[A\n",
            "5087it [11:50,  6.99it/s]\u001b[A\n",
            "5088it [11:51,  7.09it/s]\u001b[A\n",
            "5089it [11:51,  7.06it/s]\u001b[A\n",
            "5090it [11:51,  6.94it/s]\u001b[A\n",
            "5091it [11:51,  6.94it/s]\u001b[A\n",
            "5092it [11:51,  6.99it/s]\u001b[A\n",
            "5093it [11:51,  7.02it/s]\u001b[A\n",
            "5094it [11:51,  6.89it/s]\u001b[A\n",
            "5095it [11:52,  6.81it/s]\u001b[A\n",
            "5096it [11:52,  6.62it/s]\u001b[A\n",
            "5097it [11:52,  6.46it/s]\u001b[A\n",
            "5098it [11:52,  6.45it/s]\u001b[A\n",
            "5099it [11:52,  6.63it/s]\u001b[A\n",
            "5100it [11:52,  6.74it/s]\u001b[A\n",
            "5101it [11:52,  6.90it/s]\u001b[A\n",
            "5102it [11:53,  6.91it/s]\u001b[A\n",
            "5103it [11:53,  6.97it/s]\u001b[A\n",
            "5104it [11:53,  6.79it/s]\u001b[A\n",
            "5105it [11:53,  6.71it/s]\u001b[A\n",
            "5106it [11:53,  6.75it/s]\u001b[A\n",
            "5107it [11:53,  6.86it/s]\u001b[A\n",
            "5108it [11:53,  6.94it/s]\u001b[A\n",
            "5109it [11:54,  6.98it/s]\u001b[A\n",
            "5110it [11:54,  7.04it/s]\u001b[A\n",
            "5111it [11:54,  7.00it/s]\u001b[A\n",
            "5112it [11:54,  7.02it/s]\u001b[A\n",
            "5113it [11:54,  7.09it/s]\u001b[A\n",
            "5114it [11:54,  7.17it/s]\u001b[A\n",
            "5115it [11:54,  7.08it/s]\u001b[A\n",
            "5116it [11:55,  7.11it/s]\u001b[A\n",
            "5117it [11:55,  7.05it/s]\u001b[A\n",
            "5118it [11:55,  7.03it/s]\u001b[A\n",
            "5119it [11:55,  6.92it/s]\u001b[A\n",
            "5120it [11:55,  6.87it/s]\u001b[A\n",
            "5121it [11:55,  7.00it/s]\u001b[A\n",
            "5122it [11:55,  7.08it/s]\u001b[A\n",
            "5123it [11:56,  7.09it/s]\u001b[A\n",
            "5124it [11:56,  7.06it/s]\u001b[A\n",
            "5125it [11:56,  6.90it/s]\u001b[A\n",
            "5126it [11:56,  6.89it/s]\u001b[A\n",
            "5127it [11:56,  6.95it/s]\u001b[A\n",
            "5128it [11:56,  6.84it/s]\u001b[A\n",
            "5129it [11:57,  6.75it/s]\u001b[A\n",
            "5130it [11:57,  6.68it/s]\u001b[A\n",
            "5131it [11:57,  6.60it/s]\u001b[A\n",
            "5132it [11:57,  6.44it/s]\u001b[A\n",
            "5133it [11:57,  6.45it/s]\u001b[A\n",
            "5134it [11:57,  6.47it/s]\u001b[A\n",
            "5135it [11:57,  6.52it/s]\u001b[A\n",
            "5136it [11:58,  6.55it/s]\u001b[A\n",
            "5137it [11:58,  6.44it/s]\u001b[A\n",
            "5138it [11:58,  6.48it/s]\u001b[A\n",
            "5139it [11:58,  6.45it/s]\u001b[A\n",
            "5140it [11:58,  6.62it/s]\u001b[A\n",
            "5141it [11:58,  6.74it/s]\u001b[A\n",
            "5142it [11:58,  6.82it/s]\u001b[A\n",
            "5143it [11:59,  6.88it/s]\u001b[A\n",
            "5144it [11:59,  6.90it/s]\u001b[A\n",
            "5145it [11:59,  6.96it/s]\u001b[A\n",
            "5146it [11:59,  6.90it/s]\u001b[A\n",
            "5147it [11:59,  6.92it/s]\u001b[A\n",
            "5148it [11:59,  6.89it/s]\u001b[A\n",
            "5149it [11:59,  6.89it/s]\u001b[A\n",
            "5150it [12:00,  6.92it/s]\u001b[A\n",
            "5151it [12:00,  7.01it/s]\u001b[A\n",
            "5152it [12:00,  7.02it/s]\u001b[A\n",
            "5153it [12:00,  6.91it/s]\u001b[A\n",
            "5154it [12:00,  6.91it/s]\u001b[A\n",
            "5155it [12:00,  6.86it/s]\u001b[A\n",
            "5156it [12:01,  6.78it/s]\u001b[A\n",
            "5157it [12:01,  6.88it/s]\u001b[A\n",
            "5158it [12:01,  6.93it/s]\u001b[A\n",
            "5159it [12:01,  6.94it/s]\u001b[A\n",
            "5160it [12:01,  6.89it/s]\u001b[A\n",
            "5161it [12:01,  6.96it/s]\u001b[A\n",
            "5162it [12:01,  6.94it/s]\u001b[A\n",
            "5163it [12:02,  6.91it/s]\u001b[A\n",
            "5164it [12:02,  6.90it/s]\u001b[A\n",
            "5165it [12:02,  6.86it/s]\u001b[A\n",
            "5166it [12:02,  6.89it/s]\u001b[A\n",
            "5167it [12:02,  6.74it/s]\u001b[A\n",
            "5168it [12:02,  6.59it/s]\u001b[A\n",
            "5169it [12:02,  6.73it/s]\u001b[A\n",
            "5170it [12:03,  6.88it/s]\u001b[A\n",
            "5171it [12:03,  6.96it/s]\u001b[A\n",
            "5172it [12:03,  6.94it/s]\u001b[A\n",
            "5173it [12:03,  7.01it/s]\u001b[A\n",
            "5174it [12:03,  6.81it/s]\u001b[A\n",
            "5175it [12:03,  6.90it/s]\u001b[A\n",
            "5176it [12:03,  6.91it/s]\u001b[A\n",
            "5177it [12:04,  7.04it/s]\u001b[A\n",
            "5178it [12:04,  7.01it/s]\u001b[A\n",
            "5179it [12:04,  7.02it/s]\u001b[A\n",
            "5180it [12:04,  7.10it/s]\u001b[A\n",
            "5181it [12:04,  6.93it/s]\u001b[A\n",
            "5182it [12:04,  6.95it/s]\u001b[A\n",
            "5183it [12:04,  6.97it/s]\u001b[A\n",
            "5184it [12:05,  7.02it/s]\u001b[A\n",
            "5185it [12:05,  7.05it/s]\u001b[A\n",
            "5186it [12:05,  7.07it/s]\u001b[A\n",
            "5187it [12:05,  7.11it/s]\u001b[A\n",
            "5188it [12:05,  7.03it/s]\u001b[A\n",
            "5189it [12:05,  7.06it/s]\u001b[A\n",
            "5190it [12:05,  6.98it/s]\u001b[A\n",
            "5191it [12:06,  7.05it/s]\u001b[A\n",
            "5192it [12:06,  6.98it/s]\u001b[A\n",
            "5193it [12:06,  6.95it/s]\u001b[A\n",
            "5194it [12:06,  6.86it/s]\u001b[A\n",
            "5195it [12:06,  6.77it/s]\u001b[A\n",
            "5196it [12:06,  6.69it/s]\u001b[A\n",
            "5197it [12:06,  6.76it/s]\u001b[A\n",
            "5198it [12:07,  6.78it/s]\u001b[A\n",
            "5199it [12:07,  6.82it/s]\u001b[A\n",
            "5200it [12:07,  6.92it/s]\u001b[A\n",
            "5201it [12:07,  6.99it/s]\u001b[A\n",
            "5202it [12:07,  6.95it/s]\u001b[A\n",
            "5203it [12:07,  7.06it/s]\u001b[A\n",
            "5204it [12:07,  7.05it/s]\u001b[A\n",
            "5205it [12:08,  7.02it/s]\u001b[A\n",
            "5206it [12:08,  7.09it/s]\u001b[A\n",
            "5207it [12:08,  7.09it/s]\u001b[A\n",
            "5208it [12:08,  6.84it/s]\u001b[A\n",
            "5209it [12:08,  6.73it/s]\u001b[A\n",
            "5210it [12:08,  6.80it/s]\u001b[A\n",
            "5211it [12:08,  6.87it/s]\u001b[A\n",
            "5212it [12:09,  6.97it/s]\u001b[A\n",
            "5213it [12:09,  7.06it/s]\u001b[A\n",
            "5214it [12:09,  7.06it/s]\u001b[A\n",
            "5215it [12:09,  7.13it/s]\u001b[A\n",
            "5216it [12:09,  6.92it/s]\u001b[A\n",
            "5217it [12:09,  6.82it/s]\u001b[A\n",
            "5218it [12:09,  6.83it/s]\u001b[A\n",
            "5219it [12:10,  6.88it/s]\u001b[A\n",
            "5220it [12:10,  6.85it/s]\u001b[A\n",
            "5221it [12:10,  6.76it/s]\u001b[A\n",
            "5222it [12:10,  6.84it/s]\u001b[A\n",
            "5223it [12:10,  6.88it/s]\u001b[A\n",
            "5224it [12:10,  6.92it/s]\u001b[A\n",
            "5225it [12:10,  6.90it/s]\u001b[A\n",
            "5226it [12:11,  7.03it/s]\u001b[A\n",
            "5227it [12:11,  6.94it/s]\u001b[A\n",
            "5228it [12:11,  7.03it/s]\u001b[A\n",
            "5229it [12:11,  7.06it/s]\u001b[A\n",
            "5230it [12:11,  6.97it/s]\u001b[A\n",
            "5231it [12:11,  6.92it/s]\u001b[A\n",
            "5232it [12:11,  6.98it/s]\u001b[A\n",
            "5233it [12:12,  7.03it/s]\u001b[A\n",
            "5234it [12:12,  7.12it/s]\u001b[A\n",
            "5235it [12:12,  7.14it/s]\u001b[A\n",
            "5236it [12:12,  6.90it/s]\u001b[A\n",
            "5237it [12:12,  6.66it/s]\u001b[A\n",
            "5238it [12:12,  6.69it/s]\u001b[A\n",
            "5239it [12:13,  6.68it/s]\u001b[A\n",
            "5240it [12:13,  6.74it/s]\u001b[A\n",
            "5241it [12:13,  6.84it/s]\u001b[A\n",
            "5242it [12:13,  6.94it/s]\u001b[A\n",
            "5243it [12:13,  6.86it/s]\u001b[A\n",
            "5244it [12:13,  6.84it/s]\u001b[A\n",
            "5245it [12:13,  6.92it/s]\u001b[A\n",
            "5246it [12:14,  6.99it/s]\u001b[A\n",
            "5247it [12:14,  7.03it/s]\u001b[A\n",
            "5248it [12:14,  7.06it/s]\u001b[A\n",
            "5249it [12:14,  6.98it/s]\u001b[A\n",
            "5250it [12:14,  6.78it/s]\u001b[A\n",
            "5251it [12:14,  6.53it/s]\u001b[A\n",
            "5252it [12:14,  6.50it/s]\u001b[A\n",
            "5253it [12:15,  6.60it/s]\u001b[A\n",
            "5254it [12:15,  6.64it/s]\u001b[A\n",
            "5255it [12:15,  6.69it/s]\u001b[A\n",
            "5256it [12:15,  6.80it/s]\u001b[A\n",
            "5257it [12:15,  6.89it/s]\u001b[A\n",
            "5258it [12:15,  6.85it/s]\u001b[A\n",
            "5259it [12:15,  6.88it/s]\u001b[A\n",
            "5260it [12:16,  7.05it/s]\u001b[A\n",
            "5261it [12:16,  7.04it/s]\u001b[A\n",
            "5262it [12:16,  7.10it/s]\u001b[A\n",
            "5263it [12:16,  6.90it/s]\u001b[A\n",
            "5264it [12:16,  6.95it/s]\u001b[A\n",
            "5265it [12:16,  6.89it/s]\u001b[A\n",
            "5266it [12:16,  6.97it/s]\u001b[A\n",
            "5267it [12:17,  7.06it/s]\u001b[A\n",
            "5268it [12:17,  7.08it/s]\u001b[A\n",
            "5269it [12:17,  7.10it/s]\u001b[A\n",
            "5270it [12:17,  6.95it/s]\u001b[A\n",
            "5271it [12:17,  6.95it/s]\u001b[A\n",
            "5272it [12:17,  6.87it/s]\u001b[A\n",
            "5273it [12:17,  6.82it/s]\u001b[A\n",
            "5274it [12:18,  6.84it/s]\u001b[A\n",
            "5275it [12:18,  6.87it/s]\u001b[A\n",
            "5276it [12:18,  6.87it/s]\u001b[A\n",
            "5277it [12:18,  6.99it/s]\u001b[A\n",
            "5278it [12:18,  7.10it/s]\u001b[A\n",
            "5279it [12:18,  7.03it/s]\u001b[A\n",
            "5280it [12:18,  6.95it/s]\u001b[A\n",
            "5281it [12:19,  6.99it/s]\u001b[A\n",
            "5282it [12:19,  7.12it/s]\u001b[A\n",
            "5283it [12:19,  7.11it/s]\u001b[A\n",
            "5284it [12:19,  7.09it/s]\u001b[A\n",
            "5285it [12:19,  7.14it/s]\u001b[A\n",
            "5286it [12:19,  7.09it/s]\u001b[A\n",
            "5287it [12:19,  7.16it/s]\u001b[A\n",
            "5288it [12:20,  7.09it/s]\u001b[A\n",
            "5289it [12:20,  6.99it/s]\u001b[A\n",
            "5290it [12:20,  6.93it/s]\u001b[A\n",
            "5291it [12:20,  6.88it/s]\u001b[A\n",
            "5292it [12:20,  6.95it/s]\u001b[A\n",
            "5293it [12:20,  6.88it/s]\u001b[A\n",
            "5294it [12:20,  6.92it/s]\u001b[A\n",
            "5295it [12:21,  7.02it/s]\u001b[A\n",
            "5296it [12:21,  6.94it/s]\u001b[A\n",
            "5297it [12:21,  6.99it/s]\u001b[A\n",
            "5298it [12:21,  6.91it/s]\u001b[A\n",
            "5299it [12:21,  6.76it/s]\u001b[A\n",
            "5300it [12:21,  6.58it/s]\u001b[A\n",
            "5301it [12:21,  6.69it/s]\u001b[A\n",
            "5302it [12:22,  6.84it/s]\u001b[A\n",
            "5303it [12:22,  6.78it/s]\u001b[A\n",
            "5304it [12:22,  6.82it/s]\u001b[A\n",
            "5305it [12:22,  6.90it/s]\u001b[A\n",
            "5306it [12:22,  6.83it/s]\u001b[A\n",
            "5307it [12:22,  6.67it/s]\u001b[A\n",
            "5308it [12:22,  6.80it/s]\u001b[A\n",
            "5309it [12:23,  6.84it/s]\u001b[A\n",
            "5310it [12:23,  6.84it/s]\u001b[A\n",
            "5311it [12:23,  6.92it/s]\u001b[A\n",
            "5312it [12:23,  6.85it/s]\u001b[A\n",
            "5313it [12:23,  6.70it/s]\u001b[A\n",
            "5314it [12:23,  6.38it/s]\u001b[A\n",
            "5315it [12:24,  6.47it/s]\u001b[A\n",
            "5316it [12:24,  6.42it/s]\u001b[A\n",
            "5317it [12:24,  6.43it/s]\u001b[A\n",
            "5318it [12:24,  6.50it/s]\u001b[A\n",
            "5319it [12:24,  6.64it/s]\u001b[A\n",
            "5320it [12:24,  6.60it/s]\u001b[A\n",
            "5321it [12:24,  6.79it/s]\u001b[A\n",
            "5322it [12:25,  6.86it/s]\u001b[A\n",
            "5323it [12:25,  6.91it/s]\u001b[A\n",
            "5324it [12:25,  6.99it/s]\u001b[A\n",
            "5325it [12:25,  6.99it/s]\u001b[A\n",
            "5326it [12:25,  7.02it/s]\u001b[A\n",
            "5327it [12:25,  6.81it/s]\u001b[A\n",
            "5328it [12:25,  6.70it/s]\u001b[A\n",
            "5329it [12:26,  6.78it/s]\u001b[A\n",
            "5330it [12:26,  6.67it/s]\u001b[A\n",
            "5331it [12:26,  6.64it/s]\u001b[A\n",
            "5332it [12:26,  6.81it/s]\u001b[A\n",
            "5333it [12:26,  6.71it/s]\u001b[A\n",
            "5334it [12:26,  6.75it/s]\u001b[A\n",
            "5335it [12:27,  6.78it/s]\u001b[A\n",
            "5336it [12:27,  6.63it/s]\u001b[A\n",
            "5337it [12:27,  6.80it/s]\u001b[A\n",
            "5338it [12:27,  6.95it/s]\u001b[A\n",
            "5339it [12:27,  6.99it/s]\u001b[A\n",
            "5340it [12:27,  6.99it/s]\u001b[A\n",
            "5341it [12:27,  6.87it/s]\u001b[A\n",
            "5342it [12:28,  6.92it/s]\u001b[A\n",
            "5343it [12:28,  6.95it/s]\u001b[A\n",
            "5344it [12:28,  7.00it/s]\u001b[A\n",
            "5345it [12:28,  6.95it/s]\u001b[A\n",
            "5346it [12:28,  6.87it/s]\u001b[A\n",
            "5347it [12:28,  6.93it/s]\u001b[A\n",
            "5348it [12:28,  6.86it/s]\u001b[A\n",
            "5349it [12:29,  6.84it/s]\u001b[A\n",
            "5350it [12:29,  6.95it/s]\u001b[A\n",
            "5351it [12:29,  6.99it/s]\u001b[A\n",
            "5352it [12:29,  7.03it/s]\u001b[A\n",
            "5353it [12:29,  6.99it/s]\u001b[A\n",
            "5354it [12:29,  6.84it/s]\u001b[A\n",
            "5355it [12:29,  6.58it/s]\u001b[A\n",
            "5356it [12:30,  6.58it/s]\u001b[A\n",
            "5357it [12:30,  6.56it/s]\u001b[A\n",
            "5358it [12:30,  6.52it/s]\u001b[A\n",
            "5359it [12:30,  6.59it/s]\u001b[A\n",
            "5360it [12:30,  6.75it/s]\u001b[A\n",
            "5361it [12:30,  6.88it/s]\u001b[A\n",
            "5362it [12:30,  6.83it/s]\u001b[A\n",
            "5363it [12:31,  6.89it/s]\u001b[A\n",
            "5364it [12:31,  6.96it/s]\u001b[A\n",
            "5365it [12:31,  6.97it/s]\u001b[A\n",
            "5366it [12:31,  7.04it/s]\u001b[A\n",
            "5367it [12:31,  6.89it/s]\u001b[A\n",
            "5368it [12:31,  6.96it/s]\u001b[A\n",
            "5369it [12:31,  6.63it/s]\u001b[A\n",
            "5370it [12:32,  6.73it/s]\u001b[A\n",
            "5371it [12:32,  6.69it/s]\u001b[A\n",
            "5372it [12:32,  6.66it/s]\u001b[A\n",
            "5373it [12:32,  6.82it/s]\u001b[A\n",
            "5374it [12:32,  6.92it/s]\u001b[A\n",
            "5375it [12:32,  7.03it/s]\u001b[A\n",
            "5376it [12:32,  7.01it/s]\u001b[A\n",
            "5377it [12:33,  7.01it/s]\u001b[A\n",
            "5378it [12:33,  7.01it/s]\u001b[A\n",
            "5379it [12:33,  6.97it/s]\u001b[A\n",
            "5380it [12:33,  7.09it/s]\u001b[A\n",
            "5381it [12:33,  7.01it/s]\u001b[A\n",
            "5382it [12:33,  6.99it/s]\u001b[A\n",
            "5383it [12:33,  6.95it/s]\u001b[A\n",
            "5384it [12:34,  6.81it/s]\u001b[A\n",
            "5385it [12:34,  6.93it/s]\u001b[A\n",
            "5386it [12:34,  6.92it/s]\u001b[A\n",
            "5387it [12:34,  6.98it/s]\u001b[A\n",
            "5388it [12:34,  7.06it/s]\u001b[A\n",
            "5389it [12:34,  7.09it/s]\u001b[A\n",
            "5390it [12:34,  7.04it/s]\u001b[A\n",
            "5391it [12:35,  7.04it/s]\u001b[A\n",
            "5392it [12:35,  7.04it/s]\u001b[A\n",
            "5393it [12:35,  6.96it/s]\u001b[A\n",
            "5394it [12:35,  6.83it/s]\u001b[A\n",
            "5395it [12:35,  6.73it/s]\u001b[A\n",
            "5396it [12:35,  6.65it/s]\u001b[A\n",
            "5397it [12:36,  6.43it/s]\u001b[A\n",
            "5398it [12:36,  6.42it/s]\u001b[A\n",
            "5399it [12:36,  6.44it/s]\u001b[A\n",
            "5400it [12:36,  6.47it/s]\u001b[A\n",
            "5401it [12:36,  6.44it/s]\u001b[A\n",
            "5402it [12:36,  6.43it/s]\u001b[A\n",
            "5403it [12:36,  6.41it/s]\u001b[A\n",
            "5404it [12:37,  6.28it/s]\u001b[A\n",
            "5405it [12:37,  6.31it/s]\u001b[A\n",
            "5406it [12:37,  6.35it/s]\u001b[A\n",
            "5407it [12:37,  6.35it/s]\u001b[A\n",
            "5408it [12:37,  6.36it/s]\u001b[A\n",
            "5409it [12:37,  6.43it/s]\u001b[A\n",
            "5410it [12:38,  6.56it/s]\u001b[A\n",
            "5411it [12:38,  6.76it/s]\u001b[A\n",
            "5412it [12:38,  6.81it/s]\u001b[A\n",
            "5413it [12:38,  6.45it/s]\u001b[A\n",
            "5414it [12:38,  6.39it/s]\u001b[A\n",
            "5415it [12:38,  6.31it/s]\u001b[A\n",
            "5416it [12:39,  6.31it/s]\u001b[A\n",
            "5417it [12:39,  6.10it/s]\u001b[A\n",
            "5418it [12:39,  5.94it/s]\u001b[A\n",
            "5419it [12:39,  6.09it/s]\u001b[A\n",
            "5420it [12:39,  6.41it/s]\u001b[A\n",
            "5421it [12:39,  6.48it/s]\u001b[A\n",
            "5422it [12:39,  6.48it/s]\u001b[A\n",
            "5423it [12:40,  6.53it/s]\u001b[A\n",
            "5424it [12:40,  6.50it/s]\u001b[A\n",
            "5425it [12:40,  6.56it/s]\u001b[A\n",
            "5426it [12:40,  6.66it/s]\u001b[A\n",
            "5427it [12:40,  6.85it/s]\u001b[A\n",
            "5428it [12:40,  6.94it/s]\u001b[A\n",
            "5429it [12:40,  7.01it/s]\u001b[A\n",
            "5430it [12:41,  6.95it/s]\u001b[A\n",
            "5431it [12:41,  7.05it/s]\u001b[A\n",
            "5432it [12:41,  7.03it/s]\u001b[A\n",
            "5433it [12:41,  6.99it/s]\u001b[A\n",
            "5434it [12:41,  6.94it/s]\u001b[A\n",
            "5435it [12:41,  6.97it/s]\u001b[A\n",
            "5436it [12:41,  7.01it/s]\u001b[A\n",
            "5437it [12:42,  6.94it/s]\u001b[A\n",
            "5438it [12:42,  6.98it/s]\u001b[A\n",
            "5439it [12:42,  6.90it/s]\u001b[A\n",
            "5440it [12:42,  6.76it/s]\u001b[A\n",
            "5441it [12:42,  6.78it/s]\u001b[A\n",
            "5442it [12:42,  6.80it/s]\u001b[A\n",
            "5443it [12:43,  6.78it/s]\u001b[A\n",
            "5444it [12:43,  6.85it/s]\u001b[A\n",
            "5445it [12:43,  6.95it/s]\u001b[A\n",
            "5446it [12:43,  6.95it/s]\u001b[A\n",
            "5447it [12:43,  7.02it/s]\u001b[A\n",
            "5448it [12:43,  6.86it/s]\u001b[A\n",
            "5449it [12:43,  6.73it/s]\u001b[A\n",
            "5450it [12:44,  6.64it/s]\u001b[A\n",
            "5451it [12:44,  6.60it/s]\u001b[A\n",
            "5452it [12:44,  6.55it/s]\u001b[A\n",
            "5453it [12:44,  6.47it/s]\u001b[A\n",
            "5454it [12:44,  6.62it/s]\u001b[A\n",
            "5455it [12:44,  6.76it/s]\u001b[A\n",
            "5456it [12:44,  6.84it/s]\u001b[A\n",
            "5457it [12:45,  6.97it/s]\u001b[A\n",
            "5458it [12:45,  6.66it/s]\u001b[A\n",
            "5459it [12:45,  6.60it/s]\u001b[A\n",
            "5460it [12:45,  6.51it/s]\u001b[A\n",
            "5461it [12:45,  6.59it/s]\u001b[A\n",
            "5462it [12:45,  6.75it/s]\u001b[A\n",
            "5463it [12:45,  6.84it/s]\u001b[A\n",
            "5464it [12:46,  6.97it/s]\u001b[A\n",
            "5465it [12:46,  6.90it/s]\u001b[A\n",
            "5466it [12:46,  6.88it/s]\u001b[A\n",
            "5467it [12:46,  6.91it/s]\u001b[A\n",
            "5468it [12:46,  6.90it/s]\u001b[A\n",
            "5469it [12:46,  6.95it/s]\u001b[A\n",
            "5470it [12:46,  7.07it/s]\u001b[A\n",
            "5471it [12:47,  7.10it/s]\u001b[A\n",
            "5472it [12:47,  6.86it/s]\u001b[A\n",
            "5473it [12:47,  6.57it/s]\u001b[A\n",
            "5474it [12:47,  6.62it/s]\u001b[A\n",
            "5475it [12:47,  6.68it/s]\u001b[A\n",
            "5476it [12:47,  6.83it/s]\u001b[A\n",
            "5477it [12:48,  6.90it/s]\u001b[A\n",
            "5478it [12:48,  7.04it/s]\u001b[A\n",
            "5479it [12:48,  6.97it/s]\u001b[A\n",
            "5480it [12:48,  6.94it/s]\u001b[A\n",
            "5481it [12:48,  7.07it/s]\u001b[A\n",
            "5482it [12:48,  7.03it/s]\u001b[A\n",
            "5483it [12:48,  7.07it/s]\u001b[A\n",
            "5484it [12:48,  7.11it/s]\u001b[A\n",
            "5485it [12:49,  7.13it/s]\u001b[A\n",
            "5486it [12:49,  7.04it/s]\u001b[A\n",
            "5487it [12:49,  7.06it/s]\u001b[A\n",
            "5488it [12:49,  6.96it/s]\u001b[A\n",
            "5489it [12:49,  6.82it/s]\u001b[A\n",
            "5490it [12:49,  6.93it/s]\u001b[A\n",
            "5491it [12:50,  6.97it/s]\u001b[A\n",
            "5492it [12:50,  7.05it/s]\u001b[A\n",
            "5493it [12:50,  7.07it/s]\u001b[A\n",
            "5494it [12:50,  7.02it/s]\u001b[A\n",
            "5495it [12:50,  7.13it/s]\u001b[A\n",
            "5496it [12:50,  7.04it/s]\u001b[A\n",
            "5497it [12:50,  7.06it/s]\u001b[A\n",
            "5498it [12:50,  7.07it/s]\u001b[A\n",
            "5499it [12:51,  7.21it/s]\u001b[A\n",
            "5500it [12:51,  7.00it/s]\u001b[A\n",
            "5501it [12:51,  7.00it/s]\u001b[A\n",
            "5502it [12:51,  6.87it/s]\u001b[A\n",
            "5503it [12:51,  6.98it/s]\u001b[A\n",
            "5504it [12:51,  6.73it/s]\u001b[A\n",
            "5505it [12:52,  6.50it/s]\u001b[A\n",
            "5506it [12:52,  6.52it/s]\u001b[A\n",
            "5507it [12:52,  6.59it/s]\u001b[A\n",
            "5508it [12:52,  6.50it/s]\u001b[A\n",
            "5509it [12:52,  6.44it/s]\u001b[A\n",
            "5510it [12:52,  6.39it/s]\u001b[A\n",
            "5511it [12:52,  6.35it/s]\u001b[A\n",
            "5512it [12:53,  6.34it/s]\u001b[A\n",
            "5513it [12:53,  6.28it/s]\u001b[A\n",
            "5514it [12:53,  6.29it/s]\u001b[A\n",
            "5515it [12:53,  6.12it/s]\u001b[A\n",
            "5516it [12:53,  6.00it/s]\u001b[A\n",
            "5517it [12:53,  6.17it/s]\u001b[A\n",
            "5518it [12:54,  6.33it/s]\u001b[A\n",
            "5519it [12:54,  6.55it/s]\u001b[A\n",
            "5520it [12:54,  6.47it/s]\u001b[A\n",
            "5521it [12:54,  6.43it/s]\u001b[A\n",
            "5522it [12:54,  6.50it/s]\u001b[A\n",
            "5523it [12:54,  6.58it/s]\u001b[A\n",
            "5524it [12:55,  6.66it/s]\u001b[A\n",
            "5525it [12:55,  6.75it/s]\u001b[A\n",
            "5526it [12:55,  6.74it/s]\u001b[A\n",
            "5527it [12:55,  6.76it/s]\u001b[A\n",
            "5528it [12:55,  6.71it/s]\u001b[A\n",
            "5529it [12:55,  6.69it/s]\u001b[A\n",
            "5530it [12:55,  6.78it/s]\u001b[A\n",
            "5531it [12:56,  6.88it/s]\u001b[A\n",
            "5532it [12:56,  6.83it/s]\u001b[A\n",
            "5533it [12:56,  6.49it/s]\u001b[A\n",
            "5534it [12:56,  6.45it/s]\u001b[A\n",
            "5535it [12:56,  6.42it/s]\u001b[A\n",
            "5536it [12:56,  6.40it/s]\u001b[A\n",
            "5537it [12:56,  6.31it/s]\u001b[A\n",
            "5538it [12:57,  6.29it/s]\u001b[A\n",
            "5539it [12:57,  6.30it/s]\u001b[A\n",
            "5540it [12:57,  6.20it/s]\u001b[A\n",
            "5541it [12:57,  6.27it/s]\u001b[A\n",
            "5542it [12:57,  6.48it/s]\u001b[A\n",
            "5543it [12:57,  6.66it/s]\u001b[A\n",
            "5544it [12:58,  6.72it/s]\u001b[A\n",
            "5545it [12:58,  6.71it/s]\u001b[A\n",
            "5546it [12:58,  6.69it/s]\u001b[A\n",
            "5547it [12:58,  6.70it/s]\u001b[A\n",
            "5548it [12:58,  6.73it/s]\u001b[A\n",
            "5549it [12:58,  6.64it/s]\u001b[A\n",
            "5550it [12:58,  6.56it/s]\u001b[A\n",
            "5551it [12:59,  6.35it/s]\u001b[A\n",
            "5552it [12:59,  6.33it/s]\u001b[A\n",
            "5553it [12:59,  6.27it/s]\u001b[A\n",
            "5554it [12:59,  6.31it/s]\u001b[A\n",
            "5555it [12:59,  6.35it/s]\u001b[A\n",
            "5556it [12:59,  6.40it/s]\u001b[A\n",
            "5557it [13:00,  6.54it/s]\u001b[A\n",
            "5558it [13:00,  6.53it/s]\u001b[A\n",
            "5559it [13:00,  6.37it/s]\u001b[A\n",
            "5560it [13:00,  6.36it/s]\u001b[A\n",
            "5561it [13:00,  6.51it/s]\u001b[A\n",
            "5562it [13:00,  6.60it/s]\u001b[A\n",
            "5563it [13:00,  6.64it/s]\u001b[A\n",
            "5564it [13:01,  6.68it/s]\u001b[A\n",
            "5565it [13:01,  6.54it/s]\u001b[A\n",
            "5566it [13:01,  6.60it/s]\u001b[A\n",
            "5567it [13:01,  6.70it/s]\u001b[A\n",
            "5568it [13:01,  6.78it/s]\u001b[A\n",
            "5569it [13:01,  6.81it/s]\u001b[A\n",
            "5570it [13:02,  6.59it/s]\u001b[A\n",
            "5571it [13:02,  6.73it/s]\u001b[A\n",
            "5572it [13:02,  6.76it/s]\u001b[A\n",
            "5573it [13:02,  6.75it/s]\u001b[A\n",
            "5574it [13:02,  6.78it/s]\u001b[A\n",
            "5575it [13:02,  6.68it/s]\u001b[A\n",
            "5576it [13:02,  6.63it/s]\u001b[A\n",
            "5577it [13:03,  6.74it/s]\u001b[A\n",
            "5578it [13:03,  6.81it/s]\u001b[A\n",
            "5579it [13:03,  6.75it/s]\u001b[A\n",
            "5580it [13:03,  6.55it/s]\u001b[A\n",
            "5581it [13:03,  6.55it/s]\u001b[A\n",
            "5582it [13:03,  6.72it/s]\u001b[A\n",
            "5583it [13:03,  6.79it/s]\u001b[A\n",
            "5584it [13:04,  6.73it/s]\u001b[A\n",
            "5585it [13:04,  6.59it/s]\u001b[A\n",
            "5586it [13:04,  6.77it/s]\u001b[A\n",
            "5587it [13:04,  6.81it/s]\u001b[A\n",
            "5588it [13:04,  6.76it/s]\u001b[A\n",
            "5589it [13:04,  6.73it/s]\u001b[A\n",
            "5590it [13:04,  6.74it/s]\u001b[A\n",
            "5591it [13:05,  6.82it/s]\u001b[A\n",
            "5592it [13:05,  6.89it/s]\u001b[A\n",
            "5593it [13:05,  6.87it/s]\u001b[A\n",
            "5594it [13:05,  6.85it/s]\u001b[A\n",
            "5595it [13:05,  6.92it/s]\u001b[A\n",
            "5596it [13:05,  7.01it/s]\u001b[A\n",
            "5597it [13:05,  7.06it/s]\u001b[A\n",
            "5598it [13:06,  7.08it/s]\u001b[A\n",
            "5599it [13:06,  7.10it/s]\u001b[A\n",
            "5600it [13:06,  7.13it/s]\u001b[A\n",
            "5601it [13:06,  7.05it/s]\u001b[A\n",
            "5602it [13:06,  6.98it/s]\u001b[A\n",
            "5603it [13:06,  7.00it/s]\u001b[A\n",
            "5604it [13:06,  7.08it/s]\u001b[A\n",
            "5605it [13:07,  7.06it/s]\u001b[A\n",
            "5606it [13:07,  7.11it/s]\u001b[A\n",
            "5607it [13:07,  7.14it/s]\u001b[A\n",
            "5608it [13:07,  7.01it/s]\u001b[A\n",
            "5609it [13:07,  7.00it/s]\u001b[A\n",
            "5610it [13:07,  6.97it/s]\u001b[A\n",
            "5611it [13:07,  7.06it/s]\u001b[A\n",
            "5612it [13:08,  7.17it/s]\u001b[A\n",
            "5613it [13:08,  7.12it/s]\u001b[A\n",
            "5614it [13:08,  7.15it/s]\u001b[A\n",
            "5615it [13:08,  6.85it/s]\u001b[A\n",
            "5616it [13:08,  6.79it/s]\u001b[A\n",
            "5617it [13:08,  6.87it/s]\u001b[A\n",
            "5618it [13:08,  6.91it/s]\u001b[A\n",
            "5619it [13:09,  6.69it/s]\u001b[A\n",
            "5620it [13:09,  6.59it/s]\u001b[A\n",
            "5621it [13:09,  6.31it/s]\u001b[A\n",
            "5622it [13:09,  6.28it/s]\u001b[A\n",
            "5623it [13:09,  6.34it/s]\u001b[A\n",
            "5624it [13:09,  6.27it/s]\u001b[A\n",
            "5625it [13:10,  6.20it/s]\u001b[A\n",
            "5626it [13:10,  6.25it/s]\u001b[A\n",
            "5627it [13:10,  6.40it/s]\u001b[A\n",
            "5628it [13:10,  6.44it/s]\u001b[A\n",
            "5629it [13:10,  6.61it/s]\u001b[A\n",
            "5630it [13:10,  6.69it/s]\u001b[A\n",
            "5631it [13:11,  6.80it/s]\u001b[A\n",
            "5632it [13:11,  6.88it/s]\u001b[A\n",
            "5633it [13:11,  6.93it/s]\u001b[A\n",
            "5634it [13:11,  6.91it/s]\u001b[A\n",
            "5635it [13:11,  6.82it/s]\u001b[A\n",
            "5636it [13:11,  6.96it/s]\u001b[A\n",
            "5637it [13:11,  7.01it/s]\u001b[A\n",
            "5638it [13:12,  7.05it/s]\u001b[A\n",
            "5639it [13:12,  7.07it/s]\u001b[A\n",
            "5640it [13:12,  7.00it/s]\u001b[A\n",
            "5641it [13:12,  7.00it/s]\u001b[A\n",
            "5642it [13:12,  6.74it/s]\u001b[A\n",
            "5643it [13:12,  6.55it/s]\u001b[A\n",
            "5644it [13:12,  6.41it/s]\u001b[A\n",
            "5645it [13:13,  6.43it/s]\u001b[A\n",
            "5646it [13:13,  6.59it/s]\u001b[A\n",
            "5647it [13:13,  6.83it/s]\u001b[A\n",
            "5648it [13:13,  6.73it/s]\u001b[A\n",
            "5649it [13:13,  6.56it/s]\u001b[A\n",
            "5650it [13:13,  6.71it/s]\u001b[A\n",
            "5651it [13:13,  6.81it/s]\u001b[A\n",
            "5652it [13:14,  6.71it/s]\u001b[A\n",
            "5653it [13:14,  6.79it/s]\u001b[A\n",
            "5654it [13:14,  6.73it/s]\u001b[A\n",
            "5655it [13:14,  6.73it/s]\u001b[A\n",
            "5656it [13:14,  6.61it/s]\u001b[A\n",
            "5657it [13:14,  6.57it/s]\u001b[A\n",
            "5658it [13:15,  6.57it/s]\u001b[A\n",
            "5659it [13:15,  6.73it/s]\u001b[A\n",
            "5660it [13:15,  6.82it/s]\u001b[A\n",
            "5661it [13:15,  6.69it/s]\u001b[A\n",
            "5662it [13:15,  6.54it/s]\u001b[A\n",
            "5663it [13:15,  6.57it/s]\u001b[A\n",
            "5664it [13:15,  6.73it/s]\u001b[A\n",
            "5665it [13:16,  6.85it/s]\u001b[A\n",
            "5666it [13:16,  6.98it/s]\u001b[A\n",
            "5667it [13:16,  6.98it/s]\u001b[A\n",
            "5668it [13:16,  6.88it/s]\u001b[A\n",
            "5669it [13:16,  6.74it/s]\u001b[A\n",
            "5670it [13:16,  6.80it/s]\u001b[A\n",
            "5671it [13:16,  6.92it/s]\u001b[A\n",
            "5672it [13:17,  7.03it/s]\u001b[A\n",
            "5673it [13:17,  6.94it/s]\u001b[A\n",
            "5674it [13:17,  6.84it/s]\u001b[A\n",
            "5675it [13:17,  6.75it/s]\u001b[A\n",
            "5676it [13:17,  6.67it/s]\u001b[A\n",
            "5677it [13:17,  6.73it/s]\u001b[A\n",
            "5678it [13:17,  6.85it/s]\u001b[A\n",
            "5679it [13:18,  6.96it/s]\u001b[A\n",
            "5680it [13:18,  7.01it/s]\u001b[A\n",
            "5681it [13:18,  7.03it/s]\u001b[A\n",
            "5682it [13:18,  7.01it/s]\u001b[A\n",
            "5683it [13:18,  7.13it/s]\u001b[A\n",
            "5684it [13:18,  6.99it/s]\u001b[A\n",
            "5685it [13:18,  6.97it/s]\u001b[A\n",
            "5686it [13:19,  6.94it/s]\u001b[A\n",
            "5687it [13:19,  6.76it/s]\u001b[A\n",
            "5688it [13:19,  6.73it/s]\u001b[A\n",
            "5689it [13:19,  6.72it/s]\u001b[A\n",
            "5690it [13:19,  6.60it/s]\u001b[A\n",
            "5691it [13:19,  6.40it/s]\u001b[A\n",
            "5692it [13:20,  6.49it/s]\u001b[A\n",
            "5693it [13:20,  6.66it/s]\u001b[A\n",
            "5694it [13:20,  6.74it/s]\u001b[A\n",
            "5695it [13:20,  6.85it/s]\u001b[A\n",
            "5696it [13:20,  6.95it/s]\u001b[A\n",
            "5697it [13:20,  6.84it/s]\u001b[A\n",
            "5698it [13:20,  6.81it/s]\u001b[A\n",
            "5699it [13:21,  6.90it/s]\u001b[A\n",
            "5700it [13:21,  6.99it/s]\u001b[A\n",
            "5701it [13:21,  6.95it/s]\u001b[A\n",
            "5702it [13:21,  7.05it/s]\u001b[A\n",
            "5703it [13:21,  7.02it/s]\u001b[A\n",
            "5704it [13:21,  6.87it/s]\u001b[A\n",
            "5705it [13:21,  6.73it/s]\u001b[A\n",
            "5706it [13:22,  6.66it/s]\u001b[A\n",
            "5707it [13:22,  6.76it/s]\u001b[A\n",
            "5708it [13:22,  6.83it/s]\u001b[A\n",
            "5709it [13:22,  6.66it/s]\u001b[A\n",
            "5710it [13:22,  6.72it/s]\u001b[A\n",
            "5711it [13:22,  6.64it/s]\u001b[A\n",
            "5712it [13:22,  6.62it/s]\u001b[A\n",
            "5713it [13:23,  6.65it/s]\u001b[A\n",
            "5714it [13:23,  6.73it/s]\u001b[A\n",
            "5715it [13:23,  6.69it/s]\u001b[A\n",
            "5716it [13:23,  6.58it/s]\u001b[A\n",
            "5717it [13:23,  6.60it/s]\u001b[A\n",
            "5718it [13:23,  6.57it/s]\u001b[A\n",
            "5719it [13:23,  6.71it/s]\u001b[A\n",
            "5720it [13:24,  6.69it/s]\u001b[A\n",
            "5721it [13:24,  6.79it/s]\u001b[A\n",
            "5722it [13:24,  6.88it/s]\u001b[A\n",
            "5723it [13:24,  6.77it/s]\u001b[A\n",
            "5724it [13:24,  6.87it/s]\u001b[A\n",
            "5725it [13:24,  6.72it/s]\u001b[A\n",
            "5726it [13:25,  6.84it/s]\u001b[A\n",
            "5727it [13:25,  6.92it/s]\u001b[A\n",
            "5728it [13:25,  7.04it/s]\u001b[A\n",
            "5729it [13:25,  6.99it/s]\u001b[A\n",
            "5730it [13:25,  6.84it/s]\u001b[A\n",
            "5731it [13:25,  6.93it/s]\u001b[A\n",
            "5732it [13:25,  6.92it/s]\u001b[A\n",
            "5733it [13:26,  6.97it/s]\u001b[A\n",
            "5734it [13:26,  6.98it/s]\u001b[A\n",
            "5735it [13:26,  6.98it/s]\u001b[A\n",
            "5736it [13:26,  6.90it/s]\u001b[A\n",
            "5737it [13:26,  6.76it/s]\u001b[A\n",
            "5738it [13:26,  6.68it/s]\u001b[A\n",
            "5739it [13:26,  6.52it/s]\u001b[A\n",
            "5740it [13:27,  6.49it/s]\u001b[A\n",
            "5741it [13:27,  6.42it/s]\u001b[A\n",
            "5742it [13:27,  6.45it/s]\u001b[A\n",
            "5743it [13:27,  6.48it/s]\u001b[A\n",
            "5744it [13:27,  6.46it/s]\u001b[A\n",
            "5745it [13:27,  6.30it/s]\u001b[A\n",
            "5746it [13:28,  6.32it/s]\u001b[A\n",
            "5747it [13:28,  6.50it/s]\u001b[A\n",
            "5748it [13:28,  6.61it/s]\u001b[A\n",
            "5749it [13:28,  6.57it/s]\u001b[A\n",
            "5750it [13:28,  6.56it/s]\u001b[A\n",
            "5751it [13:28,  6.48it/s]\u001b[A\n",
            "5752it [13:28,  6.36it/s]\u001b[A\n",
            "5753it [13:29,  6.39it/s]\u001b[A\n",
            "5754it [13:29,  6.39it/s]\u001b[A\n",
            "5755it [13:29,  6.41it/s]\u001b[A\n",
            "5756it [13:29,  6.41it/s]\u001b[A\n",
            "5757it [13:29,  6.55it/s]\u001b[A\n",
            "5758it [13:29,  6.48it/s]\u001b[A\n",
            "5759it [13:30,  6.52it/s]\u001b[A\n",
            "5760it [13:30,  6.58it/s]\u001b[A\n",
            "5761it [13:30,  6.65it/s]\u001b[A\n",
            "5762it [13:30,  6.71it/s]\u001b[A\n",
            "5763it [13:30,  6.76it/s]\u001b[A\n",
            "5764it [13:30,  6.79it/s]\u001b[A\n",
            "5765it [13:30,  6.71it/s]\u001b[A\n",
            "5766it [13:31,  6.76it/s]\u001b[A\n",
            "5767it [13:31,  6.79it/s]\u001b[A\n",
            "5768it [13:31,  6.81it/s]\u001b[A\n",
            "5769it [13:31,  6.88it/s]\u001b[A\n",
            "5770it [13:31,  6.98it/s]\u001b[A\n",
            "5771it [13:31,  7.06it/s]\u001b[A\n",
            "5772it [13:31,  6.99it/s]\u001b[A\n",
            "5773it [13:32,  7.06it/s]\u001b[A\n",
            "5774it [13:32,  7.09it/s]\u001b[A\n",
            "5775it [13:32,  7.17it/s]\u001b[A\n",
            "5776it [13:32,  7.14it/s]\u001b[A\n",
            "5777it [13:32,  6.94it/s]\u001b[A\n",
            "5778it [13:32,  6.86it/s]\u001b[A\n",
            "5779it [13:32,  6.78it/s]\u001b[A\n",
            "5780it [13:33,  6.91it/s]\u001b[A\n",
            "5781it [13:33,  7.05it/s]\u001b[A\n",
            "5782it [13:33,  7.11it/s]\u001b[A\n",
            "5783it [13:33,  7.12it/s]\u001b[A\n",
            "5784it [13:33,  7.17it/s]\u001b[A\n",
            "5785it [13:33,  7.01it/s]\u001b[A\n",
            "5786it [13:33,  7.00it/s]\u001b[A\n",
            "5787it [13:34,  6.96it/s]\u001b[A\n",
            "5788it [13:34,  6.85it/s]\u001b[A\n",
            "5789it [13:34,  6.91it/s]\u001b[A\n",
            "5790it [13:34,  6.95it/s]\u001b[A\n",
            "5791it [13:34,  7.00it/s]\u001b[A\n",
            "5792it [13:34,  6.89it/s]\u001b[A\n",
            "5793it [13:34,  6.64it/s]\u001b[A\n",
            "5794it [13:35,  6.63it/s]\u001b[A\n",
            "5795it [13:35,  6.46it/s]\u001b[A\n",
            "5796it [13:35,  6.54it/s]\u001b[A\n",
            "5797it [13:35,  6.54it/s]\u001b[A\n",
            "5798it [13:35,  6.74it/s]\u001b[A\n",
            "5799it [13:35,  6.83it/s]\u001b[A\n",
            "5800it [13:35,  6.79it/s]\u001b[A\n",
            "5801it [13:36,  6.80it/s]\u001b[A\n",
            "5802it [13:36,  6.85it/s]\u001b[A\n",
            "5803it [13:36,  6.91it/s]\u001b[A\n",
            "5804it [13:36,  6.92it/s]\u001b[A\n",
            "5805it [13:36,  6.87it/s]\u001b[A\n",
            "5806it [13:36,  6.97it/s]\u001b[A\n",
            "5807it [13:36,  6.90it/s]\u001b[A\n",
            "5808it [13:37,  6.97it/s]\u001b[A\n",
            "5809it [13:37,  7.07it/s]\u001b[A\n",
            "5810it [13:37,  7.03it/s]\u001b[A\n",
            "5811it [13:37,  7.05it/s]\u001b[A\n",
            "5812it [13:37,  7.01it/s]\u001b[A\n",
            "5813it [13:37,  6.89it/s]\u001b[A\n",
            "5814it [13:38,  6.65it/s]\u001b[A\n",
            "5815it [13:38,  6.55it/s]\u001b[A\n",
            "5816it [13:38,  6.49it/s]\u001b[A\n",
            "5817it [13:38,  6.47it/s]\u001b[A\n",
            "5818it [13:38,  6.49it/s]\u001b[A\n",
            "5819it [13:38,  6.41it/s]\u001b[A\n",
            "5820it [13:38,  6.38it/s]\u001b[A\n",
            "5821it [13:39,  6.24it/s]\u001b[A\n",
            "5822it [13:39,  6.23it/s]\u001b[A\n",
            "5823it [13:39,  6.40it/s]\u001b[A\n",
            "5824it [13:39,  6.60it/s]\u001b[A\n",
            "5825it [13:39,  6.72it/s]\u001b[A\n",
            "5826it [13:39,  6.85it/s]\u001b[A\n",
            "5827it [13:39,  6.86it/s]\u001b[A\n",
            "5828it [13:40,  6.86it/s]\u001b[A\n",
            "5829it [13:40,  6.78it/s]\u001b[A\n",
            "5830it [13:40,  6.74it/s]\u001b[A\n",
            "5831it [13:40,  6.63it/s]\u001b[A\n",
            "5832it [13:40,  6.59it/s]\u001b[A\n",
            "5833it [13:40,  6.41it/s]\u001b[A\n",
            "5834it [13:41,  6.29it/s]\u001b[A\n",
            "5835it [13:41,  6.24it/s]\u001b[A\n",
            "5836it [13:41,  6.28it/s]\u001b[A\n",
            "5837it [13:41,  6.28it/s]\u001b[A\n",
            "5838it [13:41,  6.31it/s]\u001b[A\n",
            "5839it [13:41,  6.41it/s]\u001b[A\n",
            "5840it [13:42,  6.44it/s]\u001b[A\n",
            "5841it [13:42,  6.55it/s]\u001b[A\n",
            "5842it [13:42,  6.66it/s]\u001b[A\n",
            "5843it [13:42,  6.58it/s]\u001b[A\n",
            "5844it [13:42,  6.53it/s]\u001b[A\n",
            "5845it [13:42,  6.59it/s]\u001b[A\n",
            "5846it [13:42,  6.71it/s]\u001b[A\n",
            "5847it [13:43,  6.76it/s]\u001b[A\n",
            "5848it [13:43,  6.92it/s]\u001b[A\n",
            "5849it [13:43,  6.96it/s]\u001b[A\n",
            "5850it [13:43,  7.00it/s]\u001b[A\n",
            "5851it [13:43,  7.05it/s]\u001b[A\n",
            "5852it [13:43,  7.01it/s]\u001b[A\n",
            "5853it [13:43,  6.89it/s]\u001b[A\n",
            "5854it [13:44,  6.72it/s]\u001b[A\n",
            "5855it [13:44,  6.66it/s]\u001b[A\n",
            "5856it [13:44,  6.63it/s]\u001b[A\n",
            "5857it [13:44,  6.81it/s]\u001b[A\n",
            "5858it [13:44,  6.77it/s]\u001b[A\n",
            "5859it [13:44,  6.68it/s]\u001b[A\n",
            "5860it [13:44,  6.68it/s]\u001b[A\n",
            "5861it [13:45,  6.60it/s]\u001b[A\n",
            "5862it [13:45,  6.53it/s]\u001b[A\n",
            "5863it [13:45,  6.50it/s]\u001b[A\n",
            "5864it [13:45,  6.55it/s]\u001b[A\n",
            "5865it [13:45,  6.56it/s]\u001b[A\n",
            "5866it [13:45,  6.54it/s]\u001b[A\n",
            "5867it [13:46,  6.61it/s]\u001b[A\n",
            "5868it [13:46,  6.69it/s]\u001b[A\n",
            "5869it [13:46,  6.83it/s]\u001b[A\n",
            "5870it [13:46,  6.87it/s]\u001b[A\n",
            "5871it [13:46,  6.78it/s]\u001b[A\n",
            "5872it [13:46,  6.76it/s]\u001b[A\n",
            "5873it [13:46,  6.67it/s]\u001b[A\n",
            "5874it [13:47,  6.62it/s]\u001b[A\n",
            "5875it [13:47,  6.46it/s]\u001b[A\n",
            "5876it [13:47,  6.43it/s]\u001b[A\n",
            "5877it [13:47,  6.46it/s]\u001b[A\n",
            "5878it [13:47,  6.46it/s]\u001b[A\n",
            "5879it [13:47,  6.40it/s]\u001b[A\n",
            "5880it [13:48,  6.50it/s]\u001b[A\n",
            "5881it [13:48,  6.38it/s]\u001b[A\n",
            "5882it [13:48,  6.39it/s]\u001b[A\n",
            "5883it [13:48,  6.55it/s]\u001b[A\n",
            "5884it [13:48,  6.70it/s]\u001b[A\n",
            "5885it [13:48,  6.80it/s]\u001b[A\n",
            "5886it [13:48,  6.71it/s]\u001b[A\n",
            "5887it [13:49,  6.77it/s]\u001b[A\n",
            "5888it [13:49,  6.76it/s]\u001b[A\n",
            "5889it [13:49,  6.89it/s]\u001b[A\n",
            "5890it [13:49,  6.96it/s]\u001b[A\n",
            "5891it [13:49,  7.02it/s]\u001b[A\n",
            "5892it [13:49,  7.01it/s]\u001b[A\n",
            "5893it [13:49,  7.04it/s]\u001b[A\n",
            "5894it [13:50,  7.09it/s]\u001b[A\n",
            "5895it [13:50,  7.02it/s]\u001b[A\n",
            "5896it [13:50,  7.01it/s]\u001b[A\n",
            "5897it [13:50,  7.06it/s]\u001b[A\n",
            "5898it [13:50,  7.06it/s]\u001b[A\n",
            "5899it [13:50,  7.12it/s]\u001b[A\n",
            "5900it [13:50,  7.14it/s]\u001b[A\n",
            "5901it [13:51,  7.10it/s]\u001b[A\n",
            "5902it [13:51,  7.09it/s]\u001b[A\n",
            "5903it [13:51,  7.09it/s]\u001b[A\n",
            "5904it [13:51,  7.07it/s]\u001b[A\n",
            "5905it [13:51,  7.05it/s]\u001b[A\n",
            "5906it [13:51,  6.92it/s]\u001b[A\n",
            "5907it [13:51,  6.80it/s]\u001b[A\n",
            "5908it [13:52,  6.76it/s]\u001b[A\n",
            "5909it [13:52,  6.53it/s]\u001b[A\n",
            "5910it [13:52,  6.53it/s]\u001b[A\n",
            "5911it [13:52,  6.74it/s]\u001b[A\n",
            "5912it [13:52,  6.87it/s]\u001b[A\n",
            "5913it [13:52,  6.82it/s]\u001b[A\n",
            "5914it [13:52,  6.84it/s]\u001b[A\n",
            "5915it [13:53,  6.94it/s]\u001b[A\n",
            "5916it [13:53,  6.92it/s]\u001b[A\n",
            "5917it [13:53,  6.94it/s]\u001b[A\n",
            "5918it [13:53,  6.94it/s]\u001b[A\n",
            "5919it [13:53,  6.95it/s]\u001b[A\n",
            "5920it [13:53,  7.00it/s]\u001b[A\n",
            "5921it [13:53,  7.03it/s]\u001b[A\n",
            "5922it [13:54,  7.06it/s]\u001b[A\n",
            "5923it [13:54,  6.95it/s]\u001b[A\n",
            "5924it [13:54,  6.98it/s]\u001b[A\n",
            "5925it [13:54,  7.06it/s]\u001b[A\n",
            "5926it [13:54,  7.05it/s]\u001b[A\n",
            "5927it [13:54,  7.06it/s]\u001b[A\n",
            "5928it [13:54,  7.06it/s]\u001b[A\n",
            "5929it [13:55,  7.05it/s]\u001b[A\n",
            "5930it [13:55,  7.08it/s]\u001b[A\n",
            "5931it [13:55,  7.10it/s]\u001b[A\n",
            "5932it [13:55,  7.09it/s]\u001b[A\n",
            "5933it [13:55,  7.04it/s]\u001b[A\n",
            "5934it [13:55,  7.16it/s]\u001b[A\n",
            "5935it [13:55,  7.10it/s]\u001b[A\n",
            "5936it [13:56,  7.19it/s]\u001b[A\n",
            "5937it [13:56,  7.10it/s]\u001b[A\n",
            "5938it [13:56,  6.94it/s]\u001b[A\n",
            "5939it [13:56,  6.79it/s]\u001b[A\n",
            "5940it [13:56,  6.90it/s]\u001b[A\n",
            "5941it [13:56,  7.02it/s]\u001b[A\n",
            "5942it [13:56,  7.03it/s]\u001b[A\n",
            "5943it [13:57,  6.96it/s]\u001b[A\n",
            "5944it [13:57,  7.01it/s]\u001b[A\n",
            "5945it [13:57,  6.97it/s]\u001b[A\n",
            "5946it [13:57,  7.02it/s]\u001b[A\n",
            "5947it [13:57,  6.95it/s]\u001b[A\n",
            "5948it [13:57,  7.05it/s]\u001b[A\n",
            "5949it [13:57,  7.08it/s]\u001b[A\n",
            "5950it [13:58,  7.10it/s]\u001b[A\n",
            "5951it [13:58,  7.12it/s]\u001b[A\n",
            "5952it [13:58,  7.04it/s]\u001b[A\n",
            "5953it [13:58,  7.05it/s]\u001b[A\n",
            "5954it [13:58,  6.94it/s]\u001b[A\n",
            "5955it [13:58,  6.77it/s]\u001b[A\n",
            "5956it [13:58,  6.69it/s]\u001b[A\n",
            "5957it [13:59,  6.82it/s]\u001b[A\n",
            "5958it [13:59,  6.95it/s]\u001b[A\n",
            "5959it [13:59,  6.91it/s]\u001b[A\n",
            "5960it [13:59,  6.90it/s]\u001b[A\n",
            "5961it [13:59,  6.88it/s]\u001b[A\n",
            "5962it [13:59,  6.96it/s]\u001b[A\n",
            "5963it [13:59,  7.00it/s]\u001b[A\n",
            "5964it [14:00,  7.01it/s]\u001b[A\n",
            "5965it [14:00,  6.88it/s]\u001b[A\n",
            "5966it [14:00,  6.72it/s]\u001b[A\n",
            "5967it [14:00,  6.82it/s]\u001b[A\n",
            "5968it [14:00,  6.94it/s]\u001b[A\n",
            "5969it [14:00,  6.97it/s]\u001b[A\n",
            "5970it [14:00,  6.95it/s]\u001b[A\n",
            "5971it [14:01,  7.01it/s]\u001b[A\n",
            "5972it [14:01,  7.01it/s]\u001b[A\n",
            "5973it [14:01,  6.93it/s]\u001b[A\n",
            "5974it [14:01,  6.98it/s]\u001b[A\n",
            "5975it [14:01,  6.95it/s]\u001b[A\n",
            "5976it [14:01,  6.77it/s]\u001b[A\n",
            "5977it [14:01,  6.74it/s]\u001b[A\n",
            "5978it [14:02,  6.67it/s]\u001b[A\n",
            "5979it [14:02,  6.70it/s]\u001b[A\n",
            "5980it [14:02,  6.72it/s]\u001b[A\n",
            "5981it [14:02,  6.74it/s]\u001b[A\n",
            "5982it [14:02,  6.77it/s]\u001b[A\n",
            "5983it [14:02,  6.86it/s]\u001b[A\n",
            "5984it [14:03,  7.04it/s]\u001b[A\n",
            "5985it [14:03,  7.05it/s]\u001b[A\n",
            "5986it [14:03,  7.08it/s]\u001b[A\n",
            "5987it [14:03,  7.05it/s]\u001b[A\n",
            "5988it [14:03,  7.06it/s]\u001b[A\n",
            "5989it [14:03,  7.08it/s]\u001b[A\n",
            "5990it [14:03,  7.00it/s]\u001b[A\n",
            "5991it [14:04,  6.86it/s]\u001b[A\n",
            "5992it [14:04,  6.91it/s]\u001b[A\n",
            "5993it [14:04,  6.91it/s]\u001b[A\n",
            "5994it [14:04,  6.87it/s]\u001b[A\n",
            "5995it [14:04,  6.84it/s]\u001b[A\n",
            "5996it [14:04,  6.77it/s]\u001b[A\n",
            "5997it [14:04,  6.66it/s]\u001b[A\n",
            "5998it [14:05,  6.69it/s]\u001b[A\n",
            "5999it [14:05,  6.78it/s]\u001b[A\n",
            "6000it [14:05,  6.86it/s]\u001b[A\n",
            "6001it [14:05,  6.89it/s]\u001b[A\n",
            "6002it [14:05,  6.70it/s]\u001b[A\n",
            "6003it [14:05,  6.34it/s]\u001b[A\n",
            "6004it [14:05,  6.33it/s]\u001b[A\n",
            "6005it [14:06,  6.37it/s]\u001b[A\n",
            "6006it [14:06,  6.36it/s]\u001b[A\n",
            "6007it [14:06,  6.32it/s]\u001b[A\n",
            "6008it [14:06,  6.44it/s]\u001b[A\n",
            "6009it [14:06,  6.63it/s]\u001b[A\n",
            "6010it [14:06,  6.77it/s]\u001b[A\n",
            "6011it [14:07,  6.91it/s]\u001b[A\n",
            "6012it [14:07,  6.98it/s]\u001b[A\n",
            "6013it [14:07,  7.11it/s]\u001b[A\n",
            "6014it [14:07,  6.99it/s]\u001b[A\n",
            "6015it [14:07,  7.06it/s]\u001b[A\n",
            "6016it [14:07,  6.95it/s]\u001b[A\n",
            "6017it [14:07,  6.74it/s]\u001b[A\n",
            "6018it [14:08,  6.71it/s]\u001b[A\n",
            "6019it [14:08,  6.83it/s]\u001b[A\n",
            "6020it [14:08,  6.86it/s]\u001b[A\n",
            "6021it [14:08,  6.81it/s]\u001b[A\n",
            "6022it [14:08,  6.90it/s]\u001b[A\n",
            "6023it [14:08,  6.96it/s]\u001b[A\n",
            "6024it [14:08,  6.95it/s]\u001b[A\n",
            "6025it [14:09,  7.02it/s]\u001b[A\n",
            "6026it [14:09,  7.03it/s]\u001b[A\n",
            "6027it [14:09,  7.11it/s]\u001b[A\n",
            "6028it [14:09,  6.95it/s]\u001b[A\n",
            "6029it [14:09,  6.80it/s]\u001b[A\n",
            "6030it [14:09,  6.82it/s]\u001b[A\n",
            "6031it [14:09,  6.68it/s]\u001b[A\n",
            "6032it [14:10,  6.62it/s]\u001b[A\n",
            "6033it [14:10,  6.64it/s]\u001b[A\n",
            "6034it [14:10,  6.67it/s]\u001b[A\n",
            "6035it [14:10,  6.68it/s]\u001b[A\n",
            "6036it [14:10,  6.67it/s]\u001b[A\n",
            "6037it [14:10,  6.59it/s]\u001b[A\n",
            "6038it [14:10,  6.43it/s]\u001b[A\n",
            "6039it [14:11,  6.60it/s]\u001b[A\n",
            "6040it [14:11,  6.67it/s]\u001b[A\n",
            "6041it [14:11,  6.77it/s]\u001b[A\n",
            "6042it [14:11,  6.77it/s]\u001b[A\n",
            "6043it [14:11,  6.89it/s]\u001b[A\n",
            "6044it [14:11,  6.99it/s]\u001b[A\n",
            "6045it [14:11,  6.96it/s]\u001b[A\n",
            "6046it [14:12,  6.98it/s]\u001b[A\n",
            "6047it [14:12,  6.93it/s]\u001b[A\n",
            "6048it [14:12,  6.93it/s]\u001b[A\n",
            "6049it [14:12,  6.65it/s]\u001b[A\n",
            "6050it [14:12,  6.55it/s]\u001b[A\n",
            "6051it [14:12,  6.47it/s]\u001b[A\n",
            "6052it [14:13,  6.59it/s]\u001b[A\n",
            "6053it [14:13,  6.75it/s]\u001b[A\n",
            "6054it [14:13,  6.80it/s]\u001b[A\n",
            "6055it [14:13,  6.75it/s]\u001b[A\n",
            "6056it [14:13,  6.67it/s]\u001b[A\n",
            "6057it [14:13,  6.83it/s]\u001b[A\n",
            "6058it [14:13,  6.89it/s]\u001b[A\n",
            "6059it [14:14,  6.96it/s]\u001b[A\n",
            "6060it [14:14,  6.68it/s]\u001b[A\n",
            "6061it [14:14,  6.60it/s]\u001b[A\n",
            "6062it [14:14,  6.68it/s]\u001b[A\n",
            "6063it [14:14,  6.82it/s]\u001b[A\n",
            "6064it [14:14,  6.89it/s]\u001b[A\n",
            "6065it [14:14,  6.97it/s]\u001b[A\n",
            "6066it [14:15,  7.06it/s]\u001b[A\n",
            "6067it [14:15,  7.13it/s]\u001b[A\n",
            "6068it [14:15,  7.05it/s]\u001b[A\n",
            "6069it [14:15,  6.86it/s]\u001b[A\n",
            "6070it [14:15,  6.60it/s]\u001b[A\n",
            "6071it [14:15,  6.55it/s]\u001b[A\n",
            "6072it [14:15,  6.57it/s]\u001b[A\n",
            "6073it [14:16,  6.54it/s]\u001b[A\n",
            "6074it [14:16,  6.42it/s]\u001b[A\n",
            "6075it [14:16,  6.49it/s]\u001b[A\n",
            "6076it [14:16,  6.54it/s]\u001b[A\n",
            "6077it [14:16,  6.67it/s]\u001b[A\n",
            "6078it [14:16,  6.77it/s]\u001b[A\n",
            "6079it [14:17,  6.92it/s]\u001b[A\n",
            "6080it [14:17,  6.81it/s]\u001b[A\n",
            "6081it [14:17,  6.64it/s]\u001b[A\n",
            "6082it [14:17,  6.78it/s]\u001b[A\n",
            "6083it [14:17,  6.77it/s]\u001b[A\n",
            "6084it [14:17,  6.82it/s]\u001b[A\n",
            "6085it [14:17,  6.94it/s]\u001b[A\n",
            "6086it [14:18,  6.98it/s]\u001b[A\n",
            "6087it [14:18,  7.01it/s]\u001b[A\n",
            "6088it [14:18,  7.02it/s]\u001b[A\n",
            "6089it [14:18,  7.04it/s]\u001b[A\n",
            "6090it [14:18,  7.02it/s]\u001b[A\n",
            "6091it [14:18,  7.05it/s]\u001b[A\n",
            "6092it [14:18,  7.01it/s]\u001b[A\n",
            "6093it [14:19,  6.94it/s]\u001b[A\n",
            "6094it [14:19,  6.94it/s]\u001b[A\n",
            "6095it [14:19,  6.95it/s]\u001b[A\n",
            "6096it [14:19,  6.99it/s]\u001b[A\n",
            "6097it [14:19,  6.75it/s]\u001b[A\n",
            "6098it [14:19,  6.66it/s]\u001b[A\n",
            "6099it [14:19,  6.62it/s]\u001b[A\n",
            "6100it [14:20,  6.65it/s]\u001b[A\n",
            "6101it [14:20,  6.62it/s]\u001b[A\n",
            "6102it [14:20,  6.71it/s]\u001b[A\n",
            "6103it [14:20,  6.87it/s]\u001b[A\n",
            "6104it [14:20,  6.75it/s]\u001b[A\n",
            "6105it [14:20,  6.82it/s]\u001b[A\n",
            "6106it [14:20,  6.93it/s]\u001b[A\n",
            "6107it [14:21,  7.04it/s]\u001b[A\n",
            "6108it [14:21,  7.13it/s]\u001b[A\n",
            "6109it [14:21,  7.08it/s]\u001b[A\n",
            "6110it [14:21,  7.06it/s]\u001b[A\n",
            "6111it [14:21,  6.92it/s]\u001b[A\n",
            "6112it [14:21,  7.03it/s]\u001b[A\n",
            "6113it [14:21,  7.00it/s]\u001b[A\n",
            "6114it [14:22,  7.04it/s]\u001b[A\n",
            "6115it [14:22,  7.07it/s]\u001b[A\n",
            "6116it [14:22,  6.97it/s]\u001b[A\n",
            "6117it [14:22,  6.90it/s]\u001b[A\n",
            "6118it [14:22,  6.92it/s]\u001b[A\n",
            "6119it [14:22,  6.87it/s]\u001b[A\n",
            "6120it [14:22,  6.94it/s]\u001b[A\n",
            "6121it [14:23,  6.94it/s]\u001b[A\n",
            "6122it [14:23,  6.99it/s]\u001b[A\n",
            "6123it [14:23,  6.98it/s]\u001b[A\n",
            "6124it [14:23,  6.77it/s]\u001b[A\n",
            "6125it [14:23,  6.71it/s]\u001b[A\n",
            "6126it [14:23,  6.78it/s]\u001b[A\n",
            "6127it [14:24,  6.82it/s]\u001b[A\n",
            "6128it [14:24,  6.88it/s]\u001b[A\n",
            "6129it [14:24,  6.89it/s]\u001b[A\n",
            "6130it [14:24,  6.85it/s]\u001b[A\n",
            "6131it [14:24,  6.89it/s]\u001b[A\n",
            "6132it [14:24,  6.54it/s]\u001b[A\n",
            "6133it [14:24,  6.56it/s]\u001b[A\n",
            "6134it [14:25,  6.60it/s]\u001b[A\n",
            "6135it [14:25,  6.75it/s]\u001b[A\n",
            "6136it [14:25,  6.86it/s]\u001b[A\n",
            "6137it [14:25,  6.94it/s]\u001b[A\n",
            "6138it [14:25,  6.85it/s]\u001b[A\n",
            "6139it [14:25,  6.87it/s]\u001b[A\n",
            "6140it [14:25,  6.67it/s]\u001b[A\n",
            "6141it [14:26,  6.60it/s]\u001b[A\n",
            "6142it [14:26,  6.42it/s]\u001b[A\n",
            "6143it [14:26,  6.31it/s]\u001b[A\n",
            "6144it [14:26,  6.41it/s]\u001b[A\n",
            "6145it [14:26,  6.39it/s]\u001b[A\n",
            "6146it [14:26,  6.32it/s]\u001b[A\n",
            "6147it [14:27,  6.41it/s]\u001b[A\n",
            "6148it [14:27,  6.46it/s]\u001b[A\n",
            "6149it [14:27,  6.45it/s]\u001b[A\n",
            "6150it [14:27,  6.50it/s]\u001b[A\n",
            "6151it [14:27,  6.53it/s]\u001b[A\n",
            "6152it [14:27,  6.31it/s]\u001b[A\n",
            "6153it [14:27,  6.40it/s]\u001b[A\n",
            "6154it [14:28,  6.51it/s]\u001b[A\n",
            "6155it [14:28,  6.39it/s]\u001b[A\n",
            "6156it [14:28,  6.34it/s]\u001b[A\n",
            "6157it [14:28,  6.22it/s]\u001b[A\n",
            "6158it [14:28,  6.14it/s]\u001b[A\n",
            "6159it [14:28,  6.32it/s]\u001b[A\n",
            "6160it [14:29,  6.36it/s]\u001b[A\n",
            "6161it [14:29,  6.37it/s]\u001b[A\n",
            "6162it [14:29,  6.40it/s]\u001b[A\n",
            "6163it [14:29,  6.38it/s]\u001b[A\n",
            "6164it [14:29,  6.41it/s]\u001b[A\n",
            "6165it [14:29,  6.25it/s]\u001b[A\n",
            "6166it [14:30,  6.39it/s]\u001b[A\n",
            "6167it [14:30,  6.62it/s]\u001b[A\n",
            "6168it [14:30,  6.72it/s]\u001b[A\n",
            "6169it [14:30,  6.81it/s]\u001b[A\n",
            "6170it [14:30,  6.83it/s]\u001b[A\n",
            "6171it [14:30,  6.92it/s]\u001b[A\n",
            "6172it [14:30,  6.83it/s]\u001b[A\n",
            "6173it [14:31,  6.92it/s]\u001b[A\n",
            "6174it [14:31,  6.97it/s]\u001b[A\n",
            "6175it [14:31,  7.04it/s]\u001b[A\n",
            "6176it [14:31,  7.05it/s]\u001b[A\n",
            "6177it [14:31,  7.02it/s]\u001b[A\n",
            "6178it [14:31,  7.07it/s]\u001b[A\n",
            "6179it [14:31,  6.98it/s]\u001b[A\n",
            "6180it [14:32,  6.91it/s]\u001b[A\n",
            "6181it [14:32,  6.94it/s]\u001b[A\n",
            "6182it [14:32,  6.87it/s]\u001b[A\n",
            "6183it [14:32,  6.90it/s]\u001b[A\n",
            "6184it [14:32,  6.93it/s]\u001b[A\n",
            "6185it [14:32,  7.01it/s]\u001b[A\n",
            "6186it [14:32,  7.02it/s]\u001b[A\n",
            "6187it [14:33,  6.99it/s]\u001b[A\n",
            "6188it [14:33,  7.07it/s]\u001b[A\n",
            "6189it [14:33,  7.08it/s]\u001b[A\n",
            "6190it [14:33,  6.90it/s]\u001b[A\n",
            "6191it [14:33,  6.86it/s]\u001b[A\n",
            "6192it [14:33,  6.75it/s]\u001b[A\n",
            "6193it [14:33,  6.62it/s]\u001b[A\n",
            "6194it [14:34,  6.72it/s]\u001b[A\n",
            "6195it [14:34,  6.76it/s]\u001b[A\n",
            "6196it [14:34,  6.88it/s]\u001b[A\n",
            "6197it [14:34,  6.90it/s]\u001b[A\n",
            "6198it [14:34,  6.98it/s]\u001b[A\n",
            "6199it [14:34,  6.89it/s]\u001b[A\n",
            "6200it [14:34,  6.59it/s]\u001b[A\n",
            "6201it [14:35,  6.64it/s]\u001b[A\n",
            "6202it [14:35,  6.77it/s]\u001b[A\n",
            "6203it [14:35,  6.81it/s]\u001b[A\n",
            "6204it [14:35,  6.87it/s]\u001b[A\n",
            "6205it [14:35,  6.83it/s]\u001b[A\n",
            "6206it [14:35,  6.70it/s]\u001b[A\n",
            "6207it [14:35,  6.57it/s]\u001b[A\n",
            "6208it [14:36,  6.68it/s]\u001b[A\n",
            "6209it [14:36,  6.74it/s]\u001b[A\n",
            "6210it [14:36,  6.79it/s]\u001b[A\n",
            "6211it [14:36,  6.88it/s]\u001b[A\n",
            "6212it [14:36,  6.86it/s]\u001b[A\n",
            "6213it [14:36,  6.66it/s]\u001b[A\n",
            "6214it [14:37,  6.62it/s]\u001b[A\n",
            "6215it [14:37,  6.79it/s]\u001b[A\n",
            "6216it [14:37,  6.90it/s]\u001b[A\n",
            "6217it [14:37,  6.87it/s]\u001b[A\n",
            "6218it [14:37,  6.98it/s]\u001b[A\n",
            "6219it [14:37,  6.87it/s]\u001b[A\n",
            "6220it [14:37,  6.63it/s]\u001b[A\n",
            "6221it [14:38,  6.70it/s]\u001b[A\n",
            "6222it [14:38,  6.89it/s]\u001b[A\n",
            "6223it [14:38,  6.82it/s]\u001b[A\n",
            "6224it [14:38,  6.56it/s]\u001b[A\n",
            "6225it [14:38,  6.38it/s]\u001b[A\n",
            "6226it [14:38,  6.35it/s]\u001b[A\n",
            "6227it [14:38,  6.22it/s]\u001b[A\n",
            "6228it [14:39,  6.32it/s]\u001b[A\n",
            "6229it [14:39,  6.37it/s]\u001b[A\n",
            "6230it [14:39,  6.53it/s]\u001b[A\n",
            "6231it [14:39,  6.65it/s]\u001b[A\n",
            "6232it [14:39,  6.56it/s]\u001b[A\n",
            "6233it [14:39,  6.53it/s]\u001b[A\n",
            "6234it [14:40,  6.40it/s]\u001b[A\n",
            "6235it [14:40,  6.34it/s]\u001b[A\n",
            "6236it [14:40,  6.34it/s]\u001b[A\n",
            "6237it [14:40,  6.45it/s]\u001b[A\n",
            "6238it [14:40,  6.58it/s]\u001b[A\n",
            "6239it [14:40,  6.72it/s]\u001b[A\n",
            "6240it [14:40,  6.69it/s]\u001b[A\n",
            "6241it [14:41,  6.85it/s]\u001b[A\n",
            "6242it [14:41,  6.75it/s]\u001b[A\n",
            "6243it [14:41,  6.67it/s]\u001b[A\n",
            "6244it [14:41,  6.59it/s]\u001b[A\n",
            "6245it [14:41,  6.71it/s]\u001b[A\n",
            "6246it [14:41,  6.83it/s]\u001b[A\n",
            "6247it [14:41,  6.85it/s]\u001b[A\n",
            "6248it [14:42,  6.94it/s]\u001b[A\n",
            "6249it [14:42,  7.01it/s]\u001b[A\n",
            "6250it [14:42,  7.02it/s]\u001b[A\n",
            "6251it [14:42,  6.98it/s]\u001b[A\n",
            "6252it [14:42,  7.01it/s]\u001b[A\n",
            "6253it [14:42,  6.84it/s]\u001b[A\n",
            "6254it [14:43,  6.59it/s]\u001b[A\n",
            "6255it [14:43,  6.72it/s]\u001b[A\n",
            "6256it [14:43,  6.85it/s]\u001b[A\n",
            "6257it [14:43,  6.72it/s]\u001b[A\n",
            "6258it [14:43,  6.69it/s]\u001b[A\n",
            "6259it [14:43,  6.84it/s]\u001b[A\n",
            "6260it [14:43,  6.91it/s]\u001b[A\n",
            "6261it [14:44,  6.87it/s]\u001b[A\n",
            "6262it [14:44,  6.84it/s]\u001b[A\n",
            "6263it [14:44,  6.86it/s]\u001b[A\n",
            "6264it [14:44,  6.62it/s]\u001b[A\n",
            "6265it [14:44,  6.67it/s]\u001b[A\n",
            "6266it [14:44,  6.56it/s]\u001b[A\n",
            "6267it [14:44,  6.53it/s]\u001b[A\n",
            "6268it [14:45,  6.41it/s]\u001b[A\n",
            "6269it [14:45,  6.48it/s]\u001b[A\n",
            "6270it [14:45,  6.50it/s]\u001b[A\n",
            "6271it [14:45,  6.65it/s]\u001b[A\n",
            "6272it [14:45,  6.79it/s]\u001b[A\n",
            "6273it [14:45,  6.95it/s]\u001b[A\n",
            "6274it [14:45,  7.03it/s]\u001b[A\n",
            "6275it [14:46,  7.01it/s]\u001b[A\n",
            "6276it [14:46,  7.02it/s]\u001b[A\n",
            "6277it [14:46,  7.07it/s]\u001b[A\n",
            "6278it [14:46,  6.80it/s]\u001b[A\n",
            "6279it [14:46,  6.59it/s]\u001b[A\n",
            "6280it [14:46,  6.56it/s]\u001b[A\n",
            "6281it [14:47,  6.51it/s]\u001b[A\n",
            "6282it [14:47,  6.54it/s]\u001b[A\n",
            "6283it [14:47,  6.52it/s]\u001b[A\n",
            "6284it [14:47,  6.49it/s]\u001b[A\n",
            "6285it [14:47,  6.55it/s]\u001b[A\n",
            "6286it [14:47,  6.58it/s]\u001b[A\n",
            "6287it [14:47,  6.51it/s]\u001b[A\n",
            "6288it [14:48,  6.30it/s]\u001b[A\n",
            "6289it [14:48,  6.26it/s]\u001b[A\n",
            "6290it [14:48,  6.26it/s]\u001b[A\n",
            "6291it [14:48,  6.50it/s]\u001b[A\n",
            "6292it [14:48,  6.61it/s]\u001b[A\n",
            "6293it [14:48,  6.69it/s]\u001b[A\n",
            "6294it [14:49,  6.82it/s]\u001b[A\n",
            "6295it [14:49,  6.64it/s]\u001b[A\n",
            "6296it [14:49,  6.69it/s]\u001b[A\n",
            "6297it [14:49,  6.61it/s]\u001b[A\n",
            "6298it [14:49,  6.57it/s]\u001b[A\n",
            "6299it [14:49,  6.45it/s]\u001b[A\n",
            "6300it [14:49,  6.37it/s]\u001b[A\n",
            "6301it [14:50,  6.36it/s]\u001b[A\n",
            "6302it [14:50,  6.27it/s]\u001b[A\n",
            "6303it [14:50,  6.29it/s]\u001b[A\n",
            "6304it [14:50,  6.42it/s]\u001b[A\n",
            "6305it [14:50,  6.32it/s]\u001b[A\n",
            "6306it [14:50,  6.28it/s]\u001b[A\n",
            "6307it [14:51,  6.40it/s]\u001b[A\n",
            "6308it [14:51,  6.47it/s]\u001b[A\n",
            "6309it [14:51,  6.51it/s]\u001b[A\n",
            "6310it [14:51,  6.70it/s]\u001b[A\n",
            "6311it [14:51,  6.69it/s]\u001b[A\n",
            "6312it [14:51,  6.60it/s]\u001b[A\n",
            "6313it [14:51,  6.52it/s]\u001b[A\n",
            "6314it [14:52,  6.67it/s]\u001b[A\n",
            "6315it [14:52,  6.77it/s]\u001b[A\n",
            "6316it [14:52,  6.80it/s]\u001b[A\n",
            "6317it [14:52,  6.87it/s]\u001b[A\n",
            "6318it [14:52,  6.87it/s]\u001b[A\n",
            "6319it [14:52,  6.89it/s]\u001b[A\n",
            "6320it [14:52,  6.90it/s]\u001b[A\n",
            "6321it [14:53,  6.99it/s]\u001b[A\n",
            "6322it [14:53,  6.89it/s]\u001b[A\n",
            "6323it [14:53,  6.96it/s]\u001b[A\n",
            "6324it [14:53,  6.95it/s]\u001b[A\n",
            "6325it [14:53,  6.88it/s]\u001b[A\n",
            "6326it [14:53,  6.81it/s]\u001b[A\n",
            "6327it [14:53,  6.89it/s]\u001b[A\n",
            "6328it [14:54,  6.93it/s]\u001b[A\n",
            "6329it [14:54,  6.86it/s]\u001b[A\n",
            "6330it [14:54,  6.89it/s]\u001b[A\n",
            "6331it [14:54,  6.61it/s]\u001b[A\n",
            "6332it [14:54,  6.75it/s]\u001b[A\n",
            "6333it [14:54,  6.71it/s]\u001b[A\n",
            "6334it [14:55,  6.76it/s]\u001b[A\n",
            "6335it [14:55,  6.81it/s]\u001b[A\n",
            "6336it [14:55,  6.96it/s]\u001b[A\n",
            "6337it [14:55,  6.97it/s]\u001b[A\n",
            "6338it [14:55,  6.88it/s]\u001b[A\n",
            "6339it [14:55,  6.94it/s]\u001b[A\n",
            "6340it [14:55,  6.98it/s]\u001b[A\n",
            "6341it [14:56,  7.09it/s]\u001b[A\n",
            "6342it [14:56,  7.19it/s]\u001b[A\n",
            "6343it [14:56,  7.03it/s]\u001b[A\n",
            "6344it [14:56,  7.08it/s]\u001b[A\n",
            "6345it [14:56,  7.14it/s]\u001b[A\n",
            "6346it [14:56,  7.19it/s]\u001b[A\n",
            "6347it [14:56,  7.16it/s]\u001b[A\n",
            "6348it [14:56,  7.14it/s]\u001b[A\n",
            "6349it [14:57,  7.10it/s]\u001b[A\n",
            "6350it [14:57,  7.07it/s]\u001b[A\n",
            "6351it [14:57,  7.14it/s]\u001b[A\n",
            "6352it [14:57,  7.13it/s]\u001b[A\n",
            "6353it [14:57,  7.07it/s]\u001b[A\n",
            "6354it [14:57,  6.83it/s]\u001b[A\n",
            "6355it [14:58,  6.78it/s]\u001b[A\n",
            "6356it [14:58,  6.71it/s]\u001b[A\n",
            "6357it [14:58,  6.56it/s]\u001b[A\n",
            "6358it [14:58,  6.50it/s]\u001b[A\n",
            "6359it [14:58,  6.59it/s]\u001b[A\n",
            "6360it [14:58,  6.67it/s]\u001b[A\n",
            "6361it [14:58,  6.75it/s]\u001b[A\n",
            "6362it [14:59,  6.92it/s]\u001b[A\n",
            "6363it [14:59,  7.06it/s]\u001b[A\n",
            "6364it [14:59,  6.93it/s]\u001b[A\n",
            "6365it [14:59,  6.84it/s]\u001b[A\n",
            "6366it [14:59,  6.85it/s]\u001b[A\n",
            "6367it [14:59,  6.88it/s]\u001b[A\n",
            "6368it [14:59,  7.01it/s]\u001b[A\n",
            "6369it [15:00,  6.87it/s]\u001b[A\n",
            "6370it [15:00,  6.81it/s]\u001b[A\n",
            "6371it [15:00,  6.60it/s]\u001b[A\n",
            "6372it [15:00,  6.77it/s]\u001b[A\n",
            "6373it [15:00,  6.73it/s]\u001b[A\n",
            "6374it [15:00,  6.64it/s]\u001b[A\n",
            "6375it [15:00,  6.61it/s]\u001b[A\n",
            "6376it [15:01,  6.84it/s]\u001b[A\n",
            "6377it [15:01,  6.79it/s]\u001b[A\n",
            "6378it [15:01,  6.81it/s]\u001b[A\n",
            "6379it [15:01,  6.88it/s]\u001b[A\n",
            "6380it [15:01,  6.96it/s]\u001b[A\n",
            "6381it [15:01,  7.01it/s]\u001b[A\n",
            "6382it [15:01,  7.07it/s]\u001b[A\n",
            "6383it [15:02,  7.13it/s]\u001b[A\n",
            "6384it [15:02,  7.19it/s]\u001b[A\n",
            "6385it [15:02,  7.06it/s]\u001b[A\n",
            "6386it [15:02,  7.07it/s]\u001b[A\n",
            "6387it [15:02,  7.04it/s]\u001b[A\n",
            "6388it [15:02,  7.07it/s]\u001b[A\n",
            "6389it [15:02,  7.18it/s]\u001b[A\n",
            "6390it [15:03,  7.24it/s]\u001b[A\n",
            "6391it [15:03,  7.22it/s]\u001b[A\n",
            "6392it [15:03,  6.99it/s]\u001b[A\n",
            "6393it [15:03,  7.04it/s]\u001b[A\n",
            "6394it [15:03,  6.91it/s]\u001b[A\n",
            "6395it [15:03,  6.98it/s]\u001b[A\n",
            "6396it [15:03,  7.00it/s]\u001b[A\n",
            "6397it [15:04,  7.05it/s]\u001b[A\n",
            "6398it [15:04,  7.07it/s]\u001b[A\n",
            "6399it [15:04,  7.03it/s]\u001b[A\n",
            "6400it [15:04,  7.00it/s]\u001b[A\n",
            "6401it [15:04,  6.89it/s]\u001b[A\n",
            "6402it [15:04,  6.89it/s]\u001b[A\n",
            "6403it [15:04,  7.00it/s]\u001b[A\n",
            "6404it [15:05,  7.05it/s]\u001b[A\n",
            "6405it [15:05,  7.09it/s]\u001b[A\n",
            "6406it [15:05,  6.96it/s]\u001b[A\n",
            "6407it [15:05,  7.04it/s]\u001b[A\n",
            "6408it [15:05,  7.05it/s]\u001b[A\n",
            "6409it [15:05,  7.08it/s]\u001b[A\n",
            "6410it [15:05,  7.11it/s]\u001b[A\n",
            "6411it [15:06,  7.15it/s]\u001b[A\n",
            "6412it [15:06,  7.11it/s]\u001b[A\n",
            "6413it [15:06,  7.01it/s]\u001b[A\n",
            "6414it [15:06,  6.93it/s]\u001b[A\n",
            "6415it [15:06,  6.92it/s]\u001b[A\n",
            "6416it [15:06,  6.83it/s]\u001b[A\n",
            "6417it [15:06,  6.70it/s]\u001b[A\n",
            "6418it [15:07,  6.66it/s]\u001b[A\n",
            "6419it [15:07,  6.66it/s]\u001b[A\n",
            "6420it [15:07,  6.47it/s]\u001b[A\n",
            "6421it [15:07,  6.49it/s]\u001b[A\n",
            "6422it [15:07,  6.65it/s]\u001b[A\n",
            "6423it [15:07,  6.72it/s]\u001b[A\n",
            "6424it [15:08,  6.90it/s]\u001b[A\n",
            "6425it [15:08,  6.92it/s]\u001b[A\n",
            "6426it [15:08,  7.02it/s]\u001b[A\n",
            "6427it [15:08,  6.91it/s]\u001b[A\n",
            "6428it [15:08,  6.90it/s]\u001b[A\n",
            "6429it [15:08,  6.87it/s]\u001b[A\n",
            "6430it [15:08,  6.84it/s]\u001b[A\n",
            "6431it [15:09,  6.85it/s]\u001b[A\n",
            "6432it [15:09,  6.93it/s]\u001b[A\n",
            "6433it [15:09,  6.97it/s]\u001b[A\n",
            "6434it [15:09,  6.85it/s]\u001b[A\n",
            "6435it [15:09,  6.86it/s]\u001b[A\n",
            "6436it [15:09,  7.00it/s]\u001b[A\n",
            "6437it [15:09,  6.98it/s]\u001b[A\n",
            "6438it [15:10,  7.03it/s]\u001b[A\n",
            "6439it [15:10,  7.02it/s]\u001b[A\n",
            "6440it [15:10,  7.00it/s]\u001b[A\n",
            "6441it [15:10,  7.01it/s]\u001b[A\n",
            "6442it [15:10,  7.03it/s]\u001b[A\n",
            "6443it [15:10,  6.96it/s]\u001b[A\n",
            "6444it [15:10,  6.97it/s]\u001b[A\n",
            "6445it [15:11,  6.96it/s]\u001b[A\n",
            "6446it [15:11,  7.00it/s]\u001b[A\n",
            "6447it [15:11,  7.01it/s]\u001b[A\n",
            "6448it [15:11,  6.81it/s]\u001b[A\n",
            "6449it [15:11,  6.74it/s]\u001b[A\n",
            "6450it [15:11,  6.64it/s]\u001b[A\n",
            "6451it [15:11,  6.62it/s]\u001b[A\n",
            "6452it [15:12,  6.57it/s]\u001b[A\n",
            "6453it [15:12,  6.50it/s]\u001b[A\n",
            "6454it [15:12,  6.55it/s]\u001b[A\n",
            "6455it [15:12,  6.53it/s]\u001b[A\n",
            "6456it [15:12,  6.46it/s]\u001b[A\n",
            "6457it [15:12,  6.37it/s]\u001b[A\n",
            "6458it [15:13,  6.45it/s]\u001b[A\n",
            "6459it [15:13,  6.40it/s]\u001b[A\n",
            "6460it [15:13,  6.47it/s]\u001b[A\n",
            "6461it [15:13,  6.38it/s]\u001b[A\n",
            "6462it [15:13,  6.44it/s]\u001b[A\n",
            "6463it [15:13,  6.62it/s]\u001b[A\n",
            "6464it [15:13,  6.77it/s]\u001b[A\n",
            "6465it [15:14,  6.83it/s]\u001b[A\n",
            "6466it [15:14,  6.90it/s]\u001b[A\n",
            "6467it [15:14,  6.95it/s]\u001b[A\n",
            "6468it [15:14,  6.89it/s]\u001b[A\n",
            "6469it [15:14,  6.97it/s]\u001b[A\n",
            "6470it [15:14,  7.01it/s]\u001b[A\n",
            "6471it [15:14,  7.03it/s]\u001b[A\n",
            "6472it [15:15,  7.11it/s]\u001b[A\n",
            "6473it [15:15,  7.11it/s]\u001b[A\n",
            "6474it [15:15,  7.13it/s]\u001b[A\n",
            "6475it [15:15,  6.93it/s]\u001b[A\n",
            "6476it [15:15,  6.95it/s]\u001b[A\n",
            "6477it [15:15,  7.01it/s]\u001b[A\n",
            "6478it [15:15,  7.03it/s]\u001b[A\n",
            "6479it [15:16,  7.07it/s]\u001b[A\n",
            "6480it [15:16,  7.06it/s]\u001b[A\n",
            "6481it [15:16,  7.14it/s]\u001b[A\n",
            "6482it [15:16,  7.11it/s]\u001b[A\n",
            "6483it [15:16,  6.97it/s]\u001b[A\n",
            "6484it [15:16,  6.92it/s]\u001b[A\n",
            "6485it [15:16,  6.96it/s]\u001b[A\n",
            "6486it [15:17,  6.99it/s]\u001b[A\n",
            "6487it [15:17,  7.07it/s]\u001b[A\n",
            "6488it [15:17,  7.03it/s]\u001b[A\n",
            "6489it [15:17,  6.98it/s]\u001b[A\n",
            "6490it [15:17,  6.71it/s]\u001b[A\n",
            "6491it [15:17,  6.82it/s]\u001b[A\n",
            "6492it [15:17,  6.94it/s]\u001b[A\n",
            "6493it [15:18,  7.08it/s]\u001b[A\n",
            "6494it [15:18,  7.11it/s]\u001b[A\n",
            "6495it [15:18,  7.14it/s]\u001b[A\n",
            "6496it [15:18,  7.15it/s]\u001b[A\n",
            "6497it [15:18,  7.04it/s]\u001b[A\n",
            "6498it [15:18,  7.00it/s]\u001b[A\n",
            "6499it [15:18,  7.04it/s]\u001b[A\n",
            "6500it [15:19,  7.03it/s]\u001b[A\n",
            "6501it [15:19,  7.07it/s]\u001b[A\n",
            "6502it [15:19,  7.09it/s]\u001b[A\n",
            "6503it [15:19,  7.10it/s]\u001b[A\n",
            "6504it [15:19,  6.85it/s]\u001b[A\n",
            "6505it [15:19,  6.78it/s]\u001b[A\n",
            "6506it [15:19,  6.69it/s]\u001b[A\n",
            "6507it [15:20,  6.76it/s]\u001b[A\n",
            "6508it [15:20,  6.86it/s]\u001b[A\n",
            "6509it [15:20,  6.82it/s]\u001b[A\n",
            "6510it [15:20,  6.92it/s]\u001b[A\n",
            "6511it [15:20,  6.87it/s]\u001b[A\n",
            "6512it [15:20,  6.84it/s]\u001b[A\n",
            "6513it [15:20,  6.86it/s]\u001b[A\n",
            "6514it [15:21,  6.92it/s]\u001b[A\n",
            "6515it [15:21,  6.95it/s]\u001b[A\n",
            "6516it [15:21,  6.92it/s]\u001b[A\n",
            "6517it [15:21,  6.72it/s]\u001b[A\n",
            "6518it [15:21,  6.59it/s]\u001b[A\n",
            "6519it [15:21,  6.66it/s]\u001b[A\n",
            "6520it [15:21,  6.65it/s]\u001b[A\n",
            "6521it [15:22,  6.86it/s]\u001b[A\n",
            "6522it [15:22,  6.97it/s]\u001b[A\n",
            "6523it [15:22,  6.88it/s]\u001b[A\n",
            "6524it [15:22,  6.97it/s]\u001b[A\n",
            "6525it [15:22,  6.92it/s]\u001b[A\n",
            "6526it [15:22,  6.95it/s]\u001b[A\n",
            "6527it [15:22,  6.95it/s]\u001b[A\n",
            "6528it [15:23,  7.01it/s]\u001b[A\n",
            "6529it [15:23,  7.09it/s]\u001b[A\n",
            "6530it [15:23,  7.11it/s]\u001b[A\n",
            "6531it [15:23,  7.08it/s]\u001b[A\n",
            "6532it [15:23,  7.05it/s]\u001b[A\n",
            "6533it [15:23,  7.15it/s]\u001b[A\n",
            "6534it [15:23,  7.15it/s]\u001b[A\n",
            "6535it [15:24,  7.17it/s]\u001b[A\n",
            "6536it [15:24,  7.16it/s]\u001b[A\n",
            "6537it [15:24,  7.19it/s]\u001b[A\n",
            "6538it [15:24,  7.14it/s]\u001b[A\n",
            "6539it [15:24,  7.05it/s]\u001b[A\n",
            "6540it [15:24,  7.00it/s]\u001b[A\n",
            "6541it [15:24,  6.93it/s]\u001b[A\n",
            "6542it [15:25,  6.89it/s]\u001b[A\n",
            "6543it [15:25,  6.88it/s]\u001b[A\n",
            "6544it [15:25,  6.90it/s]\u001b[A\n",
            "6545it [15:25,  6.94it/s]\u001b[A\n",
            "6546it [15:25,  6.89it/s]\u001b[A\n",
            "6547it [15:25,  6.99it/s]\u001b[A\n",
            "6548it [15:25,  7.05it/s]\u001b[A\n",
            "6549it [15:26,  7.10it/s]\u001b[A\n",
            "6550it [15:26,  6.99it/s]\u001b[A\n",
            "6551it [15:26,  7.02it/s]\u001b[A\n",
            "6552it [15:26,  7.06it/s]\u001b[A\n",
            "6553it [15:26,  7.03it/s]\u001b[A\n",
            "6554it [15:26,  7.15it/s]\u001b[A\n",
            "6555it [15:26,  6.95it/s]\u001b[A\n",
            "6556it [15:27,  7.07it/s]\u001b[A\n",
            "6557it [15:27,  7.07it/s]\u001b[A\n",
            "6558it [15:27,  7.05it/s]\u001b[A\n",
            "6559it [15:27,  6.86it/s]\u001b[A\n",
            "6560it [15:27,  6.63it/s]\u001b[A\n",
            "6561it [15:27,  6.74it/s]\u001b[A\n",
            "6562it [15:27,  6.89it/s]\u001b[A\n",
            "6563it [15:28,  6.96it/s]\u001b[A\n",
            "6564it [15:28,  7.01it/s]\u001b[A\n",
            "6565it [15:28,  6.97it/s]\u001b[A\n",
            "6566it [15:28,  6.87it/s]\u001b[A\n",
            "6567it [15:28,  6.77it/s]\u001b[A\n",
            "6568it [15:28,  6.72it/s]\u001b[A\n",
            "6569it [15:29,  6.64it/s]\u001b[A\n",
            "6570it [15:29,  6.60it/s]\u001b[A\n",
            "6571it [15:29,  6.56it/s]\u001b[A\n",
            "6572it [15:29,  6.50it/s]\u001b[A\n",
            "6573it [15:29,  6.61it/s]\u001b[A\n",
            "6574it [15:29,  6.70it/s]\u001b[A\n",
            "6575it [15:29,  6.74it/s]\u001b[A\n",
            "6576it [15:30,  6.76it/s]\u001b[A\n",
            "6577it [15:30,  6.90it/s]\u001b[A\n",
            "6578it [15:30,  6.95it/s]\u001b[A\n",
            "6579it [15:30,  7.03it/s]\u001b[A\n",
            "6580it [15:30,  7.01it/s]\u001b[A\n",
            "6581it [15:30,  6.52it/s]\u001b[A\n",
            "6582it [15:30,  6.53it/s]\u001b[A\n",
            "6583it [15:31,  6.72it/s]\u001b[A\n",
            "6584it [15:31,  6.87it/s]\u001b[A\n",
            "6585it [15:31,  6.97it/s]\u001b[A\n",
            "6586it [15:31,  7.01it/s]\u001b[A\n",
            "6587it [15:31,  7.06it/s]\u001b[A\n",
            "6588it [15:31,  6.97it/s]\u001b[A\n",
            "6589it [15:31,  6.98it/s]\u001b[A\n",
            "6590it [15:32,  7.01it/s]\u001b[A\n",
            "6591it [15:32,  6.93it/s]\u001b[A\n",
            "6592it [15:32,  6.77it/s]\u001b[A\n",
            "6593it [15:32,  6.69it/s]\u001b[A\n",
            "6594it [15:32,  6.73it/s]\u001b[A\n",
            "6595it [15:32,  6.63it/s]\u001b[A\n",
            "6596it [15:32,  6.66it/s]\u001b[A\n",
            "6597it [15:33,  6.81it/s]\u001b[A\n",
            "6598it [15:33,  6.91it/s]\u001b[A\n",
            "6599it [15:33,  6.94it/s]\u001b[A\n",
            "6600it [15:33,  6.99it/s]\u001b[A\n",
            "6601it [15:33,  7.03it/s]\u001b[A\n",
            "6602it [15:33,  6.99it/s]\u001b[A\n",
            "6603it [15:33,  7.02it/s]\u001b[A\n",
            "6604it [15:34,  7.08it/s]\u001b[A\n",
            "6605it [15:34,  7.11it/s]\u001b[A\n",
            "6606it [15:34,  7.19it/s]\u001b[A\n",
            "6607it [15:34,  7.11it/s]\u001b[A\n",
            "6608it [15:34,  7.05it/s]\u001b[A\n",
            "6609it [15:34,  6.99it/s]\u001b[A\n",
            "6610it [15:34,  6.98it/s]\u001b[A\n",
            "6611it [15:35,  7.09it/s]\u001b[A\n",
            "6612it [15:35,  7.05it/s]\u001b[A\n",
            "6613it [15:35,  7.07it/s]\u001b[A\n",
            "6614it [15:35,  7.12it/s]\u001b[A\n",
            "6615it [15:35,  6.92it/s]\u001b[A\n",
            "6616it [15:35,  6.74it/s]\u001b[A\n",
            "6617it [15:35,  6.65it/s]\u001b[A\n",
            "6618it [15:36,  6.65it/s]\u001b[A\n",
            "6619it [15:36,  6.63it/s]\u001b[A\n",
            "6620it [15:36,  6.73it/s]\u001b[A\n",
            "6621it [15:36,  6.81it/s]\u001b[A\n",
            "6622it [15:36,  6.96it/s]\u001b[A\n",
            "6623it [15:36,  6.95it/s]\u001b[A\n",
            "6624it [15:36,  7.03it/s]\u001b[A\n",
            "6625it [15:37,  7.08it/s]\u001b[A\n",
            "6626it [15:37,  7.21it/s]\u001b[A\n",
            "6627it [15:37,  7.16it/s]\u001b[A\n",
            "6628it [15:37,  6.97it/s]\u001b[A\n",
            "6629it [15:37,  6.84it/s]\u001b[A\n",
            "6630it [15:37,  6.67it/s]\u001b[A\n",
            "6631it [15:38,  6.71it/s]\u001b[A\n",
            "6632it [15:38,  6.78it/s]\u001b[A\n",
            "6633it [15:38,  6.86it/s]\u001b[A\n",
            "6634it [15:38,  6.67it/s]\u001b[A\n",
            "6635it [15:38,  6.61it/s]\u001b[A\n",
            "6636it [15:38,  6.51it/s]\u001b[A\n",
            "6637it [15:38,  6.31it/s]\u001b[A\n",
            "6638it [15:39,  6.29it/s]\u001b[A\n",
            "6639it [15:39,  6.39it/s]\u001b[A\n",
            "6640it [15:39,  6.27it/s]\u001b[A\n",
            "6641it [15:39,  6.47it/s]\u001b[A\n",
            "6642it [15:39,  6.54it/s]\u001b[A\n",
            "6643it [15:39,  6.42it/s]\u001b[A\n",
            "6644it [15:40,  6.44it/s]\u001b[A\n",
            "6645it [15:40,  6.51it/s]\u001b[A\n",
            "6646it [15:40,  6.69it/s]\u001b[A\n",
            "6647it [15:40,  6.77it/s]\u001b[A\n",
            "6648it [15:40,  6.85it/s]\u001b[A\n",
            "6649it [15:40,  6.91it/s]\u001b[A\n",
            "6650it [15:40,  6.90it/s]\u001b[A\n",
            "6651it [15:41,  6.88it/s]\u001b[A\n",
            "6652it [15:41,  6.96it/s]\u001b[A\n",
            "6653it [15:41,  6.99it/s]\u001b[A\n",
            "6654it [15:41,  7.05it/s]\u001b[A\n",
            "6655it [15:41,  6.91it/s]\u001b[A\n",
            "6656it [15:41,  6.98it/s]\u001b[A\n",
            "6657it [15:41,  6.89it/s]\u001b[A\n",
            "6658it [15:42,  6.97it/s]\u001b[A\n",
            "6659it [15:42,  6.92it/s]\u001b[A\n",
            "6660it [15:42,  6.90it/s]\u001b[A\n",
            "6661it [15:42,  7.03it/s]\u001b[A\n",
            "6662it [15:42,  6.98it/s]\u001b[A\n",
            "6663it [15:42,  6.94it/s]\u001b[A\n",
            "6664it [15:42,  6.89it/s]\u001b[A\n",
            "6665it [15:43,  6.93it/s]\u001b[A\n",
            "6666it [15:43,  7.03it/s]\u001b[A\n",
            "6667it [15:43,  7.00it/s]\u001b[A\n",
            "6668it [15:43,  7.07it/s]\u001b[A\n",
            "6669it [15:43,  6.96it/s]\u001b[A\n",
            "6670it [15:43,  6.99it/s]\u001b[A\n",
            "6671it [15:43,  6.93it/s]\u001b[A\n",
            "6672it [15:44,  6.92it/s]\u001b[A\n",
            "6673it [15:44,  6.99it/s]\u001b[A\n",
            "6674it [15:44,  7.09it/s]\u001b[A\n",
            "6675it [15:44,  6.98it/s]\u001b[A\n",
            "6676it [15:44,  7.01it/s]\u001b[A\n",
            "6677it [15:44,  7.07it/s]\u001b[A\n",
            "6678it [15:44,  7.04it/s]\u001b[A\n",
            "6679it [15:45,  7.09it/s]\u001b[A\n",
            "6680it [15:45,  7.12it/s]\u001b[A\n",
            "6681it [15:45,  7.20it/s]\u001b[A\n",
            "6682it [15:45,  7.02it/s]\u001b[A\n",
            "6683it [15:45,  6.85it/s]\u001b[A\n",
            "6684it [15:45,  6.95it/s]\u001b[A\n",
            "6685it [15:45,  7.02it/s]\u001b[A\n",
            "6686it [15:46,  6.95it/s]\u001b[A\n",
            "6687it [15:46,  7.03it/s]\u001b[A\n",
            "6688it [15:46,  7.04it/s]\u001b[A\n",
            "6689it [15:46,  7.00it/s]\u001b[A\n",
            "6690it [15:46,  6.93it/s]\u001b[A\n",
            "6691it [15:46,  6.90it/s]\u001b[A\n",
            "6692it [15:46,  6.98it/s]\u001b[A\n",
            "6693it [15:47,  6.98it/s]\u001b[A\n",
            "6694it [15:47,  6.92it/s]\u001b[A\n",
            "6695it [15:47,  6.95it/s]\u001b[A\n",
            "6696it [15:47,  7.03it/s]\u001b[A\n",
            "6697it [15:47,  7.05it/s]\u001b[A\n",
            "6698it [15:47,  7.03it/s]\u001b[A\n",
            "6699it [15:47,  6.98it/s]\u001b[A\n",
            "6700it [15:48,  6.88it/s]\u001b[A\n",
            "6701it [15:48,  6.95it/s]\u001b[A\n",
            "6702it [15:48,  7.02it/s]\u001b[A\n",
            "6703it [15:48,  7.03it/s]\u001b[A\n",
            "6704it [15:48,  7.07it/s]\u001b[A\n",
            "6705it [15:48,  7.11it/s]\u001b[A\n",
            "6706it [15:48,  7.07it/s]\u001b[A\n",
            "6707it [15:49,  7.00it/s]\u001b[A\n",
            "6708it [15:49,  6.99it/s]\u001b[A\n",
            "6709it [15:49,  7.05it/s]\u001b[A\n",
            "6710it [15:49,  6.90it/s]\u001b[A\n",
            "6711it [15:49,  6.84it/s]\u001b[A\n",
            "6712it [15:49,  6.69it/s]\u001b[A\n",
            "6713it [15:49,  6.79it/s]\u001b[A\n",
            "6714it [15:50,  6.86it/s]\u001b[A\n",
            "6715it [15:50,  6.96it/s]\u001b[A\n",
            "6716it [15:50,  6.98it/s]\u001b[A\n",
            "6717it [15:50,  6.67it/s]\u001b[A\n",
            "6718it [15:50,  6.58it/s]\u001b[A\n",
            "6719it [15:50,  6.60it/s]\u001b[A\n",
            "6720it [15:50,  6.69it/s]\u001b[A\n",
            "6721it [15:51,  6.71it/s]\u001b[A\n",
            "6722it [15:51,  6.82it/s]\u001b[A\n",
            "6723it [15:51,  6.94it/s]\u001b[A\n",
            "6724it [15:51,  7.02it/s]\u001b[A\n",
            "6725it [15:51,  6.88it/s]\u001b[A\n",
            "6726it [15:51,  6.74it/s]\u001b[A\n",
            "6727it [15:51,  6.69it/s]\u001b[A\n",
            "6728it [15:52,  6.67it/s]\u001b[A\n",
            "6729it [15:52,  6.63it/s]\u001b[A\n",
            "6730it [15:52,  6.66it/s]\u001b[A\n",
            "6731it [15:52,  6.80it/s]\u001b[A\n",
            "6732it [15:52,  6.78it/s]\u001b[A\n",
            "6733it [15:52,  6.96it/s]\u001b[A\n",
            "6734it [15:53,  7.00it/s]\u001b[A\n",
            "6735it [15:53,  6.91it/s]\u001b[A\n",
            "6736it [15:53,  7.03it/s]\u001b[A\n",
            "6737it [15:53,  7.04it/s]\u001b[A\n",
            "6738it [15:53,  7.01it/s]\u001b[A\n",
            "6739it [15:53,  7.05it/s]\u001b[A\n",
            "6740it [15:53,  7.07it/s]\u001b[A\n",
            "6741it [15:54,  7.11it/s]\u001b[A\n",
            "6742it [15:54,  7.01it/s]\u001b[A\n",
            "6743it [15:54,  7.06it/s]\u001b[A\n",
            "6744it [15:54,  7.04it/s]\u001b[A\n",
            "6745it [15:54,  7.01it/s]\u001b[A\n",
            "6746it [15:54,  6.84it/s]\u001b[A\n",
            "6747it [15:54,  6.84it/s]\u001b[A\n",
            "6748it [15:55,  6.72it/s]\u001b[A\n",
            "6749it [15:55,  6.73it/s]\u001b[A\n",
            "6750it [15:55,  6.86it/s]\u001b[A\n",
            "6751it [15:55,  6.92it/s]\u001b[A\n",
            "6752it [15:55,  6.98it/s]\u001b[A\n",
            "6753it [15:55,  7.02it/s]\u001b[A\n",
            "6754it [15:55,  7.09it/s]\u001b[A\n",
            "6755it [15:56,  7.14it/s]\u001b[A\n",
            "6756it [15:56,  6.98it/s]\u001b[A\n",
            "6757it [15:56,  6.94it/s]\u001b[A\n",
            "6758it [15:56,  7.04it/s]\u001b[A\n",
            "6759it [15:56,  7.02it/s]\u001b[A\n",
            "6760it [15:56,  7.03it/s]\u001b[A\n",
            "6761it [15:56,  7.03it/s]\u001b[A\n",
            "6762it [15:57,  7.06it/s]\u001b[A\n",
            "6763it [15:57,  6.99it/s]\u001b[A\n",
            "6764it [15:57,  7.12it/s]\u001b[A\n",
            "6765it [15:57,  6.99it/s]\u001b[A\n",
            "6766it [15:57,  7.03it/s]\u001b[A\n",
            "6767it [15:57,  6.85it/s]\u001b[A\n",
            "6768it [15:57,  6.74it/s]\u001b[A\n",
            "6769it [15:58,  6.71it/s]\u001b[A\n",
            "6770it [15:58,  6.51it/s]\u001b[A\n",
            "6771it [15:58,  6.65it/s]\u001b[A\n",
            "6772it [15:58,  6.78it/s]\u001b[A\n",
            "6773it [15:58,  6.83it/s]\u001b[A\n",
            "6774it [15:58,  6.82it/s]\u001b[A\n",
            "6775it [15:58,  6.87it/s]\u001b[A\n",
            "6776it [15:59,  6.86it/s]\u001b[A\n",
            "6777it [15:59,  6.81it/s]\u001b[A\n",
            "6778it [15:59,  6.81it/s]\u001b[A\n",
            "6779it [15:59,  6.87it/s]\u001b[A\n",
            "6780it [15:59,  6.99it/s]\u001b[A\n",
            "6781it [15:59,  7.05it/s]\u001b[A\n",
            "6782it [15:59,  7.14it/s]\u001b[A\n",
            "6783it [16:00,  7.19it/s]\u001b[A\n",
            "6784it [16:00,  7.08it/s]\u001b[A\n",
            "6785it [16:00,  6.73it/s]\u001b[A\n",
            "6786it [16:00,  6.59it/s]\u001b[A\n",
            "6787it [16:00,  6.67it/s]\u001b[A\n",
            "6788it [16:00,  6.73it/s]\u001b[A\n",
            "6789it [16:00,  6.78it/s]\u001b[A\n",
            "6790it [16:01,  6.85it/s]\u001b[A\n",
            "6791it [16:01,  6.84it/s]\u001b[A\n",
            "6792it [16:01,  6.96it/s]\u001b[A\n",
            "6793it [16:01,  6.76it/s]\u001b[A\n",
            "6794it [16:01,  6.59it/s]\u001b[A\n",
            "6795it [16:01,  6.60it/s]\u001b[A\n",
            "6796it [16:02,  6.58it/s]\u001b[A\n",
            "6797it [16:02,  6.60it/s]\u001b[A\n",
            "6798it [16:02,  6.61it/s]\u001b[A\n",
            "6799it [16:02,  6.71it/s]\u001b[A\n",
            "6800it [16:02,  6.77it/s]\u001b[A\n",
            "6801it [16:02,  6.74it/s]\u001b[A\n",
            "6802it [16:02,  6.59it/s]\u001b[A\n",
            "6803it [16:03,  6.69it/s]\u001b[A\n",
            "6804it [16:03,  6.74it/s]\u001b[A\n",
            "6805it [16:03,  6.80it/s]\u001b[A\n",
            "6806it [16:03,  6.62it/s]\u001b[A\n",
            "6807it [16:03,  6.58it/s]\u001b[A\n",
            "6808it [16:03,  6.76it/s]\u001b[A\n",
            "6809it [16:03,  6.80it/s]\u001b[A\n",
            "6810it [16:04,  6.87it/s]\u001b[A\n",
            "6811it [16:04,  6.93it/s]\u001b[A\n",
            "6812it [16:04,  6.97it/s]\u001b[A\n",
            "6813it [16:04,  6.90it/s]\u001b[A\n",
            "6814it [16:04,  6.93it/s]\u001b[A\n",
            "6815it [16:04,  7.02it/s]\u001b[A\n",
            "6816it [16:04,  7.08it/s]\u001b[A\n",
            "6817it [16:05,  7.01it/s]\u001b[A\n",
            "6818it [16:05,  6.92it/s]\u001b[A\n",
            "6819it [16:05,  6.94it/s]\u001b[A\n",
            "6820it [16:05,  6.84it/s]\u001b[A\n",
            "6821it [16:05,  6.93it/s]\u001b[A\n",
            "6822it [16:05,  6.98it/s]\u001b[A\n",
            "6823it [16:05,  6.94it/s]\u001b[A\n",
            "6824it [16:06,  6.98it/s]\u001b[A\n",
            "6825it [16:06,  6.89it/s]\u001b[A\n",
            "6826it [16:06,  6.94it/s]\u001b[A\n",
            "6827it [16:06,  6.88it/s]\u001b[A\n",
            "6828it [16:06,  6.90it/s]\u001b[A\n",
            "6829it [16:06,  6.96it/s]\u001b[A\n",
            "6830it [16:06,  6.87it/s]\u001b[A\n",
            "6831it [16:07,  7.00it/s]\u001b[A\n",
            "6832it [16:07,  6.87it/s]\u001b[A\n",
            "6833it [16:07,  6.92it/s]\u001b[A\n",
            "6834it [16:07,  6.90it/s]\u001b[A\n",
            "6835it [16:07,  6.79it/s]\u001b[A\n",
            "6836it [16:07,  6.95it/s]\u001b[A\n",
            "6837it [16:07,  6.99it/s]\u001b[A\n",
            "6838it [16:08,  7.06it/s]\u001b[A\n",
            "6839it [16:08,  6.99it/s]\u001b[A\n",
            "6840it [16:08,  7.04it/s]\u001b[A\n",
            "6841it [16:08,  7.10it/s]\u001b[A\n",
            "6842it [16:08,  7.02it/s]\u001b[A\n",
            "6843it [16:08,  6.99it/s]\u001b[A\n",
            "6844it [16:08,  7.06it/s]\u001b[A\n",
            "6845it [16:09,  7.00it/s]\u001b[A\n",
            "6846it [16:09,  6.89it/s]\u001b[A\n",
            "6847it [16:09,  6.90it/s]\u001b[A\n",
            "6848it [16:09,  6.86it/s]\u001b[A\n",
            "6849it [16:09,  6.84it/s]\u001b[A\n",
            "6850it [16:09,  6.92it/s]\u001b[A\n",
            "6851it [16:09,  7.07it/s]\u001b[A\n",
            "6852it [16:10,  7.17it/s]\u001b[A\n",
            "6853it [16:10,  7.13it/s]\u001b[A\n",
            "6854it [16:10,  7.02it/s]\u001b[A\n",
            "6855it [16:10,  6.98it/s]\u001b[A\n",
            "6856it [16:10,  6.98it/s]\u001b[A\n",
            "6857it [16:10,  6.72it/s]\u001b[A\n",
            "6858it [16:11,  6.66it/s]\u001b[A\n",
            "6859it [16:11,  6.64it/s]\u001b[A\n",
            "6860it [16:11,  6.46it/s]\u001b[A\n",
            "6861it [16:11,  6.57it/s]\u001b[A\n",
            "6862it [16:11,  6.68it/s]\u001b[A\n",
            "6863it [16:11,  6.66it/s]\u001b[A\n",
            "6864it [16:11,  6.78it/s]\u001b[A\n",
            "6865it [16:12,  6.82it/s]\u001b[A\n",
            "6866it [16:12,  6.84it/s]\u001b[A\n",
            "6867it [16:12,  6.81it/s]\u001b[A\n",
            "6868it [16:12,  6.62it/s]\u001b[A\n",
            "6869it [16:12,  6.59it/s]\u001b[A\n",
            "6870it [16:12,  6.61it/s]\u001b[A\n",
            "6871it [16:12,  6.55it/s]\u001b[A\n",
            "6872it [16:13,  6.72it/s]\u001b[A\n",
            "6873it [16:13,  6.78it/s]\u001b[A\n",
            "6874it [16:13,  6.75it/s]\u001b[A\n",
            "6875it [16:13,  6.74it/s]\u001b[A\n",
            "6876it [16:13,  6.69it/s]\u001b[A\n",
            "6877it [16:13,  6.68it/s]\u001b[A\n",
            "6878it [16:13,  6.79it/s]\u001b[A\n",
            "6879it [16:14,  6.65it/s]\u001b[A\n",
            "6880it [16:14,  6.53it/s]\u001b[A\n",
            "6881it [16:14,  6.53it/s]\u001b[A\n",
            "6882it [16:14,  6.73it/s]\u001b[A\n",
            "6883it [16:14,  6.69it/s]\u001b[A\n",
            "6884it [16:14,  6.61it/s]\u001b[A\n",
            "6885it [16:15,  6.57it/s]\u001b[A\n",
            "6886it [16:15,  6.48it/s]\u001b[A\n",
            "6887it [16:15,  6.37it/s]\u001b[A\n",
            "6888it [16:15,  6.42it/s]\u001b[A\n",
            "6889it [16:15,  6.61it/s]\u001b[A\n",
            "6890it [16:15,  6.58it/s]\u001b[A\n",
            "6891it [16:15,  6.50it/s]\u001b[A\n",
            "6892it [16:16,  6.66it/s]\u001b[A\n",
            "6893it [16:16,  6.82it/s]\u001b[A\n",
            "6894it [16:16,  6.90it/s]\u001b[A\n",
            "6895it [16:16,  7.07it/s]\u001b[A\n",
            "6896it [16:16,  7.04it/s]\u001b[A\n",
            "6897it [16:16,  6.89it/s]\u001b[A\n",
            "6898it [16:16,  6.92it/s]\u001b[A\n",
            "6899it [16:17,  7.02it/s]\u001b[A\n",
            "6900it [16:17,  6.96it/s]\u001b[A\n",
            "6901it [16:17,  6.74it/s]\u001b[A\n",
            "6902it [16:17,  6.64it/s]\u001b[A\n",
            "6903it [16:17,  6.75it/s]\u001b[A\n",
            "6904it [16:17,  6.86it/s]\u001b[A\n",
            "6905it [16:18,  6.99it/s]\u001b[A\n",
            "6906it [16:18,  7.03it/s]\u001b[A\n",
            "6907it [16:18,  6.99it/s]\u001b[A\n",
            "6908it [16:18,  6.92it/s]\u001b[A\n",
            "6909it [16:18,  6.44it/s]\u001b[A\n",
            "6910it [16:18,  6.48it/s]\u001b[A\n",
            "6911it [16:18,  6.53it/s]\u001b[A\n",
            "6912it [16:19,  6.58it/s]\u001b[A\n",
            "6913it [16:19,  6.76it/s]\u001b[A\n",
            "6914it [16:19,  6.85it/s]\u001b[A\n",
            "6915it [16:19,  6.92it/s]\u001b[A\n",
            "6916it [16:19,  6.92it/s]\u001b[A\n",
            "6917it [16:19,  6.94it/s]\u001b[A\n",
            "6918it [16:19,  6.99it/s]\u001b[A\n",
            "6919it [16:20,  6.97it/s]\u001b[A\n",
            "6920it [16:20,  7.04it/s]\u001b[A\n",
            "6921it [16:20,  7.02it/s]\u001b[A\n",
            "6922it [16:20,  7.00it/s]\u001b[A\n",
            "6923it [16:20,  6.91it/s]\u001b[A\n",
            "6924it [16:20,  6.81it/s]\u001b[A\n",
            "6925it [16:20,  6.85it/s]\u001b[A\n",
            "6926it [16:21,  6.97it/s]\u001b[A\n",
            "6927it [16:21,  7.02it/s]\u001b[A\n",
            "6928it [16:21,  7.02it/s]\u001b[A\n",
            "6929it [16:21,  6.98it/s]\u001b[A\n",
            "6930it [16:21,  6.82it/s]\u001b[A\n",
            "6931it [16:21,  6.72it/s]\u001b[A\n",
            "6932it [16:21,  6.61it/s]\u001b[A\n",
            "6933it [16:22,  6.56it/s]\u001b[A\n",
            "6934it [16:22,  6.51it/s]\u001b[A\n",
            "6935it [16:22,  6.58it/s]\u001b[A\n",
            "6936it [16:22,  6.63it/s]\u001b[A\n",
            "6937it [16:22,  6.51it/s]\u001b[A\n",
            "6938it [16:22,  6.46it/s]\u001b[A\n",
            "6939it [16:23,  6.62it/s]\u001b[A\n",
            "6940it [16:23,  6.69it/s]\u001b[A\n",
            "6941it [16:23,  6.85it/s]\u001b[A\n",
            "6942it [16:23,  6.98it/s]\u001b[A\n",
            "6943it [16:23,  6.77it/s]\u001b[A\n",
            "6944it [16:23,  6.66it/s]\u001b[A\n",
            "6945it [16:23,  6.79it/s]\u001b[A\n",
            "6946it [16:24,  6.92it/s]\u001b[A\n",
            "6947it [16:24,  7.00it/s]\u001b[A\n",
            "6948it [16:24,  7.11it/s]\u001b[A\n",
            "6949it [16:24,  7.09it/s]\u001b[A\n",
            "6950it [16:24,  6.91it/s]\u001b[A\n",
            "6951it [16:24,  7.00it/s]\u001b[A\n",
            "6952it [16:24,  7.02it/s]\u001b[A\n",
            "6953it [16:25,  7.10it/s]\u001b[A\n",
            "6954it [16:25,  7.19it/s]\u001b[A\n",
            "6955it [16:25,  7.19it/s]\u001b[A\n",
            "6956it [16:25,  7.13it/s]\u001b[A\n",
            "6957it [16:25,  6.99it/s]\u001b[A\n",
            "6958it [16:25,  7.04it/s]\u001b[A\n",
            "6959it [16:25,  7.06it/s]\u001b[A\n",
            "6960it [16:26,  7.06it/s]\u001b[A\n",
            "6961it [16:26,  7.03it/s]\u001b[A\n",
            "6962it [16:26,  6.76it/s]\u001b[A\n",
            "6963it [16:26,  6.81it/s]\u001b[A\n",
            "6964it [16:26,  6.69it/s]\u001b[A\n",
            "6965it [16:26,  6.80it/s]\u001b[A\n",
            "6966it [16:26,  6.91it/s]\u001b[A\n",
            "6967it [16:27,  6.98it/s]\u001b[A\n",
            "6968it [16:27,  7.00it/s]\u001b[A\n",
            "6969it [16:27,  6.98it/s]\u001b[A\n",
            "6970it [16:27,  6.92it/s]\u001b[A\n",
            "6971it [16:27,  6.71it/s]\u001b[A\n",
            "6972it [16:27,  6.81it/s]\u001b[A\n",
            "6973it [16:27,  6.79it/s]\u001b[A\n",
            "6974it [16:28,  6.84it/s]\u001b[A\n",
            "6975it [16:28,  6.94it/s]\u001b[A\n",
            "6976it [16:28,  7.03it/s]\u001b[A\n",
            "6977it [16:28,  7.13it/s]\u001b[A\n",
            "6978it [16:28,  6.98it/s]\u001b[A\n",
            "6979it [16:28,  6.82it/s]\u001b[A\n",
            "6980it [16:28,  6.85it/s]\u001b[A\n",
            "6981it [16:29,  6.87it/s]\u001b[A\n",
            "6982it [16:29,  6.93it/s]\u001b[A\n",
            "6983it [16:29,  7.00it/s]\u001b[A\n",
            "6984it [16:29,  6.98it/s]\u001b[A\n",
            "6985it [16:29,  6.95it/s]\u001b[A\n",
            "6986it [16:29,  6.76it/s]\u001b[A\n",
            "6987it [16:29,  6.62it/s]\u001b[A\n",
            "6988it [16:30,  6.77it/s]\u001b[A\n",
            "6989it [16:30,  6.82it/s]\u001b[A\n",
            "6990it [16:30,  6.90it/s]\u001b[A\n",
            "6991it [16:30,  6.75it/s]\u001b[A\n",
            "6992it [16:30,  6.76it/s]\u001b[A\n",
            "6993it [16:30,  6.79it/s]\u001b[A\n",
            "6994it [16:30,  6.71it/s]\u001b[A\n",
            "6995it [16:31,  6.70it/s]\u001b[A\n",
            "6996it [16:31,  6.76it/s]\u001b[A\n",
            "6997it [16:31,  6.87it/s]\u001b[A\n",
            "6998it [16:31,  6.93it/s]\u001b[A\n",
            "6999it [16:31,  6.89it/s]\u001b[A\n",
            "7000it [16:31,  6.89it/s]\u001b[A\n",
            "7001it [16:32,  6.89it/s]\u001b[A\n",
            "7002it [16:32,  7.03it/s]\u001b[A\n",
            "7003it [16:32,  6.86it/s]\u001b[A\n",
            "7004it [16:32,  6.82it/s]\u001b[A\n",
            "7005it [16:32,  6.96it/s]\u001b[A\n",
            "7006it [16:32,  6.83it/s]\u001b[A\n",
            "7007it [16:32,  6.59it/s]\u001b[A\n",
            "7008it [16:33,  6.62it/s]\u001b[A\n",
            "7009it [16:33,  6.82it/s]\u001b[A\n",
            "7010it [16:33,  6.85it/s]\u001b[A\n",
            "7011it [16:33,  6.58it/s]\u001b[A\n",
            "7012it [16:33,  6.41it/s]\u001b[A\n",
            "7013it [16:33,  6.63it/s]\u001b[A\n",
            "7014it [16:33,  6.72it/s]\u001b[A\n",
            "7015it [16:34,  6.66it/s]\u001b[A\n",
            "7016it [16:34,  6.75it/s]\u001b[A\n",
            "7017it [16:34,  6.78it/s]\u001b[A\n",
            "7018it [16:34,  6.72it/s]\u001b[A\n",
            "7019it [16:34,  6.79it/s]\u001b[A\n",
            "7020it [16:34,  6.91it/s]\u001b[A\n",
            "7021it [16:34,  6.99it/s]\u001b[A\n",
            "7022it [16:35,  7.05it/s]\u001b[A\n",
            "7023it [16:35,  7.05it/s]\u001b[A\n",
            "7024it [16:35,  7.03it/s]\u001b[A\n",
            "7025it [16:35,  7.00it/s]\u001b[A\n",
            "7026it [16:35,  7.03it/s]\u001b[A\n",
            "7027it [16:35,  6.94it/s]\u001b[A\n",
            "7028it [16:35,  7.01it/s]\u001b[A\n",
            "7029it [16:36,  6.97it/s]\u001b[A\n",
            "7030it [16:36,  7.10it/s]\u001b[A\n",
            "7031it [16:36,  7.11it/s]\u001b[A\n",
            "7032it [16:36,  7.09it/s]\u001b[A\n",
            "7033it [16:36,  7.05it/s]\u001b[A\n",
            "7034it [16:36,  6.93it/s]\u001b[A\n",
            "7035it [16:36,  6.78it/s]\u001b[A\n",
            "7036it [16:37,  6.83it/s]\u001b[A\n",
            "7037it [16:37,  6.89it/s]\u001b[A\n",
            "7038it [16:37,  6.96it/s]\u001b[A\n",
            "7039it [16:37,  6.91it/s]\u001b[A\n",
            "7040it [16:37,  6.57it/s]\u001b[A\n",
            "7041it [16:37,  6.54it/s]\u001b[A\n",
            "7042it [16:38,  6.58it/s]\u001b[A\n",
            "7043it [16:38,  6.71it/s]\u001b[A\n",
            "7044it [16:38,  6.79it/s]\u001b[A\n",
            "7045it [16:38,  6.71it/s]\u001b[A\n",
            "7046it [16:38,  6.50it/s]\u001b[A\n",
            "7047it [16:38,  6.16it/s]\u001b[A\n",
            "7048it [16:38,  6.05it/s]\u001b[A\n",
            "7049it [16:39,  6.17it/s]\u001b[A\n",
            "7050it [16:39,  6.31it/s]\u001b[A\n",
            "7051it [16:39,  6.40it/s]\u001b[A\n",
            "7052it [16:39,  6.49it/s]\u001b[A\n",
            "7053it [16:39,  6.65it/s]\u001b[A\n",
            "7054it [16:39,  6.68it/s]\u001b[A\n",
            "7055it [16:40,  6.79it/s]\u001b[A\n",
            "7056it [16:40,  6.93it/s]\u001b[A\n",
            "7057it [16:40,  6.80it/s]\u001b[A\n",
            "7058it [16:40,  6.86it/s]\u001b[A\n",
            "7059it [16:40,  6.93it/s]\u001b[A\n",
            "7060it [16:40,  6.71it/s]\u001b[A\n",
            "7061it [16:40,  6.63it/s]\u001b[A\n",
            "7062it [16:41,  6.67it/s]\u001b[A\n",
            "7063it [16:41,  6.86it/s]\u001b[A\n",
            "7064it [16:41,  6.87it/s]\u001b[A\n",
            "7065it [16:41,  6.82it/s]\u001b[A\n",
            "7066it [16:41,  6.82it/s]\u001b[A\n",
            "7067it [16:41,  6.64it/s]\u001b[A\n",
            "7068it [16:41,  6.60it/s]\u001b[A\n",
            "7069it [16:42,  6.78it/s]\u001b[A\n",
            "7070it [16:42,  6.74it/s]\u001b[A\n",
            "7071it [16:42,  6.75it/s]\u001b[A\n",
            "7072it [16:42,  6.79it/s]\u001b[A\n",
            "7073it [16:42,  6.71it/s]\u001b[A\n",
            "7074it [16:42,  6.48it/s]\u001b[A\n",
            "7075it [16:42,  6.46it/s]\u001b[A\n",
            "7076it [16:43,  6.66it/s]\u001b[A\n",
            "7077it [16:43,  6.78it/s]\u001b[A\n",
            "7078it [16:43,  6.82it/s]\u001b[A\n",
            "7079it [16:43,  6.84it/s]\u001b[A\n",
            "7080it [16:43,  6.82it/s]\u001b[A\n",
            "7081it [16:43,  6.88it/s]\u001b[A\n",
            "7082it [16:44,  6.88it/s]\u001b[A\n",
            "7083it [16:44,  6.93it/s]\u001b[A\n",
            "7084it [16:44,  6.91it/s]\u001b[A\n",
            "7085it [16:44,  6.90it/s]\u001b[A\n",
            "7086it [16:44,  6.95it/s]\u001b[A\n",
            "7087it [16:44,  7.02it/s]\u001b[A\n",
            "7088it [16:44,  6.86it/s]\u001b[A\n",
            "7089it [16:45,  6.87it/s]\u001b[A\n",
            "7090it [16:45,  6.99it/s]\u001b[A\n",
            "7091it [16:45,  7.10it/s]\u001b[A\n",
            "7092it [16:45,  7.12it/s]\u001b[A\n",
            "7093it [16:45,  7.09it/s]\u001b[A\n",
            "7094it [16:45,  7.21it/s]\u001b[A\n",
            "7095it [16:45,  7.15it/s]\u001b[A\n",
            "7096it [16:45,  7.10it/s]\u001b[A\n",
            "7097it [16:46,  7.17it/s]\u001b[A\n",
            "7098it [16:46,  7.15it/s]\u001b[A\n",
            "7099it [16:46,  7.10it/s]\u001b[A\n",
            "7100it [16:46,  7.01it/s]\u001b[A\n",
            "7101it [16:46,  6.76it/s]\u001b[A\n",
            "7102it [16:46,  6.54it/s]\u001b[A\n",
            "7103it [16:47,  6.48it/s]\u001b[A\n",
            "7104it [16:47,  6.54it/s]\u001b[A\n",
            "7105it [16:47,  6.55it/s]\u001b[A\n",
            "7106it [16:47,  6.58it/s]\u001b[A\n",
            "7107it [16:47,  6.55it/s]\u001b[A\n",
            "7108it [16:47,  6.51it/s]\u001b[A\n",
            "7109it [16:47,  6.41it/s]\u001b[A\n",
            "7110it [16:48,  6.57it/s]\u001b[A\n",
            "7111it [16:48,  6.77it/s]\u001b[A\n",
            "7112it [16:48,  6.84it/s]\u001b[A\n",
            "7113it [16:48,  6.82it/s]\u001b[A\n",
            "7114it [16:48,  6.91it/s]\u001b[A\n",
            "7115it [16:48,  6.85it/s]\u001b[A\n",
            "7116it [16:48,  6.60it/s]\u001b[A\n",
            "7117it [16:49,  6.56it/s]\u001b[A\n",
            "7118it [16:49,  6.54it/s]\u001b[A\n",
            "7119it [16:49,  6.52it/s]\u001b[A\n",
            "7120it [16:49,  6.51it/s]\u001b[A\n",
            "7121it [16:49,  6.61it/s]\u001b[A\n",
            "7122it [16:49,  6.73it/s]\u001b[A\n",
            "7123it [16:50,  6.87it/s]\u001b[A\n",
            "7124it [16:50,  6.92it/s]\u001b[A\n",
            "7125it [16:50,  7.01it/s]\u001b[A\n",
            "7126it [16:50,  7.02it/s]\u001b[A\n",
            "7127it [16:50,  6.94it/s]\u001b[A\n",
            "7128it [16:50,  6.91it/s]\u001b[A\n",
            "7129it [16:50,  6.79it/s]\u001b[A\n",
            "7130it [16:51,  6.77it/s]\u001b[A\n",
            "7131it [16:51,  6.83it/s]\u001b[A\n",
            "7132it [16:51,  6.87it/s]\u001b[A\n",
            "7133it [16:51,  6.90it/s]\u001b[A\n",
            "7134it [16:51,  6.88it/s]\u001b[A\n",
            "7135it [16:51,  7.00it/s]\u001b[A\n",
            "7136it [16:51,  7.09it/s]\u001b[A\n",
            "7137it [16:52,  6.98it/s]\u001b[A\n",
            "7138it [16:52,  7.06it/s]\u001b[A\n",
            "7139it [16:52,  7.07it/s]\u001b[A\n",
            "7140it [16:52,  6.98it/s]\u001b[A\n",
            "7141it [16:52,  6.96it/s]\u001b[A\n",
            "7142it [16:52,  7.01it/s]\u001b[A\n",
            "7143it [16:52,  7.10it/s]\u001b[A\n",
            "7144it [16:53,  6.95it/s]\u001b[A\n",
            "7145it [16:53,  6.90it/s]\u001b[A\n",
            "7146it [16:53,  7.07it/s]\u001b[A\n",
            "7147it [16:53,  6.95it/s]\u001b[A\n",
            "7148it [16:53,  6.76it/s]\u001b[A\n",
            "7149it [16:53,  6.91it/s]\u001b[A\n",
            "7150it [16:53,  6.81it/s]\u001b[A\n",
            "7151it [16:54,  6.81it/s]\u001b[A\n",
            "7152it [16:54,  6.89it/s]\u001b[A\n",
            "7153it [16:54,  6.96it/s]\u001b[A\n",
            "7154it [16:54,  6.97it/s]\u001b[A\n",
            "7155it [16:54,  6.87it/s]\u001b[A\n",
            "7156it [16:54,  6.94it/s]\u001b[A\n",
            "7157it [16:54,  6.89it/s]\u001b[A\n",
            "7158it [16:55,  6.85it/s]\u001b[A\n",
            "7159it [16:55,  6.97it/s]\u001b[A\n",
            "7160it [16:55,  7.04it/s]\u001b[A\n",
            "7161it [16:55,  6.91it/s]\u001b[A\n",
            "7162it [16:55,  6.77it/s]\u001b[A\n",
            "7163it [16:55,  6.86it/s]\u001b[A\n",
            "7164it [16:55,  7.03it/s]\u001b[A\n",
            "7165it [16:56,  6.93it/s]\u001b[A\n",
            "7166it [16:56,  7.04it/s]\u001b[A\n",
            "7167it [16:56,  7.13it/s]\u001b[A\n",
            "7168it [16:56,  7.18it/s]\u001b[A\n",
            "7169it [16:56,  7.09it/s]\u001b[A\n",
            "7170it [16:56,  7.06it/s]\u001b[A\n",
            "7171it [16:56,  7.12it/s]\u001b[A\n",
            "7172it [16:57,  7.00it/s]\u001b[A\n",
            "7173it [16:57,  7.00it/s]\u001b[A\n",
            "7174it [16:57,  7.07it/s]\u001b[A\n",
            "7175it [16:57,  7.07it/s]\u001b[A\n",
            "7176it [16:57,  7.04it/s]\u001b[A\n",
            "7177it [16:57,  7.09it/s]\u001b[A\n",
            "7178it [16:57,  7.05it/s]\u001b[A\n",
            "7179it [16:58,  6.91it/s]\u001b[A\n",
            "7180it [16:58,  6.92it/s]\u001b[A\n",
            "7181it [16:58,  6.94it/s]\u001b[A\n",
            "7182it [16:58,  6.99it/s]\u001b[A\n",
            "7183it [16:58,  6.69it/s]\u001b[A\n",
            "7184it [16:58,  6.86it/s]\u001b[A\n",
            "7185it [16:58,  6.88it/s]\u001b[A\n",
            "7186it [16:59,  6.82it/s]\u001b[A\n",
            "7187it [16:59,  6.73it/s]\u001b[A\n",
            "7188it [16:59,  6.56it/s]\u001b[A\n",
            "7189it [16:59,  6.50it/s]\u001b[A\n",
            "7190it [16:59,  6.63it/s]\u001b[A\n",
            "7191it [16:59,  6.75it/s]\u001b[A\n",
            "7192it [16:59,  6.92it/s]\u001b[A\n",
            "7193it [17:00,  6.93it/s]\u001b[A\n",
            "7194it [17:00,  6.97it/s]\u001b[A\n",
            "7195it [17:00,  6.96it/s]\u001b[A\n",
            "7196it [17:00,  6.66it/s]\u001b[A\n",
            "7197it [17:00,  6.76it/s]\u001b[A\n",
            "7198it [17:00,  6.88it/s]\u001b[A\n",
            "7199it [17:01,  6.94it/s]\u001b[A\n",
            "7200it [17:01,  6.67it/s]\u001b[A\n",
            "7201it [17:01,  6.66it/s]\u001b[A\n",
            "7202it [17:01,  6.62it/s]\u001b[A\n",
            "7203it [17:01,  6.54it/s]\u001b[A\n",
            "7204it [17:01,  6.51it/s]\u001b[A\n",
            "7205it [17:01,  6.46it/s]\u001b[A\n",
            "7206it [17:02,  6.51it/s]\u001b[A\n",
            "7207it [17:02,  6.70it/s]\u001b[A\n",
            "7208it [17:02,  6.83it/s]\u001b[A\n",
            "7209it [17:02,  6.92it/s]\u001b[A\n",
            "7210it [17:02,  7.01it/s]\u001b[A\n",
            "7211it [17:02,  7.04it/s]\u001b[A\n",
            "7212it [17:02,  7.12it/s]\u001b[A\n",
            "7213it [17:03,  7.12it/s]\u001b[A\n",
            "7214it [17:03,  7.05it/s]\u001b[A\n",
            "7215it [17:03,  7.09it/s]\u001b[A\n",
            "7216it [17:03,  7.07it/s]\u001b[A\n",
            "7217it [17:03,  7.05it/s]\u001b[A\n",
            "7218it [17:03,  6.81it/s]\u001b[A\n",
            "7219it [17:03,  6.64it/s]\u001b[A\n",
            "7220it [17:04,  6.52it/s]\u001b[A\n",
            "7221it [17:04,  6.46it/s]\u001b[A\n",
            "7222it [17:04,  6.52it/s]\u001b[A\n",
            "7223it [17:04,  6.48it/s]\u001b[A\n",
            "7224it [17:04,  6.49it/s]\u001b[A\n",
            "7225it [17:04,  6.44it/s]\u001b[A\n",
            "7226it [17:05,  6.29it/s]\u001b[A\n",
            "7227it [17:05,  6.26it/s]\u001b[A\n",
            "7228it [17:05,  6.37it/s]\u001b[A\n",
            "7229it [17:05,  6.58it/s]\u001b[A\n",
            "7230it [17:05,  6.55it/s]\u001b[A\n",
            "7231it [17:05,  6.60it/s]\u001b[A\n",
            "7232it [17:05,  6.71it/s]\u001b[A\n",
            "7233it [17:06,  6.82it/s]\u001b[A\n",
            "7234it [17:06,  6.80it/s]\u001b[A\n",
            "7235it [17:06,  6.88it/s]\u001b[A\n",
            "7236it [17:06,  6.93it/s]\u001b[A\n",
            "7237it [17:06,  7.01it/s]\u001b[A\n",
            "7238it [17:06,  7.05it/s]\u001b[A\n",
            "7239it [17:06,  7.07it/s]\u001b[A\n",
            "7240it [17:07,  7.09it/s]\u001b[A\n",
            "7241it [17:07,  6.90it/s]\u001b[A\n",
            "7242it [17:07,  6.95it/s]\u001b[A\n",
            "7243it [17:07,  6.86it/s]\u001b[A\n",
            "7244it [17:07,  6.79it/s]\u001b[A\n",
            "7245it [17:07,  6.58it/s]\u001b[A\n",
            "7246it [17:08,  6.57it/s]\u001b[A\n",
            "7247it [17:08,  6.48it/s]\u001b[A\n",
            "7248it [17:08,  6.35it/s]\u001b[A\n",
            "7249it [17:08,  6.53it/s]\u001b[A\n",
            "7250it [17:08,  6.61it/s]\u001b[A\n",
            "7251it [17:08,  6.53it/s]\u001b[A\n",
            "7252it [17:08,  6.59it/s]\u001b[A\n",
            "7253it [17:09,  6.56it/s]\u001b[A\n",
            "7254it [17:09,  6.47it/s]\u001b[A\n",
            "7255it [17:09,  6.37it/s]\u001b[A\n",
            "7256it [17:09,  6.39it/s]\u001b[A\n",
            "7257it [17:09,  6.45it/s]\u001b[A\n",
            "7258it [17:09,  6.46it/s]\u001b[A\n",
            "7259it [17:10,  6.58it/s]\u001b[A\n",
            "7260it [17:10,  6.71it/s]\u001b[A\n",
            "7261it [17:10,  6.72it/s]\u001b[A\n",
            "7262it [17:10,  6.65it/s]\u001b[A\n",
            "7263it [17:10,  6.57it/s]\u001b[A\n",
            "7264it [17:10,  6.61it/s]\u001b[A\n",
            "7265it [17:10,  6.70it/s]\u001b[A\n",
            "7266it [17:11,  6.83it/s]\u001b[A\n",
            "7267it [17:11,  6.88it/s]\u001b[A\n",
            "7268it [17:11,  6.87it/s]\u001b[A\n",
            "7269it [17:11,  6.90it/s]\u001b[A\n",
            "7270it [17:11,  6.83it/s]\u001b[A\n",
            "7271it [17:11,  6.71it/s]\u001b[A\n",
            "7272it [17:11,  6.58it/s]\u001b[A\n",
            "7273it [17:12,  6.56it/s]\u001b[A\n",
            "7274it [17:12,  6.45it/s]\u001b[A\n",
            "7275it [17:12,  6.59it/s]\u001b[A\n",
            "7276it [17:12,  6.72it/s]\u001b[A\n",
            "7277it [17:12,  6.72it/s]\u001b[A\n",
            "7278it [17:12,  6.65it/s]\u001b[A\n",
            "7279it [17:12,  6.62it/s]\u001b[A\n",
            "7280it [17:13,  6.43it/s]\u001b[A\n",
            "7281it [17:13,  6.28it/s]\u001b[A\n",
            "7282it [17:13,  6.20it/s]\u001b[A\n",
            "7283it [17:13,  6.32it/s]\u001b[A\n",
            "7284it [17:13,  6.48it/s]\u001b[A\n",
            "7285it [17:13,  6.66it/s]\u001b[A\n",
            "7286it [17:14,  6.78it/s]\u001b[A\n",
            "7287it [17:14,  6.89it/s]\u001b[A\n",
            "7288it [17:14,  6.75it/s]\u001b[A\n",
            "7289it [17:14,  6.80it/s]\u001b[A\n",
            "7290it [17:14,  6.84it/s]\u001b[A\n",
            "7291it [17:14,  6.75it/s]\u001b[A\n",
            "7292it [17:14,  6.82it/s]\u001b[A\n",
            "7293it [17:15,  6.86it/s]\u001b[A\n",
            "7294it [17:15,  6.89it/s]\u001b[A\n",
            "7295it [17:15,  6.85it/s]\u001b[A\n",
            "7296it [17:15,  6.86it/s]\u001b[A\n",
            "7297it [17:15,  6.90it/s]\u001b[A\n",
            "7298it [17:15,  6.99it/s]\u001b[A\n",
            "7299it [17:15,  7.11it/s]\u001b[A\n",
            "7300it [17:16,  7.22it/s]\u001b[A\n",
            "7301it [17:16,  7.11it/s]\u001b[A\n",
            "7302it [17:16,  7.03it/s]\u001b[A\n",
            "7303it [17:16,  7.03it/s]\u001b[A\n",
            "7304it [17:16,  6.92it/s]\u001b[A\n",
            "7305it [17:16,  6.97it/s]\u001b[A\n",
            "7306it [17:16,  7.00it/s]\u001b[A\n",
            "7307it [17:17,  7.03it/s]\u001b[A\n",
            "7308it [17:17,  7.11it/s]\u001b[A\n",
            "7309it [17:17,  6.97it/s]\u001b[A\n",
            "7310it [17:17,  6.81it/s]\u001b[A\n",
            "7311it [17:17,  6.72it/s]\u001b[A\n",
            "7312it [17:17,  6.78it/s]\u001b[A\n",
            "7313it [17:17,  6.91it/s]\u001b[A\n",
            "7314it [17:18,  6.96it/s]\u001b[A\n",
            "7315it [17:18,  6.91it/s]\u001b[A\n",
            "7316it [17:18,  6.80it/s]\u001b[A\n",
            "7317it [17:18,  6.73it/s]\u001b[A\n",
            "7318it [17:18,  6.80it/s]\u001b[A\n",
            "7319it [17:18,  6.92it/s]\u001b[A\n",
            "7320it [17:18,  6.92it/s]\u001b[A\n",
            "7321it [17:19,  6.99it/s]\u001b[A\n",
            "7322it [17:19,  7.05it/s]\u001b[A\n",
            "7323it [17:19,  7.07it/s]\u001b[A\n",
            "7324it [17:19,  7.01it/s]\u001b[A\n",
            "7325it [17:19,  7.00it/s]\u001b[A\n",
            "7326it [17:19,  6.98it/s]\u001b[A\n",
            "7327it [17:19,  6.99it/s]\u001b[A\n",
            "7328it [17:20,  7.10it/s]\u001b[A\n",
            "7329it [17:20,  7.01it/s]\u001b[A\n",
            "7330it [17:20,  6.82it/s]\u001b[A\n",
            "7331it [17:20,  6.68it/s]\u001b[A\n",
            "7332it [17:20,  6.63it/s]\u001b[A\n",
            "7333it [17:20,  6.48it/s]\u001b[A\n",
            "7334it [17:21,  6.44it/s]\u001b[A\n",
            "7335it [17:21,  6.34it/s]\u001b[A\n",
            "7336it [17:21,  6.38it/s]\u001b[A\n",
            "7337it [17:21,  6.29it/s]\u001b[A\n",
            "7338it [17:21,  6.34it/s]\u001b[A\n",
            "7339it [17:21,  6.25it/s]\u001b[A\n",
            "7340it [17:22,  6.34it/s]\u001b[A\n",
            "7341it [17:22,  6.53it/s]\u001b[A\n",
            "7342it [17:22,  6.66it/s]\u001b[A\n",
            "7343it [17:22,  6.63it/s]\u001b[A\n",
            "7344it [17:22,  6.78it/s]\u001b[A\n",
            "7345it [17:22,  6.85it/s]\u001b[A\n",
            "7346it [17:22,  6.89it/s]\u001b[A\n",
            "7347it [17:23,  7.00it/s]\u001b[A\n",
            "7348it [17:23,  7.09it/s]\u001b[A\n",
            "7349it [17:23,  7.06it/s]\u001b[A\n",
            "7350it [17:23,  7.02it/s]\u001b[A\n",
            "7351it [17:23,  6.97it/s]\u001b[A\n",
            "7352it [17:23,  6.77it/s]\u001b[A\n",
            "7353it [17:23,  6.82it/s]\u001b[A\n",
            "7354it [17:24,  6.79it/s]\u001b[A\n",
            "7355it [17:24,  6.80it/s]\u001b[A\n",
            "7356it [17:24,  6.91it/s]\u001b[A\n",
            "7357it [17:24,  6.75it/s]\u001b[A\n",
            "7358it [17:24,  6.75it/s]\u001b[A\n",
            "7359it [17:24,  6.77it/s]\u001b[A\n",
            "7360it [17:24,  6.82it/s]\u001b[A\n",
            "7361it [17:25,  6.87it/s]\u001b[A\n",
            "7362it [17:25,  7.04it/s]\u001b[A\n",
            "7363it [17:25,  6.99it/s]\u001b[A\n",
            "7364it [17:25,  7.00it/s]\u001b[A\n",
            "7365it [17:25,  6.93it/s]\u001b[A\n",
            "7366it [17:25,  6.80it/s]\u001b[A\n",
            "7367it [17:25,  6.60it/s]\u001b[A\n",
            "7368it [17:26,  6.59it/s]\u001b[A\n",
            "7369it [17:26,  6.65it/s]\u001b[A\n",
            "7370it [17:26,  6.63it/s]\u001b[A\n",
            "7371it [17:26,  6.44it/s]\u001b[A\n",
            "7372it [17:26,  6.46it/s]\u001b[A\n",
            "7373it [17:26,  6.43it/s]\u001b[A\n",
            "7374it [17:27,  6.54it/s]\u001b[A\n",
            "7375it [17:27,  6.64it/s]\u001b[A\n",
            "7376it [17:27,  6.63it/s]\u001b[A\n",
            "7377it [17:27,  6.74it/s]\u001b[A\n",
            "7378it [17:27,  6.80it/s]\u001b[A\n",
            "7379it [17:27,  6.75it/s]\u001b[A\n",
            "7380it [17:27,  6.82it/s]\u001b[A\n",
            "7381it [17:28,  6.82it/s]\u001b[A\n",
            "7382it [17:28,  6.96it/s]\u001b[A\n",
            "7383it [17:28,  6.88it/s]\u001b[A\n",
            "7384it [17:28,  6.82it/s]\u001b[A\n",
            "7385it [17:28,  6.55it/s]\u001b[A\n",
            "7386it [17:28,  6.64it/s]\u001b[A\n",
            "7387it [17:28,  6.56it/s]\u001b[A\n",
            "7388it [17:29,  6.49it/s]\u001b[A\n",
            "7389it [17:29,  6.70it/s]\u001b[A\n",
            "7390it [17:29,  6.80it/s]\u001b[A\n",
            "7391it [17:29,  6.73it/s]\u001b[A\n",
            "7392it [17:29,  6.68it/s]\u001b[A\n",
            "7393it [17:29,  6.86it/s]\u001b[A\n",
            "7394it [17:29,  6.93it/s]\u001b[A\n",
            "7395it [17:30,  6.94it/s]\u001b[A\n",
            "7396it [17:30,  6.98it/s]\u001b[A\n",
            "7397it [17:30,  7.01it/s]\u001b[A\n",
            "7398it [17:30,  6.89it/s]\u001b[A\n",
            "7399it [17:30,  6.75it/s]\u001b[A\n",
            "7400it [17:30,  6.61it/s]\u001b[A\n",
            "7401it [17:31,  6.54it/s]\u001b[A\n",
            "7402it [17:31,  6.68it/s]\u001b[A\n",
            "7403it [17:31,  6.70it/s]\u001b[A\n",
            "7404it [17:31,  6.66it/s]\u001b[A\n",
            "7405it [17:31,  6.57it/s]\u001b[A\n",
            "7406it [17:31,  6.50it/s]\u001b[A\n",
            "7407it [17:31,  6.38it/s]\u001b[A\n",
            "7408it [17:32,  6.40it/s]\u001b[A\n",
            "7409it [17:32,  6.33it/s]\u001b[A\n",
            "7410it [17:32,  6.27it/s]\u001b[A\n",
            "7411it [17:32,  6.45it/s]\u001b[A\n",
            "7412it [17:32,  6.39it/s]\u001b[A\n",
            "7413it [17:32,  6.39it/s]\u001b[A\n",
            "7414it [17:33,  6.38it/s]\u001b[A\n",
            "7415it [17:33,  6.39it/s]\u001b[A\n",
            "7416it [17:33,  6.34it/s]\u001b[A\n",
            "7417it [17:33,  6.35it/s]\u001b[A\n",
            "7418it [17:33,  6.37it/s]\u001b[A\n",
            "7419it [17:33,  6.54it/s]\u001b[A\n",
            "7420it [17:33,  6.58it/s]\u001b[A\n",
            "7421it [17:34,  6.59it/s]\u001b[A\n",
            "7422it [17:34,  6.59it/s]\u001b[A\n",
            "7423it [17:34,  6.75it/s]\u001b[A\n",
            "7424it [17:34,  6.76it/s]\u001b[A\n",
            "7425it [17:34,  6.75it/s]\u001b[A\n",
            "7426it [17:34,  6.83it/s]\u001b[A\n",
            "7427it [17:34,  6.88it/s]\u001b[A\n",
            "7428it [17:35,  6.96it/s]\u001b[A\n",
            "7429it [17:35,  6.98it/s]\u001b[A\n",
            "7430it [17:35,  6.99it/s]\u001b[A\n",
            "7431it [17:35,  6.87it/s]\u001b[A\n",
            "7432it [17:35,  6.81it/s]\u001b[A\n",
            "7433it [17:35,  6.90it/s]\u001b[A\n",
            "7434it [17:35,  6.90it/s]\u001b[A\n",
            "7435it [17:36,  7.03it/s]\u001b[A\n",
            "7436it [17:36,  7.07it/s]\u001b[A\n",
            "7437it [17:36,  7.04it/s]\u001b[A\n",
            "7438it [17:36,  7.03it/s]\u001b[A\n",
            "7439it [17:36,  6.73it/s]\u001b[A\n",
            "7440it [17:36,  6.74it/s]\u001b[A\n",
            "7441it [17:37,  6.67it/s]\u001b[A\n",
            "7442it [17:37,  6.62it/s]\u001b[A\n",
            "7443it [17:37,  6.54it/s]\u001b[A\n",
            "7444it [17:37,  6.63it/s]\u001b[A\n",
            "7445it [17:37,  6.74it/s]\u001b[A\n",
            "7446it [17:37,  6.66it/s]\u001b[A\n",
            "7447it [17:37,  6.63it/s]\u001b[A\n",
            "7448it [17:38,  6.72it/s]\u001b[A\n",
            "7449it [17:38,  6.76it/s]\u001b[A\n",
            "7450it [17:38,  6.81it/s]\u001b[A\n",
            "7451it [17:38,  6.81it/s]\u001b[A\n",
            "7452it [17:38,  6.65it/s]\u001b[A\n",
            "7453it [17:38,  6.55it/s]\u001b[A\n",
            "7454it [17:38,  6.49it/s]\u001b[A\n",
            "7455it [17:39,  6.51it/s]\u001b[A\n",
            "7456it [17:39,  6.54it/s]\u001b[A\n",
            "7457it [17:39,  6.70it/s]\u001b[A\n",
            "7458it [17:39,  6.80it/s]\u001b[A\n",
            "7459it [17:39,  6.62it/s]\u001b[A\n",
            "7460it [17:39,  6.42it/s]\u001b[A\n",
            "7461it [17:40,  6.48it/s]\u001b[A\n",
            "7462it [17:40,  6.58it/s]\u001b[A\n",
            "7463it [17:40,  6.63it/s]\u001b[A\n",
            "7464it [17:40,  6.77it/s]\u001b[A\n",
            "7465it [17:40,  6.84it/s]\u001b[A\n",
            "7466it [17:40,  6.77it/s]\u001b[A\n",
            "7467it [17:40,  6.57it/s]\u001b[A\n",
            "7468it [17:41,  6.55it/s]\u001b[A\n",
            "7469it [17:41,  6.48it/s]\u001b[A\n",
            "7470it [17:41,  6.48it/s]\u001b[A\n",
            "7471it [17:41,  6.51it/s]\u001b[A\n",
            "7472it [17:41,  6.69it/s]\u001b[A\n",
            "7473it [17:41,  6.66it/s]\u001b[A\n",
            "7474it [17:41,  6.76it/s]\u001b[A\n",
            "7475it [17:42,  6.88it/s]\u001b[A\n",
            "7476it [17:42,  6.89it/s]\u001b[A\n",
            "7477it [17:42,  6.98it/s]\u001b[A\n",
            "7478it [17:42,  7.11it/s]\u001b[A\n",
            "7479it [17:42,  7.12it/s]\u001b[A\n",
            "7480it [17:42,  6.82it/s]\u001b[A\n",
            "7481it [17:42,  6.66it/s]\u001b[A\n",
            "7482it [17:43,  6.58it/s]\u001b[A\n",
            "7483it [17:43,  6.57it/s]\u001b[A\n",
            "7484it [17:43,  6.39it/s]\u001b[A\n",
            "7485it [17:43,  6.51it/s]\u001b[A\n",
            "7486it [17:43,  6.59it/s]\u001b[A\n",
            "7487it [17:43,  6.79it/s]\u001b[A\n",
            "7488it [17:44,  6.79it/s]\u001b[A\n",
            "7489it [17:44,  6.89it/s]\u001b[A\n",
            "7490it [17:44,  6.95it/s]\u001b[A\n",
            "7491it [17:44,  7.04it/s]\u001b[A\n",
            "7492it [17:44,  7.07it/s]\u001b[A\n",
            "7493it [17:44,  6.93it/s]\u001b[A\n",
            "7494it [17:44,  6.92it/s]\u001b[A\n",
            "7495it [17:45,  6.94it/s]\u001b[A\n",
            "7496it [17:45,  6.98it/s]\u001b[A\n",
            "7497it [17:45,  7.03it/s]\u001b[A\n",
            "7498it [17:45,  7.02it/s]\u001b[A\n",
            "7499it [17:45,  7.06it/s]\u001b[A\n",
            "7500it [17:45,  7.10it/s]\u001b[A\n",
            "7501it [17:45,  6.89it/s]\u001b[A\n",
            "7502it [17:46,  6.94it/s]\u001b[A\n",
            "7503it [17:46,  6.96it/s]\u001b[A\n",
            "7504it [17:46,  6.96it/s]\u001b[A\n",
            "7505it [17:46,  6.86it/s]\u001b[A\n",
            "7506it [17:46,  6.90it/s]\u001b[A\n",
            "7507it [17:46,  6.82it/s]\u001b[A\n",
            "7508it [17:46,  6.79it/s]\u001b[A\n",
            "7509it [17:47,  6.77it/s]\u001b[A\n",
            "7510it [17:47,  6.70it/s]\u001b[A\n",
            "7511it [17:47,  6.62it/s]\u001b[A\n",
            "7512it [17:47,  6.62it/s]\u001b[A\n",
            "7513it [17:47,  6.77it/s]\u001b[A\n",
            "7514it [17:47,  6.79it/s]\u001b[A\n",
            "7515it [17:47,  6.87it/s]\u001b[A\n",
            "7516it [17:48,  6.88it/s]\u001b[A\n",
            "7517it [17:48,  6.96it/s]\u001b[A\n",
            "7518it [17:48,  6.98it/s]\u001b[A\n",
            "7519it [17:48,  6.76it/s]\u001b[A\n",
            "7520it [17:48,  6.69it/s]\u001b[A\n",
            "7521it [17:48,  6.64it/s]\u001b[A\n",
            "7522it [17:49,  6.64it/s]\u001b[A\n",
            "7523it [17:49,  6.81it/s]\u001b[A\n",
            "7524it [17:49,  6.86it/s]\u001b[A\n",
            "7525it [17:49,  6.92it/s]\u001b[A\n",
            "7526it [17:49,  6.82it/s]\u001b[A\n",
            "7527it [17:49,  6.88it/s]\u001b[A\n",
            "7528it [17:49,  6.83it/s]\u001b[A\n",
            "7529it [17:50,  6.95it/s]\u001b[A\n",
            "7530it [17:50,  6.99it/s]\u001b[A\n",
            "7531it [17:50,  6.96it/s]\u001b[A\n",
            "7532it [17:50,  7.04it/s]\u001b[A\n",
            "7533it [17:50,  7.02it/s]\u001b[A\n",
            "7534it [17:50,  6.78it/s]\u001b[A\n",
            "7535it [17:50,  6.58it/s]\u001b[A\n",
            "7536it [17:51,  6.66it/s]\u001b[A\n",
            "7537it [17:51,  6.85it/s]\u001b[A\n",
            "7538it [17:51,  6.69it/s]\u001b[A\n",
            "7539it [17:51,  6.61it/s]\u001b[A\n",
            "7540it [17:51,  6.59it/s]\u001b[A\n",
            "7541it [17:51,  6.70it/s]\u001b[A\n",
            "7542it [17:51,  6.78it/s]\u001b[A\n",
            "7543it [17:52,  6.99it/s]\u001b[A\n",
            "7544it [17:52,  7.03it/s]\u001b[A\n",
            "7545it [17:52,  7.05it/s]\u001b[A\n",
            "7546it [17:52,  7.04it/s]\u001b[A\n",
            "7547it [17:52,  6.95it/s]\u001b[A\n",
            "7548it [17:52,  6.54it/s]\u001b[A\n",
            "7549it [17:52,  6.53it/s]\u001b[A\n",
            "7550it [17:53,  6.72it/s]\u001b[A\n",
            "7551it [17:53,  6.77it/s]\u001b[A\n",
            "7552it [17:53,  6.89it/s]\u001b[A\n",
            "7553it [17:53,  6.88it/s]\u001b[A\n",
            "7554it [17:53,  6.80it/s]\u001b[A\n",
            "7555it [17:53,  6.67it/s]\u001b[A\n",
            "7556it [17:53,  6.58it/s]\u001b[A\n",
            "7557it [17:54,  6.76it/s]\u001b[A\n",
            "7558it [17:54,  6.83it/s]\u001b[A\n",
            "7559it [17:54,  6.95it/s]\u001b[A\n",
            "7560it [17:54,  7.11it/s]\u001b[A\n",
            "7561it [17:54,  6.93it/s]\u001b[A\n",
            "7562it [17:54,  6.78it/s]\u001b[A\n",
            "7563it [17:55,  6.64it/s]\u001b[A\n",
            "7564it [17:55,  6.74it/s]\u001b[A\n",
            "7565it [17:55,  6.92it/s]\u001b[A\n",
            "7566it [17:55,  7.00it/s]\u001b[A\n",
            "7567it [17:55,  7.10it/s]\u001b[A\n",
            "7568it [17:55,  7.00it/s]\u001b[A\n",
            "7569it [17:55,  7.02it/s]\u001b[A\n",
            "7570it [17:56,  7.00it/s]\u001b[A\n",
            "7571it [17:56,  7.02it/s]\u001b[A\n",
            "7572it [17:56,  6.91it/s]\u001b[A\n",
            "7573it [17:56,  6.94it/s]\u001b[A\n",
            "7574it [17:56,  7.09it/s]\u001b[A\n",
            "7575it [17:56,  7.14it/s]\u001b[A\n",
            "7576it [17:56,  7.17it/s]\u001b[A\n",
            "7577it [17:57,  6.88it/s]\u001b[A\n",
            "7578it [17:57,  6.88it/s]\u001b[A\n",
            "7579it [17:57,  7.00it/s]\u001b[A\n",
            "7580it [17:57,  7.13it/s]\u001b[A\n",
            "7581it [17:57,  7.16it/s]\u001b[A\n",
            "7582it [17:57,  6.96it/s]\u001b[A\n",
            "7583it [17:57,  6.83it/s]\u001b[A\n",
            "7584it [17:58,  6.68it/s]\u001b[A\n",
            "7585it [17:58,  6.82it/s]\u001b[A\n",
            "7586it [17:58,  6.92it/s]\u001b[A\n",
            "7587it [17:58,  6.96it/s]\u001b[A\n",
            "7588it [17:58,  6.93it/s]\u001b[A\n",
            "7589it [17:58,  6.97it/s]\u001b[A\n",
            "7590it [17:58,  7.06it/s]\u001b[A\n",
            "7591it [17:59,  6.92it/s]\u001b[A\n",
            "7592it [17:59,  6.99it/s]\u001b[A\n",
            "7593it [17:59,  7.01it/s]\u001b[A\n",
            "7594it [17:59,  6.98it/s]\u001b[A\n",
            "7595it [17:59,  6.98it/s]\u001b[A\n",
            "7596it [17:59,  6.98it/s]\u001b[A\n",
            "7597it [17:59,  7.02it/s]\u001b[A\n",
            "7598it [18:00,  6.95it/s]\u001b[A\n",
            "7599it [18:00,  6.82it/s]\u001b[A\n",
            "7600it [18:00,  6.65it/s]\u001b[A\n",
            "7601it [18:00,  6.65it/s]\u001b[A\n",
            "7602it [18:00,  6.64it/s]\u001b[A\n",
            "7603it [18:00,  6.52it/s]\u001b[A\n",
            "7604it [18:00,  6.47it/s]\u001b[A\n",
            "7605it [18:01,  6.44it/s]\u001b[A\n",
            "7606it [18:01,  6.69it/s]\u001b[A\n",
            "7607it [18:01,  6.76it/s]\u001b[A\n",
            "7608it [18:01,  6.89it/s]\u001b[A\n",
            "7609it [18:01,  7.00it/s]\u001b[A\n",
            "7610it [18:01,  6.99it/s]\u001b[A\n",
            "7611it [18:01,  7.06it/s]\u001b[A\n",
            "7612it [18:02,  7.01it/s]\u001b[A\n",
            "7613it [18:02,  7.09it/s]\u001b[A\n",
            "7614it [18:02,  6.76it/s]\u001b[A\n",
            "7615it [18:02,  6.60it/s]\u001b[A\n",
            "7616it [18:02,  6.57it/s]\u001b[A\n",
            "7617it [18:02,  6.47it/s]\u001b[A\n",
            "7618it [18:03,  6.30it/s]\u001b[A\n",
            "7619it [18:03,  6.39it/s]\u001b[A\n",
            "7620it [18:03,  6.38it/s]\u001b[A\n",
            "7621it [18:03,  6.31it/s]\u001b[A\n",
            "7622it [18:03,  6.47it/s]\u001b[A\n",
            "7623it [18:03,  6.61it/s]\u001b[A\n",
            "7624it [18:03,  6.72it/s]\u001b[A\n",
            "7625it [18:04,  6.70it/s]\u001b[A\n",
            "7626it [18:04,  6.66it/s]\u001b[A\n",
            "7627it [18:04,  6.71it/s]\u001b[A\n",
            "7628it [18:04,  6.54it/s]\u001b[A\n",
            "7629it [18:04,  6.57it/s]\u001b[A\n",
            "7630it [18:04,  6.54it/s]\u001b[A\n",
            "7631it [18:05,  6.61it/s]\u001b[A\n",
            "7632it [18:05,  6.60it/s]\u001b[A\n",
            "7633it [18:05,  6.67it/s]\u001b[A\n",
            "7634it [18:05,  6.80it/s]\u001b[A\n",
            "7635it [18:05,  6.73it/s]\u001b[A\n",
            "7636it [18:05,  6.56it/s]\u001b[A\n",
            "7637it [18:05,  6.46it/s]\u001b[A\n",
            "7638it [18:06,  6.40it/s]\u001b[A\n",
            "7639it [18:06,  6.29it/s]\u001b[A\n",
            "7640it [18:06,  6.37it/s]\u001b[A\n",
            "7641it [18:06,  6.42it/s]\u001b[A\n",
            "7642it [18:06,  6.42it/s]\u001b[A\n",
            "7643it [18:06,  6.42it/s]\u001b[A\n",
            "7644it [18:07,  6.29it/s]\u001b[A\n",
            "7645it [18:07,  6.24it/s]\u001b[A\n",
            "7646it [18:07,  6.29it/s]\u001b[A\n",
            "7647it [18:07,  6.39it/s]\u001b[A\n",
            "7648it [18:07,  6.35it/s]\u001b[A\n",
            "7649it [18:07,  6.38it/s]\u001b[A\n",
            "7650it [18:07,  6.33it/s]\u001b[A\n",
            "7651it [18:08,  6.38it/s]\u001b[A\n",
            "7652it [18:08,  6.48it/s]\u001b[A\n",
            "7653it [18:08,  6.59it/s]\u001b[A\n",
            "7654it [18:08,  6.75it/s]\u001b[A\n",
            "7655it [18:08,  6.77it/s]\u001b[A\n",
            "7656it [18:08,  6.87it/s]\u001b[A\n",
            "7657it [18:08,  6.83it/s]\u001b[A\n",
            "7658it [18:09,  6.58it/s]\u001b[A\n",
            "7659it [18:09,  6.48it/s]\u001b[A\n",
            "7660it [18:09,  6.45it/s]\u001b[A\n",
            "7661it [18:09,  6.45it/s]\u001b[A\n",
            "7662it [18:09,  6.53it/s]\u001b[A\n",
            "7663it [18:09,  6.62it/s]\u001b[A\n",
            "7664it [18:10,  6.79it/s]\u001b[A\n",
            "7665it [18:10,  6.80it/s]\u001b[A\n",
            "7666it [18:10,  6.82it/s]\u001b[A\n",
            "7667it [18:10,  6.74it/s]\u001b[A\n",
            "7668it [18:10,  6.71it/s]\u001b[A\n",
            "7669it [18:10,  6.78it/s]\u001b[A\n",
            "7670it [18:10,  6.78it/s]\u001b[A\n",
            "7671it [18:11,  6.89it/s]\u001b[A\n",
            "7672it [18:11,  6.91it/s]\u001b[A\n",
            "7673it [18:11,  6.89it/s]\u001b[A\n",
            "7674it [18:11,  6.96it/s]\u001b[A\n",
            "7675it [18:11,  6.86it/s]\u001b[A\n",
            "7676it [18:11,  6.87it/s]\u001b[A\n",
            "7677it [18:11,  6.85it/s]\u001b[A\n",
            "7678it [18:12,  6.88it/s]\u001b[A\n",
            "7679it [18:12,  6.50it/s]\u001b[A\n",
            "7680it [18:12,  6.25it/s]\u001b[A\n",
            "7681it [18:12,  6.24it/s]\u001b[A\n",
            "7682it [18:12,  6.41it/s]\u001b[A\n",
            "7683it [18:12,  6.64it/s]\u001b[A\n",
            "7684it [18:13,  6.77it/s]\u001b[A\n",
            "7685it [18:13,  6.78it/s]\u001b[A\n",
            "7686it [18:13,  6.95it/s]\u001b[A\n",
            "7687it [18:13,  6.99it/s]\u001b[A\n",
            "7688it [18:13,  7.01it/s]\u001b[A\n",
            "7689it [18:13,  7.10it/s]\u001b[A\n",
            "7690it [18:13,  7.17it/s]\u001b[A\n",
            "7691it [18:14,  7.19it/s]\u001b[A\n",
            "7692it [18:14,  7.20it/s]\u001b[A\n",
            "7693it [18:14,  7.08it/s]\u001b[A\n",
            "7694it [18:14,  7.06it/s]\u001b[A\n",
            "7695it [18:14,  7.07it/s]\u001b[A\n",
            "7696it [18:14,  6.84it/s]\u001b[A\n",
            "7697it [18:14,  6.62it/s]\u001b[A\n",
            "7698it [18:15,  6.70it/s]\u001b[A\n",
            "7699it [18:15,  6.50it/s]\u001b[A\n",
            "7700it [18:15,  6.46it/s]\u001b[A\n",
            "7701it [18:15,  6.42it/s]\u001b[A\n",
            "7702it [18:15,  6.41it/s]\u001b[A\n",
            "7703it [18:15,  6.32it/s]\u001b[A\n",
            "7704it [18:16,  6.33it/s]\u001b[A\n",
            "7705it [18:16,  6.58it/s]\u001b[A\n",
            "7706it [18:16,  6.63it/s]\u001b[A\n",
            "7707it [18:16,  6.76it/s]\u001b[A\n",
            "7708it [18:16,  6.81it/s]\u001b[A\n",
            "7709it [18:16,  6.83it/s]\u001b[A\n",
            "7710it [18:16,  6.89it/s]\u001b[A\n",
            "7711it [18:17,  6.87it/s]\u001b[A\n",
            "7712it [18:17,  6.78it/s]\u001b[A\n",
            "7713it [18:17,  6.57it/s]\u001b[A\n",
            "7714it [18:17,  6.67it/s]\u001b[A\n",
            "7715it [18:17,  6.76it/s]\u001b[A\n",
            "7716it [18:17,  6.83it/s]\u001b[A\n",
            "7717it [18:17,  6.86it/s]\u001b[A\n",
            "7718it [18:18,  6.94it/s]\u001b[A\n",
            "7719it [18:18,  6.98it/s]\u001b[A\n",
            "7720it [18:18,  6.95it/s]\u001b[A\n",
            "7721it [18:18,  6.98it/s]\u001b[A\n",
            "7722it [18:18,  6.99it/s]\u001b[A\n",
            "7723it [18:18,  6.82it/s]\u001b[A\n",
            "7724it [18:18,  6.66it/s]\u001b[A\n",
            "7725it [18:19,  6.67it/s]\u001b[A\n",
            "7726it [18:19,  6.80it/s]\u001b[A\n",
            "7727it [18:19,  6.78it/s]\u001b[A\n",
            "7728it [18:19,  6.89it/s]\u001b[A\n",
            "7729it [18:19,  6.90it/s]\u001b[A\n",
            "7730it [18:19,  6.76it/s]\u001b[A\n",
            "7731it [18:19,  6.71it/s]\u001b[A\n",
            "7732it [18:20,  6.70it/s]\u001b[A\n",
            "7733it [18:20,  6.65it/s]\u001b[A\n",
            "7734it [18:20,  6.66it/s]\u001b[A\n",
            "7735it [18:20,  6.73it/s]\u001b[A\n",
            "7736it [18:20,  6.72it/s]\u001b[A\n",
            "7737it [18:20,  6.68it/s]\u001b[A\n",
            "7738it [18:20,  6.76it/s]\u001b[A\n",
            "7739it [18:21,  6.80it/s]\u001b[A\n",
            "7740it [18:21,  6.83it/s]\u001b[A\n",
            "7741it [18:21,  6.55it/s]\u001b[A\n",
            "7742it [18:21,  6.71it/s]\u001b[A\n",
            "7743it [18:21,  6.65it/s]\u001b[A\n",
            "7744it [18:21,  6.64it/s]\u001b[A\n",
            "7745it [18:22,  6.65it/s]\u001b[A\n",
            "7746it [18:22,  6.59it/s]\u001b[A\n",
            "7747it [18:22,  6.43it/s]\u001b[A\n",
            "7748it [18:22,  6.59it/s]\u001b[A\n",
            "7749it [18:22,  6.69it/s]\u001b[A\n",
            "7750it [18:22,  6.54it/s]\u001b[A\n",
            "7751it [18:22,  6.48it/s]\u001b[A\n",
            "7752it [18:23,  6.61it/s]\u001b[A\n",
            "7753it [18:23,  6.76it/s]\u001b[A\n",
            "7754it [18:23,  6.78it/s]\u001b[A\n",
            "7755it [18:23,  6.78it/s]\u001b[A\n",
            "7756it [18:23,  6.82it/s]\u001b[A\n",
            "7757it [18:23,  6.83it/s]\u001b[A\n",
            "7758it [18:23,  6.86it/s]\u001b[A\n",
            "7759it [18:24,  6.87it/s]\u001b[A\n",
            "7760it [18:24,  6.97it/s]\u001b[A\n",
            "7761it [18:24,  6.83it/s]\u001b[A\n",
            "7762it [18:24,  6.86it/s]\u001b[A\n",
            "7763it [18:24,  6.89it/s]\u001b[A\n",
            "7764it [18:24,  6.97it/s]\u001b[A\n",
            "7765it [18:24,  7.02it/s]\u001b[A\n",
            "7766it [18:25,  7.04it/s]\u001b[A\n",
            "7767it [18:25,  7.09it/s]\u001b[A\n",
            "7768it [18:25,  6.84it/s]\u001b[A\n",
            "7769it [18:25,  6.74it/s]\u001b[A\n",
            "7770it [18:25,  6.75it/s]\u001b[A\n",
            "7771it [18:25,  6.91it/s]\u001b[A\n",
            "7772it [18:26,  7.02it/s]\u001b[A\n",
            "7773it [18:26,  6.95it/s]\u001b[A\n",
            "7774it [18:26,  6.73it/s]\u001b[A\n",
            "7775it [18:26,  6.52it/s]\u001b[A\n",
            "7776it [18:26,  6.45it/s]\u001b[A\n",
            "7777it [18:26,  6.41it/s]\u001b[A\n",
            "7778it [18:26,  6.58it/s]\u001b[A\n",
            "7779it [18:27,  6.66it/s]\u001b[A\n",
            "7780it [18:27,  6.75it/s]\u001b[A\n",
            "7781it [18:27,  6.80it/s]\u001b[A\n",
            "7782it [18:27,  6.77it/s]\u001b[A\n",
            "7783it [18:27,  6.96it/s]\u001b[A\n",
            "7784it [18:27,  6.98it/s]\u001b[A\n",
            "7785it [18:27,  7.10it/s]\u001b[A\n",
            "7786it [18:28,  7.16it/s]\u001b[A\n",
            "7787it [18:28,  7.17it/s]\u001b[A\n",
            "7788it [18:28,  7.16it/s]\u001b[A\n",
            "7789it [18:28,  6.86it/s]\u001b[A\n",
            "7790it [18:28,  6.80it/s]\u001b[A\n",
            "7791it [18:28,  6.86it/s]\u001b[A\n",
            "7792it [18:28,  6.98it/s]\u001b[A\n",
            "7793it [18:29,  7.03it/s]\u001b[A\n",
            "7794it [18:29,  6.95it/s]\u001b[A\n",
            "7795it [18:29,  7.05it/s]\u001b[A\n",
            "7796it [18:29,  6.80it/s]\u001b[A\n",
            "7797it [18:29,  6.80it/s]\u001b[A\n",
            "7798it [18:29,  6.65it/s]\u001b[A\n",
            "7799it [18:29,  6.54it/s]\u001b[A\n",
            "7800it [18:30,  6.31it/s]\u001b[A\n",
            "7801it [18:30,  6.33it/s]\u001b[A\n",
            "7802it [18:30,  6.27it/s]\u001b[A\n",
            "7803it [18:30,  6.39it/s]\u001b[A\n",
            "7804it [18:30,  6.55it/s]\u001b[A\n",
            "7805it [18:30,  6.69it/s]\u001b[A\n",
            "7806it [18:31,  6.77it/s]\u001b[A\n",
            "7807it [18:31,  6.84it/s]\u001b[A\n",
            "7808it [18:31,  6.94it/s]\u001b[A\n",
            "7809it [18:31,  6.91it/s]\u001b[A\n",
            "7810it [18:31,  7.02it/s]\u001b[A\n",
            "7811it [18:31,  7.01it/s]\u001b[A\n",
            "7812it [18:31,  7.03it/s]\u001b[A\n",
            "7813it [18:32,  6.99it/s]\u001b[A\n",
            "7814it [18:32,  6.92it/s]\u001b[A\n",
            "7815it [18:32,  6.96it/s]\u001b[A\n",
            "7816it [18:32,  6.89it/s]\u001b[A\n",
            "7817it [18:32,  6.82it/s]\u001b[A\n",
            "7818it [18:32,  6.69it/s]\u001b[A\n",
            "7819it [18:32,  6.56it/s]\u001b[A\n",
            "7820it [18:33,  6.48it/s]\u001b[A\n",
            "7821it [18:33,  6.47it/s]\u001b[A\n",
            "7822it [18:33,  6.55it/s]\u001b[A\n",
            "7823it [18:33,  6.49it/s]\u001b[A\n",
            "7824it [18:33,  6.64it/s]\u001b[A\n",
            "7825it [18:33,  6.72it/s]\u001b[A\n",
            "7826it [18:34,  6.80it/s]\u001b[A\n",
            "7827it [18:34,  6.72it/s]\u001b[A\n",
            "7828it [18:34,  6.54it/s]\u001b[A\n",
            "7829it [18:34,  6.62it/s]\u001b[A\n",
            "7830it [18:34,  6.63it/s]\u001b[A\n",
            "7831it [18:34,  6.70it/s]\u001b[A\n",
            "7832it [18:34,  6.52it/s]\u001b[A\n",
            "7833it [18:35,  6.62it/s]\u001b[A\n",
            "7834it [18:35,  6.81it/s]\u001b[A\n",
            "7835it [18:35,  6.86it/s]\u001b[A\n",
            "7836it [18:35,  6.85it/s]\u001b[A\n",
            "7837it [18:35,  6.71it/s]\u001b[A\n",
            "7838it [18:35,  6.54it/s]\u001b[A\n",
            "7839it [18:35,  6.61it/s]\u001b[A\n",
            "7840it [18:36,  6.75it/s]\u001b[A\n",
            "7841it [18:36,  6.78it/s]\u001b[A\n",
            "7842it [18:36,  6.83it/s]\u001b[A\n",
            "7843it [18:36,  6.95it/s]\u001b[A\n",
            "7844it [18:36,  6.94it/s]\u001b[A\n",
            "7845it [18:36,  6.94it/s]\u001b[A\n",
            "7846it [18:36,  6.98it/s]\u001b[A\n",
            "7847it [18:37,  7.08it/s]\u001b[A\n",
            "7848it [18:37,  7.12it/s]\u001b[A\n",
            "7849it [18:37,  7.15it/s]\u001b[A\n",
            "7850it [18:37,  7.18it/s]\u001b[A\n",
            "7851it [18:37,  6.96it/s]\u001b[A\n",
            "7852it [18:37,  6.79it/s]\u001b[A\n",
            "7853it [18:37,  6.63it/s]\u001b[A\n",
            "7854it [18:38,  6.58it/s]\u001b[A\n",
            "7855it [18:38,  6.50it/s]\u001b[A\n",
            "7856it [18:38,  6.41it/s]\u001b[A\n",
            "7857it [18:38,  6.35it/s]\u001b[A\n",
            "7858it [18:38,  6.17it/s]\u001b[A\n",
            "7859it [18:38,  6.10it/s]\u001b[A\n",
            "7860it [18:39,  6.10it/s]\u001b[A\n",
            "7861it [18:39,  6.05it/s]\u001b[A\n",
            "7862it [18:39,  6.23it/s]\u001b[A\n",
            "7863it [18:39,  6.18it/s]\u001b[A\n",
            "7864it [18:39,  6.18it/s]\u001b[A\n",
            "7865it [18:39,  6.29it/s]\u001b[A\n",
            "7866it [18:40,  6.38it/s]\u001b[A\n",
            "7867it [18:40,  6.49it/s]\u001b[A\n",
            "7868it [18:40,  6.51it/s]\u001b[A\n",
            "7869it [18:40,  6.54it/s]\u001b[A\n",
            "7870it [18:40,  6.52it/s]\u001b[A\n",
            "7871it [18:40,  6.72it/s]\u001b[A\n",
            "7872it [18:40,  6.79it/s]\u001b[A\n",
            "7873it [18:41,  6.83it/s]\u001b[A\n",
            "7874it [18:41,  6.96it/s]\u001b[A\n",
            "7875it [18:41,  7.00it/s]\u001b[A\n",
            "7876it [18:41,  6.95it/s]\u001b[A\n",
            "7877it [18:41,  6.62it/s]\u001b[A\n",
            "7878it [18:41,  6.69it/s]\u001b[A\n",
            "7879it [18:41,  6.79it/s]\u001b[A\n",
            "7880it [18:42,  6.88it/s]\u001b[A\n",
            "7881it [18:42,  6.94it/s]\u001b[A\n",
            "7882it [18:42,  7.10it/s]\u001b[A\n",
            "7883it [18:42,  7.15it/s]\u001b[A\n",
            "7884it [18:42,  6.97it/s]\u001b[A\n",
            "7885it [18:42,  6.93it/s]\u001b[A\n",
            "7886it [18:42,  6.95it/s]\u001b[A\n",
            "7887it [18:43,  6.95it/s]\u001b[A\n",
            "7888it [18:43,  6.99it/s]\u001b[A\n",
            "7889it [18:43,  7.03it/s]\u001b[A\n",
            "7890it [18:43,  7.09it/s]\u001b[A\n",
            "7891it [18:43,  7.01it/s]\u001b[A\n",
            "7892it [18:43,  6.92it/s]\u001b[A\n",
            "7893it [18:43,  6.99it/s]\u001b[A\n",
            "7894it [18:44,  6.95it/s]\u001b[A\n",
            "7895it [18:44,  6.72it/s]\u001b[A\n",
            "7896it [18:44,  6.66it/s]\u001b[A\n",
            "7897it [18:44,  6.66it/s]\u001b[A\n",
            "7898it [18:44,  6.51it/s]\u001b[A\n",
            "7899it [18:44,  6.47it/s]\u001b[A\n",
            "7900it [18:45,  6.58it/s]\u001b[A\n",
            "7901it [18:45,  6.68it/s]\u001b[A\n",
            "7902it [18:45,  6.81it/s]\u001b[A\n",
            "7903it [18:45,  6.89it/s]\u001b[A\n",
            "7904it [18:45,  6.82it/s]\u001b[A\n",
            "7905it [18:45,  6.83it/s]\u001b[A\n",
            "7906it [18:45,  6.87it/s]\u001b[A\n",
            "7907it [18:46,  6.92it/s]\u001b[A\n",
            "7908it [18:46,  6.98it/s]\u001b[A\n",
            "7909it [18:46,  6.95it/s]\u001b[A\n",
            "7910it [18:46,  6.81it/s]\u001b[A\n",
            "7911it [18:46,  6.75it/s]\u001b[A\n",
            "7912it [18:46,  6.47it/s]\u001b[A\n",
            "7913it [18:46,  6.50it/s]\u001b[A\n",
            "7914it [18:47,  6.56it/s]\u001b[A\n",
            "7915it [18:47,  6.66it/s]\u001b[A\n",
            "7916it [18:47,  6.61it/s]\u001b[A\n",
            "7917it [18:47,  6.69it/s]\u001b[A\n",
            "7918it [18:47,  6.85it/s]\u001b[A\n",
            "7919it [18:47,  6.81it/s]\u001b[A\n",
            "7920it [18:47,  6.87it/s]\u001b[A\n",
            "7921it [18:48,  6.97it/s]\u001b[A\n",
            "7922it [18:48,  6.97it/s]\u001b[A\n",
            "7923it [18:48,  6.88it/s]\u001b[A\n",
            "7924it [18:48,  6.74it/s]\u001b[A\n",
            "7925it [18:48,  6.58it/s]\u001b[A\n",
            "7926it [18:48,  6.49it/s]\u001b[A\n",
            "7927it [18:49,  6.52it/s]\u001b[A\n",
            "7928it [18:49,  6.53it/s]\u001b[A\n",
            "7929it [18:49,  6.47it/s]\u001b[A\n",
            "7930it [18:49,  6.46it/s]\u001b[A\n",
            "7931it [18:49,  6.50it/s]\u001b[A\n",
            "7932it [18:49,  6.33it/s]\u001b[A\n",
            "7933it [18:49,  6.38it/s]\u001b[A\n",
            "7934it [18:50,  6.48it/s]\u001b[A\n",
            "7935it [18:50,  6.46it/s]\u001b[A\n",
            "7936it [18:50,  6.52it/s]\u001b[A\n",
            "7937it [18:50,  6.66it/s]\u001b[A\n",
            "7938it [18:50,  6.65it/s]\u001b[A\n",
            "7939it [18:50,  6.46it/s]\u001b[A\n",
            "7940it [18:51,  6.43it/s]\u001b[A\n",
            "7941it [18:51,  6.47it/s]\u001b[A\n",
            "7942it [18:51,  6.44it/s]\u001b[A\n",
            "7943it [18:51,  6.46it/s]\u001b[A\n",
            "7944it [18:51,  6.46it/s]\u001b[A\n",
            "7945it [18:51,  6.50it/s]\u001b[A\n",
            "7946it [18:51,  6.60it/s]\u001b[A\n",
            "7947it [18:52,  6.70it/s]\u001b[A\n",
            "7948it [18:52,  6.70it/s]\u001b[A\n",
            "7949it [18:52,  6.64it/s]\u001b[A\n",
            "7950it [18:52,  6.74it/s]\u001b[A\n",
            "7951it [18:52,  6.91it/s]\u001b[A\n",
            "7952it [18:52,  6.90it/s]\u001b[A\n",
            "7953it [18:52,  6.91it/s]\u001b[A\n",
            "7954it [18:53,  6.77it/s]\u001b[A\n",
            "7955it [18:53,  6.86it/s]\u001b[A\n",
            "7956it [18:53,  6.92it/s]\u001b[A\n",
            "7957it [18:53,  6.95it/s]\u001b[A\n",
            "7958it [18:53,  6.91it/s]\u001b[A\n",
            "7959it [18:53,  6.86it/s]\u001b[A\n",
            "7960it [18:54,  6.82it/s]\u001b[A\n",
            "7961it [18:54,  6.95it/s]\u001b[A\n",
            "7962it [18:54,  6.97it/s]\u001b[A\n",
            "7963it [18:54,  7.08it/s]\u001b[A\n",
            "7964it [18:54,  6.93it/s]\u001b[A\n",
            "7965it [18:54,  6.82it/s]\u001b[A\n",
            "7966it [18:54,  6.56it/s]\u001b[A\n",
            "7967it [18:55,  6.63it/s]\u001b[A\n",
            "7968it [18:55,  6.74it/s]\u001b[A\n",
            "7969it [18:55,  6.69it/s]\u001b[A\n",
            "7970it [18:55,  6.73it/s]\u001b[A\n",
            "7971it [18:55,  6.80it/s]\u001b[A\n",
            "7972it [18:55,  6.86it/s]\u001b[A\n",
            "7973it [18:55,  6.78it/s]\u001b[A\n",
            "7974it [18:56,  6.94it/s]\u001b[A\n",
            "7975it [18:56,  6.95it/s]\u001b[A\n",
            "7976it [18:56,  6.95it/s]\u001b[A\n",
            "7977it [18:56,  7.01it/s]\u001b[A\n",
            "7978it [18:56,  6.90it/s]\u001b[A\n",
            "7979it [18:56,  6.74it/s]\u001b[A\n",
            "7980it [18:56,  6.47it/s]\u001b[A\n",
            "7981it [18:57,  6.37it/s]\u001b[A\n",
            "7982it [18:57,  6.36it/s]\u001b[A\n",
            "7983it [18:57,  6.48it/s]\u001b[A\n",
            "7984it [18:57,  6.69it/s]\u001b[A\n",
            "7985it [18:57,  6.72it/s]\u001b[A\n",
            "7986it [18:57,  6.71it/s]\u001b[A\n",
            "7987it [18:58,  6.64it/s]\u001b[A\n",
            "7988it [18:58,  6.79it/s]\u001b[A\n",
            "7989it [18:58,  6.67it/s]\u001b[A\n",
            "7990it [18:58,  6.75it/s]\u001b[A\n",
            "7991it [18:58,  6.87it/s]\u001b[A\n",
            "7992it [18:58,  6.90it/s]\u001b[A\n",
            "7993it [18:58,  6.90it/s]\u001b[A\n",
            "7994it [18:59,  6.77it/s]\u001b[A\n",
            "7995it [18:59,  6.85it/s]\u001b[A\n",
            "7996it [18:59,  6.86it/s]\u001b[A\n",
            "7997it [18:59,  6.83it/s]\u001b[A\n",
            "7998it [18:59,  6.61it/s]\u001b[A\n",
            "7999it [18:59,  6.55it/s]\u001b[A\n",
            "8000it [18:59,  6.43it/s]\u001b[A\n",
            "8001it [19:00,  6.63it/s]\u001b[A\n",
            "8002it [19:00,  6.66it/s]\u001b[A\n",
            "8003it [19:00,  6.63it/s]\u001b[A\n",
            "8004it [19:00,  6.68it/s]\u001b[A\n",
            "8005it [19:00,  6.73it/s]\u001b[A\n",
            "8006it [19:00,  6.76it/s]\u001b[A\n",
            "8007it [19:00,  6.73it/s]\u001b[A\n",
            "8008it [19:01,  6.81it/s]\u001b[A\n",
            "8009it [19:01,  6.96it/s]\u001b[A\n",
            "8010it [19:01,  7.06it/s]\u001b[A\n",
            "8011it [19:01,  6.94it/s]\u001b[A\n",
            "8012it [19:01,  6.96it/s]\u001b[A\n",
            "8013it [19:01,  7.06it/s]\u001b[A\n",
            "8014it [19:01,  7.00it/s]\u001b[A\n",
            "8015it [19:02,  7.03it/s]\u001b[A\n",
            "8016it [19:02,  7.11it/s]\u001b[A\n",
            "8017it [19:02,  7.09it/s]\u001b[A\n",
            "8018it [19:02,  7.05it/s]\u001b[A\n",
            "8019it [19:02,  6.92it/s]\u001b[A\n",
            "8020it [19:02,  6.97it/s]\u001b[A\n",
            "8021it [19:02,  6.90it/s]\u001b[A\n",
            "8022it [19:03,  6.93it/s]\u001b[A\n",
            "8023it [19:03,  6.92it/s]\u001b[A\n",
            "8024it [19:03,  6.87it/s]\u001b[A\n",
            "8025it [19:03,  6.85it/s]\u001b[A\n",
            "8026it [19:03,  6.70it/s]\u001b[A\n",
            "8027it [19:03,  6.59it/s]\u001b[A\n",
            "8028it [19:04,  6.54it/s]\u001b[A\n",
            "8029it [19:04,  6.67it/s]\u001b[A\n",
            "8030it [19:04,  6.78it/s]\u001b[A\n",
            "8031it [19:04,  6.67it/s]\u001b[A\n",
            "8032it [19:04,  6.58it/s]\u001b[A\n",
            "8033it [19:04,  6.73it/s]\u001b[A\n",
            "8034it [19:04,  6.77it/s]\u001b[A\n",
            "8035it [19:05,  6.82it/s]\u001b[A\n",
            "8036it [19:05,  6.92it/s]\u001b[A\n",
            "8037it [19:05,  6.96it/s]\u001b[A\n",
            "8038it [19:05,  6.97it/s]\u001b[A\n",
            "8039it [19:05,  6.98it/s]\u001b[A\n",
            "8040it [19:05,  6.81it/s]\u001b[A\n",
            "8041it [19:05,  6.75it/s]\u001b[A\n",
            "8042it [19:06,  6.55it/s]\u001b[A\n",
            "8043it [19:06,  6.60it/s]\u001b[A\n",
            "8044it [19:06,  6.50it/s]\u001b[A\n",
            "8045it [19:06,  6.52it/s]\u001b[A\n",
            "8046it [19:06,  6.69it/s]\u001b[A\n",
            "8047it [19:06,  6.77it/s]\u001b[A\n",
            "8048it [19:06,  6.88it/s]\u001b[A\n",
            "8049it [19:07,  6.77it/s]\u001b[A\n",
            "8050it [19:07,  6.87it/s]\u001b[A\n",
            "8051it [19:07,  6.94it/s]\u001b[A\n",
            "8052it [19:07,  6.89it/s]\u001b[A\n",
            "8053it [19:07,  6.93it/s]\u001b[A\n",
            "8054it [19:07,  7.01it/s]\u001b[A\n",
            "8055it [19:07,  7.02it/s]\u001b[A\n",
            "8056it [19:08,  6.96it/s]\u001b[A\n",
            "8057it [19:08,  7.01it/s]\u001b[A\n",
            "8058it [19:08,  7.05it/s]\u001b[A\n",
            "8059it [19:08,  7.08it/s]\u001b[A\n",
            "8060it [19:08,  7.03it/s]\u001b[A\n",
            "8061it [19:08,  7.01it/s]\u001b[A\n",
            "8062it [19:08,  7.00it/s]\u001b[A\n",
            "8063it [19:09,  6.89it/s]\u001b[A\n",
            "8064it [19:09,  6.93it/s]\u001b[A\n",
            "8065it [19:09,  6.83it/s]\u001b[A\n",
            "8066it [19:09,  6.82it/s]\u001b[A\n",
            "8067it [19:09,  6.79it/s]\u001b[A\n",
            "8068it [19:09,  6.68it/s]\u001b[A\n",
            "8069it [19:10,  6.58it/s]\u001b[A\n",
            "8070it [19:10,  6.51it/s]\u001b[A\n",
            "8071it [19:10,  6.47it/s]\u001b[A\n",
            "8072it [19:10,  6.66it/s]\u001b[A\n",
            "8073it [19:10,  6.76it/s]\u001b[A\n",
            "8074it [19:10,  6.76it/s]\u001b[A\n",
            "8075it [19:10,  6.85it/s]\u001b[A\n",
            "8076it [19:11,  6.89it/s]\u001b[A\n",
            "8077it [19:11,  6.89it/s]\u001b[A\n",
            "8078it [19:11,  7.00it/s]\u001b[A\n",
            "8079it [19:11,  6.97it/s]\u001b[A\n",
            "8080it [19:11,  6.95it/s]\u001b[A\n",
            "8081it [19:11,  6.83it/s]\u001b[A\n",
            "8082it [19:11,  6.71it/s]\u001b[A\n",
            "8083it [19:12,  6.58it/s]\u001b[A\n",
            "8084it [19:12,  6.62it/s]\u001b[A\n",
            "8085it [19:12,  6.54it/s]\u001b[A\n",
            "8086it [19:12,  6.64it/s]\u001b[A\n",
            "8087it [19:12,  6.57it/s]\u001b[A\n",
            "8088it [19:12,  6.41it/s]\u001b[A\n",
            "8089it [19:13,  6.39it/s]\u001b[A\n",
            "8090it [19:13,  6.28it/s]\u001b[A\n",
            "8091it [19:13,  6.29it/s]\u001b[A\n",
            "8092it [19:13,  6.39it/s]\u001b[A\n",
            "8093it [19:13,  6.49it/s]\u001b[A\n",
            "8094it [19:13,  6.69it/s]\u001b[A\n",
            "8095it [19:13,  6.75it/s]\u001b[A\n",
            "8096it [19:14,  6.78it/s]\u001b[A\n",
            "8097it [19:14,  6.66it/s]\u001b[A\n",
            "8098it [19:14,  6.80it/s]\u001b[A\n",
            "8099it [19:14,  6.86it/s]\u001b[A\n",
            "8100it [19:14,  6.91it/s]\u001b[A\n",
            "8101it [19:14,  6.94it/s]\u001b[A\n",
            "8102it [19:14,  6.97it/s]\u001b[A\n",
            "8103it [19:15,  7.01it/s]\u001b[A\n",
            "8104it [19:15,  6.86it/s]\u001b[A\n",
            "8105it [19:15,  6.97it/s]\u001b[A\n",
            "8106it [19:15,  6.90it/s]\u001b[A\n",
            "8107it [19:15,  6.81it/s]\u001b[A\n",
            "8108it [19:15,  6.64it/s]\u001b[A\n",
            "8109it [19:16,  6.49it/s]\u001b[A\n",
            "8110it [19:16,  6.43it/s]\u001b[A\n",
            "8111it [19:16,  6.36it/s]\u001b[A\n",
            "8112it [19:16,  6.42it/s]\u001b[A\n",
            "8113it [19:16,  6.48it/s]\u001b[A\n",
            "8114it [19:16,  6.56it/s]\u001b[A\n",
            "8115it [19:16,  6.77it/s]\u001b[A\n",
            "8116it [19:17,  6.86it/s]\u001b[A\n",
            "8117it [19:17,  6.74it/s]\u001b[A\n",
            "8118it [19:17,  6.49it/s]\u001b[A\n",
            "8119it [19:17,  6.49it/s]\u001b[A\n",
            "8120it [19:17,  6.62it/s]\u001b[A\n",
            "8121it [19:17,  6.78it/s]\u001b[A\n",
            "8122it [19:17,  6.88it/s]\u001b[A\n",
            "8123it [19:18,  6.96it/s]\u001b[A\n",
            "8124it [19:18,  6.96it/s]\u001b[A\n",
            "8125it [19:18,  7.01it/s]\u001b[A\n",
            "8126it [19:18,  6.89it/s]\u001b[A\n",
            "8127it [19:18,  6.86it/s]\u001b[A\n",
            "8128it [19:18,  6.98it/s]\u001b[A\n",
            "8129it [19:18,  6.94it/s]\u001b[A\n",
            "8130it [19:19,  6.73it/s]\u001b[A\n",
            "8131it [19:19,  6.50it/s]\u001b[A\n",
            "8132it [19:19,  6.51it/s]\u001b[A\n",
            "8133it [19:19,  6.62it/s]\u001b[A\n",
            "8134it [19:19,  6.71it/s]\u001b[A\n",
            "8135it [19:19,  6.78it/s]\u001b[A\n",
            "8136it [19:20,  6.76it/s]\u001b[A\n",
            "8137it [19:20,  6.74it/s]\u001b[A\n",
            "8138it [19:20,  6.63it/s]\u001b[A\n",
            "8139it [19:20,  6.57it/s]\u001b[A\n",
            "8140it [19:20,  6.54it/s]\u001b[A\n",
            "8141it [19:20,  6.51it/s]\u001b[A\n",
            "8142it [19:20,  6.45it/s]\u001b[A\n",
            "8143it [19:21,  6.59it/s]\u001b[A\n",
            "8144it [19:21,  6.73it/s]\u001b[A\n",
            "8145it [19:21,  6.76it/s]\u001b[A\n",
            "8146it [19:21,  6.88it/s]\u001b[A\n",
            "8147it [19:21,  6.97it/s]\u001b[A\n",
            "8148it [19:21,  7.03it/s]\u001b[A\n",
            "8149it [19:21,  7.07it/s]\u001b[A\n",
            "8150it [19:22,  7.15it/s]\u001b[A\n",
            "8151it [19:22,  7.15it/s]\u001b[A\n",
            "8152it [19:22,  6.96it/s]\u001b[A\n",
            "8153it [19:22,  7.08it/s]\u001b[A\n",
            "8154it [19:22,  7.03it/s]\u001b[A\n",
            "8155it [19:22,  7.04it/s]\u001b[A\n",
            "8156it [19:22,  7.08it/s]\u001b[A\n",
            "8157it [19:23,  7.04it/s]\u001b[A\n",
            "8158it [19:23,  7.00it/s]\u001b[A\n",
            "8159it [19:23,  6.93it/s]\u001b[A\n",
            "8160it [19:23,  7.01it/s]\u001b[A\n",
            "8161it [19:23,  6.80it/s]\u001b[A\n",
            "8162it [19:23,  6.68it/s]\u001b[A\n",
            "8163it [19:23,  6.51it/s]\u001b[A\n",
            "8164it [19:24,  6.52it/s]\u001b[A\n",
            "8165it [19:24,  6.36it/s]\u001b[A\n",
            "8166it [19:24,  6.44it/s]\u001b[A\n",
            "8167it [19:24,  6.68it/s]\u001b[A\n",
            "8168it [19:24,  6.73it/s]\u001b[A\n",
            "8169it [19:24,  6.83it/s]\u001b[A\n",
            "8170it [19:25,  6.87it/s]\u001b[A\n",
            "8171it [19:25,  6.98it/s]\u001b[A\n",
            "8172it [19:25,  7.00it/s]\u001b[A\n",
            "8173it [19:25,  7.00it/s]\u001b[A\n",
            "8174it [19:25,  7.01it/s]\u001b[A\n",
            "8175it [19:25,  7.04it/s]\u001b[A\n",
            "8176it [19:25,  7.12it/s]\u001b[A\n",
            "8177it [19:26,  7.09it/s]\u001b[A\n",
            "8178it [19:26,  6.96it/s]\u001b[A\n",
            "8179it [19:26,  6.77it/s]\u001b[A\n",
            "8180it [19:26,  6.74it/s]\u001b[A\n",
            "8181it [19:26,  6.82it/s]\u001b[A\n",
            "8182it [19:26,  6.92it/s]\u001b[A\n",
            "8183it [19:26,  6.96it/s]\u001b[A\n",
            "8184it [19:27,  7.07it/s]\u001b[A\n",
            "8185it [19:27,  7.07it/s]\u001b[A\n",
            "8186it [19:27,  7.19it/s]\u001b[A\n",
            "8187it [19:27,  7.05it/s]\u001b[A\n",
            "8188it [19:27,  7.12it/s]\u001b[A\n",
            "8189it [19:27,  7.09it/s]\u001b[A\n",
            "8190it [19:27,  7.05it/s]\u001b[A\n",
            "8191it [19:28,  7.07it/s]\u001b[A\n",
            "8192it [19:28,  6.88it/s]\u001b[A\n",
            "8193it [19:28,  6.75it/s]\u001b[A\n",
            "8194it [19:28,  6.31it/s]\u001b[A\n",
            "8195it [19:28,  6.28it/s]\u001b[A\n",
            "8196it [19:28,  6.29it/s]\u001b[A\n",
            "8197it [19:28,  6.20it/s]\u001b[A\n",
            "8198it [19:29,  6.24it/s]\u001b[A\n",
            "8199it [19:29,  6.30it/s]\u001b[A\n",
            "8200it [19:29,  6.17it/s]\u001b[A\n",
            "8201it [19:29,  6.26it/s]\u001b[A\n",
            "8202it [19:29,  6.37it/s]\u001b[A\n",
            "8203it [19:29,  6.51it/s]\u001b[A\n",
            "8204it [19:30,  6.69it/s]\u001b[A\n",
            "8205it [19:30,  6.88it/s]\u001b[A\n",
            "8206it [19:30,  7.02it/s]\u001b[A\n",
            "8207it [19:30,  6.88it/s]\u001b[A\n",
            "8208it [19:30,  6.89it/s]\u001b[A\n",
            "8209it [19:30,  6.86it/s]\u001b[A\n",
            "8210it [19:30,  6.96it/s]\u001b[A\n",
            "8211it [19:31,  6.82it/s]\u001b[A\n",
            "8212it [19:31,  6.84it/s]\u001b[A\n",
            "8213it [19:31,  6.95it/s]\u001b[A\n",
            "8214it [19:31,  6.74it/s]\u001b[A\n",
            "8215it [19:31,  6.80it/s]\u001b[A\n",
            "8216it [19:31,  6.86it/s]\u001b[A\n",
            "8217it [19:31,  6.93it/s]\u001b[A\n",
            "8218it [19:32,  6.98it/s]\u001b[A\n",
            "8219it [19:32,  6.98it/s]\u001b[A\n",
            "8220it [19:32,  7.02it/s]\u001b[A\n",
            "8221it [19:32,  6.80it/s]\u001b[A\n",
            "8222it [19:32,  6.90it/s]\u001b[A\n",
            "8223it [19:32,  6.87it/s]\u001b[A\n",
            "8224it [19:32,  6.78it/s]\u001b[A\n",
            "8225it [19:33,  6.60it/s]\u001b[A\n",
            "8226it [19:33,  6.58it/s]\u001b[A\n",
            "8227it [19:33,  6.61it/s]\u001b[A\n",
            "8228it [19:33,  6.52it/s]\u001b[A\n",
            "8229it [19:33,  6.70it/s]\u001b[A\n",
            "8230it [19:33,  6.89it/s]\u001b[A\n",
            "8231it [19:33,  7.04it/s]\u001b[A\n",
            "8232it [19:34,  7.15it/s]\u001b[A\n",
            "8233it [19:34,  7.09it/s]\u001b[A\n",
            "8234it [19:34,  6.91it/s]\u001b[A\n",
            "8235it [19:34,  6.68it/s]\u001b[A\n",
            "8236it [19:34,  6.80it/s]\u001b[A\n",
            "8237it [19:34,  6.85it/s]\u001b[A\n",
            "8238it [19:35,  6.92it/s]\u001b[A\n",
            "8239it [19:35,  6.88it/s]\u001b[A\n",
            "8240it [19:35,  6.91it/s]\u001b[A\n",
            "8241it [19:35,  6.89it/s]\u001b[A\n",
            "8242it [19:35,  6.86it/s]\u001b[A\n",
            "8243it [19:35,  6.89it/s]\u001b[A\n",
            "8244it [19:35,  6.90it/s]\u001b[A\n",
            "8245it [19:36,  6.94it/s]\u001b[A\n",
            "8246it [19:36,  7.07it/s]\u001b[A\n",
            "8247it [19:36,  7.11it/s]\u001b[A\n",
            "8248it [19:36,  7.02it/s]\u001b[A\n",
            "8249it [19:36,  6.82it/s]\u001b[A\n",
            "8250it [19:36,  6.90it/s]\u001b[A\n",
            "8251it [19:36,  6.93it/s]\u001b[A\n",
            "8252it [19:37,  6.97it/s]\u001b[A\n",
            "8253it [19:37,  7.04it/s]\u001b[A\n",
            "8254it [19:37,  7.13it/s]\u001b[A\n",
            "8255it [19:37,  7.15it/s]\u001b[A\n",
            "8256it [19:37,  6.90it/s]\u001b[A\n",
            "8257it [19:37,  6.60it/s]\u001b[A\n",
            "8258it [19:37,  6.58it/s]\u001b[A\n",
            "8259it [19:38,  6.59it/s]\u001b[A\n",
            "8260it [19:38,  6.69it/s]\u001b[A\n",
            "8261it [19:38,  6.73it/s]\u001b[A\n",
            "8262it [19:38,  6.41it/s]\u001b[A\n",
            "8263it [19:38,  6.31it/s]\u001b[A\n",
            "8264it [19:38,  6.21it/s]\u001b[A\n",
            "8265it [19:39,  6.14it/s]\u001b[A\n",
            "8266it [19:39,  6.21it/s]\u001b[A\n",
            "8267it [19:39,  6.26it/s]\u001b[A\n",
            "8268it [19:39,  6.34it/s]\u001b[A\n",
            "8269it [19:39,  6.26it/s]\u001b[A\n",
            "8270it [19:39,  6.32it/s]\u001b[A\n",
            "8271it [19:39,  6.36it/s]\u001b[A\n",
            "8272it [19:40,  6.43it/s]\u001b[A\n",
            "8273it [19:40,  6.48it/s]\u001b[A\n",
            "8274it [19:40,  6.63it/s]\u001b[A\n",
            "8275it [19:40,  6.65it/s]\u001b[A\n",
            "8276it [19:40,  6.76it/s]\u001b[A\n",
            "8277it [19:40,  6.86it/s]\u001b[A\n",
            "8278it [19:40,  6.90it/s]\u001b[A\n",
            "8279it [19:41,  6.99it/s]\u001b[A\n",
            "8280it [19:41,  7.05it/s]\u001b[A\n",
            "8281it [19:41,  7.05it/s]\u001b[A\n",
            "8282it [19:41,  6.75it/s]\u001b[A\n",
            "8283it [19:41,  6.71it/s]\u001b[A\n",
            "8284it [19:41,  6.79it/s]\u001b[A\n",
            "8285it [19:42,  6.89it/s]\u001b[A\n",
            "8286it [19:42,  6.95it/s]\u001b[A\n",
            "8287it [19:42,  7.03it/s]\u001b[A\n",
            "8288it [19:42,  6.99it/s]\u001b[A\n",
            "8289it [19:42,  6.78it/s]\u001b[A\n",
            "8290it [19:42,  6.61it/s]\u001b[A\n",
            "8291it [19:42,  6.57it/s]\u001b[A\n",
            "8292it [19:43,  6.53it/s]\u001b[A\n",
            "8293it [19:43,  6.53it/s]\u001b[A\n",
            "8294it [19:43,  6.51it/s]\u001b[A\n",
            "8295it [19:43,  6.44it/s]\u001b[A\n",
            "8296it [19:43,  6.46it/s]\u001b[A\n",
            "8297it [19:43,  6.65it/s]\u001b[A\n",
            "8298it [19:43,  6.82it/s]\u001b[A\n",
            "8299it [19:44,  6.94it/s]\u001b[A\n",
            "8300it [19:44,  7.02it/s]\u001b[A\n",
            "8301it [19:44,  7.02it/s]\u001b[A\n",
            "8302it [19:44,  7.07it/s]\u001b[A\n",
            "8303it [19:44,  6.84it/s]\u001b[A\n",
            "8304it [19:44,  6.77it/s]\u001b[A\n",
            "8305it [19:44,  6.69it/s]\u001b[A\n",
            "8306it [19:45,  6.69it/s]\u001b[A\n",
            "8307it [19:45,  6.70it/s]\u001b[A\n",
            "8308it [19:45,  6.70it/s]\u001b[A\n",
            "8309it [19:45,  6.65it/s]\u001b[A\n",
            "8310it [19:45,  6.60it/s]\u001b[A\n",
            "8311it [19:45,  6.59it/s]\u001b[A\n",
            "8312it [19:46,  6.62it/s]\u001b[A\n",
            "8313it [19:46,  6.76it/s]\u001b[A\n",
            "8314it [19:46,  6.85it/s]\u001b[A\n",
            "8315it [19:46,  6.77it/s]\u001b[A\n",
            "8316it [19:46,  6.67it/s]\u001b[A\n",
            "8317it [19:46,  6.51it/s]\u001b[A\n",
            "8318it [19:46,  6.41it/s]\u001b[A\n",
            "8319it [19:47,  6.41it/s]\u001b[A\n",
            "8320it [19:47,  6.42it/s]\u001b[A\n",
            "8321it [19:47,  6.44it/s]\u001b[A\n",
            "8322it [19:47,  6.38it/s]\u001b[A\n",
            "8323it [19:47,  6.42it/s]\u001b[A\n",
            "8324it [19:47,  6.59it/s]\u001b[A\n",
            "8325it [19:48,  6.71it/s]\u001b[A\n",
            "8326it [19:48,  6.81it/s]\u001b[A\n",
            "8327it [19:48,  6.95it/s]\u001b[A\n",
            "8328it [19:48,  6.95it/s]\u001b[A\n",
            "8329it [19:48,  6.96it/s]\u001b[A\n",
            "8330it [19:48,  6.63it/s]\u001b[A\n",
            "8331it [19:48,  6.58it/s]\u001b[A\n",
            "8332it [19:49,  6.67it/s]\u001b[A\n",
            "8333it [19:49,  6.62it/s]\u001b[A\n",
            "8334it [19:49,  6.63it/s]\u001b[A\n",
            "8335it [19:49,  6.55it/s]\u001b[A\n",
            "8336it [19:49,  6.51it/s]\u001b[A\n",
            "8337it [19:49,  6.44it/s]\u001b[A\n",
            "8338it [19:49,  6.44it/s]\u001b[A\n",
            "8339it [19:50,  6.46it/s]\u001b[A\n",
            "8340it [19:50,  6.45it/s]\u001b[A\n",
            "8341it [19:50,  6.61it/s]\u001b[A\n",
            "8342it [19:50,  6.78it/s]\u001b[A\n",
            "8343it [19:50,  6.67it/s]\u001b[A\n",
            "8344it [19:50,  6.78it/s]\u001b[A\n",
            "8345it [19:51,  6.83it/s]\u001b[A\n",
            "8346it [19:51,  6.84it/s]\u001b[A\n",
            "8347it [19:51,  6.90it/s]\u001b[A\n",
            "8348it [19:51,  6.79it/s]\u001b[A\n",
            "8349it [19:51,  6.59it/s]\u001b[A\n",
            "8350it [19:51,  6.55it/s]\u001b[A\n",
            "8351it [19:51,  6.54it/s]\u001b[A\n",
            "8352it [19:52,  6.73it/s]\u001b[A\n",
            "8353it [19:52,  6.79it/s]\u001b[A\n",
            "8354it [19:52,  6.87it/s]\u001b[A\n",
            "8355it [19:52,  6.90it/s]\u001b[A\n",
            "8356it [19:52,  6.89it/s]\u001b[A\n",
            "8357it [19:52,  6.85it/s]\u001b[A\n",
            "8358it [19:52,  6.82it/s]\u001b[A\n",
            "8359it [19:53,  6.91it/s]\u001b[A\n",
            "8360it [19:53,  6.98it/s]\u001b[A\n",
            "8361it [19:53,  7.00it/s]\u001b[A\n",
            "8362it [19:53,  6.86it/s]\u001b[A\n",
            "8363it [19:53,  6.80it/s]\u001b[A\n",
            "8364it [19:53,  6.74it/s]\u001b[A\n",
            "8365it [19:53,  6.77it/s]\u001b[A\n",
            "8366it [19:54,  6.84it/s]\u001b[A\n",
            "8367it [19:54,  6.82it/s]\u001b[A\n",
            "8368it [19:54,  6.88it/s]\u001b[A\n",
            "8369it [19:54,  6.86it/s]\u001b[A\n",
            "8370it [19:54,  6.75it/s]\u001b[A\n",
            "8371it [19:54,  6.54it/s]\u001b[A\n",
            "8372it [19:55,  6.50it/s]\u001b[A\n",
            "8373it [19:55,  6.46it/s]\u001b[A\n",
            "8374it [19:55,  6.42it/s]\u001b[A\n",
            "8375it [19:55,  6.37it/s]\u001b[A\n",
            "8376it [19:55,  6.49it/s]\u001b[A\n",
            "8377it [19:55,  6.35it/s]\u001b[A\n",
            "8378it [19:55,  6.42it/s]\u001b[A\n",
            "8379it [19:56,  6.34it/s]\u001b[A\n",
            "8380it [19:56,  6.26it/s]\u001b[A\n",
            "8381it [19:56,  6.33it/s]\u001b[A\n",
            "8382it [19:56,  6.54it/s]\u001b[A\n",
            "8383it [19:56,  6.70it/s]\u001b[A\n",
            "8384it [19:56,  6.82it/s]\u001b[A\n",
            "8385it [19:56,  6.90it/s]\u001b[A\n",
            "8386it [19:57,  6.96it/s]\u001b[A\n",
            "8387it [19:57,  6.79it/s]\u001b[A\n",
            "8388it [19:57,  6.72it/s]\u001b[A\n",
            "8389it [19:57,  6.57it/s]\u001b[A\n",
            "8390it [19:57,  6.71it/s]\u001b[A\n",
            "8391it [19:57,  6.71it/s]\u001b[A\n",
            "8392it [19:58,  6.83it/s]\u001b[A\n",
            "8393it [19:58,  6.98it/s]\u001b[A\n",
            "8394it [19:58,  7.00it/s]\u001b[A\n",
            "8395it [19:58,  7.03it/s]\u001b[A\n",
            "8396it [19:58,  7.05it/s]\u001b[A\n",
            "8397it [19:58,  6.97it/s]\u001b[A\n",
            "8398it [19:58,  6.90it/s]\u001b[A\n",
            "8399it [19:59,  6.83it/s]\u001b[A\n",
            "8400it [19:59,  6.73it/s]\u001b[A\n",
            "8401it [19:59,  6.67it/s]\u001b[A\n",
            "8402it [19:59,  6.54it/s]\u001b[A\n",
            "8403it [19:59,  6.65it/s]\u001b[A\n",
            "8404it [19:59,  6.82it/s]\u001b[A\n",
            "8405it [19:59,  6.81it/s]\u001b[A\n",
            "8406it [20:00,  6.84it/s]\u001b[A\n",
            "8407it [20:00,  6.89it/s]\u001b[A\n",
            "8408it [20:00,  6.89it/s]\u001b[A\n",
            "8409it [20:00,  7.00it/s]\u001b[A\n",
            "8410it [20:00,  7.04it/s]\u001b[A\n",
            "8411it [20:00,  6.99it/s]\u001b[A\n",
            "8412it [20:00,  6.88it/s]\u001b[A\n",
            "8413it [20:01,  6.95it/s]\u001b[A\n",
            "8414it [20:01,  7.01it/s]\u001b[A\n",
            "8415it [20:01,  7.02it/s]\u001b[A\n",
            "8416it [20:01,  7.03it/s]\u001b[A\n",
            "8417it [20:01,  7.01it/s]\u001b[A\n",
            "8418it [20:01,  6.94it/s]\u001b[A\n",
            "8419it [20:01,  6.95it/s]\u001b[A\n",
            "8420it [20:02,  6.96it/s]\u001b[A\n",
            "8421it [20:02,  6.91it/s]\u001b[A\n",
            "8422it [20:02,  7.00it/s]\u001b[A\n",
            "8423it [20:02,  6.88it/s]\u001b[A\n",
            "8424it [20:02,  6.77it/s]\u001b[A\n",
            "8425it [20:02,  6.63it/s]\u001b[A\n",
            "8426it [20:02,  6.38it/s]\u001b[A\n",
            "8427it [20:03,  6.59it/s]\u001b[A\n",
            "8428it [20:03,  6.77it/s]\u001b[A\n",
            "8429it [20:03,  6.88it/s]\u001b[A\n",
            "8430it [20:03,  6.97it/s]\u001b[A\n",
            "8431it [20:03,  6.87it/s]\u001b[A\n",
            "8432it [20:03,  6.97it/s]\u001b[A\n",
            "8433it [20:03,  6.92it/s]\u001b[A\n",
            "8434it [20:04,  6.98it/s]\u001b[A\n",
            "8435it [20:04,  6.84it/s]\u001b[A\n",
            "8436it [20:04,  6.63it/s]\u001b[A\n",
            "8437it [20:04,  6.61it/s]\u001b[A\n",
            "8438it [20:04,  6.71it/s]\u001b[A\n",
            "8439it [20:04,  6.79it/s]\u001b[A\n",
            "8440it [20:05,  6.83it/s]\u001b[A\n",
            "8441it [20:05,  6.93it/s]\u001b[A\n",
            "8442it [20:05,  7.00it/s]\u001b[A\n",
            "8443it [20:05,  7.06it/s]\u001b[A\n",
            "8444it [20:05,  7.07it/s]\u001b[A\n",
            "8445it [20:05,  7.08it/s]\u001b[A\n",
            "8446it [20:05,  7.08it/s]\u001b[A\n",
            "8447it [20:06,  7.08it/s]\u001b[A\n",
            "8448it [20:06,  7.04it/s]\u001b[A\n",
            "8449it [20:06,  7.00it/s]\u001b[A\n",
            "8450it [20:06,  6.92it/s]\u001b[A\n",
            "8451it [20:06,  6.76it/s]\u001b[A\n",
            "8452it [20:06,  6.71it/s]\u001b[A\n",
            "8453it [20:06,  6.74it/s]\u001b[A\n",
            "8454it [20:07,  6.63it/s]\u001b[A\n",
            "8455it [20:07,  6.74it/s]\u001b[A\n",
            "8456it [20:07,  6.80it/s]\u001b[A\n",
            "8457it [20:07,  6.86it/s]\u001b[A\n",
            "8458it [20:07,  7.00it/s]\u001b[A\n",
            "8459it [20:07,  6.97it/s]\u001b[A\n",
            "8460it [20:07,  6.97it/s]\u001b[A\n",
            "8461it [20:08,  6.95it/s]\u001b[A\n",
            "8462it [20:08,  6.88it/s]\u001b[A\n",
            "8463it [20:08,  6.93it/s]\u001b[A\n",
            "8464it [20:08,  7.02it/s]\u001b[A\n",
            "8465it [20:08,  7.01it/s]\u001b[A\n",
            "8466it [20:08,  7.01it/s]\u001b[A\n",
            "8467it [20:08,  7.01it/s]\u001b[A\n",
            "8468it [20:09,  6.89it/s]\u001b[A\n",
            "8469it [20:09,  7.01it/s]\u001b[A\n",
            "8470it [20:09,  7.04it/s]\u001b[A\n",
            "8471it [20:09,  7.03it/s]\u001b[A\n",
            "8472it [20:09,  6.92it/s]\u001b[A\n",
            "8473it [20:09,  6.86it/s]\u001b[A\n",
            "8474it [20:09,  6.89it/s]\u001b[A\n",
            "8475it [20:10,  6.79it/s]\u001b[A\n",
            "8476it [20:10,  6.80it/s]\u001b[A\n",
            "8477it [20:10,  6.89it/s]\u001b[A\n",
            "8478it [20:10,  6.96it/s]\u001b[A\n",
            "8479it [20:10,  6.92it/s]\u001b[A\n",
            "8480it [20:10,  6.71it/s]\u001b[A\n",
            "8481it [20:10,  6.57it/s]\u001b[A\n",
            "8482it [20:11,  6.71it/s]\u001b[A\n",
            "8483it [20:11,  6.82it/s]\u001b[A\n",
            "8484it [20:11,  6.93it/s]\u001b[A\n",
            "8485it [20:11,  6.99it/s]\u001b[A\n",
            "8486it [20:11,  6.79it/s]\u001b[A\n",
            "8487it [20:11,  6.78it/s]\u001b[A\n",
            "8488it [20:11,  6.85it/s]\u001b[A\n",
            "8489it [20:12,  6.80it/s]\u001b[A\n",
            "8490it [20:12,  6.82it/s]\u001b[A\n",
            "8491it [20:12,  6.84it/s]\u001b[A\n",
            "8492it [20:12,  6.87it/s]\u001b[A\n",
            "8493it [20:12,  6.79it/s]\u001b[A\n",
            "8494it [20:12,  6.77it/s]\u001b[A\n",
            "8495it [20:13,  6.81it/s]\u001b[A\n",
            "8496it [20:13,  6.84it/s]\u001b[A\n",
            "8497it [20:13,  6.92it/s]\u001b[A\n",
            "8498it [20:13,  6.89it/s]\u001b[A\n",
            "8499it [20:13,  6.71it/s]\u001b[A\n",
            "8500it [20:13,  6.60it/s]\u001b[A\n",
            "8501it [20:13,  6.48it/s]\u001b[A\n",
            "8502it [20:14,  6.38it/s]\u001b[A\n",
            "8503it [20:14,  6.48it/s]\u001b[A\n",
            "8504it [20:14,  6.60it/s]\u001b[A\n",
            "8505it [20:14,  6.75it/s]\u001b[A\n",
            "8506it [20:14,  6.77it/s]\u001b[A\n",
            "8507it [20:14,  6.65it/s]\u001b[A\n",
            "8508it [20:14,  6.63it/s]\u001b[A\n",
            "8509it [20:15,  6.64it/s]\u001b[A\n",
            "8510it [20:15,  6.76it/s]\u001b[A\n",
            "8511it [20:15,  6.91it/s]\u001b[A\n",
            "8512it [20:15,  6.98it/s]\u001b[A\n",
            "8513it [20:15,  6.94it/s]\u001b[A\n",
            "8514it [20:15,  6.95it/s]\u001b[A\n",
            "8515it [20:15,  6.97it/s]\u001b[A\n",
            "8516it [20:16,  6.89it/s]\u001b[A\n",
            "8517it [20:16,  6.77it/s]\u001b[A\n",
            "8518it [20:16,  6.72it/s]\u001b[A\n",
            "8519it [20:16,  6.76it/s]\u001b[A\n",
            "8520it [20:16,  6.82it/s]\u001b[A\n",
            "8521it [20:16,  6.74it/s]\u001b[A\n",
            "8522it [20:17,  6.82it/s]\u001b[A\n",
            "8523it [20:17,  6.74it/s]\u001b[A\n",
            "8524it [20:17,  6.80it/s]\u001b[A\n",
            "8525it [20:17,  6.73it/s]\u001b[A\n",
            "8526it [20:17,  6.66it/s]\u001b[A\n",
            "8527it [20:17,  6.77it/s]\u001b[A\n",
            "8528it [20:17,  6.85it/s]\u001b[A\n",
            "8529it [20:18,  6.96it/s]\u001b[A\n",
            "8530it [20:18,  7.00it/s]\u001b[A\n",
            "8531it [20:18,  6.93it/s]\u001b[A\n",
            "8532it [20:18,  7.05it/s]\u001b[A\n",
            "8533it [20:18,  6.93it/s]\u001b[A\n",
            "8534it [20:18,  6.94it/s]\u001b[A\n",
            "8535it [20:18,  6.92it/s]\u001b[A\n",
            "8536it [20:19,  7.06it/s]\u001b[A\n",
            "8537it [20:19,  7.03it/s]\u001b[A\n",
            "8538it [20:19,  6.86it/s]\u001b[A\n",
            "8539it [20:19,  6.90it/s]\u001b[A\n",
            "8540it [20:19,  6.89it/s]\u001b[A\n",
            "8541it [20:19,  6.91it/s]\u001b[A\n",
            "8542it [20:19,  6.98it/s]\u001b[A\n",
            "8543it [20:20,  6.99it/s]\u001b[A\n",
            "8544it [20:20,  6.78it/s]\u001b[A\n",
            "8545it [20:20,  6.62it/s]\u001b[A\n",
            "8546it [20:20,  6.71it/s]\u001b[A\n",
            "8547it [20:20,  6.79it/s]\u001b[A\n",
            "8548it [20:20,  6.76it/s]\u001b[A\n",
            "8549it [20:20,  6.86it/s]\u001b[A\n",
            "8550it [20:21,  6.95it/s]\u001b[A\n",
            "8551it [20:21,  6.90it/s]\u001b[A\n",
            "8552it [20:21,  6.96it/s]\u001b[A\n",
            "8553it [20:21,  7.03it/s]\u001b[A\n",
            "8554it [20:21,  7.00it/s]\u001b[A\n",
            "8555it [20:21,  7.02it/s]\u001b[A\n",
            "8556it [20:21,  6.99it/s]\u001b[A\n",
            "8557it [20:22,  6.95it/s]\u001b[A\n",
            "8558it [20:22,  6.78it/s]\u001b[A\n",
            "8559it [20:22,  6.84it/s]\u001b[A\n",
            "8560it [20:22,  6.81it/s]\u001b[A\n",
            "8561it [20:22,  6.68it/s]\u001b[A\n",
            "8562it [20:22,  6.62it/s]\u001b[A\n",
            "8563it [20:22,  6.57it/s]\u001b[A\n",
            "8564it [20:23,  6.49it/s]\u001b[A\n",
            "8565it [20:23,  6.47it/s]\u001b[A\n",
            "8566it [20:23,  6.48it/s]\u001b[A\n",
            "8567it [20:23,  6.50it/s]\u001b[A\n",
            "8568it [20:23,  6.63it/s]\u001b[A\n",
            "8569it [20:23,  6.53it/s]\u001b[A\n",
            "8570it [20:24,  6.53it/s]\u001b[A\n",
            "8571it [20:24,  6.45it/s]\u001b[A\n",
            "8572it [20:24,  6.50it/s]\u001b[A\n",
            "8573it [20:24,  6.56it/s]\u001b[A\n",
            "8574it [20:24,  6.66it/s]\u001b[A\n",
            "8575it [20:24,  6.78it/s]\u001b[A\n",
            "8576it [20:24,  6.82it/s]\u001b[A\n",
            "8577it [20:25,  6.97it/s]\u001b[A\n",
            "8578it [20:25,  6.86it/s]\u001b[A\n",
            "8579it [20:25,  6.77it/s]\u001b[A\n",
            "8580it [20:25,  6.80it/s]\u001b[A\n",
            "8581it [20:25,  6.66it/s]\u001b[A\n",
            "8582it [20:25,  6.57it/s]\u001b[A\n",
            "8583it [20:26,  6.65it/s]\u001b[A\n",
            "8584it [20:26,  6.86it/s]\u001b[A\n",
            "8585it [20:26,  6.66it/s]\u001b[A\n",
            "8586it [20:26,  6.67it/s]\u001b[A\n",
            "8587it [20:26,  6.69it/s]\u001b[A\n",
            "8588it [20:26,  6.56it/s]\u001b[A\n",
            "8589it [20:26,  6.50it/s]\u001b[A\n",
            "8590it [20:27,  6.61it/s]\u001b[A\n",
            "8591it [20:27,  6.73it/s]\u001b[A\n",
            "8592it [20:27,  6.54it/s]\u001b[A\n",
            "8593it [20:27,  6.56it/s]\u001b[A\n",
            "8594it [20:27,  6.61it/s]\u001b[A\n",
            "8595it [20:27,  6.71it/s]\u001b[A\n",
            "8596it [20:27,  6.83it/s]\u001b[A\n",
            "8597it [20:28,  6.85it/s]\u001b[A\n",
            "8598it [20:28,  6.87it/s]\u001b[A\n",
            "8599it [20:28,  6.80it/s]\u001b[A\n",
            "8600it [20:28,  6.67it/s]\u001b[A\n",
            "8601it [20:28,  6.64it/s]\u001b[A\n",
            "8602it [20:28,  6.75it/s]\u001b[A\n",
            "8603it [20:28,  6.82it/s]\u001b[A\n",
            "8604it [20:29,  6.89it/s]\u001b[A\n",
            "8605it [20:29,  6.95it/s]\u001b[A\n",
            "8606it [20:29,  6.85it/s]\u001b[A\n",
            "8607it [20:29,  6.93it/s]\u001b[A\n",
            "8608it [20:29,  6.88it/s]\u001b[A\n",
            "8609it [20:29,  6.89it/s]\u001b[A\n",
            "8610it [20:29,  6.93it/s]\u001b[A\n",
            "8611it [20:30,  6.96it/s]\u001b[A\n",
            "8612it [20:30,  7.09it/s]\u001b[A\n",
            "8613it [20:30,  6.99it/s]\u001b[A\n",
            "8614it [20:30,  6.97it/s]\u001b[A\n",
            "8615it [20:30,  6.93it/s]\u001b[A\n",
            "8616it [20:30,  6.84it/s]\u001b[A\n",
            "8617it [20:31,  6.89it/s]\u001b[A\n",
            "8618it [20:31,  7.05it/s]\u001b[A\n",
            "8619it [20:31,  7.12it/s]\u001b[A\n",
            "8620it [20:31,  7.08it/s]\u001b[A\n",
            "8621it [20:31,  6.97it/s]\u001b[A\n",
            "8622it [20:31,  7.01it/s]\u001b[A\n",
            "8623it [20:31,  6.95it/s]\u001b[A\n",
            "8624it [20:31,  7.06it/s]\u001b[A\n",
            "8625it [20:32,  6.88it/s]\u001b[A\n",
            "8626it [20:32,  6.89it/s]\u001b[A\n",
            "8627it [20:32,  6.84it/s]\u001b[A\n",
            "8628it [20:32,  6.80it/s]\u001b[A\n",
            "8629it [20:32,  6.82it/s]\u001b[A\n",
            "8630it [20:32,  6.78it/s]\u001b[A\n",
            "8631it [20:33,  6.84it/s]\u001b[A\n",
            "8632it [20:33,  6.93it/s]\u001b[A\n",
            "8633it [20:33,  6.97it/s]\u001b[A\n",
            "8634it [20:33,  6.74it/s]\u001b[A\n",
            "8635it [20:33,  6.75it/s]\u001b[A\n",
            "8636it [20:33,  6.83it/s]\u001b[A\n",
            "8637it [20:33,  6.92it/s]\u001b[A\n",
            "8638it [20:34,  6.94it/s]\u001b[A\n",
            "8639it [20:34,  7.04it/s]\u001b[A\n",
            "8640it [20:34,  6.93it/s]\u001b[A\n",
            "8641it [20:34,  6.72it/s]\u001b[A\n",
            "8642it [20:34,  6.83it/s]\u001b[A\n",
            "8643it [20:34,  6.89it/s]\u001b[A\n",
            "8644it [20:34,  6.93it/s]\u001b[A\n",
            "8645it [20:35,  6.98it/s]\u001b[A\n",
            "8646it [20:35,  7.06it/s]\u001b[A\n",
            "8647it [20:35,  7.00it/s]\u001b[A\n",
            "8648it [20:35,  6.79it/s]\u001b[A\n",
            "8649it [20:35,  6.80it/s]\u001b[A\n",
            "8650it [20:35,  6.66it/s]\u001b[A\n",
            "8651it [20:35,  6.57it/s]\u001b[A\n",
            "8652it [20:36,  6.57it/s]\u001b[A\n",
            "8653it [20:36,  6.68it/s]\u001b[A\n",
            "8654it [20:36,  6.73it/s]\u001b[A\n",
            "8655it [20:36,  6.66it/s]\u001b[A\n",
            "8656it [20:36,  6.74it/s]\u001b[A\n",
            "8657it [20:36,  6.84it/s]\u001b[A\n",
            "8658it [20:36,  6.83it/s]\u001b[A\n",
            "8659it [20:37,  6.91it/s]\u001b[A\n",
            "8660it [20:37,  6.98it/s]\u001b[A\n",
            "8661it [20:37,  7.07it/s]\u001b[A\n",
            "8662it [20:37,  7.02it/s]\u001b[A\n",
            "8663it [20:37,  6.92it/s]\u001b[A\n",
            "8664it [20:37,  6.86it/s]\u001b[A\n",
            "8665it [20:37,  6.96it/s]\u001b[A\n",
            "8666it [20:38,  7.05it/s]\u001b[A\n",
            "8667it [20:38,  7.04it/s]\u001b[A\n",
            "8668it [20:38,  6.91it/s]\u001b[A\n",
            "8669it [20:38,  6.61it/s]\u001b[A\n",
            "8670it [20:38,  6.34it/s]\u001b[A\n",
            "8671it [20:38,  6.33it/s]\u001b[A\n",
            "8672it [20:39,  6.36it/s]\u001b[A\n",
            "8673it [20:39,  6.21it/s]\u001b[A\n",
            "8674it [20:39,  6.20it/s]\u001b[A\n",
            "8675it [20:39,  6.19it/s]\u001b[A\n",
            "8676it [20:39,  6.39it/s]\u001b[A\n",
            "8677it [20:39,  6.38it/s]\u001b[A\n",
            "8678it [20:40,  6.37it/s]\u001b[A\n",
            "8679it [20:40,  6.39it/s]\u001b[A\n",
            "8680it [20:40,  6.44it/s]\u001b[A\n",
            "8681it [20:40,  6.65it/s]\u001b[A\n",
            "8682it [20:40,  6.65it/s]\u001b[A\n",
            "8683it [20:40,  6.80it/s]\u001b[A\n",
            "8684it [20:40,  6.88it/s]\u001b[A\n",
            "8685it [20:41,  6.97it/s]\u001b[A\n",
            "8686it [20:41,  7.03it/s]\u001b[A\n",
            "8687it [20:41,  7.02it/s]\u001b[A\n",
            "8688it [20:41,  6.99it/s]\u001b[A\n",
            "8689it [20:41,  6.89it/s]\u001b[A\n",
            "8690it [20:41,  6.97it/s]\u001b[A\n",
            "8691it [20:41,  6.95it/s]\u001b[A\n",
            "8692it [20:42,  7.02it/s]\u001b[A\n",
            "8693it [20:42,  7.07it/s]\u001b[A\n",
            "8694it [20:42,  7.00it/s]\u001b[A\n",
            "8695it [20:42,  6.98it/s]\u001b[A\n",
            "8696it [20:42,  6.90it/s]\u001b[A\n",
            "8697it [20:42,  6.95it/s]\u001b[A\n",
            "8698it [20:42,  7.02it/s]\u001b[A\n",
            "8699it [20:43,  7.12it/s]\u001b[A\n",
            "8700it [20:43,  7.19it/s]\u001b[A\n",
            "8701it [20:43,  7.06it/s]\u001b[A\n",
            "8702it [20:43,  7.04it/s]\u001b[A\n",
            "8703it [20:43,  6.97it/s]\u001b[A\n",
            "8704it [20:43,  7.06it/s]\u001b[A\n",
            "8705it [20:43,  7.09it/s]\u001b[A\n",
            "8706it [20:44,  7.02it/s]\u001b[A\n",
            "8707it [20:44,  6.97it/s]\u001b[A\n",
            "8708it [20:44,  7.07it/s]\u001b[A\n",
            "8709it [20:44,  7.08it/s]\u001b[A\n",
            "8710it [20:44,  6.93it/s]\u001b[A\n",
            "8711it [20:44,  7.00it/s]\u001b[A\n",
            "8712it [20:44,  7.07it/s]\u001b[A\n",
            "8713it [20:45,  7.07it/s]\u001b[A\n",
            "8714it [20:45,  7.06it/s]\u001b[A\n",
            "8715it [20:45,  6.96it/s]\u001b[A\n",
            "8716it [20:45,  6.99it/s]\u001b[A\n",
            "8717it [20:45,  6.90it/s]\u001b[A\n",
            "8718it [20:45,  6.82it/s]\u001b[A\n",
            "8719it [20:45,  6.64it/s]\u001b[A\n",
            "8720it [20:46,  6.67it/s]\u001b[A\n",
            "8721it [20:46,  6.75it/s]\u001b[A\n",
            "8722it [20:46,  6.84it/s]\u001b[A\n",
            "8723it [20:46,  6.86it/s]\u001b[A\n",
            "8724it [20:46,  6.89it/s]\u001b[A\n",
            "8725it [20:46,  6.97it/s]\u001b[A\n",
            "8726it [20:46,  6.75it/s]\u001b[A\n",
            "8727it [20:47,  6.82it/s]\u001b[A\n",
            "8728it [20:47,  6.86it/s]\u001b[A\n",
            "8729it [20:47,  6.95it/s]\u001b[A\n",
            "8730it [20:47,  6.84it/s]\u001b[A\n",
            "8731it [20:47,  6.81it/s]\u001b[A\n",
            "8732it [20:47,  6.87it/s]\u001b[A\n",
            "8733it [20:47,  6.92it/s]\u001b[A\n",
            "8734it [20:48,  6.98it/s]\u001b[A\n",
            "8735it [20:48,  7.07it/s]\u001b[A\n",
            "8736it [20:48,  7.03it/s]\u001b[A\n",
            "8737it [20:48,  6.73it/s]\u001b[A\n",
            "8738it [20:48,  6.52it/s]\u001b[A\n",
            "8739it [20:48,  6.56it/s]\u001b[A\n",
            "8740it [20:49,  6.49it/s]\u001b[A\n",
            "8741it [20:49,  6.48it/s]\u001b[A\n",
            "8742it [20:49,  6.47it/s]\u001b[A\n",
            "8743it [20:49,  6.43it/s]\u001b[A\n",
            "8744it [20:49,  6.44it/s]\u001b[A\n",
            "8745it [20:49,  6.37it/s]\u001b[A\n",
            "8746it [20:49,  6.40it/s]\u001b[A\n",
            "8747it [20:50,  6.48it/s]\u001b[A\n",
            "8748it [20:50,  6.46it/s]\u001b[A\n",
            "8749it [20:50,  6.38it/s]\u001b[A\n",
            "8750it [20:50,  6.57it/s]\u001b[A\n",
            "8751it [20:50,  6.39it/s]\u001b[A\n",
            "8752it [20:50,  6.29it/s]\u001b[A\n",
            "8753it [20:51,  6.40it/s]\u001b[A\n",
            "8754it [20:51,  6.60it/s]\u001b[A\n",
            "8755it [20:51,  6.70it/s]\u001b[A\n",
            "8756it [20:51,  6.82it/s]\u001b[A\n",
            "8757it [20:51,  6.95it/s]\u001b[A\n",
            "8758it [20:51,  6.66it/s]\u001b[A\n",
            "8759it [20:51,  6.54it/s]\u001b[A\n",
            "8760it [20:52,  6.51it/s]\u001b[A\n",
            "8761it [20:52,  6.46it/s]\u001b[A\n",
            "8762it [20:52,  6.50it/s]\u001b[A\n",
            "8763it [20:52,  6.61it/s]\u001b[A\n",
            "8764it [20:52,  6.65it/s]\u001b[A\n",
            "8765it [20:52,  6.79it/s]\u001b[A\n",
            "8766it [20:52,  6.89it/s]\u001b[A\n",
            "8767it [20:53,  6.93it/s]\u001b[A\n",
            "8768it [20:53,  7.05it/s]\u001b[A\n",
            "8769it [20:53,  7.10it/s]\u001b[A\n",
            "8770it [20:53,  7.07it/s]\u001b[A\n",
            "8771it [20:53,  6.77it/s]\u001b[A\n",
            "8772it [20:53,  6.66it/s]\u001b[A\n",
            "8773it [20:53,  6.60it/s]\u001b[A\n",
            "8774it [20:54,  6.47it/s]\u001b[A\n",
            "8775it [20:54,  6.40it/s]\u001b[A\n",
            "8776it [20:54,  6.50it/s]\u001b[A\n",
            "8777it [20:54,  6.47it/s]\u001b[A\n",
            "8778it [20:54,  6.43it/s]\u001b[A\n",
            "8779it [20:54,  6.40it/s]\u001b[A\n",
            "8780it [20:55,  6.40it/s]\u001b[A\n",
            "8781it [20:55,  6.50it/s]\u001b[A\n",
            "8782it [20:55,  6.44it/s]\u001b[A\n",
            "8783it [20:55,  6.49it/s]\u001b[A\n",
            "8784it [20:55,  6.60it/s]\u001b[A\n",
            "8785it [20:55,  6.75it/s]\u001b[A\n",
            "8786it [20:55,  6.85it/s]\u001b[A\n",
            "8787it [20:56,  6.93it/s]\u001b[A\n",
            "8788it [20:56,  6.85it/s]\u001b[A\n",
            "8789it [20:56,  6.72it/s]\u001b[A\n",
            "8790it [20:56,  6.87it/s]\u001b[A\n",
            "8791it [20:56,  6.94it/s]\u001b[A\n",
            "8792it [20:56,  6.99it/s]\u001b[A\n",
            "8793it [20:56,  7.09it/s]\u001b[A\n",
            "8794it [20:57,  7.13it/s]\u001b[A\n",
            "8795it [20:57,  7.11it/s]\u001b[A\n",
            "8796it [20:57,  7.11it/s]\u001b[A\n",
            "8797it [20:57,  7.04it/s]\u001b[A\n",
            "8798it [20:57,  6.83it/s]\u001b[A\n",
            "8799it [20:57,  6.51it/s]\u001b[A\n",
            "8800it [20:58,  6.53it/s]\u001b[A\n",
            "8801it [20:58,  6.62it/s]\u001b[A\n",
            "8802it [20:58,  6.74it/s]\u001b[A\n",
            "8803it [20:58,  6.86it/s]\u001b[A\n",
            "8804it [20:58,  6.90it/s]\u001b[A\n",
            "8805it [20:58,  6.95it/s]\u001b[A\n",
            "8806it [20:58,  6.84it/s]\u001b[A\n",
            "8807it [20:59,  6.90it/s]\u001b[A\n",
            "8808it [20:59,  6.91it/s]\u001b[A\n",
            "8809it [20:59,  6.96it/s]\u001b[A\n",
            "8810it [20:59,  6.91it/s]\u001b[A\n",
            "8811it [20:59,  6.81it/s]\u001b[A\n",
            "8812it [20:59,  6.81it/s]\u001b[A\n",
            "8813it [20:59,  6.71it/s]\u001b[A\n",
            "8814it [21:00,  6.82it/s]\u001b[A\n",
            "8815it [21:00,  6.90it/s]\u001b[A\n",
            "8816it [21:00,  6.75it/s]\u001b[A\n",
            "8817it [21:00,  6.86it/s]\u001b[A\n",
            "8818it [21:00,  6.73it/s]\u001b[A\n",
            "8819it [21:00,  6.74it/s]\u001b[A\n",
            "8820it [21:00,  6.73it/s]\u001b[A\n",
            "8821it [21:01,  6.84it/s]\u001b[A\n",
            "8822it [21:01,  6.91it/s]\u001b[A\n",
            "8823it [21:01,  6.95it/s]\u001b[A\n",
            "8824it [21:01,  6.89it/s]\u001b[A\n",
            "8825it [21:01,  6.85it/s]\u001b[A\n",
            "8826it [21:01,  6.85it/s]\u001b[A\n",
            "8827it [21:01,  6.96it/s]\u001b[A\n",
            "8828it [21:02,  6.96it/s]\u001b[A\n",
            "8829it [21:02,  7.02it/s]\u001b[A\n",
            "8830it [21:02,  6.71it/s]\u001b[A\n",
            "8831it [21:02,  6.62it/s]\u001b[A\n",
            "8832it [21:02,  6.55it/s]\u001b[A\n",
            "8833it [21:02,  6.47it/s]\u001b[A\n",
            "8834it [21:03,  6.45it/s]\u001b[A\n",
            "8835it [21:03,  6.48it/s]\u001b[A\n",
            "8836it [21:03,  6.49it/s]\u001b[A\n",
            "8837it [21:03,  6.56it/s]\u001b[A\n",
            "8838it [21:03,  6.66it/s]\u001b[A\n",
            "8839it [21:03,  6.84it/s]\u001b[A\n",
            "8840it [21:03,  6.85it/s]\u001b[A\n",
            "8841it [21:04,  6.83it/s]\u001b[A\n",
            "8842it [21:04,  6.88it/s]\u001b[A\n",
            "8843it [21:04,  6.99it/s]\u001b[A\n",
            "8844it [21:04,  7.02it/s]\u001b[A\n",
            "8845it [21:04,  6.79it/s]\u001b[A\n",
            "8846it [21:04,  6.86it/s]\u001b[A\n",
            "8847it [21:04,  6.83it/s]\u001b[A\n",
            "8848it [21:05,  6.78it/s]\u001b[A\n",
            "8849it [21:05,  6.85it/s]\u001b[A\n",
            "8850it [21:05,  6.93it/s]\u001b[A\n",
            "8851it [21:05,  6.99it/s]\u001b[A\n",
            "8852it [21:05,  6.94it/s]\u001b[A\n",
            "8853it [21:05,  6.77it/s]\u001b[A\n",
            "8854it [21:05,  6.57it/s]\u001b[A\n",
            "8855it [21:06,  6.59it/s]\u001b[A\n",
            "8856it [21:06,  6.65it/s]\u001b[A\n",
            "8857it [21:06,  6.66it/s]\u001b[A\n",
            "8858it [21:06,  6.83it/s]\u001b[A\n",
            "8859it [21:06,  6.82it/s]\u001b[A\n",
            "8860it [21:06,  6.91it/s]\u001b[A\n",
            "8861it [21:06,  6.90it/s]\u001b[A\n",
            "8862it [21:07,  6.92it/s]\u001b[A\n",
            "8863it [21:07,  7.04it/s]\u001b[A\n",
            "8864it [21:07,  7.13it/s]\u001b[A\n",
            "8865it [21:07,  7.03it/s]\u001b[A\n",
            "8866it [21:07,  6.91it/s]\u001b[A\n",
            "8867it [21:07,  6.90it/s]\u001b[A\n",
            "8868it [21:07,  6.84it/s]\u001b[A\n",
            "8869it [21:08,  6.89it/s]\u001b[A\n",
            "8870it [21:08,  6.87it/s]\u001b[A\n",
            "8871it [21:08,  6.90it/s]\u001b[A\n",
            "8872it [21:08,  6.86it/s]\u001b[A\n",
            "8873it [21:08,  6.88it/s]\u001b[A\n",
            "8874it [21:08,  6.94it/s]\u001b[A\n",
            "8875it [21:09,  6.86it/s]\u001b[A\n",
            "8876it [21:09,  6.94it/s]\u001b[A\n",
            "8877it [21:09,  6.94it/s]\u001b[A\n",
            "8878it [21:09,  7.03it/s]\u001b[A\n",
            "8879it [21:09,  7.07it/s]\u001b[A\n",
            "8880it [21:09,  6.91it/s]\u001b[A\n",
            "8881it [21:09,  6.75it/s]\u001b[A\n",
            "8882it [21:10,  6.54it/s]\u001b[A\n",
            "8883it [21:10,  6.60it/s]\u001b[A\n",
            "8884it [21:10,  6.56it/s]\u001b[A\n",
            "8885it [21:10,  6.50it/s]\u001b[A\n",
            "8886it [21:10,  6.51it/s]\u001b[A\n",
            "8887it [21:10,  6.50it/s]\u001b[A\n",
            "8888it [21:10,  6.40it/s]\u001b[A\n",
            "8889it [21:11,  6.57it/s]\u001b[A\n",
            "8890it [21:11,  6.75it/s]\u001b[A\n",
            "8891it [21:11,  6.75it/s]\u001b[A\n",
            "8892it [21:11,  6.84it/s]\u001b[A\n",
            "8893it [21:11,  6.79it/s]\u001b[A\n",
            "8894it [21:11,  6.83it/s]\u001b[A\n",
            "8895it [21:11,  6.83it/s]\u001b[A\n",
            "8896it [21:12,  6.95it/s]\u001b[A\n",
            "8897it [21:12,  6.91it/s]\u001b[A\n",
            "8898it [21:12,  6.84it/s]\u001b[A\n",
            "8899it [21:12,  6.82it/s]\u001b[A\n",
            "8900it [21:12,  6.89it/s]\u001b[A\n",
            "8901it [21:12,  6.95it/s]\u001b[A\n",
            "8902it [21:12,  6.99it/s]\u001b[A\n",
            "8903it [21:13,  7.04it/s]\u001b[A\n",
            "8904it [21:13,  7.08it/s]\u001b[A\n",
            "8905it [21:13,  7.12it/s]\u001b[A\n",
            "8906it [21:13,  7.14it/s]\u001b[A\n",
            "8907it [21:13,  7.00it/s]\u001b[A\n",
            "8908it [21:13,  6.96it/s]\u001b[A\n",
            "8909it [21:13,  7.05it/s]\u001b[A\n",
            "8910it [21:14,  6.94it/s]\u001b[A\n",
            "8911it [21:14,  6.94it/s]\u001b[A\n",
            "8912it [21:14,  6.94it/s]\u001b[A\n",
            "8913it [21:14,  6.96it/s]\u001b[A\n",
            "8914it [21:14,  6.93it/s]\u001b[A\n",
            "8915it [21:14,  7.03it/s]\u001b[A\n",
            "8916it [21:14,  7.11it/s]\u001b[A\n",
            "8917it [21:15,  7.04it/s]\u001b[A\n",
            "8918it [21:15,  7.07it/s]\u001b[A\n",
            "8919it [21:15,  7.11it/s]\u001b[A\n",
            "8920it [21:15,  7.03it/s]\u001b[A\n",
            "8921it [21:15,  6.84it/s]\u001b[A\n",
            "8922it [21:15,  6.83it/s]\u001b[A\n",
            "8923it [21:15,  6.72it/s]\u001b[A\n",
            "8924it [21:16,  6.69it/s]\u001b[A\n",
            "8925it [21:16,  6.62it/s]\u001b[A\n",
            "8926it [21:16,  6.57it/s]\u001b[A\n",
            "8927it [21:16,  6.68it/s]\u001b[A\n",
            "8928it [21:16,  6.83it/s]\u001b[A\n",
            "8929it [21:16,  6.74it/s]\u001b[A\n",
            "8930it [21:17,  6.68it/s]\u001b[A\n",
            "8931it [21:17,  6.85it/s]\u001b[A\n",
            "8932it [21:17,  6.90it/s]\u001b[A\n",
            "8933it [21:17,  6.77it/s]\u001b[A\n",
            "8934it [21:17,  6.82it/s]\u001b[A\n",
            "8935it [21:17,  6.77it/s]\u001b[A\n",
            "8936it [21:17,  6.73it/s]\u001b[A\n",
            "8937it [21:18,  6.67it/s]\u001b[A\n",
            "8938it [21:18,  6.79it/s]\u001b[A\n",
            "8939it [21:18,  6.72it/s]\u001b[A\n",
            "8940it [21:18,  6.60it/s]\u001b[A\n",
            "8941it [21:18,  6.61it/s]\u001b[A\n",
            "8942it [21:18,  6.51it/s]\u001b[A\n",
            "8943it [21:18,  6.47it/s]\u001b[A\n",
            "8944it [21:19,  6.56it/s]\u001b[A\n",
            "8945it [21:19,  6.76it/s]\u001b[A\n",
            "8946it [21:19,  6.93it/s]\u001b[A\n",
            "8947it [21:19,  6.94it/s]\u001b[A\n",
            "8948it [21:19,  6.98it/s]\u001b[A\n",
            "8949it [21:19,  7.01it/s]\u001b[A\n",
            "8950it [21:19,  7.10it/s]\u001b[A\n",
            "8951it [21:20,  6.89it/s]\u001b[A\n",
            "8952it [21:20,  6.92it/s]\u001b[A\n",
            "8953it [21:20,  6.91it/s]\u001b[A\n",
            "8954it [21:20,  6.77it/s]\u001b[A\n",
            "8955it [21:20,  6.84it/s]\u001b[A\n",
            "8956it [21:20,  6.79it/s]\u001b[A\n",
            "8957it [21:21,  6.76it/s]\u001b[A\n",
            "8958it [21:21,  6.58it/s]\u001b[A\n",
            "8959it [21:21,  6.67it/s]\u001b[A\n",
            "8960it [21:21,  6.77it/s]\u001b[A\n",
            "8961it [21:21,  6.80it/s]\u001b[A\n",
            "8962it [21:21,  6.62it/s]\u001b[A\n",
            "8963it [21:21,  6.51it/s]\u001b[A\n",
            "8964it [21:22,  6.62it/s]\u001b[A\n",
            "8965it [21:22,  6.67it/s]\u001b[A\n",
            "8966it [21:22,  6.70it/s]\u001b[A\n",
            "8967it [21:22,  6.70it/s]\u001b[A\n",
            "8968it [21:22,  6.80it/s]\u001b[A\n",
            "8969it [21:22,  6.90it/s]\u001b[A\n",
            "8970it [21:22,  6.99it/s]\u001b[A\n",
            "8971it [21:23,  7.05it/s]\u001b[A\n",
            "8972it [21:23,  7.02it/s]\u001b[A\n",
            "8973it [21:23,  6.88it/s]\u001b[A\n",
            "8974it [21:23,  6.85it/s]\u001b[A\n",
            "8975it [21:23,  6.81it/s]\u001b[A\n",
            "8976it [21:23,  6.68it/s]\u001b[A\n",
            "8977it [21:23,  6.63it/s]\u001b[A\n",
            "8978it [21:24,  6.53it/s]\u001b[A\n",
            "8979it [21:24,  6.52it/s]\u001b[A\n",
            "8980it [21:24,  6.58it/s]\u001b[A\n",
            "8981it [21:24,  6.65it/s]\u001b[A\n",
            "8982it [21:24,  6.71it/s]\u001b[A\n",
            "8983it [21:24,  6.76it/s]\u001b[A\n",
            "8984it [21:25,  6.65it/s]\u001b[A\n",
            "8985it [21:25,  6.67it/s]\u001b[A\n",
            "8986it [21:25,  6.73it/s]\u001b[A\n",
            "8987it [21:25,  6.86it/s]\u001b[A\n",
            "8988it [21:25,  6.96it/s]\u001b[A\n",
            "8989it [21:25,  7.01it/s]\u001b[A\n",
            "8990it [21:25,  7.00it/s]\u001b[A\n",
            "8991it [21:26,  6.97it/s]\u001b[A\n",
            "8992it [21:26,  6.75it/s]\u001b[A\n",
            "8993it [21:26,  6.57it/s]\u001b[A\n",
            "8994it [21:26,  6.69it/s]\u001b[A\n",
            "8995it [21:26,  6.78it/s]\u001b[A\n",
            "8996it [21:26,  6.96it/s]\u001b[A\n",
            "8997it [21:26,  6.90it/s]\u001b[A\n",
            "8998it [21:27,  6.90it/s]\u001b[A\n",
            "8999it [21:27,  6.72it/s]\u001b[A\n",
            "9000it [21:27,  6.79it/s]\u001b[A\n",
            "9001it [21:27,  6.94it/s]\u001b[A\n",
            "9002it [21:27,  6.98it/s]\u001b[A\n",
            "9003it [21:27,  7.08it/s]\u001b[A\n",
            "9004it [21:27,  7.09it/s]\u001b[A\n",
            "9005it [21:28,  6.97it/s]\u001b[A\n",
            "9006it [21:28,  6.72it/s]\u001b[A\n",
            "9007it [21:28,  6.79it/s]\u001b[A\n",
            "9008it [21:28,  6.61it/s]\u001b[A\n",
            "9009it [21:28,  6.65it/s]\u001b[A\n",
            "9010it [21:28,  6.62it/s]\u001b[A\n",
            "9011it [21:29,  6.56it/s]\u001b[A\n",
            "9012it [21:29,  6.48it/s]\u001b[A\n",
            "9013it [21:29,  6.45it/s]\u001b[A\n",
            "9014it [21:29,  6.37it/s]\u001b[A\n",
            "9015it [21:29,  6.32it/s]\u001b[A\n",
            "9016it [21:29,  6.50it/s]\u001b[A\n",
            "9017it [21:29,  6.63it/s]\u001b[A\n",
            "9018it [21:30,  6.75it/s]\u001b[A\n",
            "9019it [21:30,  6.82it/s]\u001b[A\n",
            "9020it [21:30,  6.81it/s]\u001b[A\n",
            "9021it [21:30,  6.88it/s]\u001b[A\n",
            "9022it [21:30,  6.66it/s]\u001b[A\n",
            "9023it [21:30,  6.75it/s]\u001b[A\n",
            "9024it [21:30,  6.70it/s]\u001b[A\n",
            "9025it [21:31,  6.52it/s]\u001b[A\n",
            "9026it [21:31,  6.39it/s]\u001b[A\n",
            "9027it [21:31,  6.34it/s]\u001b[A\n",
            "9028it [21:31,  6.39it/s]\u001b[A\n",
            "9029it [21:31,  6.53it/s]\u001b[A\n",
            "9030it [21:31,  6.64it/s]\u001b[A\n",
            "9031it [21:32,  6.77it/s]\u001b[A\n",
            "9032it [21:32,  6.85it/s]\u001b[A\n",
            "9033it [21:32,  6.76it/s]\u001b[A\n",
            "9034it [21:32,  6.66it/s]\u001b[A\n",
            "9035it [21:32,  6.56it/s]\u001b[A\n",
            "9036it [21:32,  6.44it/s]\u001b[A\n",
            "9037it [21:32,  6.44it/s]\u001b[A\n",
            "9038it [21:33,  6.59it/s]\u001b[A\n",
            "9039it [21:33,  6.63it/s]\u001b[A\n",
            "9040it [21:33,  6.67it/s]\u001b[A\n",
            "9041it [21:33,  6.69it/s]\u001b[A\n",
            "9042it [21:33,  6.72it/s]\u001b[A\n",
            "9043it [21:33,  6.66it/s]\u001b[A\n",
            "9044it [21:34,  6.59it/s]\u001b[A\n",
            "9045it [21:34,  6.55it/s]\u001b[A\n",
            "9046it [21:34,  6.37it/s]\u001b[A\n",
            "9047it [21:34,  6.54it/s]\u001b[A\n",
            "9048it [21:34,  6.57it/s]\u001b[A\n",
            "9049it [21:34,  6.56it/s]\u001b[A\n",
            "9050it [21:34,  6.48it/s]\u001b[A\n",
            "9051it [21:35,  6.43it/s]\u001b[A\n",
            "9052it [21:35,  6.38it/s]\u001b[A\n",
            "9053it [21:35,  6.28it/s]\u001b[A\n",
            "9054it [21:35,  6.52it/s]\u001b[A\n",
            "9055it [21:35,  6.58it/s]\u001b[A\n",
            "9056it [21:35,  6.81it/s]\u001b[A\n",
            "9057it [21:35,  6.89it/s]\u001b[A\n",
            "9058it [21:36,  6.87it/s]\u001b[A\n",
            "9059it [21:36,  6.82it/s]\u001b[A\n",
            "9060it [21:36,  6.81it/s]\u001b[A\n",
            "9061it [21:36,  6.86it/s]\u001b[A\n",
            "9062it [21:36,  6.72it/s]\u001b[A\n",
            "9063it [21:36,  6.63it/s]\u001b[A\n",
            "9064it [21:37,  6.63it/s]\u001b[A\n",
            "9065it [21:37,  6.55it/s]\u001b[A\n",
            "9066it [21:37,  6.52it/s]\u001b[A\n",
            "9067it [21:37,  6.53it/s]\u001b[A\n",
            "9068it [21:37,  6.62it/s]\u001b[A\n",
            "9069it [21:37,  6.45it/s]\u001b[A\n",
            "9070it [21:37,  6.35it/s]\u001b[A\n",
            "9071it [21:38,  6.22it/s]\u001b[A\n",
            "9072it [21:38,  6.28it/s]\u001b[A\n",
            "9073it [21:38,  6.23it/s]\u001b[A\n",
            "9074it [21:38,  6.28it/s]\u001b[A\n",
            "9075it [21:38,  6.23it/s]\u001b[A\n",
            "9076it [21:38,  6.28it/s]\u001b[A\n",
            "9077it [21:39,  6.36it/s]\u001b[A\n",
            "9078it [21:39,  6.49it/s]\u001b[A\n",
            "9079it [21:39,  6.67it/s]\u001b[A\n",
            "9080it [21:39,  6.78it/s]\u001b[A\n",
            "9081it [21:39,  6.82it/s]\u001b[A\n",
            "9082it [21:39,  6.67it/s]\u001b[A\n",
            "9083it [21:39,  6.59it/s]\u001b[A\n",
            "9084it [21:40,  6.53it/s]\u001b[A\n",
            "9085it [21:40,  6.40it/s]\u001b[A\n",
            "9086it [21:40,  6.33it/s]\u001b[A\n",
            "9087it [21:40,  6.55it/s]\u001b[A\n",
            "9088it [21:40,  6.58it/s]\u001b[A\n",
            "9089it [21:40,  6.65it/s]\u001b[A\n",
            "9090it [21:41,  6.77it/s]\u001b[A\n",
            "9091it [21:41,  6.79it/s]\u001b[A\n",
            "9092it [21:41,  6.72it/s]\u001b[A\n",
            "9093it [21:41,  6.78it/s]\u001b[A\n",
            "9094it [21:41,  6.79it/s]\u001b[A\n",
            "9095it [21:41,  6.84it/s]\u001b[A\n",
            "9096it [21:41,  6.90it/s]\u001b[A\n",
            "9097it [21:42,  7.01it/s]\u001b[A\n",
            "9098it [21:42,  7.03it/s]\u001b[A\n",
            "9099it [21:42,  6.77it/s]\u001b[A\n",
            "9100it [21:42,  6.64it/s]\u001b[A\n",
            "9101it [21:42,  6.77it/s]\u001b[A\n",
            "9102it [21:42,  6.80it/s]\u001b[A\n",
            "9103it [21:42,  6.64it/s]\u001b[A\n",
            "9104it [21:43,  6.55it/s]\u001b[A\n",
            "9105it [21:43,  6.44it/s]\u001b[A\n",
            "9106it [21:43,  6.39it/s]\u001b[A\n",
            "9107it [21:43,  6.49it/s]\u001b[A\n",
            "9108it [21:43,  6.56it/s]\u001b[A\n",
            "9109it [21:43,  6.72it/s]\u001b[A\n",
            "9110it [21:44,  6.85it/s]\u001b[A\n",
            "9111it [21:44,  6.93it/s]\u001b[A\n",
            "9112it [21:44,  6.96it/s]\u001b[A\n",
            "9113it [21:44,  6.87it/s]\u001b[A\n",
            "9114it [21:44,  6.64it/s]\u001b[A\n",
            "9115it [21:44,  6.65it/s]\u001b[A\n",
            "9116it [21:44,  6.61it/s]\u001b[A\n",
            "9117it [21:45,  6.71it/s]\u001b[A\n",
            "9118it [21:45,  6.88it/s]\u001b[A\n",
            "9119it [21:45,  6.88it/s]\u001b[A\n",
            "9120it [21:45,  6.98it/s]\u001b[A\n",
            "9121it [21:45,  6.95it/s]\u001b[A\n",
            "9122it [21:45,  6.97it/s]\u001b[A\n",
            "9123it [21:45,  7.05it/s]\u001b[A\n",
            "9124it [21:46,  6.99it/s]\u001b[A\n",
            "9125it [21:46,  7.00it/s]\u001b[A\n",
            "9126it [21:46,  7.05it/s]\u001b[A\n",
            "9127it [21:46,  6.99it/s]\u001b[A\n",
            "9128it [21:46,  6.95it/s]\u001b[A\n",
            "9129it [21:46,  6.81it/s]\u001b[A\n",
            "9130it [21:46,  6.88it/s]\u001b[A\n",
            "9131it [21:47,  6.77it/s]\u001b[A\n",
            "9132it [21:47,  6.86it/s]\u001b[A\n",
            "9133it [21:47,  6.93it/s]\u001b[A\n",
            "9134it [21:47,  6.84it/s]\u001b[A\n",
            "9135it [21:47,  6.63it/s]\u001b[A\n",
            "9136it [21:47,  6.51it/s]\u001b[A\n",
            "9137it [21:47,  6.56it/s]\u001b[A\n",
            "9138it [21:48,  6.46it/s]\u001b[A\n",
            "9139it [21:48,  6.50it/s]\u001b[A\n",
            "9140it [21:48,  6.51it/s]\u001b[A\n",
            "9141it [21:48,  6.59it/s]\u001b[A\n",
            "9142it [21:48,  6.72it/s]\u001b[A\n",
            "9143it [21:48,  6.89it/s]\u001b[A\n",
            "9144it [21:48,  6.88it/s]\u001b[A\n",
            "9145it [21:49,  6.76it/s]\u001b[A\n",
            "9146it [21:49,  6.94it/s]\u001b[A\n",
            "9147it [21:49,  7.02it/s]\u001b[A\n",
            "9148it [21:49,  6.96it/s]\u001b[A\n",
            "9149it [21:49,  7.08it/s]\u001b[A\n",
            "9150it [21:49,  7.01it/s]\u001b[A\n",
            "9151it [21:49,  7.03it/s]\u001b[A\n",
            "9152it [21:50,  7.09it/s]\u001b[A\n",
            "9153it [21:50,  7.09it/s]\u001b[A\n",
            "9154it [21:50,  7.04it/s]\u001b[A\n",
            "9155it [21:50,  6.87it/s]\u001b[A\n",
            "9156it [21:50,  6.72it/s]\u001b[A\n",
            "9157it [21:50,  6.72it/s]\u001b[A\n",
            "9158it [21:51,  6.85it/s]\u001b[A\n",
            "9159it [21:51,  6.91it/s]\u001b[A\n",
            "9160it [21:51,  6.93it/s]\u001b[A\n",
            "9161it [21:51,  6.77it/s]\u001b[A\n",
            "9162it [21:51,  6.62it/s]\u001b[A\n",
            "9163it [21:51,  6.56it/s]\u001b[A\n",
            "9164it [21:51,  6.59it/s]\u001b[A\n",
            "9165it [21:52,  6.63it/s]\u001b[A\n",
            "9166it [21:52,  6.58it/s]\u001b[A\n",
            "9167it [21:52,  6.65it/s]\u001b[A\n",
            "9168it [21:52,  6.79it/s]\u001b[A\n",
            "9169it [21:52,  6.87it/s]\u001b[A\n",
            "9170it [21:52,  6.88it/s]\u001b[A\n",
            "9171it [21:52,  6.93it/s]\u001b[A\n",
            "9172it [21:53,  7.00it/s]\u001b[A\n",
            "9173it [21:53,  7.05it/s]\u001b[A\n",
            "9174it [21:53,  7.07it/s]\u001b[A\n",
            "9175it [21:53,  7.13it/s]\u001b[A\n",
            "9176it [21:53,  6.94it/s]\u001b[A\n",
            "9177it [21:53,  6.92it/s]\u001b[A\n",
            "9178it [21:53,  6.93it/s]\u001b[A\n",
            "9179it [21:54,  6.90it/s]\u001b[A\n",
            "9180it [21:54,  6.92it/s]\u001b[A\n",
            "9181it [21:54,  6.96it/s]\u001b[A\n",
            "9182it [21:54,  7.05it/s]\u001b[A\n",
            "9183it [21:54,  7.03it/s]\u001b[A\n",
            "9184it [21:54,  7.07it/s]\u001b[A\n",
            "9185it [21:54,  7.15it/s]\u001b[A\n",
            "9186it [21:55,  7.10it/s]\u001b[A\n",
            "9187it [21:55,  7.04it/s]\u001b[A\n",
            "9188it [21:55,  7.08it/s]\u001b[A\n",
            "9189it [21:55,  7.14it/s]\u001b[A\n",
            "9190it [21:55,  7.03it/s]\u001b[A\n",
            "9191it [21:55,  7.07it/s]\u001b[A\n",
            "9192it [21:55,  7.10it/s]\u001b[A\n",
            "9193it [21:56,  7.09it/s]\u001b[A\n",
            "9194it [21:56,  6.95it/s]\u001b[A\n",
            "9195it [21:56,  7.00it/s]\u001b[A\n",
            "9196it [21:56,  6.85it/s]\u001b[A\n",
            "9197it [21:56,  6.75it/s]\u001b[A\n",
            "9198it [21:56,  6.67it/s]\u001b[A\n",
            "9199it [21:56,  6.61it/s]\u001b[A\n",
            "9200it [21:57,  6.56it/s]\u001b[A\n",
            "9201it [21:57,  6.55it/s]\u001b[A\n",
            "9202it [21:57,  6.56it/s]\u001b[A\n",
            "9203it [21:57,  6.54it/s]\u001b[A\n",
            "9204it [21:57,  6.41it/s]\u001b[A\n",
            "9205it [21:57,  6.41it/s]\u001b[A\n",
            "9206it [21:58,  6.44it/s]\u001b[A\n",
            "9207it [21:58,  6.53it/s]\u001b[A\n",
            "9208it [21:58,  6.52it/s]\u001b[A\n",
            "9209it [21:58,  6.56it/s]\u001b[A\n",
            "9210it [21:58,  6.67it/s]\u001b[A\n",
            "9211it [21:58,  6.62it/s]\u001b[A\n",
            "9212it [21:58,  6.78it/s]\u001b[A\n",
            "9213it [21:59,  6.78it/s]\u001b[A\n",
            "9214it [21:59,  6.81it/s]\u001b[A\n",
            "9215it [21:59,  6.86it/s]\u001b[A\n",
            "9216it [21:59,  6.75it/s]\u001b[A\n",
            "9217it [21:59,  6.95it/s]\u001b[A\n",
            "9218it [21:59,  6.94it/s]\u001b[A\n",
            "9219it [21:59,  7.07it/s]\u001b[A\n",
            "9220it [22:00,  7.15it/s]\u001b[A\n",
            "9221it [22:00,  7.06it/s]\u001b[A\n",
            "9222it [22:00,  6.53it/s]\u001b[A\n",
            "9223it [22:00,  6.57it/s]\u001b[A\n",
            "9224it [22:00,  6.39it/s]\u001b[A\n",
            "9225it [22:00,  6.45it/s]\u001b[A\n",
            "9226it [22:01,  6.51it/s]\u001b[A\n",
            "9227it [22:01,  6.58it/s]\u001b[A\n",
            "9228it [22:01,  6.73it/s]\u001b[A\n",
            "9229it [22:01,  6.84it/s]\u001b[A\n",
            "9230it [22:01,  6.79it/s]\u001b[A\n",
            "9231it [22:01,  6.75it/s]\u001b[A\n",
            "9232it [22:01,  6.89it/s]\u001b[A\n",
            "9233it [22:02,  6.95it/s]\u001b[A\n",
            "9234it [22:02,  6.96it/s]\u001b[A\n",
            "9235it [22:02,  7.00it/s]\u001b[A\n",
            "9236it [22:02,  6.93it/s]\u001b[A\n",
            "9237it [22:02,  6.96it/s]\u001b[A\n",
            "9238it [22:02,  6.92it/s]\u001b[A\n",
            "9239it [22:02,  6.98it/s]\u001b[A\n",
            "9240it [22:03,  6.94it/s]\u001b[A\n",
            "9241it [22:03,  7.03it/s]\u001b[A\n",
            "9242it [22:03,  7.04it/s]\u001b[A\n",
            "9243it [22:03,  6.87it/s]\u001b[A\n",
            "9244it [22:03,  6.84it/s]\u001b[A\n",
            "9245it [22:03,  6.81it/s]\u001b[A\n",
            "9246it [22:03,  6.78it/s]\u001b[A\n",
            "9247it [22:04,  6.72it/s]\u001b[A\n",
            "9248it [22:04,  6.71it/s]\u001b[A\n",
            "9249it [22:04,  6.65it/s]\u001b[A\n",
            "9250it [22:04,  6.61it/s]\u001b[A\n",
            "9251it [22:04,  6.51it/s]\u001b[A\n",
            "9252it [22:04,  6.58it/s]\u001b[A\n",
            "9253it [22:04,  6.76it/s]\u001b[A\n",
            "9254it [22:05,  6.83it/s]\u001b[A\n",
            "9255it [22:05,  6.87it/s]\u001b[A\n",
            "9256it [22:05,  6.79it/s]\u001b[A\n",
            "9257it [22:05,  6.86it/s]\u001b[A\n",
            "9258it [22:05,  6.83it/s]\u001b[A\n",
            "9259it [22:05,  6.73it/s]\u001b[A\n",
            "9260it [22:06,  6.81it/s]\u001b[A\n",
            "9261it [22:06,  6.89it/s]\u001b[A\n",
            "9262it [22:06,  6.92it/s]\u001b[A\n",
            "9263it [22:06,  6.97it/s]\u001b[A\n",
            "9264it [22:06,  6.96it/s]\u001b[A\n",
            "9265it [22:06,  6.92it/s]\u001b[A\n",
            "9266it [22:06,  6.55it/s]\u001b[A\n",
            "9267it [22:07,  6.55it/s]\u001b[A\n",
            "9268it [22:07,  6.60it/s]\u001b[A\n",
            "9269it [22:07,  6.68it/s]\u001b[A\n",
            "9270it [22:07,  6.73it/s]\u001b[A\n",
            "9271it [22:07,  6.66it/s]\u001b[A\n",
            "9272it [22:07,  6.56it/s]\u001b[A\n",
            "9273it [22:07,  6.47it/s]\u001b[A\n",
            "9274it [22:08,  6.46it/s]\u001b[A\n",
            "9275it [22:08,  6.40it/s]\u001b[A\n",
            "9276it [22:08,  6.31it/s]\u001b[A\n",
            "9277it [22:08,  6.29it/s]\u001b[A\n",
            "9278it [22:08,  6.41it/s]\u001b[A\n",
            "9279it [22:08,  6.55it/s]\u001b[A\n",
            "9280it [22:09,  6.70it/s]\u001b[A\n",
            "9281it [22:09,  6.84it/s]\u001b[A\n",
            "9282it [22:09,  6.95it/s]\u001b[A\n",
            "9283it [22:09,  6.96it/s]\u001b[A\n",
            "9284it [22:09,  6.93it/s]\u001b[A\n",
            "9285it [22:09,  7.04it/s]\u001b[A\n",
            "9286it [22:09,  6.99it/s]\u001b[A\n",
            "9287it [22:10,  6.98it/s]\u001b[A\n",
            "9288it [22:10,  7.04it/s]\u001b[A\n",
            "9289it [22:10,  6.88it/s]\u001b[A\n",
            "9290it [22:10,  6.89it/s]\u001b[A\n",
            "9291it [22:10,  6.86it/s]\u001b[A\n",
            "9292it [22:10,  6.78it/s]\u001b[A\n",
            "9293it [22:10,  6.70it/s]\u001b[A\n",
            "9294it [22:11,  6.57it/s]\u001b[A\n",
            "9295it [22:11,  6.54it/s]\u001b[A\n",
            "9296it [22:11,  6.53it/s]\u001b[A\n",
            "9297it [22:11,  6.35it/s]\u001b[A\n",
            "9298it [22:11,  6.43it/s]\u001b[A\n",
            "9299it [22:11,  6.65it/s]\u001b[A\n",
            "9300it [22:11,  6.64it/s]\u001b[A\n",
            "9301it [22:12,  6.70it/s]\u001b[A\n",
            "9302it [22:12,  6.77it/s]\u001b[A\n",
            "9303it [22:12,  6.93it/s]\u001b[A\n",
            "9304it [22:12,  6.99it/s]\u001b[A\n",
            "9305it [22:12,  7.03it/s]\u001b[A\n",
            "9306it [22:12,  7.04it/s]\u001b[A\n",
            "9307it [22:12,  7.02it/s]\u001b[A\n",
            "9308it [22:13,  6.97it/s]\u001b[A\n",
            "9309it [22:13,  6.96it/s]\u001b[A\n",
            "9310it [22:13,  7.09it/s]\u001b[A\n",
            "9311it [22:13,  7.14it/s]\u001b[A\n",
            "9312it [22:13,  7.14it/s]\u001b[A\n",
            "9313it [22:13,  7.14it/s]\u001b[A\n",
            "9314it [22:13,  7.02it/s]\u001b[A\n",
            "9315it [22:14,  7.13it/s]\u001b[A\n",
            "9316it [22:14,  7.03it/s]\u001b[A\n",
            "9317it [22:14,  7.02it/s]\u001b[A\n",
            "9318it [22:14,  7.03it/s]\u001b[A\n",
            "9319it [22:14,  7.05it/s]\u001b[A\n",
            "9320it [22:14,  7.16it/s]\u001b[A\n",
            "9321it [22:14,  7.06it/s]\u001b[A\n",
            "9322it [22:15,  7.16it/s]\u001b[A\n",
            "9323it [22:15,  7.02it/s]\u001b[A\n",
            "9324it [22:15,  6.97it/s]\u001b[A\n",
            "9325it [22:15,  7.04it/s]\u001b[A\n",
            "9326it [22:15,  6.74it/s]\u001b[A\n",
            "9327it [22:15,  6.66it/s]\u001b[A\n",
            "9328it [22:15,  6.52it/s]\u001b[A\n",
            "9329it [22:16,  6.50it/s]\u001b[A\n",
            "9330it [22:16,  6.57it/s]\u001b[A\n",
            "9331it [22:16,  6.57it/s]\u001b[A\n",
            "9332it [22:16,  6.58it/s]\u001b[A\n",
            "9333it [22:16,  6.57it/s]\u001b[A\n",
            "9334it [22:16,  6.56it/s]\u001b[A\n",
            "9335it [22:17,  6.46it/s]\u001b[A\n",
            "9336it [22:17,  6.55it/s]\u001b[A\n",
            "9337it [22:17,  6.54it/s]\u001b[A\n",
            "9338it [22:17,  6.57it/s]\u001b[A\n",
            "9339it [22:17,  6.52it/s]\u001b[A\n",
            "9340it [22:17,  6.49it/s]\u001b[A\n",
            "9341it [22:17,  6.42it/s]\u001b[A\n",
            "9342it [22:18,  6.48it/s]\u001b[A\n",
            "9343it [22:18,  6.53it/s]\u001b[A\n",
            "9344it [22:18,  6.60it/s]\u001b[A\n",
            "9345it [22:18,  6.60it/s]\u001b[A\n",
            "9346it [22:18,  6.75it/s]\u001b[A\n",
            "9347it [22:18,  6.86it/s]\u001b[A\n",
            "9348it [22:19,  6.91it/s]\u001b[A\n",
            "9349it [22:19,  7.04it/s]\u001b[A\n",
            "9350it [22:19,  7.06it/s]\u001b[A\n",
            "9351it [22:19,  7.00it/s]\u001b[A\n",
            "9352it [22:19,  6.83it/s]\u001b[A\n",
            "9353it [22:19,  6.95it/s]\u001b[A\n",
            "9354it [22:19,  6.96it/s]\u001b[A\n",
            "9355it [22:20,  6.75it/s]\u001b[A\n",
            "9356it [22:20,  6.79it/s]\u001b[A\n",
            "9357it [22:20,  6.92it/s]\u001b[A\n",
            "9358it [22:20,  7.00it/s]\u001b[A\n",
            "9359it [22:20,  6.91it/s]\u001b[A\n",
            "9360it [22:20,  6.96it/s]\u001b[A\n",
            "9361it [22:20,  6.87it/s]\u001b[A\n",
            "9362it [22:21,  6.81it/s]\u001b[A\n",
            "9363it [22:21,  6.83it/s]\u001b[A\n",
            "9364it [22:21,  6.93it/s]\u001b[A\n",
            "9365it [22:21,  6.86it/s]\u001b[A\n",
            "9366it [22:21,  6.78it/s]\u001b[A\n",
            "9367it [22:21,  6.86it/s]\u001b[A\n",
            "9368it [22:21,  6.87it/s]\u001b[A\n",
            "9369it [22:22,  6.87it/s]\u001b[A\n",
            "9370it [22:22,  6.91it/s]\u001b[A\n",
            "9371it [22:22,  6.92it/s]\u001b[A\n",
            "9372it [22:22,  6.67it/s]\u001b[A\n",
            "9373it [22:22,  6.71it/s]\u001b[A\n",
            "9374it [22:22,  6.81it/s]\u001b[A\n",
            "9375it [22:22,  6.88it/s]\u001b[A\n",
            "9376it [22:23,  6.93it/s]\u001b[A\n",
            "9377it [22:23,  6.97it/s]\u001b[A\n",
            "9378it [22:23,  7.00it/s]\u001b[A\n",
            "9379it [22:23,  7.04it/s]\u001b[A\n",
            "9380it [22:23,  6.94it/s]\u001b[A\n",
            "9381it [22:23,  6.98it/s]\u001b[A\n",
            "9382it [22:23,  6.97it/s]\u001b[A\n",
            "9383it [22:24,  6.93it/s]\u001b[A\n",
            "9384it [22:24,  6.94it/s]\u001b[A\n",
            "9385it [22:24,  6.94it/s]\u001b[A\n",
            "9386it [22:24,  6.93it/s]\u001b[A\n",
            "9387it [22:24,  6.99it/s]\u001b[A\n",
            "9388it [22:24,  6.99it/s]\u001b[A\n",
            "9389it [22:24,  7.05it/s]\u001b[A\n",
            "9390it [22:25,  7.01it/s]\u001b[A\n",
            "9391it [22:25,  7.05it/s]\u001b[A\n",
            "9392it [22:25,  7.16it/s]\u001b[A\n",
            "9393it [22:25,  7.18it/s]\u001b[A\n",
            "9394it [22:25,  7.04it/s]\u001b[A\n",
            "9395it [22:25,  6.84it/s]\u001b[A\n",
            "9396it [22:25,  6.68it/s]\u001b[A\n",
            "9397it [22:26,  6.63it/s]\u001b[A\n",
            "9398it [22:26,  6.64it/s]\u001b[A\n",
            "9399it [22:26,  6.73it/s]\u001b[A\n",
            "9400it [22:26,  6.82it/s]\u001b[A\n",
            "9401it [22:26,  6.87it/s]\u001b[A\n",
            "9402it [22:26,  6.88it/s]\u001b[A\n",
            "9403it [22:26,  6.97it/s]\u001b[A\n",
            "9404it [22:27,  6.71it/s]\u001b[A\n",
            "9405it [22:27,  6.60it/s]\u001b[A\n",
            "9406it [22:27,  6.60it/s]\u001b[A\n",
            "9407it [22:27,  6.57it/s]\u001b[A\n",
            "9408it [22:27,  6.71it/s]\u001b[A\n",
            "9409it [22:27,  6.82it/s]\u001b[A\n",
            "9410it [22:28,  6.94it/s]\u001b[A\n",
            "9411it [22:28,  6.93it/s]\u001b[A\n",
            "9412it [22:28,  6.96it/s]\u001b[A\n",
            "9413it [22:28,  6.91it/s]\u001b[A\n",
            "9414it [22:28,  6.97it/s]\u001b[A\n",
            "9415it [22:28,  6.98it/s]\u001b[A\n",
            "9416it [22:28,  6.81it/s]\u001b[A\n",
            "9417it [22:29,  6.87it/s]\u001b[A\n",
            "9418it [22:29,  6.79it/s]\u001b[A\n",
            "9419it [22:29,  6.90it/s]\u001b[A\n",
            "9420it [22:29,  6.94it/s]\u001b[A\n",
            "9421it [22:29,  7.10it/s]\u001b[A\n",
            "9422it [22:29,  7.08it/s]\u001b[A\n",
            "9423it [22:29,  7.04it/s]\u001b[A\n",
            "9424it [22:30,  7.12it/s]\u001b[A\n",
            "9425it [22:30,  7.05it/s]\u001b[A\n",
            "9426it [22:30,  6.94it/s]\u001b[A\n",
            "9427it [22:30,  6.93it/s]\u001b[A\n",
            "9428it [22:30,  6.96it/s]\u001b[A\n",
            "9429it [22:30,  6.84it/s]\u001b[A\n",
            "9430it [22:30,  6.91it/s]\u001b[A\n",
            "9431it [22:31,  6.93it/s]\u001b[A\n",
            "9432it [22:31,  6.83it/s]\u001b[A\n",
            "9433it [22:31,  6.84it/s]\u001b[A\n",
            "9434it [22:31,  6.98it/s]\u001b[A\n",
            "9435it [22:31,  6.93it/s]\u001b[A\n",
            "9436it [22:31,  6.85it/s]\u001b[A\n",
            "9437it [22:31,  6.89it/s]\u001b[A\n",
            "9438it [22:32,  6.68it/s]\u001b[A\n",
            "9439it [22:32,  6.41it/s]\u001b[A\n",
            "9440it [22:32,  6.59it/s]\u001b[A\n",
            "9441it [22:32,  6.64it/s]\u001b[A\n",
            "9442it [22:32,  6.63it/s]\u001b[A\n",
            "9443it [22:32,  6.78it/s]\u001b[A\n",
            "9444it [22:32,  6.87it/s]\u001b[A\n",
            "9445it [22:33,  6.93it/s]\u001b[A\n",
            "9446it [22:33,  6.89it/s]\u001b[A\n",
            "9447it [22:33,  6.93it/s]\u001b[A\n",
            "9448it [22:33,  6.92it/s]\u001b[A\n",
            "9449it [22:33,  6.60it/s]\u001b[A\n",
            "9450it [22:33,  6.76it/s]\u001b[A\n",
            "9451it [22:33,  6.88it/s]\u001b[A\n",
            "9452it [22:34,  6.93it/s]\u001b[A\n",
            "9453it [22:34,  6.72it/s]\u001b[A\n",
            "9454it [22:34,  6.66it/s]\u001b[A\n",
            "9455it [22:34,  6.67it/s]\u001b[A\n",
            "9456it [22:34,  6.56it/s]\u001b[A\n",
            "9457it [22:34,  6.40it/s]\u001b[A\n",
            "9458it [22:35,  6.45it/s]\u001b[A\n",
            "9459it [22:35,  6.48it/s]\u001b[A\n",
            "9460it [22:35,  6.63it/s]\u001b[A\n",
            "9461it [22:35,  6.79it/s]\u001b[A\n",
            "9462it [22:35,  6.94it/s]\u001b[A\n",
            "9463it [22:35,  6.89it/s]\u001b[A\n",
            "9464it [22:35,  6.91it/s]\u001b[A\n",
            "9465it [22:36,  6.94it/s]\u001b[A\n",
            "9466it [22:36,  6.82it/s]\u001b[A\n",
            "9467it [22:36,  6.93it/s]\u001b[A\n",
            "9468it [22:36,  6.92it/s]\u001b[A\n",
            "9469it [22:36,  7.00it/s]\u001b[A\n",
            "9470it [22:36,  6.94it/s]\u001b[A\n",
            "9471it [22:36,  6.90it/s]\u001b[A\n",
            "9472it [22:37,  6.75it/s]\u001b[A\n",
            "9473it [22:37,  6.51it/s]\u001b[A\n",
            "9474it [22:37,  6.67it/s]\u001b[A\n",
            "9475it [22:37,  6.78it/s]\u001b[A\n",
            "9476it [22:37,  6.84it/s]\u001b[A\n",
            "9477it [22:37,  6.93it/s]\u001b[A\n",
            "9478it [22:37,  6.96it/s]\u001b[A\n",
            "9479it [22:38,  7.02it/s]\u001b[A\n",
            "9480it [22:38,  6.92it/s]\u001b[A\n",
            "9481it [22:38,  6.84it/s]\u001b[A\n",
            "9482it [22:38,  6.61it/s]\u001b[A\n",
            "9483it [22:38,  6.44it/s]\u001b[A\n",
            "9484it [22:38,  6.45it/s]\u001b[A\n",
            "9485it [22:39,  6.26it/s]\u001b[A\n",
            "9486it [22:39,  6.09it/s]\u001b[A\n",
            "9487it [22:39,  6.17it/s]\u001b[A\n",
            "9488it [22:39,  6.42it/s]\u001b[A\n",
            "9489it [22:39,  6.60it/s]\u001b[A\n",
            "9490it [22:39,  6.75it/s]\u001b[A\n",
            "9491it [22:39,  6.86it/s]\u001b[A\n",
            "9492it [22:40,  6.94it/s]\u001b[A\n",
            "9493it [22:40,  6.96it/s]\u001b[A\n",
            "9494it [22:40,  6.85it/s]\u001b[A\n",
            "9495it [22:40,  7.03it/s]\u001b[A\n",
            "9496it [22:40,  7.05it/s]\u001b[A\n",
            "9497it [22:40,  7.04it/s]\u001b[A\n",
            "9498it [22:40,  7.11it/s]\u001b[A\n",
            "9499it [22:41,  7.09it/s]\u001b[A\n",
            "9500it [22:41,  7.06it/s]\u001b[A\n",
            "9501it [22:41,  7.00it/s]\u001b[A\n",
            "9502it [22:41,  7.05it/s]\u001b[A\n",
            "9503it [22:41,  7.06it/s]\u001b[A\n",
            "9504it [22:41,  6.89it/s]\u001b[A\n",
            "9505it [22:41,  6.86it/s]\u001b[A\n",
            "9506it [22:42,  6.85it/s]\u001b[A\n",
            "9507it [22:42,  6.69it/s]\u001b[A\n",
            "9508it [22:42,  6.51it/s]\u001b[A\n",
            "9509it [22:42,  6.75it/s]\u001b[A\n",
            "9510it [22:42,  6.70it/s]\u001b[A\n",
            "9511it [22:42,  6.78it/s]\u001b[A\n",
            "9512it [22:43,  6.81it/s]\u001b[A\n",
            "9513it [22:43,  6.92it/s]\u001b[A\n",
            "9514it [22:43,  6.88it/s]\u001b[A\n",
            "9515it [22:43,  6.77it/s]\u001b[A\n",
            "9516it [22:43,  6.73it/s]\u001b[A\n",
            "9517it [22:43,  6.73it/s]\u001b[A\n",
            "9518it [22:43,  6.78it/s]\u001b[A\n",
            "9519it [22:44,  6.85it/s]\u001b[A\n",
            "9520it [22:44,  6.90it/s]\u001b[A\n",
            "9521it [22:44,  6.82it/s]\u001b[A\n",
            "9522it [22:44,  6.66it/s]\u001b[A\n",
            "9523it [22:44,  6.72it/s]\u001b[A\n",
            "9524it [22:44,  6.68it/s]\u001b[A\n",
            "9525it [22:44,  6.58it/s]\u001b[A\n",
            "9526it [22:45,  6.58it/s]\u001b[A\n",
            "9527it [22:45,  6.71it/s]\u001b[A\n",
            "9528it [22:45,  6.61it/s]\u001b[A\n",
            "9529it [22:45,  6.54it/s]\u001b[A\n",
            "9530it [22:45,  6.49it/s]\u001b[A\n",
            "9531it [22:45,  6.48it/s]\u001b[A\n",
            "9532it [22:46,  6.41it/s]\u001b[A\n",
            "9533it [22:46,  6.54it/s]\u001b[A\n",
            "9534it [22:46,  6.69it/s]\u001b[A\n",
            "9535it [22:46,  6.71it/s]\u001b[A\n",
            "9536it [22:46,  6.78it/s]\u001b[A\n",
            "9537it [22:46,  6.80it/s]\u001b[A\n",
            "9538it [22:46,  6.87it/s]\u001b[A\n",
            "9539it [22:47,  6.82it/s]\u001b[A\n",
            "9540it [22:47,  6.87it/s]\u001b[A\n",
            "9541it [22:47,  6.70it/s]\u001b[A\n",
            "9542it [22:47,  6.67it/s]\u001b[A\n",
            "9543it [22:47,  6.67it/s]\u001b[A\n",
            "9544it [22:47,  6.75it/s]\u001b[A\n",
            "9545it [22:47,  6.76it/s]\u001b[A\n",
            "9546it [22:48,  6.87it/s]\u001b[A\n",
            "9547it [22:48,  6.86it/s]\u001b[A\n",
            "9548it [22:48,  6.78it/s]\u001b[A\n",
            "9549it [22:48,  6.61it/s]\u001b[A\n",
            "9550it [22:48,  6.73it/s]\u001b[A\n",
            "9551it [22:48,  6.82it/s]\u001b[A\n",
            "9552it [22:48,  6.70it/s]\u001b[A\n",
            "9553it [22:49,  6.59it/s]\u001b[A\n",
            "9554it [22:49,  6.56it/s]\u001b[A\n",
            "9555it [22:49,  6.69it/s]\u001b[A\n",
            "9556it [22:49,  6.54it/s]\u001b[A\n",
            "9557it [22:49,  6.48it/s]\u001b[A\n",
            "9558it [22:49,  6.55it/s]\u001b[A\n",
            "9559it [22:50,  6.69it/s]\u001b[A\n",
            "9560it [22:50,  6.79it/s]\u001b[A\n",
            "9561it [22:50,  6.85it/s]\u001b[A\n",
            "9562it [22:50,  6.73it/s]\u001b[A\n",
            "9563it [22:50,  6.66it/s]\u001b[A\n",
            "9564it [22:50,  6.41it/s]\u001b[A\n",
            "9565it [22:50,  6.44it/s]\u001b[A\n",
            "9566it [22:51,  6.51it/s]\u001b[A\n",
            "9567it [22:51,  6.63it/s]\u001b[A\n",
            "9568it [22:51,  6.72it/s]\u001b[A\n",
            "9569it [22:51,  6.57it/s]\u001b[A\n",
            "9570it [22:51,  6.63it/s]\u001b[A\n",
            "9571it [22:51,  6.68it/s]\u001b[A\n",
            "9572it [22:51,  6.83it/s]\u001b[A\n",
            "9573it [22:52,  6.90it/s]\u001b[A\n",
            "9574it [22:52,  6.91it/s]\u001b[A\n",
            "9575it [22:52,  6.90it/s]\u001b[A\n",
            "9576it [22:52,  6.85it/s]\u001b[A\n",
            "9577it [22:52,  6.95it/s]\u001b[A\n",
            "9578it [22:52,  7.02it/s]\u001b[A\n",
            "9579it [22:52,  6.99it/s]\u001b[A\n",
            "9580it [22:53,  7.02it/s]\u001b[A\n",
            "9581it [22:53,  6.85it/s]\u001b[A\n",
            "9582it [22:53,  6.86it/s]\u001b[A\n",
            "9583it [22:53,  6.80it/s]\u001b[A\n",
            "9584it [22:53,  6.76it/s]\u001b[A\n",
            "9585it [22:53,  6.82it/s]\u001b[A\n",
            "9586it [22:54,  6.91it/s]\u001b[A\n",
            "9587it [22:54,  6.56it/s]\u001b[A\n",
            "9588it [22:54,  6.54it/s]\u001b[A\n",
            "9589it [22:54,  6.67it/s]\u001b[A\n",
            "9590it [22:54,  6.59it/s]\u001b[A\n",
            "9591it [22:54,  6.71it/s]\u001b[A\n",
            "9592it [22:54,  6.79it/s]\u001b[A\n",
            "9593it [22:55,  6.79it/s]\u001b[A\n",
            "9594it [22:55,  6.83it/s]\u001b[A\n",
            "9595it [22:55,  6.90it/s]\u001b[A\n",
            "9596it [22:55,  7.00it/s]\u001b[A\n",
            "9597it [22:55,  6.99it/s]\u001b[A\n",
            "9598it [22:55,  6.99it/s]\u001b[A\n",
            "9599it [22:55,  7.06it/s]\u001b[A\n",
            "9600it [22:56,  6.99it/s]\u001b[A\n",
            "9601it [22:56,  6.72it/s]\u001b[A\n",
            "9602it [22:56,  6.77it/s]\u001b[A\n",
            "9603it [22:56,  6.65it/s]\u001b[A\n",
            "9604it [22:56,  6.51it/s]\u001b[A\n",
            "9605it [22:56,  6.42it/s]\u001b[A\n",
            "9606it [22:57,  6.42it/s]\u001b[A\n",
            "9607it [22:57,  6.58it/s]\u001b[A\n",
            "9608it [22:57,  6.77it/s]\u001b[A\n",
            "9609it [22:57,  6.90it/s]\u001b[A\n",
            "9610it [22:57,  6.83it/s]\u001b[A\n",
            "9611it [22:57,  6.91it/s]\u001b[A\n",
            "9612it [22:57,  6.78it/s]\u001b[A\n",
            "9613it [22:58,  6.70it/s]\u001b[A\n",
            "9614it [22:58,  6.74it/s]\u001b[A\n",
            "9615it [22:58,  6.84it/s]\u001b[A\n",
            "9616it [22:58,  6.75it/s]\u001b[A\n",
            "9617it [22:58,  6.67it/s]\u001b[A\n",
            "9618it [22:58,  6.70it/s]\u001b[A\n",
            "9619it [22:58,  6.71it/s]\u001b[A\n",
            "9620it [22:59,  6.76it/s]\u001b[A\n",
            "9621it [22:59,  6.82it/s]\u001b[A\n",
            "9622it [22:59,  6.91it/s]\u001b[A\n",
            "9623it [22:59,  7.06it/s]\u001b[A\n",
            "9624it [22:59,  6.98it/s]\u001b[A\n",
            "9625it [22:59,  6.99it/s]\u001b[A\n",
            "9626it [22:59,  6.89it/s]\u001b[A\n",
            "9627it [23:00,  6.94it/s]\u001b[A\n",
            "9628it [23:00,  6.96it/s]\u001b[A\n",
            "9629it [23:00,  6.82it/s]\u001b[A\n",
            "9630it [23:00,  6.70it/s]\u001b[A\n",
            "9631it [23:00,  6.48it/s]\u001b[A\n",
            "9632it [23:00,  6.40it/s]\u001b[A\n",
            "9633it [23:00,  6.38it/s]\u001b[A\n",
            "9634it [23:01,  6.41it/s]\u001b[A\n",
            "9635it [23:01,  6.44it/s]\u001b[A\n",
            "9636it [23:01,  6.47it/s]\u001b[A\n",
            "9637it [23:01,  6.48it/s]\u001b[A\n",
            "9638it [23:01,  6.39it/s]\u001b[A\n",
            "9639it [23:01,  6.41it/s]\u001b[A\n",
            "9640it [23:02,  6.45it/s]\u001b[A\n",
            "9641it [23:02,  6.43it/s]\u001b[A\n",
            "9642it [23:02,  6.38it/s]\u001b[A\n",
            "9643it [23:02,  6.60it/s]\u001b[A\n",
            "9644it [23:02,  6.60it/s]\u001b[A\n",
            "9645it [23:02,  6.75it/s]\u001b[A\n",
            "9646it [23:02,  6.64it/s]\u001b[A\n",
            "9647it [23:03,  6.76it/s]\u001b[A\n",
            "9648it [23:03,  6.92it/s]\u001b[A\n",
            "9649it [23:03,  6.97it/s]\u001b[A\n",
            "9650it [23:03,  6.93it/s]\u001b[A\n",
            "9651it [23:03,  6.82it/s]\u001b[A\n",
            "9652it [23:03,  6.56it/s]\u001b[A\n",
            "9653it [23:04,  6.50it/s]\u001b[A\n",
            "9654it [23:04,  6.46it/s]\u001b[A\n",
            "9655it [23:04,  6.45it/s]\u001b[A\n",
            "9656it [23:04,  6.52it/s]\u001b[A\n",
            "9657it [23:04,  6.66it/s]\u001b[A\n",
            "9658it [23:04,  6.62it/s]\u001b[A\n",
            "9659it [23:04,  6.61it/s]\u001b[A\n",
            "9660it [23:05,  6.73it/s]\u001b[A\n",
            "9661it [23:05,  6.87it/s]\u001b[A\n",
            "9662it [23:05,  6.84it/s]\u001b[A\n",
            "9663it [23:05,  6.78it/s]\u001b[A\n",
            "9664it [23:05,  6.76it/s]\u001b[A\n",
            "9665it [23:05,  6.72it/s]\u001b[A\n",
            "9666it [23:05,  6.76it/s]\u001b[A\n",
            "9667it [23:06,  6.79it/s]\u001b[A\n",
            "9668it [23:06,  6.74it/s]\u001b[A\n",
            "9669it [23:06,  6.67it/s]\u001b[A\n",
            "9670it [23:06,  6.69it/s]\u001b[A\n",
            "9671it [23:06,  6.56it/s]\u001b[A\n",
            "9672it [23:06,  6.51it/s]\u001b[A\n",
            "9673it [23:07,  6.64it/s]\u001b[A\n",
            "9674it [23:07,  6.77it/s]\u001b[A\n",
            "9675it [23:07,  6.79it/s]\u001b[A\n",
            "9676it [23:07,  6.83it/s]\u001b[A\n",
            "9677it [23:07,  6.84it/s]\u001b[A\n",
            "9678it [23:07,  6.68it/s]\u001b[A\n",
            "9679it [23:07,  6.87it/s]\u001b[A\n",
            "9680it [23:08,  6.82it/s]\u001b[A\n",
            "9681it [23:08,  6.90it/s]\u001b[A\n",
            "9682it [23:08,  7.01it/s]\u001b[A\n",
            "9683it [23:08,  6.86it/s]\u001b[A\n",
            "9684it [23:08,  6.88it/s]\u001b[A\n",
            "9685it [23:08,  6.84it/s]\u001b[A\n",
            "9686it [23:08,  6.84it/s]\u001b[A\n",
            "9687it [23:09,  6.83it/s]\u001b[A\n",
            "9688it [23:09,  6.85it/s]\u001b[A\n",
            "9689it [23:09,  6.85it/s]\u001b[A\n",
            "9690it [23:09,  6.88it/s]\u001b[A\n",
            "9691it [23:09,  6.81it/s]\u001b[A\n",
            "9692it [23:09,  6.78it/s]\u001b[A\n",
            "9693it [23:09,  6.84it/s]\u001b[A\n",
            "9694it [23:10,  6.78it/s]\u001b[A\n",
            "9695it [23:10,  6.78it/s]\u001b[A\n",
            "9696it [23:10,  6.91it/s]\u001b[A\n",
            "9697it [23:10,  6.74it/s]\u001b[A\n",
            "9698it [23:10,  6.84it/s]\u001b[A\n",
            "9699it [23:10,  6.88it/s]\u001b[A\n",
            "9700it [23:10,  6.87it/s]\u001b[A\n",
            "9701it [23:11,  6.85it/s]\u001b[A\n",
            "9702it [23:11,  6.95it/s]\u001b[A\n",
            "9703it [23:11,  6.98it/s]\u001b[A\n",
            "9704it [23:11,  6.94it/s]\u001b[A\n",
            "9705it [23:11,  6.80it/s]\u001b[A\n",
            "9706it [23:11,  6.80it/s]\u001b[A\n",
            "9707it [23:11,  6.89it/s]\u001b[A\n",
            "9708it [23:12,  6.93it/s]\u001b[A\n",
            "9709it [23:12,  6.99it/s]\u001b[A\n",
            "9710it [23:12,  6.93it/s]\u001b[A\n",
            "9711it [23:12,  6.97it/s]\u001b[A\n",
            "9712it [23:12,  6.89it/s]\u001b[A\n",
            "9713it [23:12,  6.41it/s]\u001b[A\n",
            "9714it [23:13,  6.22it/s]\u001b[A\n",
            "9715it [23:13,  6.12it/s]\u001b[A\n",
            "9716it [23:13,  6.16it/s]\u001b[A\n",
            "9717it [23:13,  6.24it/s]\u001b[A\n",
            "9718it [23:13,  6.37it/s]\u001b[A\n",
            "9719it [23:13,  6.36it/s]\u001b[A\n",
            "9720it [23:13,  6.50it/s]\u001b[A\n",
            "9721it [23:14,  6.54it/s]\u001b[A\n",
            "9722it [23:14,  6.58it/s]\u001b[A\n",
            "9723it [23:14,  6.62it/s]\u001b[A\n",
            "9724it [23:14,  6.74it/s]\u001b[A\n",
            "9725it [23:14,  6.80it/s]\u001b[A\n",
            "9726it [23:14,  6.82it/s]\u001b[A\n",
            "9727it [23:15,  6.86it/s]\u001b[A\n",
            "9728it [23:15,  6.95it/s]\u001b[A\n",
            "9729it [23:15,  6.94it/s]\u001b[A\n",
            "9730it [23:15,  6.94it/s]\u001b[A\n",
            "9731it [23:15,  7.02it/s]\u001b[A\n",
            "9732it [23:15,  6.97it/s]\u001b[A\n",
            "9733it [23:15,  6.95it/s]\u001b[A\n",
            "9734it [23:16,  6.94it/s]\u001b[A\n",
            "9735it [23:16,  6.99it/s]\u001b[A\n",
            "9736it [23:16,  6.97it/s]\u001b[A\n",
            "9737it [23:16,  6.95it/s]\u001b[A\n",
            "9738it [23:16,  6.96it/s]\u001b[A\n",
            "9739it [23:16,  6.93it/s]\u001b[A\n",
            "9740it [23:16,  6.81it/s]\u001b[A\n",
            "9741it [23:17,  6.83it/s]\u001b[A\n",
            "9742it [23:17,  6.89it/s]\u001b[A\n",
            "9743it [23:17,  6.94it/s]\u001b[A\n",
            "9744it [23:17,  6.88it/s]\u001b[A\n",
            "9745it [23:17,  6.91it/s]\u001b[A\n",
            "9746it [23:17,  6.87it/s]\u001b[A\n",
            "9747it [23:17,  6.68it/s]\u001b[A\n",
            "9748it [23:18,  6.54it/s]\u001b[A\n",
            "9749it [23:18,  6.40it/s]\u001b[A\n",
            "9750it [23:18,  6.38it/s]\u001b[A\n",
            "9751it [23:18,  6.56it/s]\u001b[A\n",
            "9752it [23:18,  6.67it/s]\u001b[A\n",
            "9753it [23:18,  6.68it/s]\u001b[A\n",
            "9754it [23:18,  6.55it/s]\u001b[A\n",
            "9755it [23:19,  6.62it/s]\u001b[A\n",
            "9756it [23:19,  6.67it/s]\u001b[A\n",
            "9757it [23:19,  6.86it/s]\u001b[A\n",
            "9758it [23:19,  6.87it/s]\u001b[A\n",
            "9759it [23:19,  6.83it/s]\u001b[A\n",
            "9760it [23:19,  6.87it/s]\u001b[A\n",
            "9761it [23:20,  6.75it/s]\u001b[A\n",
            "9762it [23:20,  6.75it/s]\u001b[A\n",
            "9763it [23:20,  6.49it/s]\u001b[A\n",
            "9764it [23:20,  6.54it/s]\u001b[A\n",
            "9765it [23:20,  6.69it/s]\u001b[A\n",
            "9766it [23:20,  6.74it/s]\u001b[A\n",
            "9767it [23:20,  6.72it/s]\u001b[A\n",
            "9768it [23:21,  6.50it/s]\u001b[A\n",
            "9769it [23:21,  6.43it/s]\u001b[A\n",
            "9770it [23:21,  6.38it/s]\u001b[A\n",
            "9771it [23:21,  6.41it/s]\u001b[A\n",
            "9772it [23:21,  6.46it/s]\u001b[A\n",
            "9773it [23:21,  6.46it/s]\u001b[A\n",
            "9774it [23:22,  6.35it/s]\u001b[A\n",
            "9775it [23:22,  6.38it/s]\u001b[A\n",
            "9776it [23:22,  6.41it/s]\u001b[A\n",
            "9777it [23:22,  6.41it/s]\u001b[A\n",
            "9778it [23:22,  6.46it/s]\u001b[A\n",
            "9779it [23:22,  6.43it/s]\u001b[A\n",
            "9780it [23:22,  6.16it/s]\u001b[A\n",
            "9781it [23:23,  6.34it/s]\u001b[A\n",
            "9782it [23:23,  6.56it/s]\u001b[A\n",
            "9783it [23:23,  6.70it/s]\u001b[A\n",
            "9784it [23:23,  6.82it/s]\u001b[A\n",
            "9785it [23:23,  6.85it/s]\u001b[A\n",
            "9786it [23:23,  6.92it/s]\u001b[A\n",
            "9787it [23:23,  6.90it/s]\u001b[A\n",
            "9788it [23:24,  6.90it/s]\u001b[A\n",
            "9789it [23:24,  6.92it/s]\u001b[A\n",
            "9790it [23:24,  6.88it/s]\u001b[A\n",
            "9791it [23:24,  6.87it/s]\u001b[A\n",
            "9792it [23:24,  6.95it/s]\u001b[A\n",
            "9793it [23:24,  6.95it/s]\u001b[A\n",
            "9794it [23:24,  7.01it/s]\u001b[A\n",
            "9795it [23:25,  7.00it/s]\u001b[A\n",
            "9796it [23:25,  6.96it/s]\u001b[A\n",
            "9797it [23:25,  7.01it/s]\u001b[A\n",
            "9798it [23:25,  6.92it/s]\u001b[A\n",
            "9799it [23:25,  6.89it/s]\u001b[A\n",
            "9800it [23:25,  6.92it/s]\u001b[A\n",
            "9801it [23:25,  6.90it/s]\u001b[A\n",
            "9802it [23:26,  6.87it/s]\u001b[A\n",
            "9803it [23:26,  6.79it/s]\u001b[A\n",
            "9804it [23:26,  6.81it/s]\u001b[A\n",
            "9805it [23:26,  6.78it/s]\u001b[A\n",
            "9806it [23:26,  6.77it/s]\u001b[A\n",
            "9807it [23:26,  6.66it/s]\u001b[A\n",
            "9808it [23:27,  6.64it/s]\u001b[A\n",
            "9809it [23:27,  6.85it/s]\u001b[A\n",
            "9810it [23:27,  6.89it/s]\u001b[A\n",
            "9811it [23:27,  7.02it/s]\u001b[A\n",
            "9812it [23:27,  6.96it/s]\u001b[A\n",
            "9813it [23:27,  6.73it/s]\u001b[A\n",
            "9814it [23:27,  6.62it/s]\u001b[A\n",
            "9815it [23:28,  6.53it/s]\u001b[A\n",
            "9816it [23:28,  6.70it/s]\u001b[A\n",
            "9817it [23:28,  6.89it/s]\u001b[A\n",
            "9818it [23:28,  6.92it/s]\u001b[A\n",
            "9819it [23:28,  6.90it/s]\u001b[A\n",
            "9820it [23:28,  6.88it/s]\u001b[A\n",
            "9821it [23:28,  6.99it/s]\u001b[A\n",
            "9822it [23:29,  6.89it/s]\u001b[A\n",
            "9823it [23:29,  7.00it/s]\u001b[A\n",
            "9824it [23:29,  7.11it/s]\u001b[A\n",
            "9825it [23:29,  7.16it/s]\u001b[A\n",
            "9826it [23:29,  7.08it/s]\u001b[A\n",
            "9827it [23:29,  7.12it/s]\u001b[A\n",
            "9828it [23:29,  7.14it/s]\u001b[A\n",
            "9829it [23:30,  6.90it/s]\u001b[A\n",
            "9830it [23:30,  6.70it/s]\u001b[A\n",
            "9831it [23:30,  6.51it/s]\u001b[A\n",
            "9832it [23:30,  6.66it/s]\u001b[A\n",
            "9833it [23:30,  6.75it/s]\u001b[A\n",
            "9834it [23:30,  6.88it/s]\u001b[A\n",
            "9835it [23:30,  7.02it/s]\u001b[A\n",
            "9836it [23:31,  6.93it/s]\u001b[A\n",
            "9837it [23:31,  7.04it/s]\u001b[A\n",
            "9838it [23:31,  6.81it/s]\u001b[A\n",
            "9839it [23:31,  6.86it/s]\u001b[A\n",
            "9840it [23:31,  6.52it/s]\u001b[A\n",
            "9841it [23:31,  6.58it/s]\u001b[A\n",
            "9842it [23:32,  6.50it/s]\u001b[A\n",
            "9843it [23:32,  6.45it/s]\u001b[A\n",
            "9844it [23:32,  6.39it/s]\u001b[A\n",
            "9845it [23:32,  6.53it/s]\u001b[A\n",
            "9846it [23:32,  6.70it/s]\u001b[A\n",
            "9847it [23:32,  6.84it/s]\u001b[A\n",
            "9848it [23:32,  6.88it/s]\u001b[A\n",
            "9849it [23:33,  6.95it/s]\u001b[A\n",
            "9850it [23:33,  6.87it/s]\u001b[A\n",
            "9851it [23:33,  6.99it/s]\u001b[A\n",
            "9852it [23:33,  7.06it/s]\u001b[A\n",
            "9853it [23:33,  6.92it/s]\u001b[A\n",
            "9854it [23:33,  7.01it/s]\u001b[A\n",
            "9855it [23:33,  7.04it/s]\u001b[A\n",
            "9856it [23:34,  7.07it/s]\u001b[A\n",
            "9857it [23:34,  6.91it/s]\u001b[A\n",
            "9858it [23:34,  6.92it/s]\u001b[A\n",
            "9859it [23:34,  7.00it/s]\u001b[A\n",
            "9860it [23:34,  7.05it/s]\u001b[A\n",
            "9861it [23:34,  6.84it/s]\u001b[A\n",
            "9862it [23:34,  6.52it/s]\u001b[A\n",
            "9863it [23:35,  6.60it/s]\u001b[A\n",
            "9864it [23:35,  6.33it/s]\u001b[A\n",
            "9865it [23:35,  6.45it/s]\u001b[A\n",
            "9866it [23:35,  6.43it/s]\u001b[A\n",
            "9867it [23:35,  6.44it/s]\u001b[A\n",
            "9868it [23:35,  6.35it/s]\u001b[A\n",
            "9869it [23:36,  6.36it/s]\u001b[A\n",
            "9870it [23:36,  6.34it/s]\u001b[A\n",
            "9871it [23:36,  6.38it/s]\u001b[A\n",
            "9872it [23:36,  6.54it/s]\u001b[A\n",
            "9873it [23:36,  6.73it/s]\u001b[A\n",
            "9874it [23:36,  6.72it/s]\u001b[A\n",
            "9875it [23:36,  6.67it/s]\u001b[A\n",
            "9876it [23:37,  6.70it/s]\u001b[A\n",
            "9877it [23:37,  6.52it/s]\u001b[A\n",
            "9878it [23:37,  6.50it/s]\u001b[A\n",
            "9879it [23:37,  6.55it/s]\u001b[A\n",
            "9880it [23:37,  6.70it/s]\u001b[A\n",
            "9881it [23:37,  6.82it/s]\u001b[A\n",
            "9882it [23:37,  6.89it/s]\u001b[A\n",
            "9883it [23:38,  6.91it/s]\u001b[A\n",
            "9884it [23:38,  6.86it/s]\u001b[A\n",
            "9885it [23:38,  6.82it/s]\u001b[A\n",
            "9886it [23:38,  6.51it/s]\u001b[A\n",
            "9887it [23:38,  6.62it/s]\u001b[A\n",
            "9888it [23:38,  6.59it/s]\u001b[A\n",
            "9889it [23:39,  6.59it/s]\u001b[A\n",
            "9890it [23:39,  6.49it/s]\u001b[A\n",
            "9891it [23:39,  6.41it/s]\u001b[A\n",
            "9892it [23:39,  6.53it/s]\u001b[A\n",
            "9893it [23:39,  6.73it/s]\u001b[A\n",
            "9894it [23:39,  6.77it/s]\u001b[A\n",
            "9895it [23:39,  6.91it/s]\u001b[A\n",
            "9896it [23:40,  6.96it/s]\u001b[A\n",
            "9897it [23:40,  6.90it/s]\u001b[A\n",
            "9898it [23:40,  6.91it/s]\u001b[A\n",
            "9899it [23:40,  6.82it/s]\u001b[A\n",
            "9900it [23:40,  6.77it/s]\u001b[A\n",
            "9901it [23:40,  6.55it/s]\u001b[A\n",
            "9902it [23:40,  6.56it/s]\u001b[A\n",
            "9903it [23:41,  6.70it/s]\u001b[A\n",
            "9904it [23:41,  6.80it/s]\u001b[A\n",
            "9905it [23:41,  6.96it/s]\u001b[A\n",
            "9906it [23:41,  7.10it/s]\u001b[A\n",
            "9907it [23:41,  7.09it/s]\u001b[A\n",
            "9908it [23:41,  7.11it/s]\u001b[A\n",
            "9909it [23:41,  7.15it/s]\u001b[A\n",
            "9910it [23:42,  7.15it/s]\u001b[A\n",
            "9911it [23:42,  7.19it/s]\u001b[A\n",
            "9912it [23:42,  7.18it/s]\u001b[A\n",
            "9913it [23:42,  6.88it/s]\u001b[A\n",
            "9914it [23:42,  6.64it/s]\u001b[A\n",
            "9915it [23:42,  6.62it/s]\u001b[A\n",
            "9916it [23:42,  6.80it/s]\u001b[A\n",
            "9917it [23:43,  6.80it/s]\u001b[A\n",
            "9918it [23:43,  6.68it/s]\u001b[A\n",
            "9919it [23:43,  6.76it/s]\u001b[A\n",
            "9920it [23:43,  6.79it/s]\u001b[A\n",
            "9921it [23:43,  6.82it/s]\u001b[A\n",
            "9922it [23:43,  6.75it/s]\u001b[A\n",
            "9923it [23:44,  6.85it/s]\u001b[A\n",
            "9924it [23:44,  6.76it/s]\u001b[A\n",
            "9925it [23:44,  6.20it/s]\u001b[A\n",
            "9926it [23:44,  6.40it/s]\u001b[A\n",
            "9927it [23:44,  6.53it/s]\u001b[A\n",
            "9928it [23:44,  6.55it/s]\u001b[A\n",
            "9929it [23:44,  6.48it/s]\u001b[A\n",
            "9930it [23:45,  6.44it/s]\u001b[A\n",
            "9931it [23:45,  6.44it/s]\u001b[A\n",
            "9932it [23:45,  6.37it/s]\u001b[A\n",
            "9933it [23:45,  6.39it/s]\u001b[A\n",
            "9934it [23:45,  6.58it/s]\u001b[A\n",
            "9935it [23:45,  6.79it/s]\u001b[A\n",
            "9936it [23:45,  6.84it/s]\u001b[A\n",
            "9937it [23:46,  6.88it/s]\u001b[A\n",
            "9938it [23:46,  6.86it/s]\u001b[A\n",
            "9939it [23:46,  6.72it/s]\u001b[A\n",
            "9940it [23:46,  6.83it/s]\u001b[A\n",
            "9941it [23:46,  6.79it/s]\u001b[A\n",
            "9942it [23:46,  6.85it/s]\u001b[A\n",
            "9943it [23:47,  6.96it/s]\u001b[A\n",
            "9944it [23:47,  6.84it/s]\u001b[A\n",
            "9945it [23:47,  6.76it/s]\u001b[A\n",
            "9946it [23:47,  6.81it/s]\u001b[A\n",
            "9947it [23:47,  6.77it/s]\u001b[A\n",
            "9948it [23:47,  6.81it/s]\u001b[A\n",
            "9949it [23:47,  6.88it/s]\u001b[A\n",
            "9950it [23:48,  6.96it/s]\u001b[A\n",
            "9951it [23:48,  6.89it/s]\u001b[A\n",
            "9952it [23:48,  6.85it/s]\u001b[A\n",
            "9953it [23:48,  6.84it/s]\u001b[A\n",
            "9954it [23:48,  6.82it/s]\u001b[A\n",
            "9955it [23:48,  6.72it/s]\u001b[A\n",
            "9956it [23:48,  6.64it/s]\u001b[A\n",
            "9957it [23:49,  6.63it/s]\u001b[A\n",
            "9958it [23:49,  6.56it/s]\u001b[A\n",
            "9959it [23:49,  6.46it/s]\u001b[A\n",
            "9960it [23:49,  6.42it/s]\u001b[A\n",
            "9961it [23:49,  6.65it/s]\u001b[A\n",
            "9962it [23:49,  6.80it/s]\u001b[A\n",
            "9963it [23:49,  6.92it/s]\u001b[A\n",
            "9964it [23:50,  6.95it/s]\u001b[A\n",
            "9965it [23:50,  7.04it/s]\u001b[A\n",
            "9966it [23:50,  6.83it/s]\u001b[A\n",
            "9967it [23:50,  6.93it/s]\u001b[A\n",
            "9968it [23:50,  6.84it/s]\u001b[A\n",
            "9969it [23:50,  6.75it/s]\u001b[A\n",
            "9970it [23:51,  6.82it/s]\u001b[A\n",
            "9971it [23:51,  6.83it/s]\u001b[A\n",
            "9972it [23:51,  6.83it/s]\u001b[A\n",
            "9973it [23:51,  6.63it/s]\u001b[A\n",
            "9974it [23:51,  6.54it/s]\u001b[A\n",
            "9975it [23:51,  6.66it/s]\u001b[A\n",
            "9976it [23:51,  6.74it/s]\u001b[A\n",
            "9977it [23:52,  6.81it/s]\u001b[A\n",
            "9978it [23:52,  6.90it/s]\u001b[A\n",
            "9979it [23:52,  6.96it/s]\u001b[A\n",
            "9980it [23:52,  6.75it/s]\u001b[A\n",
            "9981it [23:52,  6.81it/s]\u001b[A\n",
            "9982it [23:52,  6.86it/s]\u001b[A\n",
            "9983it [23:52,  6.86it/s]\u001b[A\n",
            "9984it [23:53,  6.82it/s]\u001b[A\n",
            "9985it [23:53,  6.86it/s]\u001b[A\n",
            "9986it [23:53,  6.90it/s]\u001b[A\n",
            "9987it [23:53,  6.74it/s]\u001b[A\n",
            "9988it [23:53,  6.78it/s]\u001b[A\n",
            "9989it [23:53,  6.94it/s]\u001b[A\n",
            "9990it [23:53,  6.93it/s]\u001b[A\n",
            "9991it [23:54,  7.01it/s]\u001b[A\n",
            "9992it [23:54,  7.10it/s]\u001b[A\n",
            "9993it [23:54,  7.02it/s]\u001b[A\n",
            "9994it [23:54,  7.01it/s]\u001b[A\n",
            "9995it [23:54,  6.93it/s]\u001b[A\n",
            "9996it [23:54,  6.81it/s]\u001b[A\n",
            "9997it [23:54,  6.65it/s]\u001b[A\n",
            "9998it [23:55,  6.68it/s]\u001b[A\n",
            "9999it [23:55,  6.77it/s]\u001b[A\n",
            "10000it [23:55,  6.97it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oGzWo9u43qSq",
        "outputId": "87f06b64-18fa-4e4b-9808-68a0fb9a5316"
      },
      "source": [
        "pred_value, label"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([6, 6, 6, 6, 6, 5, 6, 6, 6], 6)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyiW-TMswAnI"
      },
      "source": [
        "pickle_out = open(\"sm_all_wt_0an.pickle\",\"wb\")\n",
        "pickle.dump(max_sm_all_wt_0an, pickle_out)\n",
        "pickle_out.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fU_uStdfwMjn"
      },
      "source": [
        "pickle_in = open(\"sm_all_wt_0an.pickle\",\"rb\")\n",
        "max_sm_all_wt_0an = pickle.load(pickle_in)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iNUyMsST1baa",
        "outputId": "07d922b4-6b2a-450b-df27-422fbd689b98"
      },
      "source": [
        "for data, lbl, p, a_l, e_ in max_sm_all_wt_0an:\n",
        "\n",
        "  print(data, lbl, a_l)\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.9999738, 0.99999714, 0.9999778, 0.9999527, 0.9999902, 0.9999989, 0.690764, 0.99995613, 0.9999988] 1 7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmlc3Jrz1P7a"
      },
      "source": [
        "from math import *\n",
        "\n",
        "def manhattan_distance(x,y):\n",
        "  return sum(abs(a-b) for a,b in zip(x,y))\n",
        "\n",
        "def euclidean_distance(x,y):\n",
        "  return sqrt(sum(pow(a-b,2) for a, b in zip(x, y)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qiTHU1mh0Mxf",
        "outputId": "bf7b8032-6423-4376-a9cc-ca4f9f60dfa7"
      },
      "source": [
        "accuracy = 0.0\n",
        "count_in = 0\n",
        "count_ood = 0\n",
        "acc_in = 0.0\n",
        "acc_ood = 0.0\n",
        "tp = 0.0\n",
        "tn = 0.0\n",
        "fp = 0.0\n",
        "fn = 0.0\n",
        "y_true = []\n",
        "y_pred = []\n",
        "sim_score = []\n",
        "sim_score_ = []\n",
        "\n",
        "for data, lbl, p, a_l, e_ in max_sm_all_wt_0an:\n",
        "\n",
        "  temp = data.copy()\n",
        "  temp.append(e_)\n",
        "\n",
        "  temp_ref = ref_vect_out_0an[0].copy()\n",
        "  temp_ref.append(entropy_out_0an[0])\n",
        "\n",
        "  score = 0.0\n",
        "  for d in data:\n",
        "    score = score + d\n",
        "  score = score / len(data)\n",
        "  sim_score.append(score)\n",
        "\n",
        "  dist_ood = np.linalg.norm(np.array(data) - np.array(ref_vect_out_0an[0])) \n",
        "  dist_in = np.linalg.norm(np.array(data) - np.array(ref_vect_in_0an[0]))\n",
        "\n",
        "  dist_in_man = manhattan_distance(data, ref_vect_in_0an[0])\n",
        "  dist_ood_man = manhattan_distance(data, ref_vect_out_0an[0])\n",
        "\n",
        "  dist_ood2 = np.linalg.norm(np.array(e_) - np.array(entropy_out_0an[0])) \n",
        "  dist_in2 = np.linalg.norm(np.array(e_) - np.array(entropy_in_0an[0]))\n",
        "\n",
        "  dist_ood_temp = np.linalg.norm(np.array(temp) - np.array(temp_ref)) \n",
        "  sim_ood_temp = 1 / (1 + dist_ood_temp)\n",
        "\n",
        "#  dist_ood_man2 = manhattan_distance(np.array([e_]), np.array(entropy_out_0an)) \n",
        "#  dist_in_man2 = manhattan_distance(np.array([e_]), np.array(entropy_in_0an))\n",
        "\n",
        "  dist_in = (dist_in + dist_in_man) / 2\n",
        "  dist_ood = (dist_ood + dist_ood_man) / 2\n",
        "\n",
        "#  dist_in2 = dist_in2 + dist_in_man2\n",
        "#  dist_ood2 = dist_ood2 + dist_ood_man2\n",
        "\n",
        "#  print(dist_in, dist_in_man, dist_ood, dist_ood_man)\n",
        "#  dist_in = dist_in + dist_in2\n",
        "#  dist_ood = dist_ood + dist_ood2\n",
        "\n",
        "  dist_in = dist_in / (dist_in + dist_ood)\n",
        "  dist_ood = dist_ood / (dist_in + dist_ood)\n",
        "\n",
        "  dist_in2 = dist_in2 / (dist_in2 + dist_ood2)\n",
        "  dist_ood2 = dist_ood2 / (dist_in2 + dist_ood2)\n",
        "\n",
        "  sim_in = 1 / (1 + dist_in)\n",
        "  sim_ood = 1 / (1 + dist_ood)\n",
        "\n",
        "  sim_in2 = 1 / (1 + dist_in2)\n",
        "  sim_ood2 = 1 / (1 + dist_ood2)\n",
        "\n",
        "#  print(sim_in, sim_in2, sim_ood, sim_ood2)\n",
        "\n",
        "  sim_in = sim_in + sim_in2\n",
        "  sim_ood = sim_ood + sim_ood2\n",
        "\n",
        "  #sim_in = sim_in / (sim_in + sim_ood)\n",
        "  #sim_ood = sim_ood / (sim_in + sim_ood)\n",
        "\n",
        "  sim_score_.append(sim_ood2)\n",
        "\n",
        "  values, counts = np.unique(p, return_counts=True)\n",
        "#  print(values, counts)\n",
        "  #print(sim_in, sim_ood, lbl, e_)\n",
        "  if sim_in >= sim_ood:\n",
        "    y_ = ind\n",
        "    if np.max(counts) >= 8:\n",
        "      y_ = ind\n",
        "    else:\n",
        "      y_ = ood\n",
        "  else:\n",
        "    y_ = ood\n",
        "\n",
        "\n",
        "  y_pred.append(y_)\n",
        "\n",
        "  if lbl == 1:\n",
        "    y_true.append(0)\n",
        "  else:\n",
        "    y_true.append(1)\n",
        "#  y_true.append(lbl)\n",
        "\n",
        "\n",
        "  if lbl == ind:\n",
        "    count_in = count_in + 1\n",
        "  else:\n",
        "    count_ood = count_ood + 1\n",
        "\n",
        "  if y_ == lbl:\n",
        "    #sim_score_.append(1)\n",
        "    accuracy = accuracy + 1\n",
        "    if y_ == ind:\n",
        "      acc_in = acc_in + 1\n",
        "      tp = tp + 1\n",
        "    else:\n",
        "      acc_ood = acc_ood + 1\n",
        "      tn = tn + 1\n",
        "  else:\n",
        "    #sim_score_.append(0)\n",
        "    if y_ == ind:\n",
        "      fp = fp + 1\n",
        "    else:\n",
        "      fn = fn + 1\n",
        "  #break\n",
        "\n",
        "print(\"Total Accuracy: \", accuracy/len(max_sm_all_wt_0an)) \n",
        "print(\"Accuracy of determining ID data: \", acc_in/count_in)\n",
        "print(\"Accuracy of determining OOD data: \", acc_ood/count_ood)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Accuracy:  0.9275\n",
            "Accuracy of determining ID data:  0.9284922394678492\n",
            "Accuracy of determining OOD data:  0.9183673469387755\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-LHvn7gL0U59",
        "outputId": "6a1887db-fabb-4618-d749-c6e61bcfc729"
      },
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "roc_auc_score(y_true, sim_score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.03620299561066112"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9REbz-JU0iRt",
        "outputId": "b0174672-1929-4e29-8ea5-923c0814ef85"
      },
      "source": [
        "roc_auc_score(y_true, y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.07385175799809947"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ch7G9l2x0lyi",
        "outputId": "c12e41dd-9618-4241-dcd2-320602f4c90d"
      },
      "source": [
        "roc_auc_score(y_true, sim_score_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9695009955201593"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwrMja870pXx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2CPsMdU_Xzz"
      },
      "source": [
        "# 1 as anomaly"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8TJuhJaW_aCG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_Mu8o31_aSz"
      },
      "source": [
        "new_train_images, new_train_labels, new_val_images, new_val_labels = separate_class(1, train_images, train_labels, val_images, val_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LiujCJmL_aS1"
      },
      "source": [
        "model0 = Model(name='1anomaly:classifier0')\n",
        "model1 = Model(name='1anomaly:classifier1')\n",
        "model2 = Model(name='1anomaly:classifier2')\n",
        "model3 = Model(name='1anomaly:classifier3')\n",
        "model4 = Model(name='1anomaly:classifier4')\n",
        "model5 = Model(name='1anomaly:classifier5')\n",
        "model6 = Model(name='1anomaly:classifier6')\n",
        "model7 = Model(name='1anomaly:classifier7')\n",
        "model8 = Model(name='1anomaly:classifier8')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1hwddHP_aTW"
      },
      "source": [
        "class_0 = model0.build()\n",
        "class_1 = model1.build()\n",
        "class_2 = model2.build()\n",
        "class_3 = model3.build()\n",
        "class_4 = model4.build()\n",
        "class_5 = model5.build()\n",
        "class_6 = model6.build()\n",
        "class_7 = model7.build()\n",
        "class_8 = model8.build()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQFl2-ke_aTX",
        "outputId": "aa9e0a6e-0ce3-45ac-eb7f-3deab753f35d"
      },
      "source": [
        "set(new_train_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0, 2, 3, 4, 5, 6, 7, 8, 9}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFUT5lz7_aTb",
        "outputId": "861da39b-9134-4f7c-bdd0-6d1bc5cc4c78"
      },
      "source": [
        "train_imgs0, train_lbls0 = get_train_data(0, new_train_images, new_train_labels)\n",
        "val_imgs0, val_lbls0 = get_train_data(0, new_val_images, new_val_labels)\n",
        "class_0 = model0.build()\n",
        "model0.train2(train_imgs0, train_lbls0, val_imgs0, val_lbls0)\n",
        "#model0.train(train_data0)\n",
        "model0.save_model(\"final_models/1anomaly-classifier0\")\n",
        "print('Model 0 saved')\n",
        "\n",
        "train_imgs1, train_lbls1 = get_train_data(2, new_train_images, new_train_labels)\n",
        "val_imgs1, val_lbls1 = get_train_data(2, new_val_images, new_val_labels)\n",
        "class_1 = model1.build()\n",
        "model1.train2(train_imgs1, train_lbls1, val_imgs1, val_lbls1)\n",
        "#model1.train(train_data1)\n",
        "model1.save_model(\"final_models/1anomaly-classifier1\")\n",
        "print('Model 1 saved')\n",
        "\n",
        "#train_data2 = get_train_data(2, new_train_images)\n",
        "train_imgs2, train_lbls2 = get_train_data(3, new_train_images, new_train_labels)\n",
        "val_imgs2, val_lbls2 = get_train_data(3, new_val_images, new_val_labels)\n",
        "class_2 = model2.build()\n",
        "model2.train2(train_imgs2, train_lbls2, val_imgs2, val_lbls2)\n",
        "#model2.train(train_data2)\n",
        "model2.save_model(\"final_models/1anomaly-classifier2\")\n",
        "print('Model 2 saved')\n",
        "\n",
        "#train_data3 = get_train_data(3, new_train_images)\n",
        "train_imgs3, train_lbls3 = get_train_data(4, new_train_images, new_train_labels)\n",
        "val_imgs3, val_lbls3 = get_train_data(4, new_val_images, new_val_labels)\n",
        "class_3 = model3.build()\n",
        "model3.train2(train_imgs3, train_lbls3, val_imgs3, val_lbls3)\n",
        "#model3.train(train_data3)\n",
        "model3.save_model(\"final_models/1anomaly-classifier3\")\n",
        "print('Model 3 saved')\n",
        "\n",
        "#train_data4 = get_train_data(4, new_train_images)\n",
        "train_imgs4, train_lbls4 = get_train_data(5, new_train_images, new_train_labels)\n",
        "val_imgs4, val_lbls4 = get_train_data(5, new_val_images, new_val_labels)\n",
        "class_4 = model4.build()\n",
        "model4.train2(train_imgs4, train_lbls4, val_imgs4, val_lbls4)\n",
        "#model4.train(train_data4)\n",
        "model4.save_model(\"final_models/1anomaly-classifier4\")\n",
        "print('Model 4 saved')\n",
        "\n",
        "#train_data5 = get_train_data(5, new_train_images)\n",
        "train_imgs5, train_lbls5 = get_train_data(6, new_train_images, new_train_labels)\n",
        "val_imgs5, val_lbls5 = get_train_data(6, new_val_images, new_val_labels)\n",
        "class_5 = model5.build()\n",
        "model5.train2(train_imgs5, train_lbls5, val_imgs5, val_lbls5)\n",
        "#model5.train(train_data5)\n",
        "model5.save_model(\"final_models/1anomaly-classifier5\")\n",
        "print('Model 5 saved')\n",
        "\n",
        "#train_data6 = get_train_data(6, new_train_images)\n",
        "train_imgs6, train_lbls6 = get_train_data(7, new_train_images, new_train_labels)\n",
        "val_imgs6, val_lbls6 = get_train_data(7, new_val_images, new_val_labels)\n",
        "class_6 = model6.build()\n",
        "model6.train2(train_imgs6, train_lbls6, val_imgs6, val_lbls6)\n",
        "#model6.train(train_data6)\n",
        "model6.save_model(\"final_models/1anomaly-classifier6\")\n",
        "print('Model 6 saved')\n",
        "\n",
        "#train_data7 = get_train_data(7, new_train_images)\n",
        "train_imgs7, train_lbls7 = get_train_data(8, new_train_images, new_train_labels)\n",
        "val_imgs7, val_lbls7 = get_train_data(8, new_val_images, new_val_labels)\n",
        "class_7 = model7.build()\n",
        "#model7.train(train_data7)\n",
        "model7.train2(train_imgs7, train_lbls7, val_imgs7, val_lbls7)\n",
        "model7.save_model(\"final_models/1anomaly-classifier7\")\n",
        "print('Model 7 saved')\n",
        "\n",
        "#train_data8 = get_train_data(8, new_train_images)\n",
        "train_imgs8, train_lbls8 = get_train_data(9, new_train_images, new_train_labels)\n",
        "val_imgs8, val_lbls8 = get_train_data(9, new_val_images, new_val_labels)\n",
        "class_8 = model8.build()\n",
        "#model8.train(train_data8)\n",
        "model8.train2(train_imgs8, train_lbls8, val_imgs8, val_lbls8)\n",
        "model8.save_model(\"final_models/1anomaly-classifier8\")\n",
        "print('Model 8 saved')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{2: 0, 3: 1, 4: 2, 5: 3, 6: 4, 7: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(37832,)\n",
            "{2: 0, 3: 1, 4: 2, 5: 3, 6: 4, 7: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9503,)\n",
            "Epoch 1/20\n",
            "1183/1183 [==============================] - 37s 31ms/step - loss: 5.7010 - accuracy: 0.7775 - val_loss: 0.4129 - val_accuracy: 0.9289\n",
            "Epoch 2/20\n",
            "1183/1183 [==============================] - 36s 31ms/step - loss: 0.1970 - accuracy: 0.9609 - val_loss: 0.2405 - val_accuracy: 0.9524\n",
            "Epoch 3/20\n",
            "1183/1183 [==============================] - 37s 31ms/step - loss: 0.0742 - accuracy: 0.9803 - val_loss: 0.0784 - val_accuracy: 0.9760\n",
            "Epoch 4/20\n",
            "1183/1183 [==============================] - 37s 32ms/step - loss: 0.0708 - accuracy: 0.9793 - val_loss: 0.0877 - val_accuracy: 0.9764\n",
            "Epoch 5/20\n",
            "1183/1183 [==============================] - 38s 32ms/step - loss: 0.0635 - accuracy: 0.9816 - val_loss: 0.0872 - val_accuracy: 0.9762\n",
            "Epoch 6/20\n",
            "1183/1183 [==============================] - 38s 32ms/step - loss: 0.0574 - accuracy: 0.9811 - val_loss: 0.0856 - val_accuracy: 0.9791\n",
            "Epoch 7/20\n",
            "1183/1183 [==============================] - 38s 32ms/step - loss: 0.0548 - accuracy: 0.9819 - val_loss: 0.1468 - val_accuracy: 0.9690\n",
            "Epoch 8/20\n",
            "1183/1183 [==============================] - 38s 32ms/step - loss: 0.0465 - accuracy: 0.9856 - val_loss: 0.1105 - val_accuracy: 0.9734\n",
            "Epoch 9/20\n",
            "1183/1183 [==============================] - 38s 32ms/step - loss: 0.0417 - accuracy: 0.9870 - val_loss: 0.2536 - val_accuracy: 0.9446\n",
            "Epoch 10/20\n",
            "1183/1183 [==============================] - 38s 32ms/step - loss: 0.0404 - accuracy: 0.9870 - val_loss: 0.1057 - val_accuracy: 0.9730\n",
            "Epoch 11/20\n",
            "1183/1183 [==============================] - 38s 32ms/step - loss: 0.0371 - accuracy: 0.9881 - val_loss: 0.0609 - val_accuracy: 0.9823\n",
            "Epoch 12/20\n",
            "1183/1183 [==============================] - 38s 32ms/step - loss: 0.0317 - accuracy: 0.9893 - val_loss: 0.0823 - val_accuracy: 0.9771\n",
            "Epoch 13/20\n",
            "1183/1183 [==============================] - 38s 32ms/step - loss: 0.0283 - accuracy: 0.9912 - val_loss: 0.4160 - val_accuracy: 0.9314\n",
            "Epoch 14/20\n",
            "1183/1183 [==============================] - 38s 32ms/step - loss: 0.0287 - accuracy: 0.9911 - val_loss: 0.1100 - val_accuracy: 0.9731\n",
            "Epoch 15/20\n",
            "1183/1183 [==============================] - 38s 32ms/step - loss: 0.0222 - accuracy: 0.9931 - val_loss: 0.0967 - val_accuracy: 0.9760\n",
            "Epoch 16/20\n",
            "1183/1183 [==============================] - 38s 32ms/step - loss: 0.0204 - accuracy: 0.9933 - val_loss: 0.0644 - val_accuracy: 0.9842\n",
            "Epoch 17/20\n",
            "1183/1183 [==============================] - 38s 32ms/step - loss: 0.0201 - accuracy: 0.9939 - val_loss: 0.1115 - val_accuracy: 0.9773\n",
            "Epoch 18/20\n",
            "1183/1183 [==============================] - 38s 32ms/step - loss: 0.0202 - accuracy: 0.9934 - val_loss: 0.1242 - val_accuracy: 0.9781\n",
            "Epoch 19/20\n",
            "1183/1183 [==============================] - 38s 32ms/step - loss: 0.0193 - accuracy: 0.9941 - val_loss: 0.1110 - val_accuracy: 0.9790\n",
            "Epoch 20/20\n",
            "1183/1183 [==============================] - 38s 32ms/step - loss: 0.0235 - accuracy: 0.9929 - val_loss: 0.0772 - val_accuracy: 0.9838\n",
            "INFO:tensorflow:Assets written to: final_models/1anomaly-classifier0/assets\n",
            "Model 0 saved\n",
            "{0: 0, 3: 1, 4: 2, 5: 3, 6: 4, 7: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(37796,)\n",
            "{0: 0, 3: 1, 4: 2, 5: 3, 6: 4, 7: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9504,)\n",
            "Epoch 1/20\n",
            "1182/1182 [==============================] - 39s 32ms/step - loss: 5.6347 - accuracy: 0.8148 - val_loss: 0.2535 - val_accuracy: 0.9513\n",
            "Epoch 2/20\n",
            "1182/1182 [==============================] - 38s 32ms/step - loss: 0.1661 - accuracy: 0.9688 - val_loss: 0.1185 - val_accuracy: 0.9677\n",
            "Epoch 3/20\n",
            "1182/1182 [==============================] - 38s 32ms/step - loss: 0.0697 - accuracy: 0.9793 - val_loss: 0.1434 - val_accuracy: 0.9638\n",
            "Epoch 4/20\n",
            "1182/1182 [==============================] - 38s 32ms/step - loss: 0.0719 - accuracy: 0.9795 - val_loss: 0.1922 - val_accuracy: 0.9599\n",
            "Epoch 5/20\n",
            "1182/1182 [==============================] - 38s 32ms/step - loss: 0.0576 - accuracy: 0.9838 - val_loss: 0.1592 - val_accuracy: 0.9619\n",
            "Epoch 6/20\n",
            "1182/1182 [==============================] - 38s 32ms/step - loss: 0.0586 - accuracy: 0.9824 - val_loss: 0.0992 - val_accuracy: 0.9744\n",
            "Epoch 7/20\n",
            "1182/1182 [==============================] - 38s 32ms/step - loss: 0.0442 - accuracy: 0.9864 - val_loss: 0.1600 - val_accuracy: 0.9619\n",
            "Epoch 8/20\n",
            "1182/1182 [==============================] - 38s 32ms/step - loss: 0.0543 - accuracy: 0.9836 - val_loss: 0.1255 - val_accuracy: 0.9721\n",
            "Epoch 9/20\n",
            "1182/1182 [==============================] - 38s 32ms/step - loss: 0.0375 - accuracy: 0.9893 - val_loss: 0.1619 - val_accuracy: 0.9673\n",
            "Epoch 10/20\n",
            "1182/1182 [==============================] - 38s 32ms/step - loss: 0.0419 - accuracy: 0.9880 - val_loss: 0.1160 - val_accuracy: 0.9734\n",
            "Epoch 11/20\n",
            "1182/1182 [==============================] - 38s 32ms/step - loss: 0.0319 - accuracy: 0.9909 - val_loss: 0.1415 - val_accuracy: 0.9721\n",
            "Epoch 12/20\n",
            "1182/1182 [==============================] - 38s 32ms/step - loss: 0.0309 - accuracy: 0.9901 - val_loss: 0.2793 - val_accuracy: 0.9335\n",
            "Epoch 13/20\n",
            "1182/1182 [==============================] - 38s 32ms/step - loss: 0.0318 - accuracy: 0.9904 - val_loss: 0.0886 - val_accuracy: 0.9817\n",
            "Epoch 14/20\n",
            "1182/1182 [==============================] - 38s 32ms/step - loss: 0.0268 - accuracy: 0.9922 - val_loss: 0.0824 - val_accuracy: 0.9814\n",
            "Epoch 15/20\n",
            "1182/1182 [==============================] - 38s 32ms/step - loss: 0.0188 - accuracy: 0.9940 - val_loss: 0.0795 - val_accuracy: 0.9824\n",
            "Epoch 16/20\n",
            "1182/1182 [==============================] - 38s 32ms/step - loss: 0.0235 - accuracy: 0.9927 - val_loss: 0.1019 - val_accuracy: 0.9786\n",
            "Epoch 17/20\n",
            "1182/1182 [==============================] - 38s 32ms/step - loss: 0.0202 - accuracy: 0.9940 - val_loss: 0.1710 - val_accuracy: 0.9725\n",
            "Epoch 18/20\n",
            "1182/1182 [==============================] - 38s 32ms/step - loss: 0.0231 - accuracy: 0.9925 - val_loss: 0.1188 - val_accuracy: 0.9760\n",
            "Epoch 19/20\n",
            "1182/1182 [==============================] - 38s 32ms/step - loss: 0.0171 - accuracy: 0.9946 - val_loss: 0.0835 - val_accuracy: 0.9827\n",
            "Epoch 20/20\n",
            "1182/1182 [==============================] - 38s 32ms/step - loss: 0.0204 - accuracy: 0.9937 - val_loss: 0.1348 - val_accuracy: 0.9747\n",
            "INFO:tensorflow:Assets written to: final_models/1anomaly-classifier1/assets\n",
            "Model 1 saved\n",
            "{0: 0, 2: 1, 4: 2, 5: 3, 6: 4, 7: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(37668,)\n",
            "{0: 0, 2: 1, 4: 2, 5: 3, 6: 4, 7: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9459,)\n",
            "Epoch 1/20\n",
            "1178/1178 [==============================] - 39s 32ms/step - loss: 5.1114 - accuracy: 0.8448 - val_loss: 0.4426 - val_accuracy: 0.9297\n",
            "Epoch 2/20\n",
            "1178/1178 [==============================] - 38s 32ms/step - loss: 0.1346 - accuracy: 0.9694 - val_loss: 0.1531 - val_accuracy: 0.9591\n",
            "Epoch 3/20\n",
            "1178/1178 [==============================] - 38s 32ms/step - loss: 0.0650 - accuracy: 0.9807 - val_loss: 0.2354 - val_accuracy: 0.9448\n",
            "Epoch 4/20\n",
            "1178/1178 [==============================] - 37s 32ms/step - loss: 0.0626 - accuracy: 0.9811 - val_loss: 0.2219 - val_accuracy: 0.9522\n",
            "Epoch 5/20\n",
            "1178/1178 [==============================] - 37s 32ms/step - loss: 0.0609 - accuracy: 0.9825 - val_loss: 0.0932 - val_accuracy: 0.9721\n",
            "Epoch 6/20\n",
            "1178/1178 [==============================] - 37s 32ms/step - loss: 0.0581 - accuracy: 0.9814 - val_loss: 0.0828 - val_accuracy: 0.9764\n",
            "Epoch 7/20\n",
            "1178/1178 [==============================] - 38s 32ms/step - loss: 0.0502 - accuracy: 0.9844 - val_loss: 0.2893 - val_accuracy: 0.9415\n",
            "Epoch 8/20\n",
            "1178/1178 [==============================] - 37s 32ms/step - loss: 0.0412 - accuracy: 0.9871 - val_loss: 0.1160 - val_accuracy: 0.9737\n",
            "Epoch 9/20\n",
            "1178/1178 [==============================] - 38s 32ms/step - loss: 0.0431 - accuracy: 0.9869 - val_loss: 0.0739 - val_accuracy: 0.9815\n",
            "Epoch 10/20\n",
            "1178/1178 [==============================] - 37s 32ms/step - loss: 0.0339 - accuracy: 0.9886 - val_loss: 0.1243 - val_accuracy: 0.9706\n",
            "Epoch 11/20\n",
            "1178/1178 [==============================] - 37s 32ms/step - loss: 0.0286 - accuracy: 0.9915 - val_loss: 0.1120 - val_accuracy: 0.9763\n",
            "Epoch 12/20\n",
            "1178/1178 [==============================] - 37s 32ms/step - loss: 0.0289 - accuracy: 0.9910 - val_loss: 0.1019 - val_accuracy: 0.9766\n",
            "Epoch 13/20\n",
            "1178/1178 [==============================] - 38s 32ms/step - loss: 0.0255 - accuracy: 0.9919 - val_loss: 0.0614 - val_accuracy: 0.9859\n",
            "Epoch 14/20\n",
            "1178/1178 [==============================] - 37s 32ms/step - loss: 0.0207 - accuracy: 0.9926 - val_loss: 0.1091 - val_accuracy: 0.9746\n",
            "Epoch 15/20\n",
            "1178/1178 [==============================] - 37s 32ms/step - loss: 0.0259 - accuracy: 0.9915 - val_loss: 0.1713 - val_accuracy: 0.9693\n",
            "Epoch 16/20\n",
            "1178/1178 [==============================] - 37s 32ms/step - loss: 0.0205 - accuracy: 0.9935 - val_loss: 0.3002 - val_accuracy: 0.9528\n",
            "Epoch 17/20\n",
            "1178/1178 [==============================] - 37s 32ms/step - loss: 0.0231 - accuracy: 0.9932 - val_loss: 0.1867 - val_accuracy: 0.9684\n",
            "Epoch 18/20\n",
            "1178/1178 [==============================] - 37s 32ms/step - loss: 0.0186 - accuracy: 0.9940 - val_loss: 0.1280 - val_accuracy: 0.9772\n",
            "Epoch 19/20\n",
            "1178/1178 [==============================] - 37s 32ms/step - loss: 0.0156 - accuracy: 0.9953 - val_loss: 0.0769 - val_accuracy: 0.9850\n",
            "Epoch 20/20\n",
            "1178/1178 [==============================] - 37s 32ms/step - loss: 0.0182 - accuracy: 0.9941 - val_loss: 0.1218 - val_accuracy: 0.9768\n",
            "INFO:tensorflow:Assets written to: final_models/1anomaly-classifier2/assets\n",
            "Model 2 saved\n",
            "{0: 0, 2: 1, 3: 2, 5: 3, 6: 4, 7: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(37914,)\n",
            "{0: 0, 2: 1, 3: 2, 5: 3, 6: 4, 7: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9502,)\n",
            "Epoch 1/20\n",
            "1185/1185 [==============================] - 39s 32ms/step - loss: 6.0878 - accuracy: 0.7915 - val_loss: 0.2437 - val_accuracy: 0.9688\n",
            "Epoch 2/20\n",
            "1185/1185 [==============================] - 38s 32ms/step - loss: 0.1759 - accuracy: 0.9734 - val_loss: 0.1217 - val_accuracy: 0.9715\n",
            "Epoch 3/20\n",
            "1185/1185 [==============================] - 38s 32ms/step - loss: 0.0636 - accuracy: 0.9829 - val_loss: 0.1598 - val_accuracy: 0.9596\n",
            "Epoch 4/20\n",
            "1185/1185 [==============================] - 38s 32ms/step - loss: 0.0558 - accuracy: 0.9848 - val_loss: 0.1393 - val_accuracy: 0.9613\n",
            "Epoch 5/20\n",
            "1185/1185 [==============================] - 38s 32ms/step - loss: 0.0555 - accuracy: 0.9823 - val_loss: 0.2068 - val_accuracy: 0.9377\n",
            "Epoch 6/20\n",
            "1185/1185 [==============================] - 38s 32ms/step - loss: 0.0577 - accuracy: 0.9835 - val_loss: 0.1880 - val_accuracy: 0.9586\n",
            "Epoch 7/20\n",
            "1185/1185 [==============================] - 38s 32ms/step - loss: 0.0435 - accuracy: 0.9860 - val_loss: 0.1189 - val_accuracy: 0.9705\n",
            "Epoch 8/20\n",
            "1185/1185 [==============================] - 38s 32ms/step - loss: 0.0460 - accuracy: 0.9861 - val_loss: 0.1315 - val_accuracy: 0.9691\n",
            "Epoch 9/20\n",
            "1185/1185 [==============================] - 38s 32ms/step - loss: 0.0366 - accuracy: 0.9883 - val_loss: 0.0869 - val_accuracy: 0.9802\n",
            "Epoch 10/20\n",
            "1185/1185 [==============================] - 38s 32ms/step - loss: 0.0321 - accuracy: 0.9899 - val_loss: 0.0732 - val_accuracy: 0.9822\n",
            "Epoch 11/20\n",
            "1185/1185 [==============================] - 38s 32ms/step - loss: 0.0320 - accuracy: 0.9904 - val_loss: 0.2396 - val_accuracy: 0.9536\n",
            "Epoch 12/20\n",
            "1185/1185 [==============================] - 38s 32ms/step - loss: 0.0276 - accuracy: 0.9913 - val_loss: 0.0757 - val_accuracy: 0.9816\n",
            "Epoch 13/20\n",
            "1185/1185 [==============================] - 38s 32ms/step - loss: 0.0249 - accuracy: 0.9919 - val_loss: 0.0785 - val_accuracy: 0.9801\n",
            "Epoch 14/20\n",
            "1185/1185 [==============================] - 38s 32ms/step - loss: 0.0252 - accuracy: 0.9923 - val_loss: 0.0763 - val_accuracy: 0.9844\n",
            "Epoch 15/20\n",
            "1185/1185 [==============================] - 38s 32ms/step - loss: 0.0213 - accuracy: 0.9933 - val_loss: 0.1207 - val_accuracy: 0.9775\n",
            "Epoch 16/20\n",
            "1185/1185 [==============================] - 38s 32ms/step - loss: 0.0164 - accuracy: 0.9945 - val_loss: 0.0781 - val_accuracy: 0.9845\n",
            "Epoch 17/20\n",
            "1185/1185 [==============================] - 38s 32ms/step - loss: 0.0157 - accuracy: 0.9946 - val_loss: 0.1457 - val_accuracy: 0.9741\n",
            "Epoch 18/20\n",
            "1185/1185 [==============================] - 38s 32ms/step - loss: 0.0159 - accuracy: 0.9944 - val_loss: 0.0759 - val_accuracy: 0.9845\n",
            "Epoch 19/20\n",
            "1185/1185 [==============================] - 38s 32ms/step - loss: 0.0201 - accuracy: 0.9939 - val_loss: 0.0777 - val_accuracy: 0.9848\n",
            "Epoch 20/20\n",
            "1185/1185 [==============================] - 38s 32ms/step - loss: 0.0119 - accuracy: 0.9957 - val_loss: 0.1375 - val_accuracy: 0.9799\n",
            "INFO:tensorflow:Assets written to: final_models/1anomaly-classifier3/assets\n",
            "Model 3 saved\n",
            "{0: 0, 2: 1, 3: 2, 4: 3, 6: 4, 7: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(38263,)\n",
            "{0: 0, 2: 1, 3: 2, 4: 3, 6: 4, 7: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9574,)\n",
            "Epoch 1/20\n",
            "1196/1196 [==============================] - 40s 32ms/step - loss: 4.5222 - accuracy: 0.8345 - val_loss: 0.1622 - val_accuracy: 0.9635\n",
            "Epoch 2/20\n",
            "1196/1196 [==============================] - 38s 32ms/step - loss: 0.1086 - accuracy: 0.9747 - val_loss: 0.1419 - val_accuracy: 0.9624\n",
            "Epoch 3/20\n",
            "1196/1196 [==============================] - 38s 32ms/step - loss: 0.0585 - accuracy: 0.9826 - val_loss: 0.0757 - val_accuracy: 0.9792\n",
            "Epoch 4/20\n",
            "1196/1196 [==============================] - 38s 32ms/step - loss: 0.0653 - accuracy: 0.9801 - val_loss: 0.0941 - val_accuracy: 0.9727\n",
            "Epoch 5/20\n",
            "1196/1196 [==============================] - 38s 32ms/step - loss: 0.0573 - accuracy: 0.9830 - val_loss: 0.1199 - val_accuracy: 0.9655\n",
            "Epoch 6/20\n",
            "1196/1196 [==============================] - 38s 32ms/step - loss: 0.0560 - accuracy: 0.9824 - val_loss: 0.1671 - val_accuracy: 0.9559\n",
            "Epoch 7/20\n",
            "1196/1196 [==============================] - 39s 32ms/step - loss: 0.0441 - accuracy: 0.9868 - val_loss: 0.2016 - val_accuracy: 0.9565\n",
            "Epoch 8/20\n",
            "1196/1196 [==============================] - 38s 32ms/step - loss: 0.0407 - accuracy: 0.9874 - val_loss: 0.0679 - val_accuracy: 0.9813\n",
            "Epoch 9/20\n",
            "1196/1196 [==============================] - 38s 32ms/step - loss: 0.0371 - accuracy: 0.9887 - val_loss: 0.0904 - val_accuracy: 0.9762\n",
            "Epoch 10/20\n",
            "1196/1196 [==============================] - 38s 32ms/step - loss: 0.0335 - accuracy: 0.9895 - val_loss: 0.0669 - val_accuracy: 0.9823\n",
            "Epoch 11/20\n",
            "1196/1196 [==============================] - 38s 32ms/step - loss: 0.0301 - accuracy: 0.9907 - val_loss: 0.1007 - val_accuracy: 0.9768\n",
            "Epoch 12/20\n",
            "1196/1196 [==============================] - 38s 32ms/step - loss: 0.0281 - accuracy: 0.9903 - val_loss: 0.1089 - val_accuracy: 0.9764\n",
            "Epoch 13/20\n",
            "1196/1196 [==============================] - 38s 32ms/step - loss: 0.0283 - accuracy: 0.9918 - val_loss: 0.1565 - val_accuracy: 0.9678\n",
            "Epoch 14/20\n",
            "1196/1196 [==============================] - 39s 32ms/step - loss: 0.0239 - accuracy: 0.9933 - val_loss: 0.0781 - val_accuracy: 0.9820\n",
            "Epoch 15/20\n",
            "1196/1196 [==============================] - 38s 32ms/step - loss: 0.0199 - accuracy: 0.9940 - val_loss: 0.0762 - val_accuracy: 0.9842\n",
            "Epoch 16/20\n",
            "1196/1196 [==============================] - 39s 32ms/step - loss: 0.0203 - accuracy: 0.9937 - val_loss: 0.1012 - val_accuracy: 0.9816\n",
            "Epoch 17/20\n",
            "1196/1196 [==============================] - 38s 32ms/step - loss: 0.0165 - accuracy: 0.9942 - val_loss: 0.0895 - val_accuracy: 0.9853\n",
            "Epoch 18/20\n",
            "1196/1196 [==============================] - 38s 32ms/step - loss: 0.0179 - accuracy: 0.9951 - val_loss: 0.0907 - val_accuracy: 0.9817\n",
            "Epoch 19/20\n",
            "1196/1196 [==============================] - 38s 32ms/step - loss: 0.0180 - accuracy: 0.9949 - val_loss: 0.0819 - val_accuracy: 0.9840\n",
            "Epoch 20/20\n",
            "1196/1196 [==============================] - 38s 32ms/step - loss: 0.0170 - accuracy: 0.9948 - val_loss: 0.0675 - val_accuracy: 0.9886\n",
            "INFO:tensorflow:Assets written to: final_models/1anomaly-classifier4/assets\n",
            "Model 4 saved\n",
            "{0: 0, 2: 1, 3: 2, 4: 3, 5: 4, 7: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(37839,)\n",
            "{0: 0, 2: 1, 3: 2, 4: 3, 5: 4, 7: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9501,)\n",
            "Epoch 1/20\n",
            "1183/1183 [==============================] - 39s 32ms/step - loss: 6.2041 - accuracy: 0.7487 - val_loss: 0.1535 - val_accuracy: 0.9666\n",
            "Epoch 2/20\n",
            "1183/1183 [==============================] - 38s 32ms/step - loss: 0.1325 - accuracy: 0.9698 - val_loss: 0.2090 - val_accuracy: 0.9495\n",
            "Epoch 3/20\n",
            "1183/1183 [==============================] - 38s 32ms/step - loss: 0.0827 - accuracy: 0.9772 - val_loss: 0.1272 - val_accuracy: 0.9676\n",
            "Epoch 4/20\n",
            "1183/1183 [==============================] - 38s 32ms/step - loss: 0.0708 - accuracy: 0.9781 - val_loss: 0.1019 - val_accuracy: 0.9757\n",
            "Epoch 5/20\n",
            "1183/1183 [==============================] - 38s 32ms/step - loss: 0.0686 - accuracy: 0.9802 - val_loss: 0.2373 - val_accuracy: 0.9465\n",
            "Epoch 6/20\n",
            "1183/1183 [==============================] - 38s 32ms/step - loss: 0.0626 - accuracy: 0.9813 - val_loss: 0.0846 - val_accuracy: 0.9794\n",
            "Epoch 7/20\n",
            "1183/1183 [==============================] - 38s 32ms/step - loss: 0.0454 - accuracy: 0.9864 - val_loss: 0.0977 - val_accuracy: 0.9755\n",
            "Epoch 8/20\n",
            "1183/1183 [==============================] - 38s 32ms/step - loss: 0.0476 - accuracy: 0.9858 - val_loss: 0.0954 - val_accuracy: 0.9768\n",
            "Epoch 9/20\n",
            "1183/1183 [==============================] - 38s 32ms/step - loss: 0.0412 - accuracy: 0.9875 - val_loss: 0.0919 - val_accuracy: 0.9762\n",
            "Epoch 10/20\n",
            "1183/1183 [==============================] - 38s 32ms/step - loss: 0.0370 - accuracy: 0.9882 - val_loss: 0.0817 - val_accuracy: 0.9794\n",
            "Epoch 11/20\n",
            "1183/1183 [==============================] - 38s 32ms/step - loss: 0.0345 - accuracy: 0.9890 - val_loss: 0.0712 - val_accuracy: 0.9822\n",
            "Epoch 12/20\n",
            "1183/1183 [==============================] - 38s 32ms/step - loss: 0.0286 - accuracy: 0.9908 - val_loss: 0.0703 - val_accuracy: 0.9848\n",
            "Epoch 13/20\n",
            "1183/1183 [==============================] - 38s 32ms/step - loss: 0.0296 - accuracy: 0.9909 - val_loss: 0.0923 - val_accuracy: 0.9799\n",
            "Epoch 14/20\n",
            "1183/1183 [==============================] - 38s 32ms/step - loss: 0.0225 - accuracy: 0.9928 - val_loss: 0.1189 - val_accuracy: 0.9751\n",
            "Epoch 15/20\n",
            "1183/1183 [==============================] - 38s 32ms/step - loss: 0.0211 - accuracy: 0.9930 - val_loss: 0.0722 - val_accuracy: 0.9832\n",
            "Epoch 16/20\n",
            "1183/1183 [==============================] - 38s 32ms/step - loss: 0.0207 - accuracy: 0.9936 - val_loss: 0.0662 - val_accuracy: 0.9861\n",
            "Epoch 17/20\n",
            "1183/1183 [==============================] - 38s 32ms/step - loss: 0.0214 - accuracy: 0.9934 - val_loss: 0.0747 - val_accuracy: 0.9855\n",
            "Epoch 18/20\n",
            "1183/1183 [==============================] - 38s 32ms/step - loss: 0.0184 - accuracy: 0.9945 - val_loss: 0.0752 - val_accuracy: 0.9846\n",
            "Epoch 19/20\n",
            "1183/1183 [==============================] - 38s 32ms/step - loss: 0.0150 - accuracy: 0.9950 - val_loss: 0.0888 - val_accuracy: 0.9844\n",
            "Epoch 20/20\n",
            "1183/1183 [==============================] - 38s 32ms/step - loss: 0.0185 - accuracy: 0.9947 - val_loss: 0.1267 - val_accuracy: 0.9781\n",
            "INFO:tensorflow:Assets written to: final_models/1anomaly-classifier5/assets\n",
            "Model 5 saved\n",
            "{0: 0, 2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(37614,)\n",
            "{0: 0, 2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9379,)\n",
            "Epoch 1/20\n",
            "1176/1176 [==============================] - 39s 32ms/step - loss: 5.7102 - accuracy: 0.7938 - val_loss: 0.4742 - val_accuracy: 0.9250\n",
            "Epoch 2/20\n",
            "1176/1176 [==============================] - 38s 32ms/step - loss: 0.1802 - accuracy: 0.9636 - val_loss: 0.7240 - val_accuracy: 0.9199\n",
            "Epoch 3/20\n",
            "1176/1176 [==============================] - 38s 32ms/step - loss: 0.1135 - accuracy: 0.9735 - val_loss: 0.2309 - val_accuracy: 0.9554\n",
            "Epoch 4/20\n",
            "1176/1176 [==============================] - 38s 32ms/step - loss: 0.0812 - accuracy: 0.9765 - val_loss: 0.1107 - val_accuracy: 0.9735\n",
            "Epoch 5/20\n",
            "1176/1176 [==============================] - 38s 32ms/step - loss: 0.0734 - accuracy: 0.9794 - val_loss: 0.0761 - val_accuracy: 0.9798\n",
            "Epoch 6/20\n",
            "1176/1176 [==============================] - 38s 32ms/step - loss: 0.0522 - accuracy: 0.9839 - val_loss: 0.2043 - val_accuracy: 0.9524\n",
            "Epoch 7/20\n",
            "1176/1176 [==============================] - 38s 32ms/step - loss: 0.0499 - accuracy: 0.9850 - val_loss: 0.1338 - val_accuracy: 0.9653\n",
            "Epoch 8/20\n",
            "1176/1176 [==============================] - 38s 32ms/step - loss: 0.0455 - accuracy: 0.9854 - val_loss: 0.1538 - val_accuracy: 0.9632\n",
            "Epoch 9/20\n",
            "1176/1176 [==============================] - 38s 32ms/step - loss: 0.0442 - accuracy: 0.9864 - val_loss: 0.0743 - val_accuracy: 0.9829\n",
            "Epoch 10/20\n",
            "1176/1176 [==============================] - 38s 32ms/step - loss: 0.0393 - accuracy: 0.9881 - val_loss: 0.1126 - val_accuracy: 0.9735\n",
            "Epoch 11/20\n",
            "1176/1176 [==============================] - 38s 32ms/step - loss: 0.0331 - accuracy: 0.9897 - val_loss: 0.0593 - val_accuracy: 0.9848\n",
            "Epoch 12/20\n",
            "1176/1176 [==============================] - 38s 32ms/step - loss: 0.0306 - accuracy: 0.9905 - val_loss: 0.1681 - val_accuracy: 0.9652\n",
            "Epoch 13/20\n",
            "1176/1176 [==============================] - 38s 32ms/step - loss: 0.0246 - accuracy: 0.9930 - val_loss: 0.0919 - val_accuracy: 0.9787\n",
            "Epoch 14/20\n",
            "1176/1176 [==============================] - 38s 32ms/step - loss: 0.0269 - accuracy: 0.9914 - val_loss: 0.1120 - val_accuracy: 0.9749\n",
            "Epoch 15/20\n",
            "1176/1176 [==============================] - 38s 32ms/step - loss: 0.0220 - accuracy: 0.9934 - val_loss: 0.1091 - val_accuracy: 0.9780\n",
            "Epoch 16/20\n",
            "1176/1176 [==============================] - 38s 32ms/step - loss: 0.0195 - accuracy: 0.9939 - val_loss: 0.0627 - val_accuracy: 0.9864\n",
            "Epoch 17/20\n",
            "1176/1176 [==============================] - 38s 32ms/step - loss: 0.0224 - accuracy: 0.9928 - val_loss: 0.2027 - val_accuracy: 0.9596\n",
            "Epoch 18/20\n",
            "1176/1176 [==============================] - 38s 32ms/step - loss: 0.0197 - accuracy: 0.9938 - val_loss: 0.0495 - val_accuracy: 0.9890\n",
            "Epoch 19/20\n",
            "1176/1176 [==============================] - 38s 32ms/step - loss: 0.0150 - accuracy: 0.9955 - val_loss: 0.0605 - val_accuracy: 0.9872\n",
            "Epoch 20/20\n",
            "1176/1176 [==============================] - 38s 32ms/step - loss: 0.0190 - accuracy: 0.9939 - val_loss: 0.0659 - val_accuracy: 0.9861\n",
            "INFO:tensorflow:Assets written to: final_models/1anomaly-classifier6/assets\n",
            "Model 6 saved\n",
            "{0: 0, 2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(37889,)\n",
            "{0: 0, 2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9518,)\n",
            "Epoch 1/20\n",
            "1185/1185 [==============================] - 39s 33ms/step - loss: 5.8873 - accuracy: 0.7991 - val_loss: 0.6529 - val_accuracy: 0.9352\n",
            "Epoch 2/20\n",
            "1185/1185 [==============================] - 38s 32ms/step - loss: 0.1531 - accuracy: 0.9677 - val_loss: 0.1509 - val_accuracy: 0.9592\n",
            "Epoch 3/20\n",
            "1185/1185 [==============================] - 38s 32ms/step - loss: 0.0737 - accuracy: 0.9785 - val_loss: 0.1099 - val_accuracy: 0.9684\n",
            "Epoch 4/20\n",
            "1185/1185 [==============================] - 38s 32ms/step - loss: 0.0640 - accuracy: 0.9819 - val_loss: 0.1052 - val_accuracy: 0.9737\n",
            "Epoch 5/20\n",
            "1185/1185 [==============================] - 38s 32ms/step - loss: 0.0637 - accuracy: 0.9820 - val_loss: 0.0882 - val_accuracy: 0.9770\n",
            "Epoch 6/20\n",
            "1185/1185 [==============================] - 38s 32ms/step - loss: 0.0556 - accuracy: 0.9842 - val_loss: 0.0877 - val_accuracy: 0.9760\n",
            "Epoch 7/20\n",
            "1185/1185 [==============================] - 38s 32ms/step - loss: 0.0509 - accuracy: 0.9840 - val_loss: 0.1491 - val_accuracy: 0.9662\n",
            "Epoch 8/20\n",
            "1185/1185 [==============================] - 38s 32ms/step - loss: 0.0462 - accuracy: 0.9859 - val_loss: 0.3256 - val_accuracy: 0.9424\n",
            "Epoch 9/20\n",
            "1185/1185 [==============================] - 38s 32ms/step - loss: 0.0369 - accuracy: 0.9875 - val_loss: 0.1501 - val_accuracy: 0.9679\n",
            "Epoch 10/20\n",
            "1185/1185 [==============================] - 38s 32ms/step - loss: 0.0338 - accuracy: 0.9899 - val_loss: 0.0992 - val_accuracy: 0.9764\n",
            "Epoch 11/20\n",
            "1185/1185 [==============================] - 38s 32ms/step - loss: 0.0372 - accuracy: 0.9890 - val_loss: 0.1940 - val_accuracy: 0.9555\n",
            "Epoch 12/20\n",
            "1185/1185 [==============================] - 38s 32ms/step - loss: 0.0291 - accuracy: 0.9910 - val_loss: 0.1008 - val_accuracy: 0.9786\n",
            "Epoch 13/20\n",
            "1185/1185 [==============================] - 38s 32ms/step - loss: 0.0288 - accuracy: 0.9907 - val_loss: 0.1019 - val_accuracy: 0.9776\n",
            "Epoch 14/20\n",
            "1185/1185 [==============================] - 38s 32ms/step - loss: 0.0280 - accuracy: 0.9913 - val_loss: 0.0828 - val_accuracy: 0.9811\n",
            "Epoch 15/20\n",
            "1185/1185 [==============================] - 38s 32ms/step - loss: 0.0237 - accuracy: 0.9925 - val_loss: 0.0763 - val_accuracy: 0.9821\n",
            "Epoch 16/20\n",
            "1185/1185 [==============================] - 38s 32ms/step - loss: 0.0245 - accuracy: 0.9924 - val_loss: 0.0462 - val_accuracy: 0.9891\n",
            "Epoch 17/20\n",
            "1185/1185 [==============================] - 38s 32ms/step - loss: 0.0214 - accuracy: 0.9932 - val_loss: 0.0679 - val_accuracy: 0.9853\n",
            "Epoch 18/20\n",
            "1185/1185 [==============================] - 38s 32ms/step - loss: 0.0171 - accuracy: 0.9951 - val_loss: 0.0847 - val_accuracy: 0.9826\n",
            "Epoch 19/20\n",
            "1185/1185 [==============================] - 38s 32ms/step - loss: 0.0196 - accuracy: 0.9939 - val_loss: 0.0832 - val_accuracy: 0.9804\n",
            "Epoch 20/20\n",
            "1185/1185 [==============================] - 38s 32ms/step - loss: 0.0177 - accuracy: 0.9951 - val_loss: 0.0810 - val_accuracy: 0.9843\n",
            "INFO:tensorflow:Assets written to: final_models/1anomaly-classifier7/assets\n",
            "Model 7 saved\n",
            "{0: 0, 2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, 8: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(37825,)\n",
            "{0: 0, 2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, 8: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9484,)\n",
            "Epoch 1/20\n",
            "1183/1183 [==============================] - 39s 32ms/step - loss: 3.8753 - accuracy: 0.8436 - val_loss: 0.3669 - val_accuracy: 0.9501\n",
            "Epoch 2/20\n",
            "1183/1183 [==============================] - 37s 32ms/step - loss: 0.1238 - accuracy: 0.9769 - val_loss: 0.1247 - val_accuracy: 0.9664\n",
            "Epoch 3/20\n",
            "1183/1183 [==============================] - 38s 32ms/step - loss: 0.0586 - accuracy: 0.9836 - val_loss: 0.1037 - val_accuracy: 0.9756\n",
            "Epoch 4/20\n",
            "1183/1183 [==============================] - 38s 32ms/step - loss: 0.0534 - accuracy: 0.9849 - val_loss: 0.1577 - val_accuracy: 0.9657\n",
            "Epoch 5/20\n",
            "1183/1183 [==============================] - 38s 32ms/step - loss: 0.0514 - accuracy: 0.9852 - val_loss: 0.0978 - val_accuracy: 0.9761\n",
            "Epoch 6/20\n",
            "1183/1183 [==============================] - 38s 32ms/step - loss: 0.0452 - accuracy: 0.9857 - val_loss: 0.1998 - val_accuracy: 0.9549\n",
            "Epoch 7/20\n",
            "1183/1183 [==============================] - 38s 32ms/step - loss: 0.0385 - accuracy: 0.9873 - val_loss: 0.1245 - val_accuracy: 0.9686\n",
            "Epoch 8/20\n",
            "1183/1183 [==============================] - 38s 32ms/step - loss: 0.0376 - accuracy: 0.9884 - val_loss: 0.0722 - val_accuracy: 0.9817\n",
            "Epoch 9/20\n",
            "1183/1183 [==============================] - 38s 32ms/step - loss: 0.0408 - accuracy: 0.9871 - val_loss: 0.1563 - val_accuracy: 0.9691\n",
            "Epoch 10/20\n",
            "1183/1183 [==============================] - 38s 32ms/step - loss: 0.0357 - accuracy: 0.9890 - val_loss: 0.1055 - val_accuracy: 0.9787\n",
            "Epoch 11/20\n",
            "1183/1183 [==============================] - 38s 32ms/step - loss: 0.0305 - accuracy: 0.9902 - val_loss: 0.0844 - val_accuracy: 0.9814\n",
            "Epoch 12/20\n",
            "1183/1183 [==============================] - 38s 32ms/step - loss: 0.0244 - accuracy: 0.9922 - val_loss: 0.0810 - val_accuracy: 0.9841\n",
            "Epoch 13/20\n",
            "1183/1183 [==============================] - 38s 32ms/step - loss: 0.0200 - accuracy: 0.9941 - val_loss: 0.1372 - val_accuracy: 0.9714\n",
            "Epoch 14/20\n",
            "1183/1183 [==============================] - 38s 32ms/step - loss: 0.0224 - accuracy: 0.9922 - val_loss: 0.0919 - val_accuracy: 0.9830\n",
            "Epoch 15/20\n",
            "1183/1183 [==============================] - 38s 32ms/step - loss: 0.0455 - accuracy: 0.9891 - val_loss: 0.1076 - val_accuracy: 0.9818\n",
            "Epoch 16/20\n",
            "1183/1183 [==============================] - 38s 32ms/step - loss: 0.0141 - accuracy: 0.9956 - val_loss: 0.1162 - val_accuracy: 0.9782\n",
            "Epoch 17/20\n",
            "1183/1183 [==============================] - 38s 32ms/step - loss: 0.0218 - accuracy: 0.9935 - val_loss: 0.1038 - val_accuracy: 0.9805\n",
            "Epoch 18/20\n",
            "1183/1183 [==============================] - 38s 32ms/step - loss: 0.0164 - accuracy: 0.9948 - val_loss: 0.0983 - val_accuracy: 0.9802\n",
            "Epoch 19/20\n",
            "1183/1183 [==============================] - 38s 32ms/step - loss: 0.0126 - accuracy: 0.9955 - val_loss: 0.1522 - val_accuracy: 0.9768\n",
            "Epoch 20/20\n",
            " 207/1183 [====>.........................] - ETA: 28s - loss: 0.0191 - accuracy: 0.9941"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RxX5sixa_y2u",
        "outputId": "52e9f297-6511-4352-f3a3-a6ad653338e9"
      },
      "source": [
        "#train_data8 = get_train_data(8, new_train_images)\n",
        "train_imgs8, train_lbls8 = get_train_data(9, new_train_images, new_train_labels)\n",
        "val_imgs8, val_lbls8 = get_train_data(9, new_val_images, new_val_labels)\n",
        "class_8 = model8.build()\n",
        "#model8.train(train_data8)\n",
        "model8.train2(train_imgs8, train_lbls8, val_imgs8, val_lbls8)\n",
        "model8.save_model(\"final_models/1anomaly-classifier8\")\n",
        "print('Model 8 saved')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{0: 0, 2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, 8: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(37825,)\n",
            "{0: 0, 2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, 8: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9484,)\n",
            "Epoch 1/20\n",
            "1183/1183 [==============================] - 43s 30ms/step - loss: 5.4658 - accuracy: 0.8050 - val_loss: 1.7318 - val_accuracy: 0.8135\n",
            "Epoch 2/20\n",
            "1183/1183 [==============================] - 36s 31ms/step - loss: 0.6752 - accuracy: 0.9087 - val_loss: 0.3964 - val_accuracy: 0.9406\n",
            "Epoch 3/20\n",
            "1183/1183 [==============================] - 37s 31ms/step - loss: 0.0844 - accuracy: 0.9768 - val_loss: 0.0801 - val_accuracy: 0.9766\n",
            "Epoch 4/20\n",
            "1183/1183 [==============================] - 37s 31ms/step - loss: 0.0587 - accuracy: 0.9837 - val_loss: 0.0883 - val_accuracy: 0.9778\n",
            "Epoch 5/20\n",
            "1183/1183 [==============================] - 37s 31ms/step - loss: 0.0557 - accuracy: 0.9843 - val_loss: 0.0734 - val_accuracy: 0.9800\n",
            "Epoch 6/20\n",
            "1183/1183 [==============================] - 37s 31ms/step - loss: 0.0454 - accuracy: 0.9863 - val_loss: 0.0850 - val_accuracy: 0.9793\n",
            "Epoch 7/20\n",
            "1183/1183 [==============================] - 37s 31ms/step - loss: 0.0492 - accuracy: 0.9855 - val_loss: 0.0757 - val_accuracy: 0.9831\n",
            "Epoch 8/20\n",
            "1183/1183 [==============================] - 37s 31ms/step - loss: 0.0471 - accuracy: 0.9853 - val_loss: 0.0994 - val_accuracy: 0.9764\n",
            "Epoch 9/20\n",
            "1183/1183 [==============================] - 37s 31ms/step - loss: 0.0442 - accuracy: 0.9865 - val_loss: 0.1296 - val_accuracy: 0.9739\n",
            "Epoch 10/20\n",
            "1183/1183 [==============================] - 37s 31ms/step - loss: 0.0377 - accuracy: 0.9894 - val_loss: 0.0851 - val_accuracy: 0.9811\n",
            "Epoch 11/20\n",
            "1183/1183 [==============================] - 37s 31ms/step - loss: 0.0304 - accuracy: 0.9915 - val_loss: 0.0563 - val_accuracy: 0.9872\n",
            "Epoch 12/20\n",
            "1183/1183 [==============================] - 37s 32ms/step - loss: 0.0263 - accuracy: 0.9918 - val_loss: 0.1404 - val_accuracy: 0.9713\n",
            "Epoch 13/20\n",
            "1183/1183 [==============================] - 37s 31ms/step - loss: 0.0244 - accuracy: 0.9925 - val_loss: 0.0807 - val_accuracy: 0.9827\n",
            "Epoch 14/20\n",
            "1183/1183 [==============================] - 37s 31ms/step - loss: 0.0212 - accuracy: 0.9934 - val_loss: 0.2156 - val_accuracy: 0.9636\n",
            "Epoch 15/20\n",
            "1183/1183 [==============================] - 37s 31ms/step - loss: 0.0239 - accuracy: 0.9928 - val_loss: 0.1060 - val_accuracy: 0.9792\n",
            "Epoch 16/20\n",
            "1183/1183 [==============================] - 37s 31ms/step - loss: 0.0163 - accuracy: 0.9947 - val_loss: 0.0997 - val_accuracy: 0.9793\n",
            "Epoch 17/20\n",
            "1183/1183 [==============================] - 37s 31ms/step - loss: 0.0164 - accuracy: 0.9948 - val_loss: 0.0510 - val_accuracy: 0.9902\n",
            "Epoch 18/20\n",
            "1183/1183 [==============================] - 37s 31ms/step - loss: 0.0134 - accuracy: 0.9957 - val_loss: 0.1327 - val_accuracy: 0.9782\n",
            "Epoch 19/20\n",
            "1183/1183 [==============================] - 37s 31ms/step - loss: 0.0176 - accuracy: 0.9945 - val_loss: 0.0943 - val_accuracy: 0.9833\n",
            "Epoch 20/20\n",
            "1183/1183 [==============================] - 37s 31ms/step - loss: 0.0180 - accuracy: 0.9944 - val_loss: 0.1121 - val_accuracy: 0.9833\n",
            "INFO:tensorflow:Assets written to: final_models/1anomaly-classifier8/assets\n",
            "Model 8 saved\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yr1YXZHmPduj"
      },
      "source": [
        "class_0 = model0.load_model(\"final_models/1anomaly-classifier0\")\n",
        "class_1 = model1.load_model(\"final_models/1anomaly-classifier1\")\n",
        "class_2 = model2.load_model(\"final_models/1anomaly-classifier2\")\n",
        "class_3 = model3.load_model(\"final_models/1anomaly-classifier3\")\n",
        "class_4 = model4.load_model(\"final_models/1anomaly-classifier4\")\n",
        "class_5 = model5.load_model(\"final_models/1anomaly-classifier5\")\n",
        "class_6 = model6.load_model(\"final_models/1anomaly-classifier6\")\n",
        "class_7 = model7.load_model(\"final_models/1anomaly-classifier7\")\n",
        "class_8 = model8.load_model(\"final_models/1anomaly-classifier8\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DAY7JJu0SiDE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iBRztkcYS6vs",
        "outputId": "8cb4157d-c926-46eb-fa4c-b59de8cc457f"
      },
      "source": [
        "layer_name_list = []\n",
        "\n",
        "layer_name_list.append(class_0.layers[-2:][0].name)\n",
        "layer_name_list.append(class_1.layers[-2:][0].name)\n",
        "layer_name_list.append(class_2.layers[-2:][0].name)\n",
        "layer_name_list.append(class_3.layers[-2:][0].name)\n",
        "layer_name_list.append(class_4.layers[-2:][0].name)\n",
        "layer_name_list.append(class_5.layers[-2:][0].name)\n",
        "layer_name_list.append(class_6.layers[-2:][0].name)\n",
        "layer_name_list.append(class_7.layers[-2:][0].name)\n",
        "layer_name_list.append(class_8.layers[-2:][0].name)\n",
        "\n",
        "print(layer_name_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['dense_61', 'dense_63', 'dense_65', 'dense_67', 'dense_69', 'dense_71', 'dense_73', 'dense_75', 'dense_19']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RIzp8OYQS6wc"
      },
      "source": [
        "from keras import Model\n",
        "model_dict = {}\n",
        "model_output0 = class_0.get_layer(layer_name_list[0]).output\n",
        "m0 = Model(inputs=class_0.input, outputs=model_output0)\n",
        "model_dict[0] = m0\n",
        "\n",
        "model_output1 = class_1.get_layer(layer_name_list[1]).output\n",
        "m1 = Model(inputs=class_1.input, outputs=model_output1)\n",
        "model_dict[1] = m1\n",
        "\n",
        "model_output2 = class_2.get_layer(layer_name_list[2]).output\n",
        "m2 = Model(inputs=class_2.input, outputs=model_output2)\n",
        "model_dict[2] = m2\n",
        "\n",
        "model_output3 = class_3.get_layer(layer_name_list[3]).output\n",
        "m3 = Model(inputs=class_3.input, outputs=model_output3)\n",
        "model_dict[3] = m3\n",
        "\n",
        "model_output4 = class_4.get_layer(layer_name_list[4]).output\n",
        "m4 = Model(inputs=class_4.input, outputs=model_output4)\n",
        "model_dict[4] = m4\n",
        "\n",
        "model_output5 = class_5.get_layer(layer_name_list[5]).output\n",
        "m5 = Model(inputs=class_5.input, outputs=model_output5)\n",
        "model_dict[5] = m5\n",
        "\n",
        "model_output6 = class_6.get_layer(layer_name_list[6]).output\n",
        "m6 = Model(inputs=class_6.input, outputs=model_output6)\n",
        "model_dict[6] = m6\n",
        "\n",
        "model_output7 = class_7.get_layer(layer_name_list[7]).output\n",
        "m7 = Model(inputs=class_7.input, outputs=model_output7)\n",
        "model_dict[7] = m7\n",
        "\n",
        "model_output8 = class_8.get_layer(layer_name_list[8]).output\n",
        "m8 = Model(inputs=class_8.input, outputs=model_output8)\n",
        "model_dict[8] = m8\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H0XshJlAS6wf",
        "outputId": "0e3f7932-b136-4113-a65e-f2c36f495887"
      },
      "source": [
        "temp_val = []\n",
        "y_pred = []\n",
        "labels = set(new_val_labels)\n",
        "for i, lo in zip(range(9), labels):\n",
        "  m = model_dict[i]\n",
        "  val_imgs_, val_lbls_ = get_train_data(lo, new_val_images, new_val_labels)\n",
        "  y_p = m.predict(val_imgs_)\n",
        "  y_pred.append(y_p)\n",
        "  temp = temp_cal(y_p, val_lbls_)\n",
        "  temp_val.append(temp)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{2: 0, 3: 1, 4: 2, 5: 3, 6: 4, 7: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9503,)\n",
            "Temperature Initial value: 1.0\n",
            "Temperature Final value: 2.06091570854187\n",
            "{0: 0, 3: 1, 4: 2, 5: 3, 6: 4, 7: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9504,)\n",
            "Temperature Initial value: 1.0\n",
            "Temperature Final value: 2.3180222511291504\n",
            "{0: 0, 2: 1, 4: 2, 5: 3, 6: 4, 7: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9459,)\n",
            "Temperature Initial value: 1.0\n",
            "Temperature Final value: 2.2263615131378174\n",
            "{0: 0, 2: 1, 3: 2, 5: 3, 6: 4, 7: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9502,)\n",
            "Temperature Initial value: 1.0\n",
            "Temperature Final value: 2.51077938079834\n",
            "{0: 0, 2: 1, 3: 2, 4: 3, 6: 4, 7: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9574,)\n",
            "Temperature Initial value: 1.0\n",
            "Temperature Final value: 2.166799545288086\n",
            "{0: 0, 2: 1, 3: 2, 4: 3, 5: 4, 7: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9501,)\n",
            "Temperature Initial value: 1.0\n",
            "Temperature Final value: 2.330876111984253\n",
            "{0: 0, 2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9379,)\n",
            "Temperature Initial value: 1.0\n",
            "Temperature Final value: 1.9582384824752808\n",
            "{0: 0, 2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9518,)\n",
            "Temperature Initial value: 1.0\n",
            "Temperature Final value: 2.149815559387207\n",
            "{0: 0, 2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, 8: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9484,)\n",
            "Temperature Initial value: 1.0\n",
            "Temperature Final value: 2.477947950363159\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "odKS3QeAS6wl",
        "outputId": "3462651c-2986-4a47-e2cc-1ebb3ae080b4"
      },
      "source": [
        "temp_val"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=2.0609157>,\n",
              " <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=2.3180223>,\n",
              " <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=2.2263615>,\n",
              " <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=2.5107794>,\n",
              " <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=2.1667995>,\n",
              " <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=2.330876>,\n",
              " <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=1.9582385>,\n",
              " <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=2.1498156>,\n",
              " <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=2.477948>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8wYDS561dO_D"
      },
      "source": [
        "temp_val = [2.0609157, 2.3180223, 2.2263615, 2.5107794, 2.1667995, 2.330876, 1.9582385, 2.1498156, 2.477948]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WzJIrq-9S6wn",
        "outputId": "24a25a6f-7cc0-4446-ff49-35a537bca90b"
      },
      "source": [
        "from tqdm import tqdm\n",
        "avg = [0,0,0,0,0,0,0,0,0]\n",
        "count = [0,0,0,0,0,0,0,0,0]\n",
        "entropy_list = [0,0,0,0,0,0,0,0,0]\n",
        "for img, lbl in tqdm(zip(new_val_images,new_val_labels)):\n",
        "  img = img.reshape([-1, 28, 28, 1])\n",
        "  if not lbl == 0:\n",
        "    logits = model_dict[0](img)\n",
        "    logits = tf.math.divide(logits, temp_val[0])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e0 = entropy(pred[0])\n",
        "    entropy_list[0] = entropy_list[0] + e0\n",
        "    max_val0 = np.max(pred)\n",
        "    avg[0] = avg[0] + max_val0\n",
        "    count[0] = count[0] + 1\n",
        "  if not lbl == 2:\n",
        "    logits = model_dict[1](img)\n",
        "    logits = tf.math.divide(logits, temp_val[1])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e1 = entropy(pred[0])\n",
        "    entropy_list[1] = entropy_list[1] + e1\n",
        "    max_val1 = np.max(pred)\n",
        "    avg[1] = avg[1] + max_val1\n",
        "    count[1] = count[1] + 1\n",
        "  if not lbl == 3:\n",
        "    logits = model_dict[2](img)\n",
        "    logits = tf.math.divide(logits, temp_val[2])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e2 = entropy(pred[0])\n",
        "    entropy_list[2] = entropy_list[2] + e2\n",
        "    max_val2 = np.max(pred)\n",
        "    avg[2] = avg[2] + max_val2\n",
        "    count[2] = count[2] + 1\n",
        "  if not lbl == 4:\n",
        "    logits = model_dict[3](img)\n",
        "    logits = tf.math.divide(logits, temp_val[3])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e3 = entropy(pred[0])\n",
        "    entropy_list[3] = entropy_list[3] + e3\n",
        "    max_val3 = np.max(pred)  \n",
        "    avg[3] = avg[3] + max_val3\n",
        "    count[3] = count[3] + 1\n",
        "  if not lbl == 5:\n",
        "    logits = model_dict[4](img)\n",
        "    logits = tf.math.divide(logits, temp_val[4])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e4 = entropy(pred[0])\n",
        "    entropy_list[4] = entropy_list[4] + e4\n",
        "    max_val4 = np.max(pred)\n",
        "    avg[4] = avg[4] + max_val4\n",
        "    count[4] = count[4] + 1\n",
        "  if not lbl == 6:\n",
        "    logits = model_dict[5](img)\n",
        "    logits = tf.math.divide(logits, temp_val[5])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e5 = entropy(pred[0])\n",
        "    entropy_list[5] = entropy_list[5] + e5\n",
        "    max_val5 = np.max(pred)\n",
        "    avg[5] = avg[5] + max_val5\n",
        "    count[5] = count[5] + 1\n",
        "  if not lbl == 7:\n",
        "    logits = model_dict[6](img)\n",
        "    logits = tf.math.divide(logits, temp_val[6])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e6 = entropy(pred[0])\n",
        "    entropy_list[6] = entropy_list[6] + e6\n",
        "    max_val6 = np.max(pred)\n",
        "    avg[6] = avg[6] + max_val6\n",
        "    count[6] = count[6] + 1\n",
        "  if not lbl == 8:\n",
        "    logits = model_dict[7](img)\n",
        "    logits = tf.math.divide(logits, temp_val[7])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e7 = entropy(pred[0])\n",
        "    entropy_list[7] = entropy_list[7] + e7\n",
        "    max_val7 = np.max(pred)\n",
        "    avg[7] = avg[7] + max_val7\n",
        "    count[7] = count[7] + 1\n",
        "  if not lbl == 9:\n",
        "    logits = model_dict[8](img)\n",
        "    logits = tf.math.divide(logits, temp_val[8])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e8 = entropy(pred[0])\n",
        "    entropy_list[8] = entropy_list[8] + e8\n",
        "    max_val8 = np.max(pred)\n",
        "    avg[8] = avg[8] + max_val8\n",
        "    count[8] = count[8] + 1\n",
        "\n",
        "print(avg)\n",
        "print(count)\n",
        "print(entropy_list)\n",
        "\n",
        "entropy_avg_t = [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]\n",
        "for i in range(9):\n",
        "  entropy_avg_t[i] = entropy_list[i]/count[i]\n",
        "\n",
        "entropy_value_t = 0.0\n",
        "for i in range(9):\n",
        "  entropy_value_t = entropy_value_t + entropy_avg_t[i]\n",
        "\n",
        "entropy_t = entropy_value_t/len(entropy_avg_t)\n",
        "\n",
        "print('Entropy:', entropy_t)\n",
        "\n",
        "classifier_avg_t = [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]\n",
        "for i in range(9):\n",
        "  classifier_avg_t[i] = avg[i]/count[i]\n",
        "\n",
        "print('Each Classifier Average: ',classifier_avg_t)\n",
        "\n",
        "treshold_value = 0.0\n",
        "for i in range(9):\n",
        "  treshold_value = treshold_value + classifier_avg_t[i]\n",
        "\n",
        "treshold_t = treshold_value/len(classifier_avg_t)\n",
        "\n",
        "print('Threshold:', treshold_t)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10678it [12:39, 14.06it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[9347.98394420743, 9278.456224650145, 9234.90728765726, 9345.79588869214, 9441.71300148964, 9293.35782277584, 9240.628234177828, 9357.519878834486, 9342.639295220375]\n",
            "[9503, 9504, 9459, 9502, 9574, 9501, 9379, 9518, 9484]\n",
            "[496.24585637980846, 682.8849439422588, 687.3766117310041, 461.4241289756502, 409.26674899533475, 629.3891915531387, 442.9177857183027, 493.7653927540591, 417.6592559437346]\n",
            "Entropy: 0.05527045100628685\n",
            "Each Classifier Average:  [0.9836876717044544, 0.9762685421559496, 0.9763090482775411, 0.9835609228259462, 0.9861826824200585, 0.9781452292154342, 0.98524663974601, 0.9831393022519948, 0.9850948223555858]\n",
            "Threshold: 0.981959428994775\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lRUpHZcbS6wr",
        "outputId": "f2db98fb-c594-4d19-8167-cd941d4c4543"
      },
      "source": [
        "ref_vect_in_1an = []\n",
        "ref_vect_in_1an.append(classifier_avg_t)\n",
        "\n",
        "threshold_in_1an = []\n",
        "threshold_in_1an.append(treshold_t)\n",
        "\n",
        "entropy_in_1an = []\n",
        "entropy_in_1an.append(entropy_t)\n",
        "\n",
        "print(entropy_in_1an)\n",
        "print(ref_vect_in_1an)\n",
        "print(threshold_in_1an)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.05527045100628685]\n",
            "[[0.9836876717044544, 0.9762685421559496, 0.9763090482775411, 0.9835609228259462, 0.9861826824200585, 0.9781452292154342, 0.98524663974601, 0.9831393022519948, 0.9850948223555858]]\n",
            "[0.981959428994775]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rV0ptxwUdcxi"
      },
      "source": [
        "entropy_in_1an = [0.05527045100628685]\n",
        "ref_vect_in_1an = [[0.9836876717044544, 0.9762685421559496, 0.9763090482775411, 0.9835609228259462, 0.9861826824200585, 0.9781452292154342, 0.98524663974601, 0.9831393022519948, 0.9850948223555858]]\n",
        "threshold_in_1an = [0.981959428994775]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qn9QfdNsS6wt",
        "outputId": "72a9b8cc-7f07-441a-f107-7a8ac11367d8"
      },
      "source": [
        "from tqdm import tqdm\n",
        "avg = [0,0,0,0,0,0,0,0,0]\n",
        "count = [0,0,0,0,0,0,0,0,0]\n",
        "entropy_list = [0,0,0,0,0,0,0,0,0]\n",
        "\n",
        "for img, lbl in tqdm(zip(new_val_images,new_val_labels)):\n",
        "  img = img.reshape([-1, 28, 28, 1])\n",
        "  if lbl == 0:\n",
        "    logits = model_dict[0](img)\n",
        "    logits = tf.math.divide(logits, temp_val[0])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e0 = entropy(pred[0])\n",
        "    entropy_list[0] = entropy_list[0] + e0\n",
        "    max_val0 = np.max(pred)\n",
        "    avg[0] = avg[0] + max_val0\n",
        "    count[0] = count[0] + 1\n",
        "  if lbl == 2:\n",
        "    logits = model_dict[1](img)\n",
        "    logits = tf.math.divide(logits, temp_val[1])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e1 = entropy(pred[0])\n",
        "    entropy_list[1] = entropy_list[1] + e1\n",
        "    max_val1 = np.max(pred)\n",
        "    avg[1] = avg[1] + max_val1\n",
        "    count[1] = count[1] + 1\n",
        "  if lbl == 3:\n",
        "    logits = model_dict[2](img)\n",
        "    logits = tf.math.divide(logits, temp_val[2])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e2 = entropy(pred[0])\n",
        "    entropy_list[2] = entropy_list[2] + e2\n",
        "    max_val2 = np.max(pred)\n",
        "    avg[2] = avg[2] + max_val2\n",
        "    count[2] = count[2] + 1\n",
        "  if lbl == 4:\n",
        "    logits = model_dict[3](img)\n",
        "    logits = tf.math.divide(logits, temp_val[3])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e3 = entropy(pred[0])\n",
        "    entropy_list[3] = entropy_list[3] + e3\n",
        "    max_val3 = np.max(pred)  \n",
        "    avg[3] = avg[3] + max_val3\n",
        "    count[3] = count[3] + 1\n",
        "  if lbl == 5:\n",
        "    logits = model_dict[4](img)\n",
        "    logits = tf.math.divide(logits, temp_val[4])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e4 = entropy(pred[0])\n",
        "    entropy_list[4] = entropy_list[4] + e4\n",
        "    max_val4 = np.max(pred)\n",
        "    avg[4] = avg[4] + max_val4\n",
        "    count[4] = count[4] + 1\n",
        "  if lbl == 6:\n",
        "    logits = model_dict[5](img)\n",
        "    logits = tf.math.divide(logits, temp_val[5])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e5 = entropy(pred[0])\n",
        "    entropy_list[5] = entropy_list[5] + e5\n",
        "    max_val5 = np.max(pred)\n",
        "    avg[5] = avg[5] + max_val5\n",
        "    count[5] = count[5] + 1\n",
        "  if lbl == 7:\n",
        "    logits = model_dict[6](img)\n",
        "    logits = tf.math.divide(logits, temp_val[6])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e6 = entropy(pred[0])\n",
        "    entropy_list[6] = entropy_list[6] + e6\n",
        "    max_val6 = np.max(pred)\n",
        "    avg[6] = avg[6] + max_val6\n",
        "    count[6] = count[6] + 1\n",
        "  if lbl == 8:\n",
        "    logits = model_dict[7](img)\n",
        "    logits = tf.math.divide(logits, temp_val[7])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e7 = entropy(pred[0])\n",
        "    entropy_list[7] = entropy_list[7] + e7\n",
        "    max_val7 = np.max(pred)\n",
        "    avg[7] = avg[7] + max_val7\n",
        "    count[7] = count[7] + 1\n",
        "  if lbl == 9:\n",
        "    logits = model_dict[8](img)\n",
        "    logits = tf.math.divide(logits, temp_val[8])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e8 = entropy(pred[0])\n",
        "    entropy_list[8] = entropy_list[8] + e8\n",
        "    max_val8 = np.max(pred)\n",
        "    avg[8] = avg[8] + max_val8\n",
        "    count[8] = count[8] + 1\n",
        "\n",
        "print(avg)\n",
        "print(count)\n",
        "print(entropy_list)\n",
        "\n",
        "entropy_avg_t = [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]\n",
        "for i in range(9):\n",
        "  entropy_avg_t[i] = entropy_list[i]/count[i]\n",
        "\n",
        "entropy_value_t = 0.0\n",
        "for i in range(9):\n",
        "  entropy_value_t = entropy_value_t + entropy_avg_t[i]\n",
        "\n",
        "entropy_t = entropy_value_t/len(entropy_avg_t)\n",
        "\n",
        "print('Entropy:', entropy_t)\n",
        "\n",
        "classifier_avg_t = [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]\n",
        "for i in range(9):\n",
        "  classifier_avg_t[i] = avg[i]/count[i]\n",
        "\n",
        "print('Each Classifier Average: ',classifier_avg_t)\n",
        "\n",
        "treshold_value = 0.0\n",
        "for i in range(9):\n",
        "  treshold_value = treshold_value + classifier_avg_t[i]\n",
        "\n",
        "treshold_t = treshold_value/len(classifier_avg_t)\n",
        "\n",
        "print('Threshold:', treshold_t)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10678it [01:34, 112.98it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[941.3688916862011, 915.7900085449219, 970.7751380354166, 1043.6230748593807, 865.9130089879036, 893.5144730508327, 1028.0956514179707, 886.7211111187935, 1091.8376369774342]\n",
            "[1175, 1174, 1219, 1176, 1104, 1177, 1299, 1160, 1194]\n",
            "[592.6858783224889, 687.8466444238438, 658.8614348977835, 354.9468186097744, 621.0151225871814, 727.5807700690093, 741.4647662199568, 729.2438900739653, 280.5161680721851]\n",
            "Entropy: 0.5053005462416496\n",
            "Each Classifier Average:  [0.8011650142010223, 0.7800596324914155, 0.7963700886262647, 0.8874345874654598, 0.7843414936484634, 0.7591456865342674, 0.7914516177197619, 0.7644147509644772, 0.9144368818906484]\n",
            "Threshold: 0.8087577503935313\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nUdcRwQNS6w5",
        "outputId": "fef559d1-dc0c-4b0b-c897-27bf22318847"
      },
      "source": [
        "ref_vect_out_1an = []\n",
        "ref_vect_out_1an.append(classifier_avg_t)\n",
        "\n",
        "threshold_out_1an = []\n",
        "threshold_out_1an.append(treshold_t)\n",
        "\n",
        "entropy_out_1an = []\n",
        "entropy_out_1an.append(entropy_t)\n",
        "\n",
        "print(entropy_out_1an)\n",
        "print(ref_vect_out_1an)\n",
        "print(threshold_out_1an)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.5053005462416496]\n",
            "[[0.8011650142010223, 0.7800596324914155, 0.7963700886262647, 0.8874345874654598, 0.7843414936484634, 0.7591456865342674, 0.7914516177197619, 0.7644147509644772, 0.9144368818906484]]\n",
            "[0.8087577503935313]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fAeoI0dIdtaT"
      },
      "source": [
        "entropy_out_1an = [0.5053005462416496]\n",
        "ref_vect_out_1an = [[0.8011650142010223, 0.7800596324914155, 0.7963700886262647, 0.8874345874654598, 0.7843414936484634, 0.7591456865342674, 0.7914516177197619, 0.7644147509644772, 0.9144368818906484]]\n",
        "threshold_out_1an = [0.8087577503935313]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "waqaVD2VS6xE"
      },
      "source": [
        "def get_max_pred_value(model, img, temp):\n",
        "  logits = model(img)\n",
        "  logits = tf.math.divide(logits, temp)\n",
        "  pred = tf.nn.softmax(logits)\n",
        "  e = entropy(pred[0])\n",
        "\n",
        "  return np.max(pred), tf.argmax(pred[0]).numpy(), e"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Y3zHxkfS6xG",
        "outputId": "1d009dbe-3755-48ae-9371-396190edd041"
      },
      "source": [
        "set(train_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whjOHAlbS6xH"
      },
      "source": [
        "def get_mapping(leave_out_class, anomaly_class):\n",
        "  mapping = {}\n",
        "\n",
        "  labels = set(train_labels)\n",
        "  labels.remove(anomaly_class)\n",
        "  labels.remove(leave_out_class)\n",
        "  labels = sorted(labels)\n",
        "\n",
        "  for i,j in enumerate(labels):\n",
        "    mapping[i] = j\n",
        "\n",
        "  return mapping\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwD8LlepS6xI"
      },
      "source": [
        "ood = 0\n",
        "ind = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wOnN0afpS6xJ",
        "outputId": "4273647a-0c04-4903-d4f2-a17765da255f"
      },
      "source": [
        "max_sm_all_wt_1an = []\n",
        "for data, label in tqdm(zip(test_imgs, test_lbls)):\n",
        "  img = data.reshape([-1, 28, 28, 1])\n",
        "  ref_value = []\n",
        "  \n",
        "  if label == 1:\n",
        "    lbl = ood\n",
        "  else:\n",
        "    lbl = ind\n",
        "\n",
        "\n",
        "  max0, pred_0, e0 = get_max_pred_value(model_dict[0], img, temp=temp_val[0])\n",
        "  map0 = get_mapping(0, 1)\n",
        "  pred_0 = map0[pred_0]\n",
        "\n",
        "  max1, pred_1, e1 = get_max_pred_value(model_dict[1], img, temp=temp_val[1])\n",
        "  map1 = get_mapping(2, 1)\n",
        "  pred_1 = map1[pred_1]\n",
        "\n",
        "  max2, pred_2, e2 = get_max_pred_value(model_dict[2], img, temp=temp_val[2])\n",
        "  map2 = get_mapping(3, 1)\n",
        "  pred_2 = map2[pred_2]\n",
        "\n",
        "  max3, pred_3, e3 = get_max_pred_value(model_dict[3], img, temp=temp_val[3])\n",
        "  map3 = get_mapping(4, 1)\n",
        "  pred_3 = map3[pred_3]\n",
        "\n",
        "  max4, pred_4, e4 = get_max_pred_value(model_dict[4], img, temp=temp_val[4])\n",
        "  map4 = get_mapping(5, 1)\n",
        "  pred_4 = map4[pred_4]\n",
        "\n",
        "  max5, pred_5, e5 = get_max_pred_value(model_dict[5], img, temp=temp_val[5])\n",
        "  map5 = get_mapping(6, 1)\n",
        "  pred_5 = map5[pred_5]\n",
        "\n",
        "  max6, pred_6, e6 = get_max_pred_value(model_dict[6], img, temp=temp_val[6])\n",
        "  map6 = get_mapping(7, 1)\n",
        "  pred_6 = map6[pred_6]\n",
        "\n",
        "  max7, pred_7, e7 = get_max_pred_value(model_dict[7], img, temp=temp_val[7])\n",
        "  map7 = get_mapping(8, 1)\n",
        "  pred_7 = map7[pred_7]\n",
        "\n",
        "  max8, pred_8, e8 = get_max_pred_value(model_dict[8], img, temp=temp_val[8])\n",
        "  map8 = get_mapping(9, 1)\n",
        "  pred_8 = map8[pred_8]\n",
        "\n",
        "  ref_value =[max0, max1, max2, max3, max4, max5, max6, max7, max8]\n",
        "  pred_value = [pred_0, pred_1, pred_2, pred_3, pred_4, pred_5, pred_6, pred_7, pred_8]\n",
        "  e_value = [e0, e1, e2, e3, e4, e5, e6, e7, e8]\n",
        "  e_ = 0.0\n",
        "  for  e in e_value:\n",
        "    e_ = e_ + e\n",
        "  e_ = e_/len(e_value)\n",
        "  max_sm_all_wt_1an.append([ref_value, lbl, pred_value, label, e_])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000it [20:53,  7.98it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8nABxfKKS6xK"
      },
      "source": [
        "pickle_out = open(\"sm_all_wt_1an.pickle\",\"wb\")\n",
        "pickle.dump(max_sm_all_wt_1an, pickle_out)\n",
        "pickle_out.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNRNhAmdS6xL"
      },
      "source": [
        "pickle_in = open(\"sm_all_wt_1an.pickle\",\"rb\")\n",
        "max_sm_all_wt_1an = pickle.load(pickle_in)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o6EyxtMMeAvZ",
        "outputId": "514ab608-5aa1-49fb-ec4c-68e879981320"
      },
      "source": [
        "for data, lbl, p, a_l, e_ in max_sm_all_wt_1an:\n",
        "  print(p, lbl, a_l)\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[7, 7, 7, 7, 7, 7, 9, 7, 7] 1 7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EdKK_XgtS6xM",
        "outputId": "3b91cc2a-f482-4591-bd4e-2a9eb49a4733"
      },
      "source": [
        "accuracy = 0.0\n",
        "count_in = 0\n",
        "count_ood = 0\n",
        "acc_in = 0.0\n",
        "acc_ood = 0.0\n",
        "tp = 0.0\n",
        "tn = 0.0\n",
        "fp = 0.0\n",
        "fn = 0.0\n",
        "y_true = []\n",
        "y_pred = []\n",
        "sim_score = []\n",
        "sim_score_ = []\n",
        "\n",
        "for data, lbl, p, a_l, e_ in max_sm_all_wt_1an:\n",
        "\n",
        "  score = 0.0\n",
        "  for d in data:\n",
        "    score = score + d\n",
        "  score = score / len(data)\n",
        "  sim_score.append(score)\n",
        "\n",
        "  dist_ood = np.linalg.norm(np.array(data) - np.array(ref_vect_out_1an[0])) \n",
        "  dist_in = np.linalg.norm(np.array(data) - np.array(ref_vect_in_1an[0]))\n",
        "\n",
        "  dist_ood2 = np.linalg.norm(np.array(e_) - np.array(entropy_out_1an[0])) \n",
        "  dist_in2 = np.linalg.norm(np.array(e_) - np.array(entropy_in_1an[0]))\n",
        "\n",
        "  dist_in = dist_in / (dist_in + dist_ood)\n",
        "  dist_ood = dist_ood / (dist_in + dist_ood)\n",
        "\n",
        "  dist_in2 = dist_in2 / (dist_in2 + dist_ood2)\n",
        "  dist_ood2 = dist_ood2 / (dist_in2 + dist_ood2)\n",
        "\n",
        "  sim_in = 1 / (1 + dist_in)\n",
        "  sim_ood = 1 / (1 + dist_ood)\n",
        "\n",
        "  sim_in2 = 1 / (1 + dist_in2)\n",
        "  sim_ood2 = 1 / (1 + dist_ood2)\n",
        "\n",
        "  sim_in = sim_in + sim_in2\n",
        "  sim_ood = sim_ood + sim_ood2\n",
        "\n",
        "  sim_score_.append(sim_ood2)\n",
        "\n",
        "  values, counts = np.unique(p, return_counts=True)\n",
        "#  print(values, counts)\n",
        "  #print(sim_in, sim_ood, lbl, e_)\n",
        "\n",
        "  if sim_in >= sim_ood:\n",
        "    y_ = ind    \n",
        "    if np.max(counts) >= 8:\n",
        "      y_ = ind\n",
        "    else:\n",
        "      y_ = ood\n",
        "  else:\n",
        "    y_ = ood\n",
        "\n",
        "\n",
        "  y_pred.append(y_)\n",
        "  if lbl == 1:\n",
        "    y_true.append(0)\n",
        "  else:\n",
        "    y_true.append(1)\n",
        "#  y_true.append(lbl)\n",
        "\n",
        "\n",
        "  if lbl == ind:\n",
        "    count_in = count_in + 1\n",
        "  else:\n",
        "    count_ood = count_ood + 1\n",
        "\n",
        "  if y_ == lbl:\n",
        "    #sim_score_.append(1)\n",
        "    accuracy = accuracy + 1\n",
        "    if y_ == ind:\n",
        "      acc_in = acc_in + 1\n",
        "      tp = tp + 1\n",
        "    else:\n",
        "      acc_ood = acc_ood + 1\n",
        "      tn = tn + 1\n",
        "  else:\n",
        "    #sim_score_.append(0)\n",
        "    if y_ == ind:\n",
        "      fp = fp + 1\n",
        "    else:\n",
        "      fn = fn + 1\n",
        "\n",
        "\n",
        "print(\"Total Accuracy: \", accuracy/len(max_sm_all_wt_1an)) \n",
        "print(\"Accuracy of determining ID data: \", acc_in/count_in)\n",
        "print(\"Accuracy of determining OOD data: \", acc_ood/count_ood)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Accuracy:  0.9159\n",
            "Accuracy of determining ID data:  0.9054709531866892\n",
            "Accuracy of determining OOD data:  0.9973568281938326\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D56ebTtkS6xN",
        "outputId": "2e0efff7-188d-4de7-966d-beeb5c15b3c0"
      },
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "roc_auc_score(y_true, sim_score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9949769300148334"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 159
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1LBx6-YQS6xO",
        "outputId": "4a505cf3-730d-4e04-abf0-dbc62d81d262"
      },
      "source": [
        "roc_auc_score(y_true, y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.951413890690261"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wBBAo_MFS6xS",
        "outputId": "554131e6-663d-43ef-e79f-3ec4bd6dfedf"
      },
      "source": [
        "roc_auc_score(y_true, sim_score_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9425150135040785"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 179
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qvifv7oeAlB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sH89EaIVf6_J"
      },
      "source": [
        "# 2 as anomaly"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHA_uN2uf95A"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulGTYczqgbfn"
      },
      "source": [
        "new_train_images, new_train_labels, new_val_images, new_val_labels = separate_class(2, train_images, train_labels, val_images, val_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XlUnp0Ulgbft"
      },
      "source": [
        "model0 = Model(name='2anomaly:classifier0')\n",
        "model1 = Model(name='2anomaly:classifier1')\n",
        "model2 = Model(name='2anomaly:classifier2')\n",
        "model3 = Model(name='2anomaly:classifier3')\n",
        "model4 = Model(name='2anomaly:classifier4')\n",
        "model5 = Model(name='2anomaly:classifier5')\n",
        "model6 = Model(name='2anomaly:classifier6')\n",
        "model7 = Model(name='2anomaly:classifier7')\n",
        "model8 = Model(name='2anomaly:classifier8')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IyjEKM-1gbfv"
      },
      "source": [
        "class_0 = model0.build()\n",
        "class_1 = model1.build()\n",
        "class_2 = model2.build()\n",
        "class_3 = model3.build()\n",
        "class_4 = model4.build()\n",
        "class_5 = model5.build()\n",
        "class_6 = model6.build()\n",
        "class_7 = model7.build()\n",
        "class_8 = model8.build()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kkm7CHZKgbfw",
        "outputId": "fe927201-e67c-4d3d-8991-efffb390ac80"
      },
      "source": [
        "train_imgs0, train_lbls0 = get_train_data(0, new_train_images, new_train_labels)\n",
        "val_imgs0, val_lbls0 = get_train_data(0, new_val_images, new_val_labels)\n",
        "class_0 = model0.build()\n",
        "model0.train2(train_imgs0, train_lbls0, val_imgs0, val_lbls0)\n",
        "#model0.train(train_data0)\n",
        "model0.save_model(\"final_models/2anomaly-classifier0\")\n",
        "print('Model 0 saved')\n",
        "\n",
        "train_imgs1, train_lbls1 = get_train_data(1, new_train_images, new_train_labels)\n",
        "val_imgs1, val_lbls1 = get_train_data(1, new_val_images, new_val_labels)\n",
        "class_1 = model1.build()\n",
        "model1.train2(train_imgs1, train_lbls1, val_imgs1, val_lbls1)\n",
        "#model1.train(train_data1)\n",
        "model1.save_model(\"final_models/2anomaly-classifier1\")\n",
        "print('Model 1 saved')\n",
        "\n",
        "#train_data2 = get_train_data(2, new_train_images)\n",
        "train_imgs2, train_lbls2 = get_train_data(3, new_train_images, new_train_labels)\n",
        "val_imgs2, val_lbls2 = get_train_data(3, new_val_images, new_val_labels)\n",
        "class_2 = model2.build()\n",
        "model2.train2(train_imgs2, train_lbls2, val_imgs2, val_lbls2)\n",
        "#model2.train(train_data2)\n",
        "model2.save_model(\"final_models/2anomaly-classifier2\")\n",
        "print('Model 2 saved')\n",
        "\n",
        "#train_data3 = get_train_data(3, new_train_images)\n",
        "train_imgs3, train_lbls3 = get_train_data(4, new_train_images, new_train_labels)\n",
        "val_imgs3, val_lbls3 = get_train_data(4, new_val_images, new_val_labels)\n",
        "class_3 = model3.build()\n",
        "model3.train2(train_imgs3, train_lbls3, val_imgs3, val_lbls3)\n",
        "#model3.train(train_data3)\n",
        "model3.save_model(\"final_models/2anomaly-classifier3\")\n",
        "print('Model 3 saved')\n",
        "\n",
        "#train_data4 = get_train_data(4, new_train_images)\n",
        "train_imgs4, train_lbls4 = get_train_data(5, new_train_images, new_train_labels)\n",
        "val_imgs4, val_lbls4 = get_train_data(5, new_val_images, new_val_labels)\n",
        "class_4 = model4.build()\n",
        "model4.train2(train_imgs4, train_lbls4, val_imgs4, val_lbls4)\n",
        "#model4.train(train_data4)\n",
        "model4.save_model(\"final_models/2anomaly-classifier4\")\n",
        "print('Model 4 saved')\n",
        "\n",
        "#train_data5 = get_train_data(5, new_train_images)\n",
        "train_imgs5, train_lbls5 = get_train_data(6, new_train_images, new_train_labels)\n",
        "val_imgs5, val_lbls5 = get_train_data(6, new_val_images, new_val_labels)\n",
        "class_5 = model5.build()\n",
        "model5.train2(train_imgs5, train_lbls5, val_imgs5, val_lbls5)\n",
        "#model5.train(train_data5)\n",
        "model5.save_model(\"final_models/2anomaly-classifier5\")\n",
        "print('Model 5 saved')\n",
        "\n",
        "#train_data6 = get_train_data(6, new_train_images)\n",
        "train_imgs6, train_lbls6 = get_train_data(7, new_train_images, new_train_labels)\n",
        "val_imgs6, val_lbls6 = get_train_data(7, new_val_images, new_val_labels)\n",
        "class_6 = model6.build()\n",
        "model6.train2(train_imgs6, train_lbls6, val_imgs6, val_lbls6)\n",
        "#model6.train(train_data6)\n",
        "model6.save_model(\"final_models/2anomaly-classifier6\")\n",
        "print('Model 6 saved')\n",
        "\n",
        "#train_data7 = get_train_data(7, new_train_images)\n",
        "train_imgs7, train_lbls7 = get_train_data(8, new_train_images, new_train_labels)\n",
        "val_imgs7, val_lbls7 = get_train_data(8, new_val_images, new_val_labels)\n",
        "class_7 = model7.build()\n",
        "#model7.train(train_data7)\n",
        "model7.train2(train_imgs7, train_lbls7, val_imgs7, val_lbls7)\n",
        "model7.save_model(\"final_models/2anomaly-classifier7\")\n",
        "print('Model 7 saved')\n",
        "\n",
        "#train_data8 = get_train_data(8, new_train_images)\n",
        "train_imgs8, train_lbls8 = get_train_data(9, new_train_images, new_train_labels)\n",
        "val_imgs8, val_lbls8 = get_train_data(9, new_val_images, new_val_labels)\n",
        "class_8 = model8.build()\n",
        "#model8.train(train_data8)\n",
        "model8.train2(train_imgs8, train_lbls8, val_imgs8, val_lbls8)\n",
        "model8.save_model(\"final_models/2anomaly-classifier8\")\n",
        "print('Model 8 saved')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{1: 0, 3: 1, 4: 2, 5: 3, 6: 4, 7: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(38468,)\n",
            "{1: 0, 3: 1, 4: 2, 5: 3, 6: 4, 7: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9651,)\n",
            "Epoch 1/20\n",
            "1203/1203 [==============================] - 39s 32ms/step - loss: 5.3457 - accuracy: 0.8408 - val_loss: 0.2821 - val_accuracy: 0.9575\n",
            "Epoch 2/20\n",
            "1203/1203 [==============================] - 38s 31ms/step - loss: 0.1390 - accuracy: 0.9737 - val_loss: 0.1374 - val_accuracy: 0.9702\n",
            "Epoch 3/20\n",
            "1203/1203 [==============================] - 38s 31ms/step - loss: 0.0704 - accuracy: 0.9810 - val_loss: 0.0665 - val_accuracy: 0.9810\n",
            "Epoch 4/20\n",
            "1203/1203 [==============================] - 38s 31ms/step - loss: 0.0636 - accuracy: 0.9808 - val_loss: 0.1759 - val_accuracy: 0.9483\n",
            "Epoch 5/20\n",
            "1203/1203 [==============================] - 38s 31ms/step - loss: 0.0542 - accuracy: 0.9824 - val_loss: 0.1057 - val_accuracy: 0.9712\n",
            "Epoch 6/20\n",
            "1203/1203 [==============================] - 38s 31ms/step - loss: 0.0493 - accuracy: 0.9847 - val_loss: 0.0794 - val_accuracy: 0.9783\n",
            "Epoch 7/20\n",
            "1203/1203 [==============================] - 37s 31ms/step - loss: 0.0459 - accuracy: 0.9854 - val_loss: 0.0989 - val_accuracy: 0.9715\n",
            "Epoch 8/20\n",
            "1203/1203 [==============================] - 38s 31ms/step - loss: 0.0476 - accuracy: 0.9849 - val_loss: 0.0844 - val_accuracy: 0.9747\n",
            "Epoch 9/20\n",
            "1203/1203 [==============================] - 37s 31ms/step - loss: 0.0363 - accuracy: 0.9889 - val_loss: 0.0701 - val_accuracy: 0.9804\n",
            "Epoch 10/20\n",
            "1203/1203 [==============================] - 38s 31ms/step - loss: 0.0343 - accuracy: 0.9892 - val_loss: 0.0783 - val_accuracy: 0.9792\n",
            "Epoch 11/20\n",
            "1203/1203 [==============================] - 38s 31ms/step - loss: 0.0342 - accuracy: 0.9887 - val_loss: 0.0668 - val_accuracy: 0.9836\n",
            "Epoch 12/20\n",
            "1203/1203 [==============================] - 38s 31ms/step - loss: 0.0288 - accuracy: 0.9914 - val_loss: 0.1465 - val_accuracy: 0.9669\n",
            "Epoch 13/20\n",
            "1203/1203 [==============================] - 38s 31ms/step - loss: 0.0276 - accuracy: 0.9911 - val_loss: 0.0796 - val_accuracy: 0.9803\n",
            "Epoch 14/20\n",
            "1203/1203 [==============================] - 38s 31ms/step - loss: 0.0251 - accuracy: 0.9919 - val_loss: 0.0822 - val_accuracy: 0.9800\n",
            "Epoch 15/20\n",
            "1203/1203 [==============================] - 38s 31ms/step - loss: 0.0247 - accuracy: 0.9923 - val_loss: 0.0729 - val_accuracy: 0.9843\n",
            "Epoch 16/20\n",
            "1203/1203 [==============================] - 38s 31ms/step - loss: 0.0190 - accuracy: 0.9945 - val_loss: 0.0635 - val_accuracy: 0.9859\n",
            "Epoch 17/20\n",
            "1203/1203 [==============================] - 38s 31ms/step - loss: 0.0207 - accuracy: 0.9936 - val_loss: 0.0695 - val_accuracy: 0.9837\n",
            "Epoch 18/20\n",
            "1203/1203 [==============================] - 38s 31ms/step - loss: 0.0214 - accuracy: 0.9940 - val_loss: 0.0809 - val_accuracy: 0.9836\n",
            "Epoch 19/20\n",
            "1203/1203 [==============================] - 38s 31ms/step - loss: 0.0181 - accuracy: 0.9950 - val_loss: 0.0533 - val_accuracy: 0.9882\n",
            "Epoch 20/20\n",
            "1203/1203 [==============================] - 38s 31ms/step - loss: 0.0169 - accuracy: 0.9942 - val_loss: 0.1348 - val_accuracy: 0.9731\n",
            "INFO:tensorflow:Assets written to: final_models/2anomaly-classifier0/assets\n",
            "Model 0 saved\n",
            "{0: 0, 3: 1, 4: 2, 5: 3, 6: 4, 7: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(37796,)\n",
            "{0: 0, 3: 1, 4: 2, 5: 3, 6: 4, 7: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9504,)\n",
            "Epoch 1/20\n",
            "1182/1182 [==============================] - 38s 31ms/step - loss: 5.8744 - accuracy: 0.7644 - val_loss: 0.4139 - val_accuracy: 0.9469\n",
            "Epoch 2/20\n",
            "1182/1182 [==============================] - 37s 31ms/step - loss: 0.1843 - accuracy: 0.9636 - val_loss: 0.1480 - val_accuracy: 0.9753\n",
            "Epoch 3/20\n",
            "1182/1182 [==============================] - 37s 31ms/step - loss: 0.1373 - accuracy: 0.9697 - val_loss: 0.1372 - val_accuracy: 0.9703\n",
            "Epoch 4/20\n",
            "1182/1182 [==============================] - 37s 31ms/step - loss: 0.0804 - accuracy: 0.9795 - val_loss: 0.1969 - val_accuracy: 0.9589\n",
            "Epoch 5/20\n",
            "1182/1182 [==============================] - 37s 31ms/step - loss: 0.0752 - accuracy: 0.9792 - val_loss: 0.1047 - val_accuracy: 0.9735\n",
            "Epoch 6/20\n",
            "1182/1182 [==============================] - 37s 31ms/step - loss: 0.0580 - accuracy: 0.9840 - val_loss: 0.0763 - val_accuracy: 0.9806\n",
            "Epoch 7/20\n",
            "1182/1182 [==============================] - 37s 31ms/step - loss: 0.0469 - accuracy: 0.9853 - val_loss: 0.1681 - val_accuracy: 0.9649\n",
            "Epoch 8/20\n",
            "1182/1182 [==============================] - 37s 31ms/step - loss: 0.0482 - accuracy: 0.9858 - val_loss: 0.2547 - val_accuracy: 0.9565\n",
            "Epoch 9/20\n",
            "1182/1182 [==============================] - 37s 31ms/step - loss: 0.0413 - accuracy: 0.9871 - val_loss: 0.3378 - val_accuracy: 0.9342\n",
            "Epoch 10/20\n",
            "1182/1182 [==============================] - 37s 31ms/step - loss: 0.0374 - accuracy: 0.9886 - val_loss: 0.0817 - val_accuracy: 0.9784\n",
            "Epoch 11/20\n",
            "1182/1182 [==============================] - 37s 31ms/step - loss: 0.0331 - accuracy: 0.9893 - val_loss: 0.0753 - val_accuracy: 0.9818\n",
            "Epoch 12/20\n",
            "1182/1182 [==============================] - 37s 31ms/step - loss: 0.0274 - accuracy: 0.9915 - val_loss: 0.0392 - val_accuracy: 0.9896\n",
            "Epoch 13/20\n",
            "1182/1182 [==============================] - 37s 32ms/step - loss: 0.0339 - accuracy: 0.9896 - val_loss: 0.0645 - val_accuracy: 0.9842\n",
            "Epoch 14/20\n",
            "1182/1182 [==============================] - 37s 31ms/step - loss: 0.0223 - accuracy: 0.9932 - val_loss: 0.0659 - val_accuracy: 0.9851\n",
            "Epoch 15/20\n",
            "1182/1182 [==============================] - 37s 31ms/step - loss: 0.0245 - accuracy: 0.9925 - val_loss: 0.0651 - val_accuracy: 0.9837\n",
            "Epoch 16/20\n",
            "1182/1182 [==============================] - 37s 31ms/step - loss: 0.0177 - accuracy: 0.9945 - val_loss: 0.0521 - val_accuracy: 0.9872\n",
            "Epoch 17/20\n",
            "1182/1182 [==============================] - 37s 31ms/step - loss: 0.0192 - accuracy: 0.9937 - val_loss: 0.0942 - val_accuracy: 0.9803\n",
            "Epoch 18/20\n",
            "1182/1182 [==============================] - 37s 31ms/step - loss: 0.0176 - accuracy: 0.9940 - val_loss: 0.0472 - val_accuracy: 0.9888\n",
            "Epoch 19/20\n",
            "1182/1182 [==============================] - 37s 31ms/step - loss: 0.0147 - accuracy: 0.9951 - val_loss: 0.0651 - val_accuracy: 0.9854\n",
            "Epoch 20/20\n",
            "1182/1182 [==============================] - 37s 31ms/step - loss: 0.0125 - accuracy: 0.9957 - val_loss: 0.0796 - val_accuracy: 0.9846\n",
            "INFO:tensorflow:Assets written to: final_models/2anomaly-classifier1/assets\n",
            "Model 1 saved\n",
            "{0: 0, 1: 1, 4: 2, 5: 3, 6: 4, 7: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(38304,)\n",
            "{0: 0, 1: 1, 4: 2, 5: 3, 6: 4, 7: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9607,)\n",
            "Epoch 1/20\n",
            "1197/1197 [==============================] - 39s 32ms/step - loss: 5.4775 - accuracy: 0.7819 - val_loss: 0.6817 - val_accuracy: 0.9188\n",
            "Epoch 2/20\n",
            "1197/1197 [==============================] - 37s 31ms/step - loss: 0.1923 - accuracy: 0.9679 - val_loss: 0.1556 - val_accuracy: 0.9635\n",
            "Epoch 3/20\n",
            "1197/1197 [==============================] - 37s 31ms/step - loss: 0.0813 - accuracy: 0.9796 - val_loss: 0.3319 - val_accuracy: 0.9352\n",
            "Epoch 4/20\n",
            "1197/1197 [==============================] - 37s 31ms/step - loss: 0.0683 - accuracy: 0.9805 - val_loss: 0.0743 - val_accuracy: 0.9770\n",
            "Epoch 5/20\n",
            "1197/1197 [==============================] - 37s 31ms/step - loss: 0.0602 - accuracy: 0.9822 - val_loss: 0.1857 - val_accuracy: 0.9545\n",
            "Epoch 6/20\n",
            "1197/1197 [==============================] - 38s 31ms/step - loss: 0.0556 - accuracy: 0.9836 - val_loss: 0.1996 - val_accuracy: 0.9550\n",
            "Epoch 7/20\n",
            "1197/1197 [==============================] - 37s 31ms/step - loss: 0.0467 - accuracy: 0.9868 - val_loss: 0.1453 - val_accuracy: 0.9677\n",
            "Epoch 8/20\n",
            "1197/1197 [==============================] - 37s 31ms/step - loss: 0.0512 - accuracy: 0.9849 - val_loss: 0.1256 - val_accuracy: 0.9726\n",
            "Epoch 9/20\n",
            "1197/1197 [==============================] - 37s 31ms/step - loss: 0.0411 - accuracy: 0.9877 - val_loss: 0.0795 - val_accuracy: 0.9781\n",
            "Epoch 10/20\n",
            "1197/1197 [==============================] - 37s 31ms/step - loss: 0.0446 - accuracy: 0.9874 - val_loss: 0.3690 - val_accuracy: 0.9179\n",
            "Epoch 11/20\n",
            "1197/1197 [==============================] - 37s 31ms/step - loss: 0.0353 - accuracy: 0.9886 - val_loss: 0.0997 - val_accuracy: 0.9741\n",
            "Epoch 12/20\n",
            "1197/1197 [==============================] - 38s 31ms/step - loss: 0.0287 - accuracy: 0.9908 - val_loss: 0.0627 - val_accuracy: 0.9852\n",
            "Epoch 13/20\n",
            "1197/1197 [==============================] - 38s 31ms/step - loss: 0.0255 - accuracy: 0.9917 - val_loss: 0.0499 - val_accuracy: 0.9884\n",
            "Epoch 14/20\n",
            "1197/1197 [==============================] - 38s 31ms/step - loss: 0.0258 - accuracy: 0.9921 - val_loss: 0.1012 - val_accuracy: 0.9775\n",
            "Epoch 15/20\n",
            "1197/1197 [==============================] - 38s 31ms/step - loss: 0.0218 - accuracy: 0.9934 - val_loss: 0.0977 - val_accuracy: 0.9783\n",
            "Epoch 16/20\n",
            "1197/1197 [==============================] - 38s 31ms/step - loss: 0.0230 - accuracy: 0.9933 - val_loss: 0.0962 - val_accuracy: 0.9785\n",
            "Epoch 17/20\n",
            "1197/1197 [==============================] - 37s 31ms/step - loss: 0.0197 - accuracy: 0.9933 - val_loss: 0.0817 - val_accuracy: 0.9823\n",
            "Epoch 18/20\n",
            "1197/1197 [==============================] - 38s 31ms/step - loss: 0.0204 - accuracy: 0.9935 - val_loss: 0.1550 - val_accuracy: 0.9726\n",
            "Epoch 19/20\n",
            "1197/1197 [==============================] - 37s 31ms/step - loss: 0.0180 - accuracy: 0.9945 - val_loss: 0.0810 - val_accuracy: 0.9810\n",
            "Epoch 20/20\n",
            "1197/1197 [==============================] - 37s 31ms/step - loss: 0.0162 - accuracy: 0.9959 - val_loss: 0.1358 - val_accuracy: 0.9721\n",
            "INFO:tensorflow:Assets written to: final_models/2anomaly-classifier2/assets\n",
            "Model 2 saved\n",
            "{0: 0, 1: 1, 3: 2, 5: 3, 6: 4, 7: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(38550,)\n",
            "{0: 0, 1: 1, 3: 2, 5: 3, 6: 4, 7: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9650,)\n",
            "Epoch 1/20\n",
            "1205/1205 [==============================] - 39s 32ms/step - loss: 5.4933 - accuracy: 0.8244 - val_loss: 0.2645 - val_accuracy: 0.9710\n",
            "Epoch 2/20\n",
            "1205/1205 [==============================] - 38s 31ms/step - loss: 0.1398 - accuracy: 0.9757 - val_loss: 0.1019 - val_accuracy: 0.9732\n",
            "Epoch 3/20\n",
            "1205/1205 [==============================] - 38s 31ms/step - loss: 0.0671 - accuracy: 0.9814 - val_loss: 0.0870 - val_accuracy: 0.9750\n",
            "Epoch 4/20\n",
            "1205/1205 [==============================] - 38s 31ms/step - loss: 0.0524 - accuracy: 0.9846 - val_loss: 0.0575 - val_accuracy: 0.9846\n",
            "Epoch 5/20\n",
            "1205/1205 [==============================] - 38s 31ms/step - loss: 0.0524 - accuracy: 0.9840 - val_loss: 0.0964 - val_accuracy: 0.9739\n",
            "Epoch 6/20\n",
            "1205/1205 [==============================] - 38s 31ms/step - loss: 0.0426 - accuracy: 0.9869 - val_loss: 0.0692 - val_accuracy: 0.9801\n",
            "Epoch 7/20\n",
            "1205/1205 [==============================] - 38s 31ms/step - loss: 0.0413 - accuracy: 0.9878 - val_loss: 0.1587 - val_accuracy: 0.9684\n",
            "Epoch 8/20\n",
            "1205/1205 [==============================] - 38s 31ms/step - loss: 0.0392 - accuracy: 0.9873 - val_loss: 0.0803 - val_accuracy: 0.9787\n",
            "Epoch 9/20\n",
            "1205/1205 [==============================] - 38s 31ms/step - loss: 0.0405 - accuracy: 0.9888 - val_loss: 0.0433 - val_accuracy: 0.9887\n",
            "Epoch 10/20\n",
            "1205/1205 [==============================] - 38s 31ms/step - loss: 0.0314 - accuracy: 0.9896 - val_loss: 0.0636 - val_accuracy: 0.9821\n",
            "Epoch 11/20\n",
            "1205/1205 [==============================] - 38s 31ms/step - loss: 0.0271 - accuracy: 0.9916 - val_loss: 0.0801 - val_accuracy: 0.9792\n",
            "Epoch 12/20\n",
            "1205/1205 [==============================] - 38s 31ms/step - loss: 0.0253 - accuracy: 0.9926 - val_loss: 0.0652 - val_accuracy: 0.9833\n",
            "Epoch 13/20\n",
            "1205/1205 [==============================] - 38s 31ms/step - loss: 0.0272 - accuracy: 0.9917 - val_loss: 0.0797 - val_accuracy: 0.9822\n",
            "Epoch 14/20\n",
            "1205/1205 [==============================] - 38s 31ms/step - loss: 0.0253 - accuracy: 0.9916 - val_loss: 0.1081 - val_accuracy: 0.9762\n",
            "Epoch 15/20\n",
            "1205/1205 [==============================] - 38s 31ms/step - loss: 0.0218 - accuracy: 0.9932 - val_loss: 0.0616 - val_accuracy: 0.9880\n",
            "Epoch 16/20\n",
            "1205/1205 [==============================] - 38s 31ms/step - loss: 0.0203 - accuracy: 0.9936 - val_loss: 0.0723 - val_accuracy: 0.9837\n",
            "Epoch 17/20\n",
            "1205/1205 [==============================] - 38s 31ms/step - loss: 0.0159 - accuracy: 0.9953 - val_loss: 0.1399 - val_accuracy: 0.9714\n",
            "Epoch 18/20\n",
            "1205/1205 [==============================] - 38s 31ms/step - loss: 0.0172 - accuracy: 0.9951 - val_loss: 0.0553 - val_accuracy: 0.9880\n",
            "Epoch 19/20\n",
            "1205/1205 [==============================] - 38s 31ms/step - loss: 0.0178 - accuracy: 0.9947 - val_loss: 0.0763 - val_accuracy: 0.9853\n",
            "Epoch 20/20\n",
            "1205/1205 [==============================] - 38s 31ms/step - loss: 0.0146 - accuracy: 0.9958 - val_loss: 0.1042 - val_accuracy: 0.9762\n",
            "INFO:tensorflow:Assets written to: final_models/2anomaly-classifier3/assets\n",
            "Model 3 saved\n",
            "{0: 0, 1: 1, 3: 2, 4: 3, 6: 4, 7: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(38899,)\n",
            "{0: 0, 1: 1, 3: 2, 4: 3, 6: 4, 7: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9722,)\n",
            "Epoch 1/20\n",
            "1216/1216 [==============================] - 39s 32ms/step - loss: 5.5809 - accuracy: 0.8487 - val_loss: 0.5199 - val_accuracy: 0.9452\n",
            "Epoch 2/20\n",
            "1216/1216 [==============================] - 38s 31ms/step - loss: 0.2684 - accuracy: 0.9672 - val_loss: 0.1319 - val_accuracy: 0.9673\n",
            "Epoch 3/20\n",
            "1216/1216 [==============================] - 38s 31ms/step - loss: 0.0813 - accuracy: 0.9805 - val_loss: 0.1555 - val_accuracy: 0.9529\n",
            "Epoch 4/20\n",
            "1216/1216 [==============================] - 38s 31ms/step - loss: 0.0593 - accuracy: 0.9824 - val_loss: 0.1227 - val_accuracy: 0.9651\n",
            "Epoch 5/20\n",
            "1216/1216 [==============================] - 38s 31ms/step - loss: 0.0459 - accuracy: 0.9865 - val_loss: 0.3127 - val_accuracy: 0.9271\n",
            "Epoch 6/20\n",
            "1216/1216 [==============================] - 38s 31ms/step - loss: 0.0454 - accuracy: 0.9870 - val_loss: 0.0650 - val_accuracy: 0.9818\n",
            "Epoch 7/20\n",
            "1216/1216 [==============================] - 38s 31ms/step - loss: 0.0421 - accuracy: 0.9871 - val_loss: 0.0699 - val_accuracy: 0.9808\n",
            "Epoch 8/20\n",
            "1216/1216 [==============================] - 38s 31ms/step - loss: 0.0389 - accuracy: 0.9888 - val_loss: 0.1359 - val_accuracy: 0.9662\n",
            "Epoch 9/20\n",
            "1216/1216 [==============================] - 38s 31ms/step - loss: 0.0369 - accuracy: 0.9887 - val_loss: 0.0735 - val_accuracy: 0.9830\n",
            "Epoch 10/20\n",
            "1216/1216 [==============================] - 38s 31ms/step - loss: 0.0367 - accuracy: 0.9898 - val_loss: 0.0908 - val_accuracy: 0.9816\n",
            "Epoch 11/20\n",
            "1216/1216 [==============================] - 38s 31ms/step - loss: 0.0265 - accuracy: 0.9913 - val_loss: 0.0665 - val_accuracy: 0.9841\n",
            "Epoch 12/20\n",
            "1216/1216 [==============================] - 38s 31ms/step - loss: 0.0274 - accuracy: 0.9915 - val_loss: 0.1102 - val_accuracy: 0.9743\n",
            "Epoch 13/20\n",
            "1216/1216 [==============================] - 38s 31ms/step - loss: 0.0261 - accuracy: 0.9923 - val_loss: 0.1434 - val_accuracy: 0.9734\n",
            "Epoch 14/20\n",
            "1216/1216 [==============================] - 38s 31ms/step - loss: 0.0276 - accuracy: 0.9921 - val_loss: 0.0688 - val_accuracy: 0.9868\n",
            "Epoch 15/20\n",
            "1216/1216 [==============================] - 38s 31ms/step - loss: 0.0198 - accuracy: 0.9943 - val_loss: 0.0694 - val_accuracy: 0.9844\n",
            "Epoch 16/20\n",
            "1216/1216 [==============================] - 38s 31ms/step - loss: 0.0164 - accuracy: 0.9952 - val_loss: 0.0755 - val_accuracy: 0.9834\n",
            "Epoch 17/20\n",
            "1216/1216 [==============================] - 38s 31ms/step - loss: 0.0128 - accuracy: 0.9955 - val_loss: 0.0749 - val_accuracy: 0.9849\n",
            "Epoch 18/20\n",
            "1216/1216 [==============================] - 38s 31ms/step - loss: 0.0171 - accuracy: 0.9948 - val_loss: 0.1168 - val_accuracy: 0.9773\n",
            "Epoch 19/20\n",
            "1216/1216 [==============================] - 38s 31ms/step - loss: 0.0163 - accuracy: 0.9946 - val_loss: 0.0812 - val_accuracy: 0.9871\n",
            "Epoch 20/20\n",
            "1216/1216 [==============================] - 38s 31ms/step - loss: 0.0126 - accuracy: 0.9964 - val_loss: 0.0927 - val_accuracy: 0.9821\n",
            "INFO:tensorflow:Assets written to: final_models/2anomaly-classifier4/assets\n",
            "Model 4 saved\n",
            "{0: 0, 1: 1, 3: 2, 4: 3, 5: 4, 7: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(38475,)\n",
            "{0: 0, 1: 1, 3: 2, 4: 3, 5: 4, 7: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9649,)\n",
            "Epoch 1/20\n",
            "1203/1203 [==============================] - 39s 32ms/step - loss: 5.4473 - accuracy: 0.8089 - val_loss: 0.2995 - val_accuracy: 0.9458\n",
            "Epoch 2/20\n",
            "1203/1203 [==============================] - 38s 31ms/step - loss: 0.1180 - accuracy: 0.9710 - val_loss: 0.0841 - val_accuracy: 0.9757\n",
            "Epoch 3/20\n",
            "1203/1203 [==============================] - 38s 31ms/step - loss: 0.0662 - accuracy: 0.9813 - val_loss: 0.1134 - val_accuracy: 0.9658\n",
            "Epoch 4/20\n",
            "1203/1203 [==============================] - 38s 31ms/step - loss: 0.0624 - accuracy: 0.9813 - val_loss: 0.1627 - val_accuracy: 0.9612\n",
            "Epoch 5/20\n",
            "1203/1203 [==============================] - 38s 31ms/step - loss: 0.0616 - accuracy: 0.9830 - val_loss: 0.0831 - val_accuracy: 0.9762\n",
            "Epoch 6/20\n",
            "1203/1203 [==============================] - 38s 31ms/step - loss: 0.0548 - accuracy: 0.9841 - val_loss: 0.0636 - val_accuracy: 0.9829\n",
            "Epoch 7/20\n",
            "1203/1203 [==============================] - 38s 31ms/step - loss: 0.0536 - accuracy: 0.9847 - val_loss: 0.0518 - val_accuracy: 0.9862\n",
            "Epoch 8/20\n",
            "1203/1203 [==============================] - 38s 31ms/step - loss: 0.0459 - accuracy: 0.9871 - val_loss: 0.0565 - val_accuracy: 0.9836\n",
            "Epoch 9/20\n",
            "1203/1203 [==============================] - 38s 31ms/step - loss: 0.0397 - accuracy: 0.9882 - val_loss: 0.0759 - val_accuracy: 0.9801\n",
            "Epoch 10/20\n",
            "1203/1203 [==============================] - 38s 31ms/step - loss: 0.0362 - accuracy: 0.9887 - val_loss: 0.1094 - val_accuracy: 0.9739\n",
            "Epoch 11/20\n",
            "1203/1203 [==============================] - 38s 31ms/step - loss: 0.0351 - accuracy: 0.9895 - val_loss: 0.0594 - val_accuracy: 0.9842\n",
            "Epoch 12/20\n",
            "1203/1203 [==============================] - 38s 31ms/step - loss: 0.0272 - accuracy: 0.9920 - val_loss: 0.0775 - val_accuracy: 0.9803\n",
            "Epoch 13/20\n",
            "1203/1203 [==============================] - 38s 31ms/step - loss: 0.0240 - accuracy: 0.9926 - val_loss: 0.0938 - val_accuracy: 0.9746\n",
            "Epoch 14/20\n",
            "1203/1203 [==============================] - 38s 31ms/step - loss: 0.0221 - accuracy: 0.9924 - val_loss: 0.0569 - val_accuracy: 0.9834\n",
            "Epoch 15/20\n",
            "1203/1203 [==============================] - 38s 31ms/step - loss: 0.0196 - accuracy: 0.9939 - val_loss: 0.0714 - val_accuracy: 0.9811\n",
            "Epoch 16/20\n",
            "1203/1203 [==============================] - 38s 31ms/step - loss: 0.0257 - accuracy: 0.9918 - val_loss: 0.0442 - val_accuracy: 0.9884\n",
            "Epoch 17/20\n",
            "1203/1203 [==============================] - 38s 31ms/step - loss: 0.0233 - accuracy: 0.9931 - val_loss: 0.0510 - val_accuracy: 0.9870\n",
            "Epoch 18/20\n",
            "1203/1203 [==============================] - 38s 31ms/step - loss: 0.0191 - accuracy: 0.9934 - val_loss: 0.0707 - val_accuracy: 0.9845\n",
            "Epoch 19/20\n",
            "1203/1203 [==============================] - 38s 31ms/step - loss: 0.0191 - accuracy: 0.9939 - val_loss: 0.0684 - val_accuracy: 0.9848\n",
            "Epoch 20/20\n",
            "1203/1203 [==============================] - 38s 31ms/step - loss: 0.0143 - accuracy: 0.9953 - val_loss: 0.0607 - val_accuracy: 0.9874\n",
            "INFO:tensorflow:Assets written to: final_models/2anomaly-classifier5/assets\n",
            "Model 5 saved\n",
            "{0: 0, 1: 1, 3: 2, 4: 3, 5: 4, 6: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(38250,)\n",
            "{0: 0, 1: 1, 3: 2, 4: 3, 5: 4, 6: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9527,)\n",
            "Epoch 1/20\n",
            "1196/1196 [==============================] - 39s 32ms/step - loss: 5.4299 - accuracy: 0.7834 - val_loss: 0.2066 - val_accuracy: 0.9662\n",
            "Epoch 2/20\n",
            "1196/1196 [==============================] - 37s 31ms/step - loss: 0.1310 - accuracy: 0.9743 - val_loss: 0.1777 - val_accuracy: 0.9521\n",
            "Epoch 3/20\n",
            "1196/1196 [==============================] - 37s 31ms/step - loss: 0.0688 - accuracy: 0.9820 - val_loss: 0.1192 - val_accuracy: 0.9676\n",
            "Epoch 4/20\n",
            "1196/1196 [==============================] - 38s 31ms/step - loss: 0.0616 - accuracy: 0.9821 - val_loss: 0.1082 - val_accuracy: 0.9733\n",
            "Epoch 5/20\n",
            "1196/1196 [==============================] - 38s 31ms/step - loss: 0.0591 - accuracy: 0.9828 - val_loss: 0.1364 - val_accuracy: 0.9685\n",
            "Epoch 6/20\n",
            "1196/1196 [==============================] - 37s 31ms/step - loss: 0.0526 - accuracy: 0.9841 - val_loss: 0.1871 - val_accuracy: 0.9601\n",
            "Epoch 7/20\n",
            "1196/1196 [==============================] - 38s 31ms/step - loss: 0.0462 - accuracy: 0.9859 - val_loss: 0.1160 - val_accuracy: 0.9698\n",
            "Epoch 8/20\n",
            "1196/1196 [==============================] - 38s 31ms/step - loss: 0.0456 - accuracy: 0.9866 - val_loss: 0.0542 - val_accuracy: 0.9850\n",
            "Epoch 9/20\n",
            "1196/1196 [==============================] - 37s 31ms/step - loss: 0.0448 - accuracy: 0.9865 - val_loss: 0.0916 - val_accuracy: 0.9773\n",
            "Epoch 10/20\n",
            "1196/1196 [==============================] - 37s 31ms/step - loss: 0.0361 - accuracy: 0.9886 - val_loss: 0.1348 - val_accuracy: 0.9659\n",
            "Epoch 11/20\n",
            "1196/1196 [==============================] - 37s 31ms/step - loss: 0.0291 - accuracy: 0.9904 - val_loss: 0.0640 - val_accuracy: 0.9832\n",
            "Epoch 12/20\n",
            "1196/1196 [==============================] - 38s 31ms/step - loss: 0.0321 - accuracy: 0.9893 - val_loss: 0.1002 - val_accuracy: 0.9768\n",
            "Epoch 13/20\n",
            "1196/1196 [==============================] - 37s 31ms/step - loss: 0.0229 - accuracy: 0.9929 - val_loss: 0.0667 - val_accuracy: 0.9826\n",
            "Epoch 14/20\n",
            "1196/1196 [==============================] - 38s 32ms/step - loss: 0.0210 - accuracy: 0.9932 - val_loss: 0.0581 - val_accuracy: 0.9855\n",
            "Epoch 15/20\n",
            "1196/1196 [==============================] - 37s 31ms/step - loss: 0.0217 - accuracy: 0.9934 - val_loss: 0.0581 - val_accuracy: 0.9842\n",
            "Epoch 16/20\n",
            "1196/1196 [==============================] - 37s 31ms/step - loss: 0.0200 - accuracy: 0.9942 - val_loss: 0.0668 - val_accuracy: 0.9846\n",
            "Epoch 17/20\n",
            "1196/1196 [==============================] - 37s 31ms/step - loss: 0.0198 - accuracy: 0.9939 - val_loss: 0.0735 - val_accuracy: 0.9835\n",
            "Epoch 18/20\n",
            "1196/1196 [==============================] - 37s 31ms/step - loss: 0.0187 - accuracy: 0.9937 - val_loss: 0.0817 - val_accuracy: 0.9823\n",
            "Epoch 19/20\n",
            "1196/1196 [==============================] - 37s 31ms/step - loss: 0.0174 - accuracy: 0.9950 - val_loss: 0.0645 - val_accuracy: 0.9849\n",
            "Epoch 20/20\n",
            "1196/1196 [==============================] - 37s 31ms/step - loss: 0.0151 - accuracy: 0.9959 - val_loss: 0.0926 - val_accuracy: 0.9781\n",
            "INFO:tensorflow:Assets written to: final_models/2anomaly-classifier6/assets\n",
            "Model 6 saved\n",
            "{0: 0, 1: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(38525,)\n",
            "{0: 0, 1: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9666,)\n",
            "Epoch 1/20\n",
            "1204/1204 [==============================] - 39s 32ms/step - loss: 5.5999 - accuracy: 0.8220 - val_loss: 0.1442 - val_accuracy: 0.9640\n",
            "Epoch 2/20\n",
            "1204/1204 [==============================] - 38s 31ms/step - loss: 0.1173 - accuracy: 0.9733 - val_loss: 0.0701 - val_accuracy: 0.9802\n",
            "Epoch 3/20\n",
            "1204/1204 [==============================] - 38s 31ms/step - loss: 0.0679 - accuracy: 0.9811 - val_loss: 0.1237 - val_accuracy: 0.9698\n",
            "Epoch 4/20\n",
            "1204/1204 [==============================] - 38s 31ms/step - loss: 0.0603 - accuracy: 0.9829 - val_loss: 0.1822 - val_accuracy: 0.9557\n",
            "Epoch 5/20\n",
            "1204/1204 [==============================] - 38s 31ms/step - loss: 0.0504 - accuracy: 0.9847 - val_loss: 0.2169 - val_accuracy: 0.9537\n",
            "Epoch 6/20\n",
            "1204/1204 [==============================] - 38s 31ms/step - loss: 0.0551 - accuracy: 0.9835 - val_loss: 0.1206 - val_accuracy: 0.9715\n",
            "Epoch 7/20\n",
            "1204/1204 [==============================] - 38s 31ms/step - loss: 0.0482 - accuracy: 0.9856 - val_loss: 0.1303 - val_accuracy: 0.9689\n",
            "Epoch 8/20\n",
            "1204/1204 [==============================] - 38s 31ms/step - loss: 0.0457 - accuracy: 0.9861 - val_loss: 0.0806 - val_accuracy: 0.9796\n",
            "Epoch 9/20\n",
            "1204/1204 [==============================] - 38s 31ms/step - loss: 0.0391 - accuracy: 0.9885 - val_loss: 0.0793 - val_accuracy: 0.9820\n",
            "Epoch 10/20\n",
            "1204/1204 [==============================] - 38s 31ms/step - loss: 0.0360 - accuracy: 0.9896 - val_loss: 0.1059 - val_accuracy: 0.9760\n",
            "Epoch 11/20\n",
            "1204/1204 [==============================] - 38s 31ms/step - loss: 0.0298 - accuracy: 0.9906 - val_loss: 0.0789 - val_accuracy: 0.9822\n",
            "Epoch 12/20\n",
            "1204/1204 [==============================] - 38s 31ms/step - loss: 0.0256 - accuracy: 0.9920 - val_loss: 0.1061 - val_accuracy: 0.9725\n",
            "Epoch 13/20\n",
            "1204/1204 [==============================] - 38s 31ms/step - loss: 0.0250 - accuracy: 0.9925 - val_loss: 0.0856 - val_accuracy: 0.9827\n",
            "Epoch 14/20\n",
            "1204/1204 [==============================] - 38s 31ms/step - loss: 0.0248 - accuracy: 0.9929 - val_loss: 0.1055 - val_accuracy: 0.9738\n",
            "Epoch 15/20\n",
            "1204/1204 [==============================] - 38s 31ms/step - loss: 0.0217 - accuracy: 0.9933 - val_loss: 0.2276 - val_accuracy: 0.9525\n",
            "Epoch 16/20\n",
            "1204/1204 [==============================] - 38s 31ms/step - loss: 0.0186 - accuracy: 0.9943 - val_loss: 0.0804 - val_accuracy: 0.9842\n",
            "Epoch 17/20\n",
            "1204/1204 [==============================] - 38s 31ms/step - loss: 0.0195 - accuracy: 0.9938 - val_loss: 0.0569 - val_accuracy: 0.9867\n",
            "Epoch 18/20\n",
            "1204/1204 [==============================] - 38s 31ms/step - loss: 0.0156 - accuracy: 0.9948 - val_loss: 0.0583 - val_accuracy: 0.9870\n",
            "Epoch 19/20\n",
            "1204/1204 [==============================] - 38s 32ms/step - loss: 0.0144 - accuracy: 0.9954 - val_loss: 0.0805 - val_accuracy: 0.9838\n",
            "Epoch 20/20\n",
            "1204/1204 [==============================] - 38s 31ms/step - loss: 0.0139 - accuracy: 0.9957 - val_loss: 0.0498 - val_accuracy: 0.9890\n",
            "INFO:tensorflow:Assets written to: final_models/2anomaly-classifier7/assets\n",
            "Model 7 saved\n",
            "{0: 0, 1: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, 8: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(38461,)\n",
            "{0: 0, 1: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, 8: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9632,)\n",
            "Epoch 1/20\n",
            "1202/1202 [==============================] - 39s 32ms/step - loss: 4.8325 - accuracy: 0.8541 - val_loss: 0.1887 - val_accuracy: 0.9752\n",
            "Epoch 2/20\n",
            "1202/1202 [==============================] - 38s 31ms/step - loss: 0.1413 - accuracy: 0.9752 - val_loss: 0.1756 - val_accuracy: 0.9655\n",
            "Epoch 3/20\n",
            "1202/1202 [==============================] - 38s 31ms/step - loss: 0.0613 - accuracy: 0.9837 - val_loss: 0.0821 - val_accuracy: 0.9764\n",
            "Epoch 4/20\n",
            "1202/1202 [==============================] - 38s 31ms/step - loss: 0.0572 - accuracy: 0.9834 - val_loss: 0.3457 - val_accuracy: 0.9274\n",
            "Epoch 5/20\n",
            "1202/1202 [==============================] - 38s 31ms/step - loss: 0.0500 - accuracy: 0.9848 - val_loss: 0.0786 - val_accuracy: 0.9766\n",
            "Epoch 6/20\n",
            "1202/1202 [==============================] - 38s 31ms/step - loss: 0.0439 - accuracy: 0.9866 - val_loss: 0.0493 - val_accuracy: 0.9873\n",
            "Epoch 7/20\n",
            "1202/1202 [==============================] - 38s 31ms/step - loss: 0.0450 - accuracy: 0.9867 - val_loss: 0.1536 - val_accuracy: 0.9634\n",
            "Epoch 8/20\n",
            "1202/1202 [==============================] - 38s 31ms/step - loss: 0.0449 - accuracy: 0.9869 - val_loss: 0.0928 - val_accuracy: 0.9776\n",
            "Epoch 9/20\n",
            "1202/1202 [==============================] - 38s 31ms/step - loss: 0.0329 - accuracy: 0.9897 - val_loss: 0.1157 - val_accuracy: 0.9738\n",
            "Epoch 10/20\n",
            "1202/1202 [==============================] - 37s 31ms/step - loss: 0.0307 - accuracy: 0.9908 - val_loss: 0.0719 - val_accuracy: 0.9836\n",
            "Epoch 11/20\n",
            "1202/1202 [==============================] - 38s 31ms/step - loss: 0.0287 - accuracy: 0.9911 - val_loss: 0.0908 - val_accuracy: 0.9775\n",
            "Epoch 12/20\n",
            "1202/1202 [==============================] - 38s 31ms/step - loss: 0.0218 - accuracy: 0.9934 - val_loss: 0.0846 - val_accuracy: 0.9819\n",
            "Epoch 13/20\n",
            "1202/1202 [==============================] - 38s 31ms/step - loss: 0.0217 - accuracy: 0.9932 - val_loss: 0.1377 - val_accuracy: 0.9740\n",
            "Epoch 14/20\n",
            "1202/1202 [==============================] - 38s 31ms/step - loss: 0.0214 - accuracy: 0.9932 - val_loss: 0.0959 - val_accuracy: 0.9788\n",
            "Epoch 15/20\n",
            "1202/1202 [==============================] - 38s 31ms/step - loss: 0.0180 - accuracy: 0.9942 - val_loss: 0.0477 - val_accuracy: 0.9877\n",
            "Epoch 16/20\n",
            "1202/1202 [==============================] - 38s 31ms/step - loss: 0.0202 - accuracy: 0.9940 - val_loss: 0.1177 - val_accuracy: 0.9755\n",
            "Epoch 17/20\n",
            "1202/1202 [==============================] - 38s 31ms/step - loss: 0.0190 - accuracy: 0.9938 - val_loss: 0.0502 - val_accuracy: 0.9883\n",
            "Epoch 18/20\n",
            "1202/1202 [==============================] - 38s 31ms/step - loss: 0.0133 - accuracy: 0.9957 - val_loss: 0.0915 - val_accuracy: 0.9806\n",
            "Epoch 19/20\n",
            "1202/1202 [==============================] - 38s 31ms/step - loss: 0.0152 - accuracy: 0.9951 - val_loss: 0.1586 - val_accuracy: 0.9737\n",
            "Epoch 20/20\n",
            "1202/1202 [==============================] - 38s 31ms/step - loss: 0.0116 - accuracy: 0.9962 - val_loss: 0.1374 - val_accuracy: 0.9782\n",
            "INFO:tensorflow:Assets written to: final_models/2anomaly-classifier8/assets\n",
            "Model 8 saved\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHVlDVmGgbf0"
      },
      "source": [
        "class_0 = model0.load_model(\"final_models/2anomaly-classifier0\")\n",
        "class_1 = model1.load_model(\"final_models/2anomaly-classifier1\")\n",
        "class_2 = model2.load_model(\"final_models/2anomaly-classifier2\")\n",
        "class_3 = model3.load_model(\"final_models/2anomaly-classifier3\")\n",
        "class_4 = model4.load_model(\"final_models/2anomaly-classifier4\")\n",
        "class_5 = model5.load_model(\"final_models/2anomaly-classifier5\")\n",
        "class_6 = model6.load_model(\"final_models/2anomaly-classifier6\")\n",
        "class_7 = model7.load_model(\"final_models/2anomaly-classifier7\")\n",
        "class_8 = model8.load_model(\"final_models/2anomaly-classifier8\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58RxjYm_gbf2",
        "outputId": "1a705a57-0d40-417a-c46c-f55b0b7c7982"
      },
      "source": [
        "layer_name_list = []\n",
        "\n",
        "layer_name_list.append(class_0.layers[-2:][0].name)\n",
        "layer_name_list.append(class_1.layers[-2:][0].name)\n",
        "layer_name_list.append(class_2.layers[-2:][0].name)\n",
        "layer_name_list.append(class_3.layers[-2:][0].name)\n",
        "layer_name_list.append(class_4.layers[-2:][0].name)\n",
        "layer_name_list.append(class_5.layers[-2:][0].name)\n",
        "layer_name_list.append(class_6.layers[-2:][0].name)\n",
        "layer_name_list.append(class_7.layers[-2:][0].name)\n",
        "layer_name_list.append(class_8.layers[-2:][0].name)\n",
        "\n",
        "print(layer_name_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['dense_39', 'dense_41', 'dense_43', 'dense_45', 'dense_47', 'dense_49', 'dense_51', 'dense_53', 'dense_55']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5uSs3a7vgbf3"
      },
      "source": [
        "from keras import Model\n",
        "model_dict = {}\n",
        "model_output0 = class_0.get_layer(layer_name_list[0]).output\n",
        "m0 = Model(inputs=class_0.input, outputs=model_output0)\n",
        "model_dict[0] = m0\n",
        "\n",
        "model_output1 = class_1.get_layer(layer_name_list[1]).output\n",
        "m1 = Model(inputs=class_1.input, outputs=model_output1)\n",
        "model_dict[1] = m1\n",
        "\n",
        "model_output2 = class_2.get_layer(layer_name_list[2]).output\n",
        "m2 = Model(inputs=class_2.input, outputs=model_output2)\n",
        "model_dict[2] = m2\n",
        "\n",
        "model_output3 = class_3.get_layer(layer_name_list[3]).output\n",
        "m3 = Model(inputs=class_3.input, outputs=model_output3)\n",
        "model_dict[3] = m3\n",
        "\n",
        "model_output4 = class_4.get_layer(layer_name_list[4]).output\n",
        "m4 = Model(inputs=class_4.input, outputs=model_output4)\n",
        "model_dict[4] = m4\n",
        "\n",
        "model_output5 = class_5.get_layer(layer_name_list[5]).output\n",
        "m5 = Model(inputs=class_5.input, outputs=model_output5)\n",
        "model_dict[5] = m5\n",
        "\n",
        "model_output6 = class_6.get_layer(layer_name_list[6]).output\n",
        "m6 = Model(inputs=class_6.input, outputs=model_output6)\n",
        "model_dict[6] = m6\n",
        "\n",
        "model_output7 = class_7.get_layer(layer_name_list[7]).output\n",
        "m7 = Model(inputs=class_7.input, outputs=model_output7)\n",
        "model_dict[7] = m7\n",
        "\n",
        "model_output8 = class_8.get_layer(layer_name_list[8]).output\n",
        "m8 = Model(inputs=class_8.input, outputs=model_output8)\n",
        "model_dict[8] = m8\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aoNTrGmDgbf5",
        "outputId": "58548e66-933c-45fd-a5df-64bc8adaf613"
      },
      "source": [
        "temp_val = []\n",
        "y_pred = []\n",
        "labels = set(new_val_labels)\n",
        "for i, lo in zip(range(9), labels):\n",
        "  m = model_dict[i]\n",
        "  val_imgs_, val_lbls_ = get_train_data(lo, new_val_images, new_val_labels)\n",
        "  y_p = m.predict(val_imgs_)\n",
        "  y_pred.append(y_p)\n",
        "  temp = temp_cal(y_p, val_lbls_)\n",
        "  temp_val.append(temp)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{1: 0, 3: 1, 4: 2, 5: 3, 6: 4, 7: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9651,)\n",
            "Temperature Initial value: 1.0\n",
            "Temperature Final value: 2.2466559410095215\n",
            "{0: 0, 3: 1, 4: 2, 5: 3, 6: 4, 7: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9504,)\n",
            "Temperature Initial value: 1.0\n",
            "Temperature Final value: 2.210195302963257\n",
            "{0: 0, 1: 1, 4: 2, 5: 3, 6: 4, 7: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9607,)\n",
            "Temperature Initial value: 1.0\n",
            "Temperature Final value: 2.264735460281372\n",
            "{0: 0, 1: 1, 3: 2, 5: 3, 6: 4, 7: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9650,)\n",
            "Temperature Initial value: 1.0\n",
            "Temperature Final value: 2.2229294776916504\n",
            "{0: 0, 1: 1, 3: 2, 4: 3, 6: 4, 7: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9722,)\n",
            "Temperature Initial value: 1.0\n",
            "Temperature Final value: 2.145726442337036\n",
            "{0: 0, 1: 1, 3: 2, 4: 3, 5: 4, 7: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9649,)\n",
            "Temperature Initial value: 1.0\n",
            "Temperature Final value: 2.14382266998291\n",
            "{0: 0, 1: 1, 3: 2, 4: 3, 5: 4, 6: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9527,)\n",
            "Temperature Initial value: 1.0\n",
            "Temperature Final value: 2.1131978034973145\n",
            "{0: 0, 1: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9666,)\n",
            "Temperature Initial value: 1.0\n",
            "Temperature Final value: 2.0234012603759766\n",
            "{0: 0, 1: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, 8: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9632,)\n",
            "Temperature Initial value: 1.0\n",
            "Temperature Final value: 2.4829792976379395\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AT1JoPQTgbf7",
        "outputId": "25b73dab-194e-43ff-ce8f-9a07df9b705a"
      },
      "source": [
        "temp_val"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=2.246656>,\n",
              " <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=2.2101953>,\n",
              " <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=2.2647355>,\n",
              " <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=2.2229295>,\n",
              " <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=2.1457264>,\n",
              " <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=2.1438227>,\n",
              " <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=2.1131978>,\n",
              " <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=2.0234013>,\n",
              " <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=2.4829793>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FX7tANwKgbf9",
        "outputId": "ac15c579-aed4-4b98-a4c5-cce7e39d2a27"
      },
      "source": [
        "from tqdm import tqdm\n",
        "avg = [0,0,0,0,0,0,0,0,0]\n",
        "count = [0,0,0,0,0,0,0,0,0]\n",
        "entropy_list = [0,0,0,0,0,0,0,0,0]\n",
        "for img, lbl in tqdm(zip(new_val_images,new_val_labels)):\n",
        "  img = img.reshape([-1, 28, 28, 1])\n",
        "  if not lbl == 0:\n",
        "    logits = model_dict[0](img)\n",
        "    logits = tf.math.divide(logits, temp_val[0])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e0 = entropy(pred[0])\n",
        "    entropy_list[0] = entropy_list[0] + e0\n",
        "    max_val0 = np.max(pred)\n",
        "    avg[0] = avg[0] + max_val0\n",
        "    count[0] = count[0] + 1\n",
        "  if not lbl == 1:\n",
        "    logits = model_dict[1](img)\n",
        "    logits = tf.math.divide(logits, temp_val[1])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e1 = entropy(pred[0])\n",
        "    entropy_list[1] = entropy_list[1] + e1\n",
        "    max_val1 = np.max(pred)\n",
        "    avg[1] = avg[1] + max_val1\n",
        "    count[1] = count[1] + 1\n",
        "  if not lbl == 3:\n",
        "    logits = model_dict[2](img)\n",
        "    logits = tf.math.divide(logits, temp_val[2])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e2 = entropy(pred[0])\n",
        "    entropy_list[2] = entropy_list[2] + e2\n",
        "    max_val2 = np.max(pred)\n",
        "    avg[2] = avg[2] + max_val2\n",
        "    count[2] = count[2] + 1\n",
        "  if not lbl == 4:\n",
        "    logits = model_dict[3](img)\n",
        "    logits = tf.math.divide(logits, temp_val[3])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e3 = entropy(pred[0])\n",
        "    entropy_list[3] = entropy_list[3] + e3\n",
        "    max_val3 = np.max(pred)  \n",
        "    avg[3] = avg[3] + max_val3\n",
        "    count[3] = count[3] + 1\n",
        "  if not lbl == 5:\n",
        "    logits = model_dict[4](img)\n",
        "    logits = tf.math.divide(logits, temp_val[4])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e4 = entropy(pred[0])\n",
        "    entropy_list[4] = entropy_list[4] + e4\n",
        "    max_val4 = np.max(pred)\n",
        "    avg[4] = avg[4] + max_val4\n",
        "    count[4] = count[4] + 1\n",
        "  if not lbl == 6:\n",
        "    logits = model_dict[5](img)\n",
        "    logits = tf.math.divide(logits, temp_val[5])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e5 = entropy(pred[0])\n",
        "    entropy_list[5] = entropy_list[5] + e5\n",
        "    max_val5 = np.max(pred)\n",
        "    avg[5] = avg[5] + max_val5\n",
        "    count[5] = count[5] + 1\n",
        "  if not lbl == 7:\n",
        "    logits = model_dict[6](img)\n",
        "    logits = tf.math.divide(logits, temp_val[6])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e6 = entropy(pred[0])\n",
        "    entropy_list[6] = entropy_list[6] + e6\n",
        "    max_val6 = np.max(pred)\n",
        "    avg[6] = avg[6] + max_val6\n",
        "    count[6] = count[6] + 1\n",
        "  if not lbl == 8:\n",
        "    logits = model_dict[7](img)\n",
        "    logits = tf.math.divide(logits, temp_val[7])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e7 = entropy(pred[0])\n",
        "    entropy_list[7] = entropy_list[7] + e7\n",
        "    max_val7 = np.max(pred)\n",
        "    avg[7] = avg[7] + max_val7\n",
        "    count[7] = count[7] + 1\n",
        "  if not lbl == 9:\n",
        "    logits = model_dict[8](img)\n",
        "    logits = tf.math.divide(logits, temp_val[8])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e8 = entropy(pred[0])\n",
        "    entropy_list[8] = entropy_list[8] + e8\n",
        "    max_val8 = np.max(pred)\n",
        "    avg[8] = avg[8] + max_val8\n",
        "    count[8] = count[8] + 1\n",
        "\n",
        "print(avg)\n",
        "print(count)\n",
        "print(entropy_list)\n",
        "\n",
        "entropy_avg_t = [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]\n",
        "for i in range(9):\n",
        "  entropy_avg_t[i] = entropy_list[i]/count[i]\n",
        "\n",
        "entropy_value_t = 0.0\n",
        "for i in range(9):\n",
        "  entropy_value_t = entropy_value_t + entropy_avg_t[i]\n",
        "\n",
        "entropy_t = entropy_value_t/len(entropy_avg_t)\n",
        "\n",
        "print('Entropy:', entropy_t)\n",
        "\n",
        "classifier_avg_t = [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]\n",
        "for i in range(9):\n",
        "  classifier_avg_t[i] = avg[i]/count[i]\n",
        "\n",
        "print('Each Classifier Average: ',classifier_avg_t)\n",
        "\n",
        "treshold_value = 0.0\n",
        "for i in range(9):\n",
        "  treshold_value = treshold_value + classifier_avg_t[i]\n",
        "\n",
        "treshold_t = treshold_value/len(classifier_avg_t)\n",
        "\n",
        "print('Threshold:', treshold_t)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10826it [12:16, 14.71it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[9405.049283653498, 9348.631170630455, 9351.427759766579, 9434.45449385047, 9538.491575554013, 9528.481483578682, 9328.142667412758, 9555.529257655144, 9467.76197116077]\n",
            "[9651, 9504, 9607, 9650, 9722, 9649, 9527, 9666, 9632]\n",
            "[759.5902696749478, 465.77641399661775, 758.9109294853397, 620.9661511954807, 577.9073483017497, 376.98345040381264, 591.5475185285524, 338.60580607712694, 502.7499658321673]\n",
            "Entropy: 0.05765442328513453\n",
            "Each Classifier Average:  [0.9745155200138326, 0.9836522696370428, 0.9733972894521264, 0.9776636781192196, 0.9811244163293574, 0.9875097402403028, 0.9791269725425378, 0.9885712039783927, 0.9829487096304785]\n",
            "Threshold: 0.9809455333270323\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_HCCVI0Ngbf_",
        "outputId": "b32952fe-7500-41cd-b5f1-83bcc096ad7b"
      },
      "source": [
        "ref_vect_in_2an = []\n",
        "ref_vect_in_2an.append(classifier_avg_t)\n",
        "\n",
        "threshold_in_2an = []\n",
        "threshold_in_2an.append(treshold_t)\n",
        "\n",
        "entropy_in_2an = []\n",
        "entropy_in_2an.append(entropy_t)\n",
        "\n",
        "print(entropy_in_2an)\n",
        "print(ref_vect_in_2an)\n",
        "print(threshold_in_2an)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.05765442328513453]\n",
            "[[0.9745155200138326, 0.9836522696370428, 0.9733972894521264, 0.9776636781192196, 0.9811244163293574, 0.9875097402403028, 0.9791269725425378, 0.9885712039783927, 0.9829487096304785]]\n",
            "[0.9809455333270323]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZIYHhiV_VNZ"
      },
      "source": [
        "entropy_in_2an = [0.05765442328513453]\n",
        "ref_vect_in_2an = [[0.9745155200138326, 0.9836522696370428, 0.9733972894521264, 0.9776636781192196, 0.9811244163293574, 0.9875097402403028, 0.9791269725425378, 0.9885712039783927, 0.9829487096304785]]\n",
        "threshold_in_2an = [0.9809455333270323]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9swXiudhgbgB",
        "outputId": "fe742aeb-83c9-489d-d79e-f2f74f46728c"
      },
      "source": [
        "from tqdm import tqdm\n",
        "avg = [0,0,0,0,0,0,0,0,0]\n",
        "count = [0,0,0,0,0,0,0,0,0]\n",
        "entropy_list = [0,0,0,0,0,0,0,0,0]\n",
        "\n",
        "for img, lbl in tqdm(zip(new_val_images,new_val_labels)):\n",
        "  img = img.reshape([-1, 28, 28, 1])\n",
        "  if lbl == 0:\n",
        "    logits = model_dict[0](img)\n",
        "    logits = tf.math.divide(logits, temp_val[0])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e0 = entropy(pred[0])\n",
        "    entropy_list[0] = entropy_list[0] + e0\n",
        "    max_val0 = np.max(pred)\n",
        "    avg[0] = avg[0] + max_val0\n",
        "    count[0] = count[0] + 1\n",
        "  if lbl == 1:\n",
        "    logits = model_dict[1](img)\n",
        "    logits = tf.math.divide(logits, temp_val[1])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e1 = entropy(pred[0])\n",
        "    entropy_list[1] = entropy_list[1] + e1\n",
        "    max_val1 = np.max(pred)\n",
        "    avg[1] = avg[1] + max_val1\n",
        "    count[1] = count[1] + 1\n",
        "  if lbl == 3:\n",
        "    logits = model_dict[2](img)\n",
        "    logits = tf.math.divide(logits, temp_val[2])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e2 = entropy(pred[0])\n",
        "    entropy_list[2] = entropy_list[2] + e2\n",
        "    max_val2 = np.max(pred)\n",
        "    avg[2] = avg[2] + max_val2\n",
        "    count[2] = count[2] + 1\n",
        "  if lbl == 4:\n",
        "    logits = model_dict[3](img)\n",
        "    logits = tf.math.divide(logits, temp_val[3])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e3 = entropy(pred[0])\n",
        "    entropy_list[3] = entropy_list[3] + e3\n",
        "    max_val3 = np.max(pred)  \n",
        "    avg[3] = avg[3] + max_val3\n",
        "    count[3] = count[3] + 1\n",
        "  if lbl == 5:\n",
        "    logits = model_dict[4](img)\n",
        "    logits = tf.math.divide(logits, temp_val[4])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e4 = entropy(pred[0])\n",
        "    entropy_list[4] = entropy_list[4] + e4\n",
        "    max_val4 = np.max(pred)\n",
        "    avg[4] = avg[4] + max_val4\n",
        "    count[4] = count[4] + 1\n",
        "  if lbl == 6:\n",
        "    logits = model_dict[5](img)\n",
        "    logits = tf.math.divide(logits, temp_val[5])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e5 = entropy(pred[0])\n",
        "    entropy_list[5] = entropy_list[5] + e5\n",
        "    max_val5 = np.max(pred)\n",
        "    avg[5] = avg[5] + max_val5\n",
        "    count[5] = count[5] + 1\n",
        "  if lbl == 7:\n",
        "    logits = model_dict[6](img)\n",
        "    logits = tf.math.divide(logits, temp_val[6])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e6 = entropy(pred[0])\n",
        "    entropy_list[6] = entropy_list[6] + e6\n",
        "    max_val6 = np.max(pred)\n",
        "    avg[6] = avg[6] + max_val6\n",
        "    count[6] = count[6] + 1\n",
        "  if lbl == 8:\n",
        "    logits = model_dict[7](img)\n",
        "    logits = tf.math.divide(logits, temp_val[7])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e7 = entropy(pred[0])\n",
        "    entropy_list[7] = entropy_list[7] + e7\n",
        "    max_val7 = np.max(pred)\n",
        "    avg[7] = avg[7] + max_val7\n",
        "    count[7] = count[7] + 1\n",
        "  if lbl == 9:\n",
        "    logits = model_dict[8](img)\n",
        "    logits = tf.math.divide(logits, temp_val[8])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e8 = entropy(pred[0])\n",
        "    entropy_list[8] = entropy_list[8] + e8\n",
        "    max_val8 = np.max(pred)\n",
        "    avg[8] = avg[8] + max_val8\n",
        "    count[8] = count[8] + 1\n",
        "\n",
        "print(avg)\n",
        "print(count)\n",
        "print(entropy_list)\n",
        "\n",
        "entropy_avg_t = [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]\n",
        "for i in range(9):\n",
        "  entropy_avg_t[i] = entropy_list[i]/count[i]\n",
        "\n",
        "entropy_value_t = 0.0\n",
        "for i in range(9):\n",
        "  entropy_value_t = entropy_value_t + entropy_avg_t[i]\n",
        "\n",
        "entropy_t = entropy_value_t/len(entropy_avg_t)\n",
        "\n",
        "print('Entropy:', entropy_t)\n",
        "\n",
        "classifier_avg_t = [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]\n",
        "for i in range(9):\n",
        "  classifier_avg_t[i] = avg[i]/count[i]\n",
        "\n",
        "print('Each Classifier Average: ',classifier_avg_t)\n",
        "\n",
        "treshold_value = 0.0\n",
        "for i in range(9):\n",
        "  treshold_value = treshold_value + classifier_avg_t[i]\n",
        "\n",
        "treshold_t = treshold_value/len(classifier_avg_t)\n",
        "\n",
        "print('Threshold:', treshold_t)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10826it [01:33, 116.08it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[989.6919656097889, 967.0002437233925, 985.5703043341637, 958.5422583520412, 912.68167501688, 939.2893269062042, 1002.4835924506187, 878.8140273094177, 946.6589447259903]\n",
            "[1175, 1322, 1219, 1176, 1104, 1177, 1299, 1160, 1194]\n",
            "[503.93807428907076, 1004.7887137681246, 614.641632284809, 598.5627212467662, 497.61645826513995, 607.1953896166997, 728.5454240590625, 741.3068669619388, 660.052928874884]\n",
            "Entropy: 0.5468306124703104\n",
            "Each Classifier Average:  [0.8422910345615224, 0.7314676578845631, 0.808507222587501, 0.8150869543809874, 0.8267044157761595, 0.7980368113051862, 0.7717348671675279, 0.7575982994046705, 0.7928466873752013]\n",
            "Threshold: 0.7938082167159244\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GOuw4VK2gbgD",
        "outputId": "be0c9679-4b83-43d1-f370-72868bced7bf"
      },
      "source": [
        "ref_vect_out_2an = []\n",
        "ref_vect_out_2an.append(classifier_avg_t)\n",
        "\n",
        "threshold_out_2an = []\n",
        "threshold_out_2an.append(treshold_t)\n",
        "\n",
        "entropy_out_2an = []\n",
        "entropy_out_2an.append(entropy_t)\n",
        "\n",
        "print(entropy_out_2an)\n",
        "print(ref_vect_out_2an)\n",
        "print(threshold_out_2an)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.5468306124703104]\n",
            "[[0.8422910345615224, 0.7314676578845631, 0.808507222587501, 0.8150869543809874, 0.8267044157761595, 0.7980368113051862, 0.7717348671675279, 0.7575982994046705, 0.7928466873752013]]\n",
            "[0.7938082167159244]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AianoNnp_ib1"
      },
      "source": [
        "entropy_out_2an = [0.5468306124703104]\n",
        "ref_vect_out_2an = [[0.8422910345615224, 0.7314676578845631, 0.808507222587501, 0.8150869543809874, 0.8267044157761595, 0.7980368113051862, 0.7717348671675279, 0.7575982994046705, 0.7928466873752013]]\n",
        "threshold_out_2an = [0.7938082167159244]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1f_Q_TB_gbgE"
      },
      "source": [
        "def get_max_pred_value(model, img, temp):\n",
        "  logits = model(img)\n",
        "  logits = tf.math.divide(logits, temp)\n",
        "  pred = tf.nn.softmax(logits)\n",
        "  e = entropy(pred[0])\n",
        "\n",
        "  return np.max(pred), tf.argmax(pred[0]).numpy(), e"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJpx6TLIgbgF"
      },
      "source": [
        "def get_mapping(leave_out_class, anomaly_class):\n",
        "  mapping = {}\n",
        "\n",
        "  labels = set(train_labels)\n",
        "  labels.remove(anomaly_class)\n",
        "  labels.remove(leave_out_class)\n",
        "  labels = sorted(labels)\n",
        "\n",
        "  for i,j in enumerate(labels):\n",
        "    mapping[i] = j\n",
        "\n",
        "  return mapping\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEaQpzNjgbgG"
      },
      "source": [
        "ood = 0\n",
        "ind = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5RB4V-5ggbgG",
        "outputId": "91af71c0-e26c-429c-eb2f-aebad663b678"
      },
      "source": [
        "max_sm_all_wt_2an = []\n",
        "for data, label in tqdm(zip(test_imgs, test_lbls)):\n",
        "  img = data.reshape([-1, 28, 28, 1])\n",
        "  ref_value = []\n",
        "  \n",
        "  if label == 2:\n",
        "    lbl = ood\n",
        "  else:\n",
        "    lbl = ind\n",
        "\n",
        "\n",
        "  max0, pred_0, e0 = get_max_pred_value(model_dict[0], img, temp=temp_val[0])\n",
        "  map0 = get_mapping(0, 0)\n",
        "  pred_0 = map0[pred_0]\n",
        "\n",
        "  max1, pred_1, e1 = get_max_pred_value(model_dict[1], img, temp=temp_val[1])\n",
        "  map1 = get_mapping(1, 0)\n",
        "  pred_1 = map1[pred_1]\n",
        "\n",
        "  max2, pred_2, e2 = get_max_pred_value(model_dict[2], img, temp=temp_val[2])\n",
        "  map2 = get_mapping(3, 0)\n",
        "  pred_2 = map2[pred_2]\n",
        "\n",
        "  max3, pred_3, e3 = get_max_pred_value(model_dict[3], img, temp=temp_val[3])\n",
        "  map3 = get_mapping(4, 0)\n",
        "  pred_3 = map3[pred_3]\n",
        "\n",
        "  max4, pred_4, e4 = get_max_pred_value(model_dict[4], img, temp=temp_val[4])\n",
        "  map4 = get_mapping(5, 0)\n",
        "  pred_4 = map4[pred_4]\n",
        "\n",
        "  max5, pred_5, e5 = get_max_pred_value(model_dict[5], img, temp=temp_val[5])\n",
        "  map5 = get_mapping(6, 0)\n",
        "  pred_5 = map5[pred_5]\n",
        "\n",
        "  max6, pred_6, e6 = get_max_pred_value(model_dict[6], img, temp=temp_val[6])\n",
        "  map6 = get_mapping(7, 0)\n",
        "  pred_6 = map6[pred_6]\n",
        "\n",
        "  max7, pred_7, e7 = get_max_pred_value(model_dict[7], img, temp=temp_val[7])\n",
        "  map7 = get_mapping(8, 0)\n",
        "  pred_7 = map7[pred_7]\n",
        "\n",
        "  max8, pred_8, e8 = get_max_pred_value(model_dict[8], img, temp=temp_val[8])\n",
        "  map8 = get_mapping(9, 0)\n",
        "  pred_8 = map8[pred_8]\n",
        "\n",
        "  ref_value =[max0, max1, max2, max3, max4, max5, max6, max7, max8]\n",
        "  pred_value = [pred_0, pred_1, pred_2, pred_3, pred_4, pred_5, pred_6, pred_7, pred_8]\n",
        "  e_value = [e0, e1, e2, e3, e4, e5, e6, e7, e8]\n",
        "  e_ = 0.0\n",
        "  for  e in e_value:\n",
        "    e_ = e_ + e\n",
        "  e_ = e_/len(e_value)\n",
        "  max_sm_all_wt_2an.append([ref_value, lbl, pred_value, label, e_])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000it [20:03,  8.31it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-b4X9pygbgH"
      },
      "source": [
        "pickle_out = open(\"sm_all_wt_2an.pickle\",\"wb\")\n",
        "pickle.dump(max_sm_all_wt_2an, pickle_out)\n",
        "pickle_out.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMvfODD8gbgI"
      },
      "source": [
        "pickle_in = open(\"sm_all_wt_2an.pickle\",\"rb\")\n",
        "max_sm_all_wt_2an = pickle.load(pickle_in)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ep8dpcuPgbgJ",
        "outputId": "700285c4-9aff-4021-c509-a2cff663a1d2"
      },
      "source": [
        "accuracy = 0.0\n",
        "count_in = 0\n",
        "count_ood = 0\n",
        "acc_in = 0.0\n",
        "acc_ood = 0.0\n",
        "tp = 0.0\n",
        "tn = 0.0\n",
        "fp = 0.0\n",
        "fn = 0.0\n",
        "y_true = []\n",
        "y_pred = []\n",
        "sim_score = []\n",
        "sim_score_ = []\n",
        "\n",
        "for data, lbl, p, a_l, e_ in max_sm_all_wt_2an:\n",
        "\n",
        "  score = 0.0\n",
        "  for d in data:\n",
        "    score = score + d\n",
        "  score = score / len(data)\n",
        "  sim_score.append(score)\n",
        "\n",
        "  dist_ood = np.linalg.norm(np.array(data) - np.array(ref_vect_out_2an[0])) \n",
        "  dist_in = np.linalg.norm(np.array(data) - np.array(ref_vect_in_2an[0]))\n",
        "\n",
        "  dist_ood2 = np.linalg.norm(np.array(e_) - np.array(entropy_out_2an[0])) \n",
        "  dist_in2 = np.linalg.norm(np.array(e_) - np.array(entropy_in_2an[0]))\n",
        "\n",
        "  dist_in = dist_in / (dist_in + dist_ood)\n",
        "  dist_ood = dist_ood / (dist_in + dist_ood)\n",
        "\n",
        "  dist_in2 = dist_in2 / (dist_in2 + dist_ood2)\n",
        "  dist_ood2 = dist_ood2 / (dist_in2 + dist_ood2)\n",
        "\n",
        "  sim_in = 1 / (1 + dist_in)\n",
        "  sim_ood = 1 / (1 + dist_ood)\n",
        "\n",
        "  sim_in2 = 1 / (1 + dist_in2)\n",
        "  sim_ood2 = 1 / (1 + dist_ood2)\n",
        "\n",
        "  sim_in = sim_in + sim_in2\n",
        "  sim_ood = sim_ood + sim_ood2\n",
        "\n",
        "  sim_score_.append(sim_ood2)\n",
        "\n",
        "  values, counts = np.unique(p, return_counts=True)\n",
        "#  print(values, counts)\n",
        "  #print(sim_in, sim_ood, lbl, e_)\n",
        "\n",
        "  if sim_in >= sim_ood:\n",
        "    y_ = ind    \n",
        "    if np.max(counts) >= 8:\n",
        "      y_ = ind\n",
        "    else:\n",
        "      y_ = ood\n",
        "  else:\n",
        "    y_ = ood\n",
        "\n",
        "\n",
        "  y_pred.append(y_)\n",
        "  if lbl == 1:\n",
        "    y_true.append(0)\n",
        "  else:\n",
        "    y_true.append(1)\n",
        "#  y_true.append(lbl)\n",
        "\n",
        "\n",
        "  if lbl == ind:\n",
        "    count_in = count_in + 1\n",
        "  else:\n",
        "    count_ood = count_ood + 1\n",
        "\n",
        "  if y_ == lbl:\n",
        "    #sim_score_.append(1)\n",
        "    accuracy = accuracy + 1\n",
        "    if y_ == ind:\n",
        "      acc_in = acc_in + 1\n",
        "      tp = tp + 1\n",
        "    else:\n",
        "      acc_ood = acc_ood + 1\n",
        "      tn = tn + 1\n",
        "  else:\n",
        "    #sim_score_.append(0)\n",
        "    if y_ == ind:\n",
        "      fp = fp + 1\n",
        "    else:\n",
        "      fn = fn + 1\n",
        "\n",
        "\n",
        "print(\"Total Accuracy: \", accuracy/len(max_sm_all_wt_2an)) \n",
        "print(\"Accuracy of determining ID data: \", acc_in/count_in)\n",
        "print(\"Accuracy of determining OOD data: \", acc_ood/count_ood)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Accuracy:  0.9091\n",
            "Accuracy of determining ID data:  0.90421498661909\n",
            "Accuracy of determining OOD data:  0.9515503875968992\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hg4-B5J4gbgK",
        "outputId": "f8921776-c276-4f86-c04b-5da1885df064"
      },
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "roc_auc_score(y_true, sim_score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9580710960244521"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 186
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tepik48EgbgL",
        "outputId": "365202bb-6326-4b97-e1bc-7adb26012733"
      },
      "source": [
        "roc_auc_score(y_true, y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9278826871079946"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 187
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SvEdoJjbgbgM",
        "outputId": "4707f2ee-ee42-491a-83db-60de6f6900d4"
      },
      "source": [
        "roc_auc_score(y_true, sim_score_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9596073506835673"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 195
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cpoon0HwDmnI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QTqj6-WoGQw3"
      },
      "source": [
        "# 3 as anomaly"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tsy_hLz-GTcJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zb_P31TRYhR8"
      },
      "source": [
        "new_train_images, new_train_labels, new_val_images, new_val_labels = separate_class(3, train_images, train_labels, val_images, val_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A57Hvz8VYhSA"
      },
      "source": [
        "model0 = Model(name='3anomaly:classifier0')\n",
        "model1 = Model(name='3anomaly:classifier1')\n",
        "model2 = Model(name='3anomaly:classifier2')\n",
        "model3 = Model(name='3anomaly:classifier3')\n",
        "model4 = Model(name='3anomaly:classifier4')\n",
        "model5 = Model(name='3anomaly:classifier5')\n",
        "model6 = Model(name='3anomaly:classifier6')\n",
        "model7 = Model(name='3anomaly:classifier7')\n",
        "model8 = Model(name='3anomaly:classifier8')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vj60LvNYhSB"
      },
      "source": [
        "class_0 = model0.build()\n",
        "class_1 = model1.build()\n",
        "class_2 = model2.build()\n",
        "class_3 = model3.build()\n",
        "class_4 = model4.build()\n",
        "class_5 = model5.build()\n",
        "class_6 = model6.build()\n",
        "class_7 = model7.build()\n",
        "class_8 = model8.build()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xxOo5kBQYhSB",
        "outputId": "1cb19d41-c301-4059-f1b4-03f7664789c2"
      },
      "source": [
        "train_imgs0, train_lbls0 = get_train_data(0, new_train_images, new_train_labels)\n",
        "val_imgs0, val_lbls0 = get_train_data(0, new_val_images, new_val_labels)\n",
        "class_0 = model0.build()\n",
        "model0.train2(train_imgs0, train_lbls0, val_imgs0, val_lbls0)\n",
        "#model0.train(train_data0)\n",
        "model0.save_model(\"final_models/3anomaly-classifier0\")\n",
        "print('Model 0 saved')\n",
        "\n",
        "train_imgs1, train_lbls1 = get_train_data(1, new_train_images, new_train_labels)\n",
        "val_imgs1, val_lbls1 = get_train_data(1, new_val_images, new_val_labels)\n",
        "class_1 = model1.build()\n",
        "model1.train2(train_imgs1, train_lbls1, val_imgs1, val_lbls1)\n",
        "#model1.train(train_data1)\n",
        "model1.save_model(\"final_models/3anomaly-classifier1\")\n",
        "print('Model 1 saved')\n",
        "\n",
        "#train_data2 = get_train_data(2, new_train_images)\n",
        "train_imgs2, train_lbls2 = get_train_data(2, new_train_images, new_train_labels)\n",
        "val_imgs2, val_lbls2 = get_train_data(2, new_val_images, new_val_labels)\n",
        "class_2 = model2.build()\n",
        "model2.train2(train_imgs2, train_lbls2, val_imgs2, val_lbls2)\n",
        "#model2.train(train_data2)\n",
        "model2.save_model(\"final_models/3anomaly-classifier2\")\n",
        "print('Model 2 saved')\n",
        "\n",
        "#train_data3 = get_train_data(3, new_train_images)\n",
        "train_imgs3, train_lbls3 = get_train_data(4, new_train_images, new_train_labels)\n",
        "val_imgs3, val_lbls3 = get_train_data(4, new_val_images, new_val_labels)\n",
        "class_3 = model3.build()\n",
        "model3.train2(train_imgs3, train_lbls3, val_imgs3, val_lbls3)\n",
        "#model3.train(train_data3)\n",
        "model3.save_model(\"final_models/3anomaly-classifier3\")\n",
        "print('Model 3 saved')\n",
        "\n",
        "#train_data4 = get_train_data(4, new_train_images)\n",
        "train_imgs4, train_lbls4 = get_train_data(5, new_train_images, new_train_labels)\n",
        "val_imgs4, val_lbls4 = get_train_data(5, new_val_images, new_val_labels)\n",
        "class_4 = model4.build()\n",
        "model4.train2(train_imgs4, train_lbls4, val_imgs4, val_lbls4)\n",
        "#model4.train(train_data4)\n",
        "model4.save_model(\"final_models/3anomaly-classifier4\")\n",
        "print('Model 4 saved')\n",
        "\n",
        "#train_data5 = get_train_data(5, new_train_images)\n",
        "train_imgs5, train_lbls5 = get_train_data(6, new_train_images, new_train_labels)\n",
        "val_imgs5, val_lbls5 = get_train_data(6, new_val_images, new_val_labels)\n",
        "class_5 = model5.build()\n",
        "model5.train2(train_imgs5, train_lbls5, val_imgs5, val_lbls5)\n",
        "#model5.train(train_data5)\n",
        "model5.save_model(\"final_models/3anomaly-classifier5\")\n",
        "print('Model 5 saved')\n",
        "\n",
        "#train_data6 = get_train_data(6, new_train_images)\n",
        "train_imgs6, train_lbls6 = get_train_data(7, new_train_images, new_train_labels)\n",
        "val_imgs6, val_lbls6 = get_train_data(7, new_val_images, new_val_labels)\n",
        "class_6 = model6.build()\n",
        "model6.train2(train_imgs6, train_lbls6, val_imgs6, val_lbls6)\n",
        "#model6.train(train_data6)\n",
        "model6.save_model(\"final_models/3anomaly-classifier6\")\n",
        "print('Model 6 saved')\n",
        "\n",
        "#train_data7 = get_train_data(7, new_train_images)\n",
        "train_imgs7, train_lbls7 = get_train_data(8, new_train_images, new_train_labels)\n",
        "val_imgs7, val_lbls7 = get_train_data(8, new_val_images, new_val_labels)\n",
        "class_7 = model7.build()\n",
        "#model7.train(train_data7)\n",
        "model7.train2(train_imgs7, train_lbls7, val_imgs7, val_lbls7)\n",
        "model7.save_model(\"final_models/3anomaly-classifier7\")\n",
        "print('Model 7 saved')\n",
        "\n",
        "#train_data8 = get_train_data(8, new_train_images)\n",
        "train_imgs8, train_lbls8 = get_train_data(9, new_train_images, new_train_labels)\n",
        "val_imgs8, val_lbls8 = get_train_data(9, new_val_images, new_val_labels)\n",
        "class_8 = model8.build()\n",
        "#model8.train(train_data8)\n",
        "model8.train2(train_imgs8, train_lbls8, val_imgs8, val_lbls8)\n",
        "model8.save_model(\"final_models/3anomaly-classifier8\")\n",
        "print('Model 8 saved')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{1: 0, 2: 1, 4: 2, 5: 3, 6: 4, 7: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(38340,)\n",
            "{1: 0, 2: 1, 4: 2, 5: 3, 6: 4, 7: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9606,)\n",
            "Epoch 1/20\n",
            "1199/1199 [==============================] - 45s 31ms/step - loss: 3.5449 - accuracy: 0.8636 - val_loss: 0.1443 - val_accuracy: 0.9666\n",
            "Epoch 2/20\n",
            "1199/1199 [==============================] - 38s 32ms/step - loss: 0.1130 - accuracy: 0.9732 - val_loss: 0.0815 - val_accuracy: 0.9738\n",
            "Epoch 3/20\n",
            "1199/1199 [==============================] - 39s 33ms/step - loss: 0.0700 - accuracy: 0.9803 - val_loss: 0.0888 - val_accuracy: 0.9740\n",
            "Epoch 4/20\n",
            "1199/1199 [==============================] - 39s 32ms/step - loss: 0.0593 - accuracy: 0.9821 - val_loss: 0.2302 - val_accuracy: 0.9469\n",
            "Epoch 5/20\n",
            "1199/1199 [==============================] - 39s 32ms/step - loss: 0.0583 - accuracy: 0.9825 - val_loss: 0.0800 - val_accuracy: 0.9766\n",
            "Epoch 6/20\n",
            "1199/1199 [==============================] - 39s 32ms/step - loss: 0.0602 - accuracy: 0.9819 - val_loss: 0.0666 - val_accuracy: 0.9833\n",
            "Epoch 7/20\n",
            "1199/1199 [==============================] - 39s 32ms/step - loss: 0.0478 - accuracy: 0.9849 - val_loss: 0.1245 - val_accuracy: 0.9733\n",
            "Epoch 8/20\n",
            "1199/1199 [==============================] - 39s 32ms/step - loss: 0.0490 - accuracy: 0.9853 - val_loss: 0.1205 - val_accuracy: 0.9699\n",
            "Epoch 9/20\n",
            "1199/1199 [==============================] - 39s 32ms/step - loss: 0.0375 - accuracy: 0.9886 - val_loss: 0.0857 - val_accuracy: 0.9773\n",
            "Epoch 10/20\n",
            "1199/1199 [==============================] - 39s 32ms/step - loss: 0.0328 - accuracy: 0.9896 - val_loss: 0.0684 - val_accuracy: 0.9837\n",
            "Epoch 11/20\n",
            "1199/1199 [==============================] - 39s 32ms/step - loss: 0.0296 - accuracy: 0.9906 - val_loss: 0.0766 - val_accuracy: 0.9823\n",
            "Epoch 12/20\n",
            "1199/1199 [==============================] - 39s 32ms/step - loss: 0.0309 - accuracy: 0.9900 - val_loss: 0.0662 - val_accuracy: 0.9851\n",
            "Epoch 13/20\n",
            "1199/1199 [==============================] - 39s 32ms/step - loss: 0.0251 - accuracy: 0.9919 - val_loss: 0.0754 - val_accuracy: 0.9812\n",
            "Epoch 14/20\n",
            "1199/1199 [==============================] - 39s 32ms/step - loss: 0.0209 - accuracy: 0.9933 - val_loss: 0.1134 - val_accuracy: 0.9746\n",
            "Epoch 15/20\n",
            "1199/1199 [==============================] - 39s 32ms/step - loss: 0.0221 - accuracy: 0.9937 - val_loss: 0.0839 - val_accuracy: 0.9833\n",
            "Epoch 16/20\n",
            "1199/1199 [==============================] - 39s 32ms/step - loss: 0.0236 - accuracy: 0.9936 - val_loss: 0.0893 - val_accuracy: 0.9843\n",
            "Epoch 17/20\n",
            "1199/1199 [==============================] - 39s 32ms/step - loss: 0.0213 - accuracy: 0.9926 - val_loss: 0.0859 - val_accuracy: 0.9790\n",
            "Epoch 18/20\n",
            "1199/1199 [==============================] - 39s 32ms/step - loss: 0.0212 - accuracy: 0.9932 - val_loss: 0.0723 - val_accuracy: 0.9830\n",
            "Epoch 19/20\n",
            "1199/1199 [==============================] - 39s 32ms/step - loss: 0.0191 - accuracy: 0.9937 - val_loss: 0.1085 - val_accuracy: 0.9802\n",
            "Epoch 20/20\n",
            "1199/1199 [==============================] - 39s 32ms/step - loss: 0.0167 - accuracy: 0.9950 - val_loss: 0.0727 - val_accuracy: 0.9837\n",
            "INFO:tensorflow:Assets written to: final_models/3anomaly-classifier0/assets\n",
            "Model 0 saved\n",
            "{0: 0, 2: 1, 4: 2, 5: 3, 6: 4, 7: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(37668,)\n",
            "{0: 0, 2: 1, 4: 2, 5: 3, 6: 4, 7: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9459,)\n",
            "Epoch 1/20\n",
            "1178/1178 [==============================] - 39s 33ms/step - loss: 6.0100 - accuracy: 0.7919 - val_loss: 0.1399 - val_accuracy: 0.9747\n",
            "Epoch 2/20\n",
            "1178/1178 [==============================] - 38s 32ms/step - loss: 0.1496 - accuracy: 0.9692 - val_loss: 0.0908 - val_accuracy: 0.9734\n",
            "Epoch 3/20\n",
            "1178/1178 [==============================] - 38s 32ms/step - loss: 0.0888 - accuracy: 0.9780 - val_loss: 0.0858 - val_accuracy: 0.9772\n",
            "Epoch 4/20\n",
            "1178/1178 [==============================] - 38s 32ms/step - loss: 0.0725 - accuracy: 0.9808 - val_loss: 0.0743 - val_accuracy: 0.9766\n",
            "Epoch 5/20\n",
            "1178/1178 [==============================] - 38s 32ms/step - loss: 0.0695 - accuracy: 0.9799 - val_loss: 0.2451 - val_accuracy: 0.9478\n",
            "Epoch 6/20\n",
            "1178/1178 [==============================] - 38s 32ms/step - loss: 0.0546 - accuracy: 0.9840 - val_loss: 0.0673 - val_accuracy: 0.9808\n",
            "Epoch 7/20\n",
            "1178/1178 [==============================] - 38s 32ms/step - loss: 0.0543 - accuracy: 0.9840 - val_loss: 0.1862 - val_accuracy: 0.9599\n",
            "Epoch 8/20\n",
            "1178/1178 [==============================] - 38s 32ms/step - loss: 0.0487 - accuracy: 0.9851 - val_loss: 0.0536 - val_accuracy: 0.9853\n",
            "Epoch 9/20\n",
            "1178/1178 [==============================] - 38s 32ms/step - loss: 0.0490 - accuracy: 0.9866 - val_loss: 0.1031 - val_accuracy: 0.9762\n",
            "Epoch 10/20\n",
            "1178/1178 [==============================] - 38s 32ms/step - loss: 0.0375 - accuracy: 0.9883 - val_loss: 0.0517 - val_accuracy: 0.9850\n",
            "Epoch 11/20\n",
            "1178/1178 [==============================] - 38s 33ms/step - loss: 0.0341 - accuracy: 0.9887 - val_loss: 0.0776 - val_accuracy: 0.9818\n",
            "Epoch 12/20\n",
            "1178/1178 [==============================] - 38s 32ms/step - loss: 0.0309 - accuracy: 0.9904 - val_loss: 0.0884 - val_accuracy: 0.9812\n",
            "Epoch 13/20\n",
            "1178/1178 [==============================] - 38s 33ms/step - loss: 0.0269 - accuracy: 0.9926 - val_loss: 0.0660 - val_accuracy: 0.9836\n",
            "Epoch 14/20\n",
            "1178/1178 [==============================] - 38s 32ms/step - loss: 0.0242 - accuracy: 0.9918 - val_loss: 0.1372 - val_accuracy: 0.9730\n",
            "Epoch 15/20\n",
            "1178/1178 [==============================] - 38s 33ms/step - loss: 0.0245 - accuracy: 0.9921 - val_loss: 0.0701 - val_accuracy: 0.9845\n",
            "Epoch 16/20\n",
            "1178/1178 [==============================] - 38s 32ms/step - loss: 0.0225 - accuracy: 0.9927 - val_loss: 0.0648 - val_accuracy: 0.9858\n",
            "Epoch 17/20\n",
            "1178/1178 [==============================] - 38s 33ms/step - loss: 0.0184 - accuracy: 0.9942 - val_loss: 0.0962 - val_accuracy: 0.9794\n",
            "Epoch 18/20\n",
            "1178/1178 [==============================] - 38s 32ms/step - loss: 0.0172 - accuracy: 0.9943 - val_loss: 0.0787 - val_accuracy: 0.9850\n",
            "Epoch 19/20\n",
            "1178/1178 [==============================] - 38s 32ms/step - loss: 0.0169 - accuracy: 0.9951 - val_loss: 0.0587 - val_accuracy: 0.9878\n",
            "Epoch 20/20\n",
            "1178/1178 [==============================] - 38s 32ms/step - loss: 0.0172 - accuracy: 0.9944 - val_loss: 0.0700 - val_accuracy: 0.9839\n",
            "INFO:tensorflow:Assets written to: final_models/3anomaly-classifier1/assets\n",
            "Model 1 saved\n",
            "{0: 0, 1: 1, 4: 2, 5: 3, 6: 4, 7: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(38304,)\n",
            "{0: 0, 1: 1, 4: 2, 5: 3, 6: 4, 7: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9607,)\n",
            "Epoch 1/20\n",
            "1197/1197 [==============================] - 40s 33ms/step - loss: 3.7032 - accuracy: 0.8625 - val_loss: 0.1436 - val_accuracy: 0.9616\n",
            "Epoch 2/20\n",
            "1197/1197 [==============================] - 39s 33ms/step - loss: 0.0813 - accuracy: 0.9782 - val_loss: 0.1965 - val_accuracy: 0.9477\n",
            "Epoch 3/20\n",
            "1197/1197 [==============================] - 39s 33ms/step - loss: 0.0593 - accuracy: 0.9832 - val_loss: 0.0949 - val_accuracy: 0.9751\n",
            "Epoch 4/20\n",
            "1197/1197 [==============================] - 39s 33ms/step - loss: 0.0614 - accuracy: 0.9816 - val_loss: 0.0717 - val_accuracy: 0.9814\n",
            "Epoch 5/20\n",
            "1197/1197 [==============================] - 39s 33ms/step - loss: 0.0539 - accuracy: 0.9836 - val_loss: 0.1466 - val_accuracy: 0.9687\n",
            "Epoch 6/20\n",
            "1197/1197 [==============================] - 39s 33ms/step - loss: 0.0586 - accuracy: 0.9830 - val_loss: 0.0655 - val_accuracy: 0.9824\n",
            "Epoch 7/20\n",
            "1197/1197 [==============================] - 39s 33ms/step - loss: 0.0473 - accuracy: 0.9853 - val_loss: 0.0572 - val_accuracy: 0.9848\n",
            "Epoch 8/20\n",
            "1197/1197 [==============================] - 39s 33ms/step - loss: 0.0378 - accuracy: 0.9889 - val_loss: 0.1407 - val_accuracy: 0.9647\n",
            "Epoch 9/20\n",
            "1197/1197 [==============================] - 39s 33ms/step - loss: 0.0400 - accuracy: 0.9869 - val_loss: 0.0838 - val_accuracy: 0.9792\n",
            "Epoch 10/20\n",
            "1197/1197 [==============================] - 39s 33ms/step - loss: 0.0332 - accuracy: 0.9890 - val_loss: 0.1037 - val_accuracy: 0.9774\n",
            "Epoch 11/20\n",
            "1197/1197 [==============================] - 39s 33ms/step - loss: 0.0275 - accuracy: 0.9918 - val_loss: 0.0954 - val_accuracy: 0.9781\n",
            "Epoch 12/20\n",
            "1197/1197 [==============================] - 39s 33ms/step - loss: 0.0254 - accuracy: 0.9920 - val_loss: 0.0850 - val_accuracy: 0.9814\n",
            "Epoch 13/20\n",
            "1197/1197 [==============================] - 39s 33ms/step - loss: 0.0220 - accuracy: 0.9926 - val_loss: 0.0659 - val_accuracy: 0.9843\n",
            "Epoch 14/20\n",
            "1197/1197 [==============================] - 39s 33ms/step - loss: 0.0247 - accuracy: 0.9916 - val_loss: 0.0787 - val_accuracy: 0.9849\n",
            "Epoch 15/20\n",
            "1197/1197 [==============================] - 39s 33ms/step - loss: 0.0191 - accuracy: 0.9934 - val_loss: 0.0595 - val_accuracy: 0.9889\n",
            "Epoch 16/20\n",
            "1197/1197 [==============================] - 39s 33ms/step - loss: 0.0222 - accuracy: 0.9938 - val_loss: 0.0844 - val_accuracy: 0.9837\n",
            "Epoch 17/20\n",
            "1197/1197 [==============================] - 39s 33ms/step - loss: 0.0174 - accuracy: 0.9943 - val_loss: 0.0885 - val_accuracy: 0.9826\n",
            "Epoch 18/20\n",
            "1197/1197 [==============================] - 39s 33ms/step - loss: 0.0221 - accuracy: 0.9933 - val_loss: 0.0759 - val_accuracy: 0.9849\n",
            "Epoch 19/20\n",
            "1197/1197 [==============================] - 39s 33ms/step - loss: 0.0151 - accuracy: 0.9960 - val_loss: 0.0904 - val_accuracy: 0.9838\n",
            "Epoch 20/20\n",
            "1197/1197 [==============================] - 39s 33ms/step - loss: 0.0169 - accuracy: 0.9948 - val_loss: 0.0606 - val_accuracy: 0.9868\n",
            "INFO:tensorflow:Assets written to: final_models/3anomaly-classifier2/assets\n",
            "Model 2 saved\n",
            "{0: 0, 1: 1, 2: 2, 5: 3, 6: 4, 7: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(38422,)\n",
            "{0: 0, 1: 1, 2: 2, 5: 3, 6: 4, 7: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9605,)\n",
            "Epoch 1/20\n",
            "1201/1201 [==============================] - 41s 33ms/step - loss: 4.2903 - accuracy: 0.8435 - val_loss: 0.1883 - val_accuracy: 0.9693\n",
            "Epoch 2/20\n",
            "1201/1201 [==============================] - 39s 32ms/step - loss: 0.1275 - accuracy: 0.9747 - val_loss: 0.0815 - val_accuracy: 0.9771\n",
            "Epoch 3/20\n",
            "1201/1201 [==============================] - 39s 32ms/step - loss: 0.0573 - accuracy: 0.9832 - val_loss: 0.0643 - val_accuracy: 0.9819\n",
            "Epoch 4/20\n",
            "1201/1201 [==============================] - 39s 32ms/step - loss: 0.0521 - accuracy: 0.9845 - val_loss: 0.1404 - val_accuracy: 0.9651\n",
            "Epoch 5/20\n",
            "1201/1201 [==============================] - 39s 33ms/step - loss: 0.0523 - accuracy: 0.9837 - val_loss: 0.1111 - val_accuracy: 0.9690\n",
            "Epoch 6/20\n",
            "1201/1201 [==============================] - 39s 32ms/step - loss: 0.0564 - accuracy: 0.9839 - val_loss: 0.1420 - val_accuracy: 0.9646\n",
            "Epoch 7/20\n",
            "1201/1201 [==============================] - 39s 32ms/step - loss: 0.0465 - accuracy: 0.9863 - val_loss: 0.1138 - val_accuracy: 0.9716\n",
            "Epoch 8/20\n",
            "1201/1201 [==============================] - 39s 32ms/step - loss: 0.0460 - accuracy: 0.9864 - val_loss: 0.1291 - val_accuracy: 0.9706\n",
            "Epoch 9/20\n",
            "1201/1201 [==============================] - 39s 32ms/step - loss: 0.0387 - accuracy: 0.9886 - val_loss: 0.1712 - val_accuracy: 0.9607\n",
            "Epoch 10/20\n",
            "1201/1201 [==============================] - 39s 32ms/step - loss: 0.0327 - accuracy: 0.9893 - val_loss: 0.2991 - val_accuracy: 0.9500\n",
            "Epoch 11/20\n",
            "1201/1201 [==============================] - 39s 32ms/step - loss: 0.0310 - accuracy: 0.9903 - val_loss: 0.1003 - val_accuracy: 0.9752\n",
            "Epoch 12/20\n",
            "1201/1201 [==============================] - 39s 32ms/step - loss: 0.0282 - accuracy: 0.9904 - val_loss: 0.1826 - val_accuracy: 0.9647\n",
            "Epoch 13/20\n",
            "1201/1201 [==============================] - 39s 32ms/step - loss: 0.0219 - accuracy: 0.9929 - val_loss: 0.0900 - val_accuracy: 0.9784\n",
            "Epoch 14/20\n",
            "1201/1201 [==============================] - 39s 32ms/step - loss: 0.0228 - accuracy: 0.9929 - val_loss: 0.1699 - val_accuracy: 0.9664\n",
            "Epoch 15/20\n",
            "1201/1201 [==============================] - 39s 32ms/step - loss: 0.0210 - accuracy: 0.9938 - val_loss: 0.1436 - val_accuracy: 0.9707\n",
            "Epoch 16/20\n",
            "1201/1201 [==============================] - 39s 33ms/step - loss: 0.0190 - accuracy: 0.9932 - val_loss: 0.0655 - val_accuracy: 0.9855\n",
            "Epoch 17/20\n",
            "1201/1201 [==============================] - 39s 32ms/step - loss: 0.0186 - accuracy: 0.9937 - val_loss: 0.0999 - val_accuracy: 0.9779\n",
            "Epoch 18/20\n",
            "1201/1201 [==============================] - 39s 32ms/step - loss: 0.0154 - accuracy: 0.9952 - val_loss: 0.1376 - val_accuracy: 0.9750\n",
            "Epoch 19/20\n",
            "1201/1201 [==============================] - 39s 32ms/step - loss: 0.0168 - accuracy: 0.9949 - val_loss: 0.1148 - val_accuracy: 0.9776\n",
            "Epoch 20/20\n",
            "1201/1201 [==============================] - 39s 32ms/step - loss: 0.0173 - accuracy: 0.9950 - val_loss: 0.0838 - val_accuracy: 0.9831\n",
            "INFO:tensorflow:Assets written to: final_models/3anomaly-classifier3/assets\n",
            "Model 3 saved\n",
            "{0: 0, 1: 1, 2: 2, 4: 3, 6: 4, 7: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(38771,)\n",
            "{0: 0, 1: 1, 2: 2, 4: 3, 6: 4, 7: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9677,)\n",
            "Epoch 1/20\n",
            "1212/1212 [==============================] - 41s 33ms/step - loss: 4.5289 - accuracy: 0.8454 - val_loss: 0.2004 - val_accuracy: 0.9655\n",
            "Epoch 2/20\n",
            "1212/1212 [==============================] - 39s 32ms/step - loss: 0.1383 - accuracy: 0.9723 - val_loss: 0.1123 - val_accuracy: 0.9695\n",
            "Epoch 3/20\n",
            "1212/1212 [==============================] - 39s 32ms/step - loss: 0.0592 - accuracy: 0.9829 - val_loss: 0.0977 - val_accuracy: 0.9749\n",
            "Epoch 4/20\n",
            "1212/1212 [==============================] - 39s 32ms/step - loss: 0.0691 - accuracy: 0.9807 - val_loss: 0.1552 - val_accuracy: 0.9656\n",
            "Epoch 5/20\n",
            "1212/1212 [==============================] - 39s 33ms/step - loss: 0.0579 - accuracy: 0.9836 - val_loss: 0.1003 - val_accuracy: 0.9707\n",
            "Epoch 6/20\n",
            "1212/1212 [==============================] - 39s 32ms/step - loss: 0.0504 - accuracy: 0.9852 - val_loss: 0.1144 - val_accuracy: 0.9724\n",
            "Epoch 7/20\n",
            "1212/1212 [==============================] - 39s 32ms/step - loss: 0.0517 - accuracy: 0.9851 - val_loss: 0.1348 - val_accuracy: 0.9695\n",
            "Epoch 8/20\n",
            "1212/1212 [==============================] - 39s 32ms/step - loss: 0.0429 - accuracy: 0.9878 - val_loss: 0.0642 - val_accuracy: 0.9812\n",
            "Epoch 9/20\n",
            "1212/1212 [==============================] - 39s 32ms/step - loss: 0.0390 - accuracy: 0.9868 - val_loss: 0.0892 - val_accuracy: 0.9753\n",
            "Epoch 10/20\n",
            "1212/1212 [==============================] - 39s 32ms/step - loss: 0.0348 - accuracy: 0.9887 - val_loss: 0.0692 - val_accuracy: 0.9832\n",
            "Epoch 11/20\n",
            "1212/1212 [==============================] - 39s 32ms/step - loss: 0.0380 - accuracy: 0.9881 - val_loss: 0.0954 - val_accuracy: 0.9757\n",
            "Epoch 12/20\n",
            "1212/1212 [==============================] - 39s 32ms/step - loss: 0.0309 - accuracy: 0.9897 - val_loss: 0.0607 - val_accuracy: 0.9869\n",
            "Epoch 13/20\n",
            "1212/1212 [==============================] - 39s 32ms/step - loss: 0.0263 - accuracy: 0.9916 - val_loss: 0.0765 - val_accuracy: 0.9842\n",
            "Epoch 14/20\n",
            "1212/1212 [==============================] - 39s 32ms/step - loss: 0.0240 - accuracy: 0.9933 - val_loss: 0.0920 - val_accuracy: 0.9835\n",
            "Epoch 15/20\n",
            "1212/1212 [==============================] - 39s 32ms/step - loss: 0.0222 - accuracy: 0.9930 - val_loss: 0.0702 - val_accuracy: 0.9860\n",
            "Epoch 16/20\n",
            "1212/1212 [==============================] - 39s 32ms/step - loss: 0.0211 - accuracy: 0.9936 - val_loss: 0.0662 - val_accuracy: 0.9841\n",
            "Epoch 17/20\n",
            "1212/1212 [==============================] - 39s 32ms/step - loss: 0.0207 - accuracy: 0.9941 - val_loss: 0.0719 - val_accuracy: 0.9859\n",
            "Epoch 18/20\n",
            "1212/1212 [==============================] - 39s 32ms/step - loss: 0.0178 - accuracy: 0.9944 - val_loss: 0.0650 - val_accuracy: 0.9866\n",
            "Epoch 19/20\n",
            "1212/1212 [==============================] - 39s 32ms/step - loss: 0.0190 - accuracy: 0.9936 - val_loss: 0.0747 - val_accuracy: 0.9847\n",
            "Epoch 20/20\n",
            "1212/1212 [==============================] - 39s 32ms/step - loss: 0.0145 - accuracy: 0.9955 - val_loss: 0.0642 - val_accuracy: 0.9881\n",
            "INFO:tensorflow:Assets written to: final_models/3anomaly-classifier4/assets\n",
            "Model 4 saved\n",
            "{0: 0, 1: 1, 2: 2, 4: 3, 5: 4, 7: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(38347,)\n",
            "{0: 0, 1: 1, 2: 2, 4: 3, 5: 4, 7: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9604,)\n",
            "Epoch 1/20\n",
            "1199/1199 [==============================] - 40s 33ms/step - loss: 6.0440 - accuracy: 0.8279 - val_loss: 0.3117 - val_accuracy: 0.9621\n",
            "Epoch 2/20\n",
            "1199/1199 [==============================] - 39s 32ms/step - loss: 0.1953 - accuracy: 0.9710 - val_loss: 0.0844 - val_accuracy: 0.9805\n",
            "Epoch 3/20\n",
            "1199/1199 [==============================] - 39s 32ms/step - loss: 0.0680 - accuracy: 0.9814 - val_loss: 0.0967 - val_accuracy: 0.9766\n",
            "Epoch 4/20\n",
            "1199/1199 [==============================] - 39s 32ms/step - loss: 0.0573 - accuracy: 0.9835 - val_loss: 0.0887 - val_accuracy: 0.9805\n",
            "Epoch 5/20\n",
            "1199/1199 [==============================] - 39s 32ms/step - loss: 0.0579 - accuracy: 0.9833 - val_loss: 0.1388 - val_accuracy: 0.9625\n",
            "Epoch 6/20\n",
            "1199/1199 [==============================] - 39s 32ms/step - loss: 0.0553 - accuracy: 0.9832 - val_loss: 0.2007 - val_accuracy: 0.9569\n",
            "Epoch 7/20\n",
            "1199/1199 [==============================] - 39s 32ms/step - loss: 0.0496 - accuracy: 0.9853 - val_loss: 0.1095 - val_accuracy: 0.9771\n",
            "Epoch 8/20\n",
            "1199/1199 [==============================] - 39s 32ms/step - loss: 0.0428 - accuracy: 0.9867 - val_loss: 0.0973 - val_accuracy: 0.9792\n",
            "Epoch 9/20\n",
            "1199/1199 [==============================] - 39s 32ms/step - loss: 0.0419 - accuracy: 0.9866 - val_loss: 0.0742 - val_accuracy: 0.9816\n",
            "Epoch 10/20\n",
            "1199/1199 [==============================] - 39s 32ms/step - loss: 0.0373 - accuracy: 0.9888 - val_loss: 0.1154 - val_accuracy: 0.9726\n",
            "Epoch 11/20\n",
            "1199/1199 [==============================] - 39s 32ms/step - loss: 0.0310 - accuracy: 0.9907 - val_loss: 0.1030 - val_accuracy: 0.9780\n",
            "Epoch 12/20\n",
            "1199/1199 [==============================] - 39s 32ms/step - loss: 0.0343 - accuracy: 0.9903 - val_loss: 0.0778 - val_accuracy: 0.9834\n",
            "Epoch 13/20\n",
            "1199/1199 [==============================] - 39s 32ms/step - loss: 0.0326 - accuracy: 0.9902 - val_loss: 0.0778 - val_accuracy: 0.9846\n",
            "Epoch 14/20\n",
            "1199/1199 [==============================] - 39s 32ms/step - loss: 0.0276 - accuracy: 0.9911 - val_loss: 0.1179 - val_accuracy: 0.9683\n",
            "Epoch 15/20\n",
            "1199/1199 [==============================] - 39s 32ms/step - loss: 0.0223 - accuracy: 0.9928 - val_loss: 0.2202 - val_accuracy: 0.9497\n",
            "Epoch 16/20\n",
            "1199/1199 [==============================] - 39s 32ms/step - loss: 0.0225 - accuracy: 0.9931 - val_loss: 0.0979 - val_accuracy: 0.9772\n",
            "Epoch 17/20\n",
            "1199/1199 [==============================] - 39s 33ms/step - loss: 0.0206 - accuracy: 0.9943 - val_loss: 0.0867 - val_accuracy: 0.9799\n",
            "Epoch 18/20\n",
            "1199/1199 [==============================] - 39s 32ms/step - loss: 0.0183 - accuracy: 0.9941 - val_loss: 0.1249 - val_accuracy: 0.9777\n",
            "Epoch 19/20\n",
            "1199/1199 [==============================] - 39s 32ms/step - loss: 0.0172 - accuracy: 0.9949 - val_loss: 0.0890 - val_accuracy: 0.9833\n",
            "Epoch 20/20\n",
            "1199/1199 [==============================] - 39s 32ms/step - loss: 0.0165 - accuracy: 0.9949 - val_loss: 0.0891 - val_accuracy: 0.9804\n",
            "INFO:tensorflow:Assets written to: final_models/3anomaly-classifier5/assets\n",
            "Model 5 saved\n",
            "{0: 0, 1: 1, 2: 2, 4: 3, 5: 4, 6: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(38122,)\n",
            "{0: 0, 1: 1, 2: 2, 4: 3, 5: 4, 6: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9482,)\n",
            "Epoch 1/20\n",
            "1192/1192 [==============================] - 40s 33ms/step - loss: 6.3658 - accuracy: 0.7838 - val_loss: 0.2389 - val_accuracy: 0.9679\n",
            "Epoch 2/20\n",
            "1192/1192 [==============================] - 39s 32ms/step - loss: 0.2096 - accuracy: 0.9705 - val_loss: 0.1079 - val_accuracy: 0.9737\n",
            "Epoch 3/20\n",
            "1192/1192 [==============================] - 39s 32ms/step - loss: 0.0801 - accuracy: 0.9803 - val_loss: 0.3354 - val_accuracy: 0.9014\n",
            "Epoch 4/20\n",
            "1192/1192 [==============================] - 39s 32ms/step - loss: 0.0589 - accuracy: 0.9832 - val_loss: 0.1339 - val_accuracy: 0.9652\n",
            "Epoch 5/20\n",
            "1192/1192 [==============================] - 39s 32ms/step - loss: 0.0597 - accuracy: 0.9822 - val_loss: 0.0871 - val_accuracy: 0.9784\n",
            "Epoch 6/20\n",
            "1192/1192 [==============================] - 39s 32ms/step - loss: 0.0552 - accuracy: 0.9829 - val_loss: 0.1035 - val_accuracy: 0.9770\n",
            "Epoch 7/20\n",
            "1192/1192 [==============================] - 39s 32ms/step - loss: 0.0474 - accuracy: 0.9854 - val_loss: 0.1416 - val_accuracy: 0.9657\n",
            "Epoch 8/20\n",
            "1192/1192 [==============================] - 39s 32ms/step - loss: 0.0493 - accuracy: 0.9846 - val_loss: 0.0782 - val_accuracy: 0.9784\n",
            "Epoch 9/20\n",
            "1192/1192 [==============================] - 39s 32ms/step - loss: 0.0397 - accuracy: 0.9873 - val_loss: 0.1315 - val_accuracy: 0.9726\n",
            "Epoch 10/20\n",
            "1192/1192 [==============================] - 39s 32ms/step - loss: 0.0415 - accuracy: 0.9875 - val_loss: 0.3366 - val_accuracy: 0.9337\n",
            "Epoch 11/20\n",
            "1192/1192 [==============================] - 39s 32ms/step - loss: 0.0288 - accuracy: 0.9908 - val_loss: 0.2601 - val_accuracy: 0.9505\n",
            "Epoch 12/20\n",
            "1192/1192 [==============================] - 39s 32ms/step - loss: 0.0277 - accuracy: 0.9910 - val_loss: 0.1008 - val_accuracy: 0.9747\n",
            "Epoch 13/20\n",
            "1192/1192 [==============================] - 39s 32ms/step - loss: 0.0270 - accuracy: 0.9915 - val_loss: 0.2910 - val_accuracy: 0.9463\n",
            "Epoch 14/20\n",
            "1192/1192 [==============================] - 39s 32ms/step - loss: 0.0239 - accuracy: 0.9923 - val_loss: 0.3233 - val_accuracy: 0.9534\n",
            "Epoch 15/20\n",
            "1192/1192 [==============================] - 39s 32ms/step - loss: 0.0246 - accuracy: 0.9919 - val_loss: 0.0763 - val_accuracy: 0.9841\n",
            "Epoch 16/20\n",
            "1192/1192 [==============================] - 39s 32ms/step - loss: 0.0175 - accuracy: 0.9944 - val_loss: 0.1073 - val_accuracy: 0.9796\n",
            "Epoch 17/20\n",
            "1192/1192 [==============================] - 38s 32ms/step - loss: 0.0209 - accuracy: 0.9935 - val_loss: 0.0891 - val_accuracy: 0.9813\n",
            "Epoch 18/20\n",
            "1192/1192 [==============================] - 39s 32ms/step - loss: 0.0176 - accuracy: 0.9945 - val_loss: 0.1205 - val_accuracy: 0.9779\n",
            "Epoch 19/20\n",
            "1192/1192 [==============================] - 39s 32ms/step - loss: 0.0186 - accuracy: 0.9943 - val_loss: 0.0704 - val_accuracy: 0.9868\n",
            "Epoch 20/20\n",
            "1192/1192 [==============================] - 39s 32ms/step - loss: 0.0172 - accuracy: 0.9949 - val_loss: 0.1232 - val_accuracy: 0.9784\n",
            "INFO:tensorflow:Assets written to: final_models/3anomaly-classifier6/assets\n",
            "Model 6 saved\n",
            "{0: 0, 1: 1, 2: 2, 4: 3, 5: 4, 6: 5, 7: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(38397,)\n",
            "{0: 0, 1: 1, 2: 2, 4: 3, 5: 4, 6: 5, 7: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9621,)\n",
            "Epoch 1/20\n",
            "1200/1200 [==============================] - 40s 33ms/step - loss: 5.1931 - accuracy: 0.8471 - val_loss: 0.1281 - val_accuracy: 0.9729\n",
            "Epoch 2/20\n",
            "1200/1200 [==============================] - 39s 32ms/step - loss: 0.1096 - accuracy: 0.9778 - val_loss: 0.0850 - val_accuracy: 0.9731\n",
            "Epoch 3/20\n",
            "1200/1200 [==============================] - 39s 32ms/step - loss: 0.0592 - accuracy: 0.9827 - val_loss: 0.1494 - val_accuracy: 0.9627\n",
            "Epoch 4/20\n",
            "1200/1200 [==============================] - 39s 32ms/step - loss: 0.0520 - accuracy: 0.9853 - val_loss: 0.0560 - val_accuracy: 0.9853\n",
            "Epoch 5/20\n",
            "1200/1200 [==============================] - 39s 33ms/step - loss: 0.0560 - accuracy: 0.9837 - val_loss: 0.0761 - val_accuracy: 0.9808\n",
            "Epoch 6/20\n",
            "1200/1200 [==============================] - 39s 33ms/step - loss: 0.0569 - accuracy: 0.9831 - val_loss: 0.0984 - val_accuracy: 0.9771\n",
            "Epoch 7/20\n",
            "1200/1200 [==============================] - 39s 33ms/step - loss: 0.0515 - accuracy: 0.9842 - val_loss: 0.0937 - val_accuracy: 0.9777\n",
            "Epoch 8/20\n",
            "1200/1200 [==============================] - 39s 32ms/step - loss: 0.0429 - accuracy: 0.9869 - val_loss: 0.1250 - val_accuracy: 0.9735\n",
            "Epoch 9/20\n",
            "1200/1200 [==============================] - 39s 32ms/step - loss: 0.0377 - accuracy: 0.9884 - val_loss: 0.0735 - val_accuracy: 0.9820\n",
            "Epoch 10/20\n",
            "1200/1200 [==============================] - 39s 32ms/step - loss: 0.0353 - accuracy: 0.9886 - val_loss: 0.0769 - val_accuracy: 0.9817\n",
            "Epoch 11/20\n",
            "1200/1200 [==============================] - 39s 32ms/step - loss: 0.0311 - accuracy: 0.9913 - val_loss: 0.0629 - val_accuracy: 0.9840\n",
            "Epoch 12/20\n",
            "1200/1200 [==============================] - 39s 32ms/step - loss: 0.0309 - accuracy: 0.9892 - val_loss: 0.0594 - val_accuracy: 0.9857\n",
            "Epoch 13/20\n",
            "1200/1200 [==============================] - 39s 32ms/step - loss: 0.0277 - accuracy: 0.9912 - val_loss: 0.1583 - val_accuracy: 0.9717\n",
            "Epoch 14/20\n",
            "1200/1200 [==============================] - 39s 32ms/step - loss: 0.0260 - accuracy: 0.9918 - val_loss: 0.0771 - val_accuracy: 0.9865\n",
            "Epoch 15/20\n",
            "1200/1200 [==============================] - 39s 32ms/step - loss: 0.0263 - accuracy: 0.9921 - val_loss: 0.0722 - val_accuracy: 0.9837\n",
            "Epoch 16/20\n",
            "1200/1200 [==============================] - 39s 32ms/step - loss: 0.0182 - accuracy: 0.9939 - val_loss: 0.1357 - val_accuracy: 0.9740\n",
            "Epoch 17/20\n",
            "1200/1200 [==============================] - 39s 32ms/step - loss: 0.0203 - accuracy: 0.9934 - val_loss: 0.0713 - val_accuracy: 0.9860\n",
            "Epoch 18/20\n",
            "1200/1200 [==============================] - 39s 32ms/step - loss: 0.0176 - accuracy: 0.9947 - val_loss: 0.0716 - val_accuracy: 0.9837\n",
            "Epoch 19/20\n",
            "1200/1200 [==============================] - 39s 32ms/step - loss: 0.0141 - accuracy: 0.9954 - val_loss: 0.0883 - val_accuracy: 0.9830\n",
            "Epoch 20/20\n",
            "1200/1200 [==============================] - 39s 32ms/step - loss: 0.0158 - accuracy: 0.9953 - val_loss: 0.1188 - val_accuracy: 0.9816\n",
            "INFO:tensorflow:Assets written to: final_models/3anomaly-classifier7/assets\n",
            "Model 7 saved\n",
            "{0: 0, 1: 1, 2: 2, 4: 3, 5: 4, 6: 5, 7: 6, 8: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(38333,)\n",
            "{0: 0, 1: 1, 2: 2, 4: 3, 5: 4, 6: 5, 7: 6, 8: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9587,)\n",
            "Epoch 1/20\n",
            "1198/1198 [==============================] - 40s 33ms/step - loss: 4.2559 - accuracy: 0.8631 - val_loss: 0.1696 - val_accuracy: 0.9670\n",
            "Epoch 2/20\n",
            "1198/1198 [==============================] - 39s 32ms/step - loss: 0.0884 - accuracy: 0.9785 - val_loss: 0.1710 - val_accuracy: 0.9566\n",
            "Epoch 3/20\n",
            "1198/1198 [==============================] - 39s 33ms/step - loss: 0.0568 - accuracy: 0.9842 - val_loss: 0.0954 - val_accuracy: 0.9771\n",
            "Epoch 4/20\n",
            "1198/1198 [==============================] - 39s 32ms/step - loss: 0.0590 - accuracy: 0.9847 - val_loss: 0.2756 - val_accuracy: 0.9438\n",
            "Epoch 5/20\n",
            "1198/1198 [==============================] - 39s 32ms/step - loss: 0.0518 - accuracy: 0.9856 - val_loss: 0.0710 - val_accuracy: 0.9798\n",
            "Epoch 6/20\n",
            "1198/1198 [==============================] - 39s 32ms/step - loss: 0.0485 - accuracy: 0.9857 - val_loss: 0.0640 - val_accuracy: 0.9820\n",
            "Epoch 7/20\n",
            "1198/1198 [==============================] - 39s 32ms/step - loss: 0.0423 - accuracy: 0.9858 - val_loss: 0.0928 - val_accuracy: 0.9752\n",
            "Epoch 8/20\n",
            "1198/1198 [==============================] - 39s 32ms/step - loss: 0.0383 - accuracy: 0.9883 - val_loss: 0.2202 - val_accuracy: 0.9522\n",
            "Epoch 9/20\n",
            "1198/1198 [==============================] - 39s 33ms/step - loss: 0.0371 - accuracy: 0.9886 - val_loss: 0.0993 - val_accuracy: 0.9796\n",
            "Epoch 10/20\n",
            "1198/1198 [==============================] - 39s 32ms/step - loss: 0.0322 - accuracy: 0.9897 - val_loss: 0.1012 - val_accuracy: 0.9775\n",
            "Epoch 11/20\n",
            "1198/1198 [==============================] - 39s 32ms/step - loss: 0.0344 - accuracy: 0.9895 - val_loss: 0.1968 - val_accuracy: 0.9573\n",
            "Epoch 12/20\n",
            "1198/1198 [==============================] - 39s 32ms/step - loss: 0.0243 - accuracy: 0.9923 - val_loss: 0.0913 - val_accuracy: 0.9809\n",
            "Epoch 13/20\n",
            "1198/1198 [==============================] - 39s 32ms/step - loss: 0.0260 - accuracy: 0.9929 - val_loss: 0.0644 - val_accuracy: 0.9847\n",
            "Epoch 14/20\n",
            "1198/1198 [==============================] - 39s 32ms/step - loss: 0.0184 - accuracy: 0.9941 - val_loss: 0.1021 - val_accuracy: 0.9805\n",
            "Epoch 15/20\n",
            "1198/1198 [==============================] - 39s 32ms/step - loss: 0.0190 - accuracy: 0.9941 - val_loss: 0.0945 - val_accuracy: 0.9813\n",
            "Epoch 16/20\n",
            "1198/1198 [==============================] - 39s 32ms/step - loss: 0.0163 - accuracy: 0.9946 - val_loss: 0.0657 - val_accuracy: 0.9845\n",
            "Epoch 17/20\n",
            "1198/1198 [==============================] - 39s 32ms/step - loss: 0.0170 - accuracy: 0.9947 - val_loss: 0.0640 - val_accuracy: 0.9870\n",
            "Epoch 18/20\n",
            "1198/1198 [==============================] - 39s 32ms/step - loss: 0.0166 - accuracy: 0.9950 - val_loss: 0.1953 - val_accuracy: 0.9720\n",
            "Epoch 19/20\n",
            "1198/1198 [==============================] - 39s 32ms/step - loss: 0.0144 - accuracy: 0.9951 - val_loss: 0.0860 - val_accuracy: 0.9844\n",
            "Epoch 20/20\n",
            "1198/1198 [==============================] - 39s 32ms/step - loss: 0.0139 - accuracy: 0.9949 - val_loss: 0.0665 - val_accuracy: 0.9879\n",
            "INFO:tensorflow:Assets written to: final_models/3anomaly-classifier8/assets\n",
            "Model 8 saved\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RyfHk4eYhSC"
      },
      "source": [
        "class_0 = model0.load_model(\"final_models/3anomaly-classifier0\")\n",
        "class_1 = model1.load_model(\"final_models/3anomaly-classifier1\")\n",
        "class_2 = model2.load_model(\"final_models/3anomaly-classifier2\")\n",
        "class_3 = model3.load_model(\"final_models/3anomaly-classifier3\")\n",
        "class_4 = model4.load_model(\"final_models/3anomaly-classifier4\")\n",
        "class_5 = model5.load_model(\"final_models/3anomaly-classifier5\")\n",
        "class_6 = model6.load_model(\"final_models/3anomaly-classifier6\")\n",
        "class_7 = model7.load_model(\"final_models/3anomaly-classifier7\")\n",
        "class_8 = model8.load_model(\"final_models/3anomaly-classifier8\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EeCd0otjYhSD",
        "outputId": "d39c6388-149a-4674-9a86-ef872f44a7b9"
      },
      "source": [
        "layer_name_list = []\n",
        "\n",
        "layer_name_list.append(class_0.layers[-2:][0].name)\n",
        "layer_name_list.append(class_1.layers[-2:][0].name)\n",
        "layer_name_list.append(class_2.layers[-2:][0].name)\n",
        "layer_name_list.append(class_3.layers[-2:][0].name)\n",
        "layer_name_list.append(class_4.layers[-2:][0].name)\n",
        "layer_name_list.append(class_5.layers[-2:][0].name)\n",
        "layer_name_list.append(class_6.layers[-2:][0].name)\n",
        "layer_name_list.append(class_7.layers[-2:][0].name)\n",
        "layer_name_list.append(class_8.layers[-2:][0].name)\n",
        "\n",
        "print(layer_name_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['dense_19', 'dense_21', 'dense_23', 'dense_25', 'dense_27', 'dense_29', 'dense_31', 'dense_33', 'dense_35']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEI5ENShYhSD"
      },
      "source": [
        "from keras import Model\n",
        "model_dict = {}\n",
        "model_output0 = class_0.get_layer(layer_name_list[0]).output\n",
        "m0 = Model(inputs=class_0.input, outputs=model_output0)\n",
        "model_dict[0] = m0\n",
        "\n",
        "model_output1 = class_1.get_layer(layer_name_list[1]).output\n",
        "m1 = Model(inputs=class_1.input, outputs=model_output1)\n",
        "model_dict[1] = m1\n",
        "\n",
        "model_output2 = class_2.get_layer(layer_name_list[2]).output\n",
        "m2 = Model(inputs=class_2.input, outputs=model_output2)\n",
        "model_dict[2] = m2\n",
        "\n",
        "model_output3 = class_3.get_layer(layer_name_list[3]).output\n",
        "m3 = Model(inputs=class_3.input, outputs=model_output3)\n",
        "model_dict[3] = m3\n",
        "\n",
        "model_output4 = class_4.get_layer(layer_name_list[4]).output\n",
        "m4 = Model(inputs=class_4.input, outputs=model_output4)\n",
        "model_dict[4] = m4\n",
        "\n",
        "model_output5 = class_5.get_layer(layer_name_list[5]).output\n",
        "m5 = Model(inputs=class_5.input, outputs=model_output5)\n",
        "model_dict[5] = m5\n",
        "\n",
        "model_output6 = class_6.get_layer(layer_name_list[6]).output\n",
        "m6 = Model(inputs=class_6.input, outputs=model_output6)\n",
        "model_dict[6] = m6\n",
        "\n",
        "model_output7 = class_7.get_layer(layer_name_list[7]).output\n",
        "m7 = Model(inputs=class_7.input, outputs=model_output7)\n",
        "model_dict[7] = m7\n",
        "\n",
        "model_output8 = class_8.get_layer(layer_name_list[8]).output\n",
        "m8 = Model(inputs=class_8.input, outputs=model_output8)\n",
        "model_dict[8] = m8\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gztVcVuCYhSD",
        "outputId": "4430022d-3f14-4c5f-f8c2-eb88d4fdfe31"
      },
      "source": [
        "temp_val = []\n",
        "y_pred = []\n",
        "labels = set(new_val_labels)\n",
        "for i, lo in zip(range(9), labels):\n",
        "  m = model_dict[i]\n",
        "  val_imgs_, val_lbls_ = get_train_data(lo, new_val_images, new_val_labels)\n",
        "  y_p = m.predict(val_imgs_)\n",
        "  y_pred.append(y_p)\n",
        "  temp = temp_cal(y_p, val_lbls_)\n",
        "  temp_val.append(temp)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{1: 0, 2: 1, 4: 2, 5: 3, 6: 4, 7: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9606,)\n",
            "Temperature Initial value: 1.0\n",
            "Temperature Final value: 1.931548833847046\n",
            "{0: 0, 2: 1, 4: 2, 5: 3, 6: 4, 7: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9459,)\n",
            "Temperature Initial value: 1.0\n",
            "Temperature Final value: 2.004016637802124\n",
            "{0: 0, 1: 1, 4: 2, 5: 3, 6: 4, 7: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9607,)\n",
            "Temperature Initial value: 1.0\n",
            "Temperature Final value: 1.7066195011138916\n",
            "{0: 0, 1: 1, 2: 2, 5: 3, 6: 4, 7: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9605,)\n",
            "Temperature Initial value: 1.0\n",
            "Temperature Final value: 2.3148810863494873\n",
            "{0: 0, 1: 1, 2: 2, 4: 3, 6: 4, 7: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9677,)\n",
            "Temperature Initial value: 1.0\n",
            "Temperature Final value: 2.081744909286499\n",
            "{0: 0, 1: 1, 2: 2, 4: 3, 5: 4, 7: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9604,)\n",
            "Temperature Initial value: 1.0\n",
            "Temperature Final value: 1.9893512725830078\n",
            "{0: 0, 1: 1, 2: 2, 4: 3, 5: 4, 6: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9482,)\n",
            "Temperature Initial value: 1.0\n",
            "Temperature Final value: 2.4744114875793457\n",
            "{0: 0, 1: 1, 2: 2, 4: 3, 5: 4, 6: 5, 7: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9621,)\n",
            "Temperature Initial value: 1.0\n",
            "Temperature Final value: 2.3960418701171875\n",
            "{0: 0, 1: 1, 2: 2, 4: 3, 5: 4, 6: 5, 7: 6, 8: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9587,)\n",
            "Temperature Initial value: 1.0\n",
            "Temperature Final value: 2.157576322555542\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vOBJRHaTYhSE",
        "outputId": "9b59ebdc-8f2f-4272-97bc-54f0f37f78c7"
      },
      "source": [
        "temp_val"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=1.9315488>,\n",
              " <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=2.0040166>,\n",
              " <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=1.7066195>,\n",
              " <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=2.314881>,\n",
              " <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=2.081745>,\n",
              " <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=1.9893513>,\n",
              " <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=2.4744115>,\n",
              " <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=2.3960419>,\n",
              " <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=2.1575763>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2Yd2Xw2Jlot"
      },
      "source": [
        "temp_val = [1.9315488, 2.0040166, 1.7066195, 2.314881, 2.081745, 1.9893513, 2.4744115, 2.3960419, 2.1575763]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "081g7c5FYhSE",
        "outputId": "c19c137a-b0d6-4866-9bee-fe19e1f8abc8"
      },
      "source": [
        "from tqdm import tqdm\n",
        "avg = [0,0,0,0,0,0,0,0,0]\n",
        "count = [0,0,0,0,0,0,0,0,0]\n",
        "entropy_list = [0,0,0,0,0,0,0,0,0]\n",
        "for img, lbl in tqdm(zip(new_val_images,new_val_labels)):\n",
        "  img = img.reshape([-1, 28, 28, 1])\n",
        "  if not lbl == 0:\n",
        "    logits = model_dict[0](img)\n",
        "    logits = tf.math.divide(logits, temp_val[0])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e0 = entropy(pred[0])\n",
        "    entropy_list[0] = entropy_list[0] + e0\n",
        "    max_val0 = np.max(pred)\n",
        "    avg[0] = avg[0] + max_val0\n",
        "    count[0] = count[0] + 1\n",
        "  if not lbl == 1:\n",
        "    logits = model_dict[1](img)\n",
        "    logits = tf.math.divide(logits, temp_val[1])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e1 = entropy(pred[0])\n",
        "    entropy_list[1] = entropy_list[1] + e1\n",
        "    max_val1 = np.max(pred)\n",
        "    avg[1] = avg[1] + max_val1\n",
        "    count[1] = count[1] + 1\n",
        "  if not lbl == 2:\n",
        "    logits = model_dict[2](img)\n",
        "    logits = tf.math.divide(logits, temp_val[2])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e2 = entropy(pred[0])\n",
        "    entropy_list[2] = entropy_list[2] + e2\n",
        "    max_val2 = np.max(pred)\n",
        "    avg[2] = avg[2] + max_val2\n",
        "    count[2] = count[2] + 1\n",
        "  if not lbl == 4:\n",
        "    logits = model_dict[3](img)\n",
        "    logits = tf.math.divide(logits, temp_val[3])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e3 = entropy(pred[0])\n",
        "    entropy_list[3] = entropy_list[3] + e3\n",
        "    max_val3 = np.max(pred)  \n",
        "    avg[3] = avg[3] + max_val3\n",
        "    count[3] = count[3] + 1\n",
        "  if not lbl == 5:\n",
        "    logits = model_dict[4](img)\n",
        "    logits = tf.math.divide(logits, temp_val[4])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e4 = entropy(pred[0])\n",
        "    entropy_list[4] = entropy_list[4] + e4\n",
        "    max_val4 = np.max(pred)\n",
        "    avg[4] = avg[4] + max_val4\n",
        "    count[4] = count[4] + 1\n",
        "  if not lbl == 6:\n",
        "    logits = model_dict[5](img)\n",
        "    logits = tf.math.divide(logits, temp_val[5])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e5 = entropy(pred[0])\n",
        "    entropy_list[5] = entropy_list[5] + e5\n",
        "    max_val5 = np.max(pred)\n",
        "    avg[5] = avg[5] + max_val5\n",
        "    count[5] = count[5] + 1\n",
        "  if not lbl == 7:\n",
        "    logits = model_dict[6](img)\n",
        "    logits = tf.math.divide(logits, temp_val[6])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e6 = entropy(pred[0])\n",
        "    entropy_list[6] = entropy_list[6] + e6\n",
        "    max_val6 = np.max(pred)\n",
        "    avg[6] = avg[6] + max_val6\n",
        "    count[6] = count[6] + 1\n",
        "  if not lbl == 8:\n",
        "    logits = model_dict[7](img)\n",
        "    logits = tf.math.divide(logits, temp_val[7])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e7 = entropy(pred[0])\n",
        "    entropy_list[7] = entropy_list[7] + e7\n",
        "    max_val7 = np.max(pred)\n",
        "    avg[7] = avg[7] + max_val7\n",
        "    count[7] = count[7] + 1\n",
        "  if not lbl == 9:\n",
        "    logits = model_dict[8](img)\n",
        "    logits = tf.math.divide(logits, temp_val[8])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e8 = entropy(pred[0])\n",
        "    entropy_list[8] = entropy_list[8] + e8\n",
        "    max_val8 = np.max(pred)\n",
        "    avg[8] = avg[8] + max_val8\n",
        "    count[8] = count[8] + 1\n",
        "\n",
        "print(avg)\n",
        "print(count)\n",
        "print(entropy_list)\n",
        "\n",
        "entropy_avg_t = [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]\n",
        "for i in range(9):\n",
        "  entropy_avg_t[i] = entropy_list[i]/count[i]\n",
        "\n",
        "entropy_value_t = 0.0\n",
        "for i in range(9):\n",
        "  entropy_value_t = entropy_value_t + entropy_avg_t[i]\n",
        "\n",
        "entropy_t = entropy_value_t/len(entropy_avg_t)\n",
        "\n",
        "print('Entropy:', entropy_t)\n",
        "\n",
        "classifier_avg_t = [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]\n",
        "for i in range(9):\n",
        "  classifier_avg_t[i] = avg[i]/count[i]\n",
        "\n",
        "print('Each Classifier Average: ',classifier_avg_t)\n",
        "\n",
        "treshold_value = 0.0\n",
        "for i in range(9):\n",
        "  treshold_value = treshold_value + classifier_avg_t[i]\n",
        "\n",
        "treshold_t = treshold_value/len(classifier_avg_t)\n",
        "\n",
        "print('Threshold:', treshold_t)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10781it [12:24, 14.48it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[9447.016822248697, 9301.52622115612, 9468.218563318253, 9457.007133245468, 9546.94389435649, 9412.477506011724, 9310.00702676177, 9456.177287399769, 9463.62655544281]\n",
            "[9606, 9459, 9607, 9605, 9677, 9604, 9482, 9621, 9587]\n",
            "[508.6683546499203, 473.8475824471871, 462.0240203240533, 439.62953608612577, 415.68070369158715, 608.3904361484526, 474.91548737375604, 524.5318875828478, 400.0190230457493]\n",
            "Entropy: 0.04994946632199426\n",
            "Each Classifier Average:  [0.9834495963198727, 0.983351963331866, 0.985554133789763, 0.9845921013269618, 0.9865602866959273, 0.9800580493556564, 0.9818611080744326, 0.9828684427190281, 0.9871311729887149]\n",
            "Threshold: 0.9839363171780248\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zIBjZEpXYhSF",
        "outputId": "cc3cfc23-6516-4cf7-b20b-5a0652ddcefe"
      },
      "source": [
        "ref_vect_in_3an = []\n",
        "ref_vect_in_3an.append(classifier_avg_t)\n",
        "\n",
        "threshold_in_3an = []\n",
        "threshold_in_3an.append(treshold_t)\n",
        "\n",
        "entropy_in_3an = []\n",
        "entropy_in_3an.append(entropy_t)\n",
        "\n",
        "print(entropy_in_3an)\n",
        "print(ref_vect_in_3an)\n",
        "print(threshold_in_3an)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.04994946632199426]\n",
            "[[0.9834495963198727, 0.983351963331866, 0.985554133789763, 0.9845921013269618, 0.9865602866959273, 0.9800580493556564, 0.9818611080744326, 0.9828684427190281, 0.9871311729887149]]\n",
            "[0.9839363171780248]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhvkU0LZJ2NA"
      },
      "source": [
        "entropy_in_3an = [0.04994946632199426]\n",
        "ref_vect_in_3an = [[0.9834495963198727, 0.983351963331866, 0.985554133789763, 0.9845921013269618, 0.9865602866959273, 0.9800580493556564, 0.9818611080744326, 0.9828684427190281, 0.9871311729887149]]\n",
        "threshold_in_3an = [0.9839363171780248]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HAdQMuWSYhSF",
        "outputId": "fe4aa7e5-187f-4c1d-eb0d-ac78f1a98f74"
      },
      "source": [
        "from tqdm import tqdm\n",
        "avg = [0,0,0,0,0,0,0,0,0]\n",
        "count = [0,0,0,0,0,0,0,0,0]\n",
        "entropy_list = [0,0,0,0,0,0,0,0,0]\n",
        "\n",
        "for img, lbl in tqdm(zip(new_val_images,new_val_labels)):\n",
        "  img = img.reshape([-1, 28, 28, 1])\n",
        "  if lbl == 0:\n",
        "    logits = model_dict[0](img)\n",
        "    logits = tf.math.divide(logits, temp_val[0])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e0 = entropy(pred[0])\n",
        "    entropy_list[0] = entropy_list[0] + e0\n",
        "    max_val0 = np.max(pred)\n",
        "    avg[0] = avg[0] + max_val0\n",
        "    count[0] = count[0] + 1\n",
        "  if lbl == 1:\n",
        "    logits = model_dict[1](img)\n",
        "    logits = tf.math.divide(logits, temp_val[1])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e1 = entropy(pred[0])\n",
        "    entropy_list[1] = entropy_list[1] + e1\n",
        "    max_val1 = np.max(pred)\n",
        "    avg[1] = avg[1] + max_val1\n",
        "    count[1] = count[1] + 1\n",
        "  if lbl == 2:\n",
        "    logits = model_dict[2](img)\n",
        "    logits = tf.math.divide(logits, temp_val[2])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e2 = entropy(pred[0])\n",
        "    entropy_list[2] = entropy_list[2] + e2\n",
        "    max_val2 = np.max(pred)\n",
        "    avg[2] = avg[2] + max_val2\n",
        "    count[2] = count[2] + 1\n",
        "  if lbl == 4:\n",
        "    logits = model_dict[3](img)\n",
        "    logits = tf.math.divide(logits, temp_val[3])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e3 = entropy(pred[0])\n",
        "    entropy_list[3] = entropy_list[3] + e3\n",
        "    max_val3 = np.max(pred)  \n",
        "    avg[3] = avg[3] + max_val3\n",
        "    count[3] = count[3] + 1\n",
        "  if lbl == 5:\n",
        "    logits = model_dict[4](img)\n",
        "    logits = tf.math.divide(logits, temp_val[4])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e4 = entropy(pred[0])\n",
        "    entropy_list[4] = entropy_list[4] + e4\n",
        "    max_val4 = np.max(pred)\n",
        "    avg[4] = avg[4] + max_val4\n",
        "    count[4] = count[4] + 1\n",
        "  if lbl == 6:\n",
        "    logits = model_dict[5](img)\n",
        "    logits = tf.math.divide(logits, temp_val[5])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e5 = entropy(pred[0])\n",
        "    entropy_list[5] = entropy_list[5] + e5\n",
        "    max_val5 = np.max(pred)\n",
        "    avg[5] = avg[5] + max_val5\n",
        "    count[5] = count[5] + 1\n",
        "  if lbl == 7:\n",
        "    logits = model_dict[6](img)\n",
        "    logits = tf.math.divide(logits, temp_val[6])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e6 = entropy(pred[0])\n",
        "    entropy_list[6] = entropy_list[6] + e6\n",
        "    max_val6 = np.max(pred)\n",
        "    avg[6] = avg[6] + max_val6\n",
        "    count[6] = count[6] + 1\n",
        "  if lbl == 8:\n",
        "    logits = model_dict[7](img)\n",
        "    logits = tf.math.divide(logits, temp_val[7])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e7 = entropy(pred[0])\n",
        "    entropy_list[7] = entropy_list[7] + e7\n",
        "    max_val7 = np.max(pred)\n",
        "    avg[7] = avg[7] + max_val7\n",
        "    count[7] = count[7] + 1\n",
        "  if lbl == 9:\n",
        "    logits = model_dict[8](img)\n",
        "    logits = tf.math.divide(logits, temp_val[8])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e8 = entropy(pred[0])\n",
        "    entropy_list[8] = entropy_list[8] + e8\n",
        "    max_val8 = np.max(pred)\n",
        "    avg[8] = avg[8] + max_val8\n",
        "    count[8] = count[8] + 1\n",
        "\n",
        "print(avg)\n",
        "print(count)\n",
        "print(entropy_list)\n",
        "\n",
        "entropy_avg_t = [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]\n",
        "for i in range(9):\n",
        "  entropy_avg_t[i] = entropy_list[i]/count[i]\n",
        "\n",
        "entropy_value_t = 0.0\n",
        "for i in range(9):\n",
        "  entropy_value_t = entropy_value_t + entropy_avg_t[i]\n",
        "\n",
        "entropy_t = entropy_value_t/len(entropy_avg_t)\n",
        "\n",
        "print('Entropy:', entropy_t)\n",
        "\n",
        "classifier_avg_t = [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]\n",
        "for i in range(9):\n",
        "  classifier_avg_t[i] = avg[i]/count[i]\n",
        "\n",
        "print('Each Classifier Average: ',classifier_avg_t)\n",
        "\n",
        "treshold_value = 0.0\n",
        "for i in range(9):\n",
        "  treshold_value = treshold_value + classifier_avg_t[i]\n",
        "\n",
        "treshold_t = treshold_value/len(classifier_avg_t)\n",
        "\n",
        "print('Threshold:', treshold_t)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10781it [01:33, 115.22it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[932.4524344801903, 802.844724625349, 986.0760701298714, 962.5460428744555, 872.8528325855732, 1016.6342995464802, 1052.8210000097752, 932.3528594970703, 1100.4509341716766]\n",
            "[1175, 1322, 1174, 1176, 1104, 1177, 1299, 1160, 1194]\n",
            "[636.5551197232853, 1377.858542952701, 483.8661005220247, 570.7016475885794, 598.2657914990777, 442.29709160014136, 627.5183741055953, 568.9808160095199, 261.42190548987924]\n",
            "Entropy: 0.5101844694644414\n",
            "Each Classifier Average:  [0.7935765399831407, 0.6072955556923971, 0.8399285094802993, 0.8184915330565098, 0.7906275657478018, 0.8637504669044012, 0.8104857582831217, 0.8037524650836813, 0.921650698636245]\n",
            "Threshold: 0.8055065658741776\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1IEp4niEYhSF",
        "outputId": "4e257943-6371-4900-bde8-6e2b48bbd7d7"
      },
      "source": [
        "ref_vect_out_3an = []\n",
        "ref_vect_out_3an.append(classifier_avg_t)\n",
        "\n",
        "threshold_out_3an = []\n",
        "threshold_out_3an.append(treshold_t)\n",
        "\n",
        "entropy_out_3an = []\n",
        "entropy_out_3an.append(entropy_t)\n",
        "\n",
        "print(entropy_out_3an)\n",
        "print(ref_vect_out_3an)\n",
        "print(threshold_out_3an)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.5101844694644414]\n",
            "[[0.7935765399831407, 0.6072955556923971, 0.8399285094802993, 0.8184915330565098, 0.7906275657478018, 0.8637504669044012, 0.8104857582831217, 0.8037524650836813, 0.921650698636245]]\n",
            "[0.8055065658741776]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8cQcIPvOKHlV"
      },
      "source": [
        "entropy_out_3an = [0.5101844694644414]\n",
        "ref_vect_out_3an = [[0.7935765399831407, 0.6072955556923971, 0.8399285094802993, 0.8184915330565098, 0.7906275657478018, 0.8637504669044012, 0.8104857582831217, 0.8037524650836813, 0.921650698636245]]\n",
        "threshold_out_3an = [0.8055065658741776]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97vImFPWYhSG"
      },
      "source": [
        "def get_max_pred_value(model, img, temp):\n",
        "  logits = model(img)\n",
        "  logits = tf.math.divide(logits, temp)\n",
        "  pred = tf.nn.softmax(logits)\n",
        "  e = entropy(pred[0])\n",
        "\n",
        "  return np.max(pred), tf.argmax(pred[0]).numpy(), e"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TxSc1KXgYhSG"
      },
      "source": [
        "def get_mapping(leave_out_class, anomaly_class):\n",
        "  mapping = {}\n",
        "\n",
        "  labels = set(train_labels)\n",
        "  labels.remove(anomaly_class)\n",
        "  labels.remove(leave_out_class)\n",
        "  labels = sorted(labels)\n",
        "\n",
        "  for i,j in enumerate(labels):\n",
        "    mapping[i] = j\n",
        "\n",
        "  return mapping\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bF0zg7HNYhSG"
      },
      "source": [
        "ood = 0\n",
        "ind = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tVvkp_aVYhSG",
        "outputId": "51034498-3150-458a-fbea-359f1eb6e51e"
      },
      "source": [
        "max_sm_all_wt_3an = []\n",
        "for data, label in tqdm(zip(test_imgs, test_lbls)):\n",
        "  img = data.reshape([-1, 28, 28, 1])\n",
        "  ref_value = []\n",
        "  \n",
        "  if label == 3:\n",
        "    lbl = ood\n",
        "  else:\n",
        "    lbl = ind\n",
        "\n",
        "\n",
        "  max0, pred_0, e0 = get_max_pred_value(model_dict[0], img, temp=temp_val[0])\n",
        "  map0 = get_mapping(0, 3)\n",
        "  pred_0 = map0[pred_0]\n",
        "\n",
        "  max1, pred_1, e1 = get_max_pred_value(model_dict[1], img, temp=temp_val[1])\n",
        "  map1 = get_mapping(1, 3)\n",
        "  pred_1 = map1[pred_1]\n",
        "\n",
        "  max2, pred_2, e2 = get_max_pred_value(model_dict[2], img, temp=temp_val[2])\n",
        "  map2 = get_mapping(2, 3)\n",
        "  pred_2 = map2[pred_2]\n",
        "\n",
        "  max3, pred_3, e3 = get_max_pred_value(model_dict[3], img, temp=temp_val[3])\n",
        "  map3 = get_mapping(4, 3)\n",
        "  pred_3 = map3[pred_3]\n",
        "\n",
        "  max4, pred_4, e4 = get_max_pred_value(model_dict[4], img, temp=temp_val[4])\n",
        "  map4 = get_mapping(5, 3)\n",
        "  pred_4 = map4[pred_4]\n",
        "\n",
        "  max5, pred_5, e5 = get_max_pred_value(model_dict[5], img, temp=temp_val[5])\n",
        "  map5 = get_mapping(6, 3)\n",
        "  pred_5 = map5[pred_5]\n",
        "\n",
        "  max6, pred_6, e6 = get_max_pred_value(model_dict[6], img, temp=temp_val[6])\n",
        "  map6 = get_mapping(7, 3)\n",
        "  pred_6 = map6[pred_6]\n",
        "\n",
        "  max7, pred_7, e7 = get_max_pred_value(model_dict[7], img, temp=temp_val[7])\n",
        "  map7 = get_mapping(8, 3)\n",
        "  pred_7 = map7[pred_7]\n",
        "\n",
        "  max8, pred_8, e8 = get_max_pred_value(model_dict[8], img, temp=temp_val[8])\n",
        "  map8 = get_mapping(9, 3)\n",
        "  pred_8 = map8[pred_8]\n",
        "\n",
        "  ref_value =[max0, max1, max2, max3, max4, max5, max6, max7, max8]\n",
        "  pred_value = [pred_0, pred_1, pred_2, pred_3, pred_4, pred_5, pred_6, pred_7, pred_8]\n",
        "  e_value = [e0, e1, e2, e3, e4, e5, e6, e7, e8]\n",
        "  e_ = 0.0\n",
        "  for  e in e_value:\n",
        "    e_ = e_ + e\n",
        "  e_ = e_/len(e_value)\n",
        "  max_sm_all_wt_3an.append([ref_value, lbl, pred_value, label, e_])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "5001it [11:44,  6.52it/s]\u001b[A\n",
            "5002it [11:44,  6.56it/s]\u001b[A\n",
            "5003it [11:44,  6.51it/s]\u001b[A\n",
            "5004it [11:44,  6.41it/s]\u001b[A\n",
            "5005it [11:45,  6.42it/s]\u001b[A\n",
            "5006it [11:45,  6.39it/s]\u001b[A\n",
            "5007it [11:45,  6.49it/s]\u001b[A\n",
            "5008it [11:45,  6.47it/s]\u001b[A\n",
            "5009it [11:45,  6.46it/s]\u001b[A\n",
            "5010it [11:45,  6.35it/s]\u001b[A\n",
            "5011it [11:46,  6.52it/s]\u001b[A\n",
            "5012it [11:46,  6.65it/s]\u001b[A\n",
            "5013it [11:46,  6.59it/s]\u001b[A\n",
            "5014it [11:46,  6.59it/s]\u001b[A\n",
            "5015it [11:46,  6.54it/s]\u001b[A\n",
            "5016it [11:46,  6.53it/s]\u001b[A\n",
            "5017it [11:46,  6.39it/s]\u001b[A\n",
            "5018it [11:47,  6.53it/s]\u001b[A\n",
            "5019it [11:47,  6.46it/s]\u001b[A\n",
            "5020it [11:47,  6.42it/s]\u001b[A\n",
            "5021it [11:47,  6.50it/s]\u001b[A\n",
            "5022it [11:47,  6.53it/s]\u001b[A\n",
            "5023it [11:47,  6.51it/s]\u001b[A\n",
            "5024it [11:48,  6.62it/s]\u001b[A\n",
            "5025it [11:48,  6.68it/s]\u001b[A\n",
            "5026it [11:48,  6.76it/s]\u001b[A\n",
            "5027it [11:48,  6.81it/s]\u001b[A\n",
            "5028it [11:48,  6.81it/s]\u001b[A\n",
            "5029it [11:48,  6.93it/s]\u001b[A\n",
            "5030it [11:48,  6.88it/s]\u001b[A\n",
            "5031it [11:49,  6.86it/s]\u001b[A\n",
            "5032it [11:49,  6.87it/s]\u001b[A\n",
            "5033it [11:49,  6.90it/s]\u001b[A\n",
            "5034it [11:49,  6.90it/s]\u001b[A\n",
            "5035it [11:49,  6.78it/s]\u001b[A\n",
            "5036it [11:49,  6.82it/s]\u001b[A\n",
            "5037it [11:49,  6.85it/s]\u001b[A\n",
            "5038it [11:50,  7.02it/s]\u001b[A\n",
            "5039it [11:50,  7.10it/s]\u001b[A\n",
            "5040it [11:50,  6.95it/s]\u001b[A\n",
            "5041it [11:50,  7.00it/s]\u001b[A\n",
            "5042it [11:50,  7.06it/s]\u001b[A\n",
            "5043it [11:50,  7.04it/s]\u001b[A\n",
            "5044it [11:50,  7.05it/s]\u001b[A\n",
            "5045it [11:51,  6.81it/s]\u001b[A\n",
            "5046it [11:51,  6.65it/s]\u001b[A\n",
            "5047it [11:51,  6.58it/s]\u001b[A\n",
            "5048it [11:51,  6.47it/s]\u001b[A\n",
            "5049it [11:51,  6.47it/s]\u001b[A\n",
            "5050it [11:51,  6.62it/s]\u001b[A\n",
            "5051it [11:51,  6.62it/s]\u001b[A\n",
            "5052it [11:52,  6.60it/s]\u001b[A\n",
            "5053it [11:52,  6.71it/s]\u001b[A\n",
            "5054it [11:52,  6.81it/s]\u001b[A\n",
            "5055it [11:52,  6.91it/s]\u001b[A\n",
            "5056it [11:52,  6.99it/s]\u001b[A\n",
            "5057it [11:52,  6.87it/s]\u001b[A\n",
            "5058it [11:53,  6.72it/s]\u001b[A\n",
            "5059it [11:53,  6.56it/s]\u001b[A\n",
            "5060it [11:53,  6.68it/s]\u001b[A\n",
            "5061it [11:53,  6.76it/s]\u001b[A\n",
            "5062it [11:53,  6.78it/s]\u001b[A\n",
            "5063it [11:53,  6.78it/s]\u001b[A\n",
            "5064it [11:53,  6.84it/s]\u001b[A\n",
            "5065it [11:54,  6.75it/s]\u001b[A\n",
            "5066it [11:54,  6.82it/s]\u001b[A\n",
            "5067it [11:54,  6.84it/s]\u001b[A\n",
            "5068it [11:54,  6.95it/s]\u001b[A\n",
            "5069it [11:54,  7.00it/s]\u001b[A\n",
            "5070it [11:54,  7.00it/s]\u001b[A\n",
            "5071it [11:54,  7.07it/s]\u001b[A\n",
            "5072it [11:55,  6.87it/s]\u001b[A\n",
            "5073it [11:55,  6.74it/s]\u001b[A\n",
            "5074it [11:55,  6.70it/s]\u001b[A\n",
            "5075it [11:55,  6.54it/s]\u001b[A\n",
            "5076it [11:55,  6.57it/s]\u001b[A\n",
            "5077it [11:55,  6.60it/s]\u001b[A\n",
            "5078it [11:55,  6.43it/s]\u001b[A\n",
            "5079it [11:56,  6.44it/s]\u001b[A\n",
            "5080it [11:56,  6.46it/s]\u001b[A\n",
            "5081it [11:56,  6.47it/s]\u001b[A\n",
            "5082it [11:56,  6.44it/s]\u001b[A\n",
            "5083it [11:56,  6.46it/s]\u001b[A\n",
            "5084it [11:56,  6.50it/s]\u001b[A\n",
            "5085it [11:57,  6.39it/s]\u001b[A\n",
            "5086it [11:57,  6.55it/s]\u001b[A\n",
            "5087it [11:57,  6.50it/s]\u001b[A\n",
            "5088it [11:57,  6.42it/s]\u001b[A\n",
            "5089it [11:57,  6.39it/s]\u001b[A\n",
            "5090it [11:57,  6.43it/s]\u001b[A\n",
            "5091it [11:57,  6.52it/s]\u001b[A\n",
            "5092it [11:58,  6.55it/s]\u001b[A\n",
            "5093it [11:58,  6.52it/s]\u001b[A\n",
            "5094it [11:58,  6.42it/s]\u001b[A\n",
            "5095it [11:58,  6.44it/s]\u001b[A\n",
            "5096it [11:58,  6.46it/s]\u001b[A\n",
            "5097it [11:58,  6.43it/s]\u001b[A\n",
            "5098it [11:59,  6.36it/s]\u001b[A\n",
            "5099it [11:59,  6.55it/s]\u001b[A\n",
            "5100it [11:59,  6.74it/s]\u001b[A\n",
            "5101it [11:59,  6.76it/s]\u001b[A\n",
            "5102it [11:59,  6.83it/s]\u001b[A\n",
            "5103it [11:59,  6.93it/s]\u001b[A\n",
            "5104it [11:59,  6.90it/s]\u001b[A\n",
            "5105it [12:00,  6.77it/s]\u001b[A\n",
            "5106it [12:00,  6.90it/s]\u001b[A\n",
            "5107it [12:00,  6.93it/s]\u001b[A\n",
            "5108it [12:00,  6.96it/s]\u001b[A\n",
            "5109it [12:00,  6.98it/s]\u001b[A\n",
            "5110it [12:00,  6.82it/s]\u001b[A\n",
            "5111it [12:00,  6.66it/s]\u001b[A\n",
            "5112it [12:01,  6.57it/s]\u001b[A\n",
            "5113it [12:01,  6.63it/s]\u001b[A\n",
            "5114it [12:01,  6.74it/s]\u001b[A\n",
            "5115it [12:01,  6.84it/s]\u001b[A\n",
            "5116it [12:01,  6.83it/s]\u001b[A\n",
            "5117it [12:01,  6.94it/s]\u001b[A\n",
            "5118it [12:02,  6.86it/s]\u001b[A\n",
            "5119it [12:02,  6.67it/s]\u001b[A\n",
            "5120it [12:02,  6.80it/s]\u001b[A\n",
            "5121it [12:02,  6.85it/s]\u001b[A\n",
            "5122it [12:02,  6.93it/s]\u001b[A\n",
            "5123it [12:02,  6.97it/s]\u001b[A\n",
            "5124it [12:02,  7.07it/s]\u001b[A\n",
            "5125it [12:03,  7.06it/s]\u001b[A\n",
            "5126it [12:03,  6.95it/s]\u001b[A\n",
            "5127it [12:03,  6.94it/s]\u001b[A\n",
            "5128it [12:03,  7.00it/s]\u001b[A\n",
            "5129it [12:03,  6.97it/s]\u001b[A\n",
            "5130it [12:03,  7.09it/s]\u001b[A\n",
            "5131it [12:03,  7.11it/s]\u001b[A\n",
            "5132it [12:04,  7.04it/s]\u001b[A\n",
            "5133it [12:04,  6.83it/s]\u001b[A\n",
            "5134it [12:04,  6.88it/s]\u001b[A\n",
            "5135it [12:04,  6.80it/s]\u001b[A\n",
            "5136it [12:04,  6.90it/s]\u001b[A\n",
            "5137it [12:04,  6.99it/s]\u001b[A\n",
            "5138it [12:04,  6.91it/s]\u001b[A\n",
            "5139it [12:05,  6.83it/s]\u001b[A\n",
            "5140it [12:05,  6.57it/s]\u001b[A\n",
            "5141it [12:05,  6.56it/s]\u001b[A\n",
            "5142it [12:05,  6.44it/s]\u001b[A\n",
            "5143it [12:05,  6.42it/s]\u001b[A\n",
            "5144it [12:05,  6.33it/s]\u001b[A\n",
            "5145it [12:05,  6.37it/s]\u001b[A\n",
            "5146it [12:06,  6.29it/s]\u001b[A\n",
            "5147it [12:06,  6.29it/s]\u001b[A\n",
            "5148it [12:06,  6.31it/s]\u001b[A\n",
            "5149it [12:06,  6.30it/s]\u001b[A\n",
            "5150it [12:06,  6.30it/s]\u001b[A\n",
            "5151it [12:06,  6.37it/s]\u001b[A\n",
            "5152it [12:07,  6.35it/s]\u001b[A\n",
            "5153it [12:07,  6.21it/s]\u001b[A\n",
            "5154it [12:07,  6.31it/s]\u001b[A\n",
            "5155it [12:07,  6.36it/s]\u001b[A\n",
            "5156it [12:07,  6.33it/s]\u001b[A\n",
            "5157it [12:07,  6.33it/s]\u001b[A\n",
            "5158it [12:08,  6.45it/s]\u001b[A\n",
            "5159it [12:08,  6.39it/s]\u001b[A\n",
            "5160it [12:08,  6.37it/s]\u001b[A\n",
            "5161it [12:08,  6.44it/s]\u001b[A\n",
            "5162it [12:08,  6.45it/s]\u001b[A\n",
            "5163it [12:08,  6.45it/s]\u001b[A\n",
            "5164it [12:08,  6.42it/s]\u001b[A\n",
            "5165it [12:09,  6.23it/s]\u001b[A\n",
            "5166it [12:09,  6.23it/s]\u001b[A\n",
            "5167it [12:09,  6.28it/s]\u001b[A\n",
            "5168it [12:09,  6.28it/s]\u001b[A\n",
            "5169it [12:09,  6.28it/s]\u001b[A\n",
            "5170it [12:09,  6.34it/s]\u001b[A\n",
            "5171it [12:10,  6.44it/s]\u001b[A\n",
            "5172it [12:10,  6.42it/s]\u001b[A\n",
            "5173it [12:10,  6.34it/s]\u001b[A\n",
            "5174it [12:10,  6.42it/s]\u001b[A\n",
            "5175it [12:10,  6.51it/s]\u001b[A\n",
            "5176it [12:10,  6.48it/s]\u001b[A\n",
            "5177it [12:11,  6.40it/s]\u001b[A\n",
            "5178it [12:11,  6.51it/s]\u001b[A\n",
            "5179it [12:11,  6.60it/s]\u001b[A\n",
            "5180it [12:11,  6.67it/s]\u001b[A\n",
            "5181it [12:11,  6.77it/s]\u001b[A\n",
            "5182it [12:11,  6.78it/s]\u001b[A\n",
            "5183it [12:11,  6.90it/s]\u001b[A\n",
            "5184it [12:12,  6.93it/s]\u001b[A\n",
            "5185it [12:12,  6.95it/s]\u001b[A\n",
            "5186it [12:12,  6.83it/s]\u001b[A\n",
            "5187it [12:12,  6.82it/s]\u001b[A\n",
            "5188it [12:12,  6.84it/s]\u001b[A\n",
            "5189it [12:12,  6.84it/s]\u001b[A\n",
            "5190it [12:12,  6.83it/s]\u001b[A\n",
            "5191it [12:13,  6.81it/s]\u001b[A\n",
            "5192it [12:13,  6.67it/s]\u001b[A\n",
            "5193it [12:13,  6.65it/s]\u001b[A\n",
            "5194it [12:13,  6.77it/s]\u001b[A\n",
            "5195it [12:13,  6.76it/s]\u001b[A\n",
            "5196it [12:13,  6.81it/s]\u001b[A\n",
            "5197it [12:13,  6.88it/s]\u001b[A\n",
            "5198it [12:14,  6.87it/s]\u001b[A\n",
            "5199it [12:14,  6.80it/s]\u001b[A\n",
            "5200it [12:14,  6.73it/s]\u001b[A\n",
            "5201it [12:14,  6.82it/s]\u001b[A\n",
            "5202it [12:14,  6.92it/s]\u001b[A\n",
            "5203it [12:14,  6.94it/s]\u001b[A\n",
            "5204it [12:14,  6.92it/s]\u001b[A\n",
            "5205it [12:15,  7.02it/s]\u001b[A\n",
            "5206it [12:15,  7.02it/s]\u001b[A\n",
            "5207it [12:15,  7.00it/s]\u001b[A\n",
            "5208it [12:15,  6.99it/s]\u001b[A\n",
            "5209it [12:15,  7.00it/s]\u001b[A\n",
            "5210it [12:15,  7.07it/s]\u001b[A\n",
            "5211it [12:15,  7.04it/s]\u001b[A\n",
            "5212it [12:16,  6.99it/s]\u001b[A\n",
            "5213it [12:16,  6.98it/s]\u001b[A\n",
            "5214it [12:16,  6.91it/s]\u001b[A\n",
            "5215it [12:16,  6.96it/s]\u001b[A\n",
            "5216it [12:16,  7.00it/s]\u001b[A\n",
            "5217it [12:16,  7.02it/s]\u001b[A\n",
            "5218it [12:16,  7.05it/s]\u001b[A\n",
            "5219it [12:17,  7.10it/s]\u001b[A\n",
            "5220it [12:17,  7.12it/s]\u001b[A\n",
            "5221it [12:17,  6.99it/s]\u001b[A\n",
            "5222it [12:17,  7.08it/s]\u001b[A\n",
            "5223it [12:17,  7.09it/s]\u001b[A\n",
            "5224it [12:17,  6.90it/s]\u001b[A\n",
            "5225it [12:17,  7.02it/s]\u001b[A\n",
            "5226it [12:18,  6.87it/s]\u001b[A\n",
            "5227it [12:18,  6.90it/s]\u001b[A\n",
            "5228it [12:18,  6.85it/s]\u001b[A\n",
            "5229it [12:18,  6.89it/s]\u001b[A\n",
            "5230it [12:18,  6.90it/s]\u001b[A\n",
            "5231it [12:18,  6.99it/s]\u001b[A\n",
            "5232it [12:18,  6.97it/s]\u001b[A\n",
            "5233it [12:19,  6.97it/s]\u001b[A\n",
            "5234it [12:19,  6.92it/s]\u001b[A\n",
            "5235it [12:19,  6.87it/s]\u001b[A\n",
            "5236it [12:19,  6.83it/s]\u001b[A\n",
            "5237it [12:19,  6.85it/s]\u001b[A\n",
            "5238it [12:19,  6.93it/s]\u001b[A\n",
            "5239it [12:19,  6.84it/s]\u001b[A\n",
            "5240it [12:20,  6.79it/s]\u001b[A\n",
            "5241it [12:20,  6.69it/s]\u001b[A\n",
            "5242it [12:20,  6.55it/s]\u001b[A\n",
            "5243it [12:20,  6.41it/s]\u001b[A\n",
            "5244it [12:20,  6.41it/s]\u001b[A\n",
            "5245it [12:20,  6.48it/s]\u001b[A\n",
            "5246it [12:21,  6.46it/s]\u001b[A\n",
            "5247it [12:21,  6.50it/s]\u001b[A\n",
            "5248it [12:21,  6.44it/s]\u001b[A\n",
            "5249it [12:21,  6.44it/s]\u001b[A\n",
            "5250it [12:21,  6.42it/s]\u001b[A\n",
            "5251it [12:21,  6.41it/s]\u001b[A\n",
            "5252it [12:22,  6.49it/s]\u001b[A\n",
            "5253it [12:22,  6.56it/s]\u001b[A\n",
            "5254it [12:22,  6.60it/s]\u001b[A\n",
            "5255it [12:22,  6.61it/s]\u001b[A\n",
            "5256it [12:22,  6.69it/s]\u001b[A\n",
            "5257it [12:22,  6.71it/s]\u001b[A\n",
            "5258it [12:22,  6.84it/s]\u001b[A\n",
            "5259it [12:23,  6.87it/s]\u001b[A\n",
            "5260it [12:23,  6.85it/s]\u001b[A\n",
            "5261it [12:23,  6.87it/s]\u001b[A\n",
            "5262it [12:23,  6.80it/s]\u001b[A\n",
            "5263it [12:23,  6.83it/s]\u001b[A\n",
            "5264it [12:23,  6.96it/s]\u001b[A\n",
            "5265it [12:23,  7.00it/s]\u001b[A\n",
            "5266it [12:24,  6.92it/s]\u001b[A\n",
            "5267it [12:24,  6.96it/s]\u001b[A\n",
            "5268it [12:24,  6.74it/s]\u001b[A\n",
            "5269it [12:24,  6.57it/s]\u001b[A\n",
            "5270it [12:24,  6.52it/s]\u001b[A\n",
            "5271it [12:24,  6.49it/s]\u001b[A\n",
            "5272it [12:24,  6.53it/s]\u001b[A\n",
            "5273it [12:25,  6.58it/s]\u001b[A\n",
            "5274it [12:25,  6.62it/s]\u001b[A\n",
            "5275it [12:25,  6.68it/s]\u001b[A\n",
            "5276it [12:25,  6.62it/s]\u001b[A\n",
            "5277it [12:25,  6.74it/s]\u001b[A\n",
            "5278it [12:25,  6.73it/s]\u001b[A\n",
            "5279it [12:26,  6.70it/s]\u001b[A\n",
            "5280it [12:26,  6.82it/s]\u001b[A\n",
            "5281it [12:26,  6.91it/s]\u001b[A\n",
            "5282it [12:26,  6.93it/s]\u001b[A\n",
            "5283it [12:26,  6.90it/s]\u001b[A\n",
            "5284it [12:26,  6.93it/s]\u001b[A\n",
            "5285it [12:26,  6.91it/s]\u001b[A\n",
            "5286it [12:27,  6.92it/s]\u001b[A\n",
            "5287it [12:27,  6.85it/s]\u001b[A\n",
            "5288it [12:27,  6.75it/s]\u001b[A\n",
            "5289it [12:27,  6.64it/s]\u001b[A\n",
            "5290it [12:27,  6.48it/s]\u001b[A\n",
            "5291it [12:27,  6.49it/s]\u001b[A\n",
            "5292it [12:27,  6.45it/s]\u001b[A\n",
            "5293it [12:28,  6.54it/s]\u001b[A\n",
            "5294it [12:28,  4.28it/s]\u001b[A\n",
            "5295it [12:28,  4.89it/s]\u001b[A\n",
            "5296it [12:28,  5.37it/s]\u001b[A\n",
            "5297it [12:28,  5.80it/s]\u001b[A\n",
            "5298it [12:29,  6.02it/s]\u001b[A\n",
            "5299it [12:29,  6.24it/s]\u001b[A\n",
            "5300it [12:29,  6.53it/s]\u001b[A\n",
            "5301it [12:29,  6.57it/s]\u001b[A\n",
            "5302it [12:29,  6.69it/s]\u001b[A\n",
            "5303it [12:29,  6.78it/s]\u001b[A\n",
            "5304it [12:29,  6.93it/s]\u001b[A\n",
            "5305it [12:30,  6.90it/s]\u001b[A\n",
            "5306it [12:30,  6.97it/s]\u001b[A\n",
            "5307it [12:30,  7.00it/s]\u001b[A\n",
            "5308it [12:30,  7.01it/s]\u001b[A\n",
            "5309it [12:30,  6.98it/s]\u001b[A\n",
            "5310it [12:30,  7.01it/s]\u001b[A\n",
            "5311it [12:30,  6.94it/s]\u001b[A\n",
            "5312it [12:31,  6.85it/s]\u001b[A\n",
            "5313it [12:31,  6.77it/s]\u001b[A\n",
            "5314it [12:31,  6.86it/s]\u001b[A\n",
            "5315it [12:31,  6.79it/s]\u001b[A\n",
            "5316it [12:31,  6.85it/s]\u001b[A\n",
            "5317it [12:31,  7.01it/s]\u001b[A\n",
            "5318it [12:31,  7.00it/s]\u001b[A\n",
            "5319it [12:32,  7.09it/s]\u001b[A\n",
            "5320it [12:32,  7.09it/s]\u001b[A\n",
            "5321it [12:32,  7.03it/s]\u001b[A\n",
            "5322it [12:32,  6.92it/s]\u001b[A\n",
            "5323it [12:32,  6.89it/s]\u001b[A\n",
            "5324it [12:32,  7.04it/s]\u001b[A\n",
            "5325it [12:32,  6.96it/s]\u001b[A\n",
            "5326it [12:33,  6.90it/s]\u001b[A\n",
            "5327it [12:33,  6.88it/s]\u001b[A\n",
            "5328it [12:33,  6.69it/s]\u001b[A\n",
            "5329it [12:33,  6.53it/s]\u001b[A\n",
            "5330it [12:33,  6.45it/s]\u001b[A\n",
            "5331it [12:33,  6.50it/s]\u001b[A\n",
            "5332it [12:34,  6.47it/s]\u001b[A\n",
            "5333it [12:34,  6.57it/s]\u001b[A\n",
            "5334it [12:34,  6.54it/s]\u001b[A\n",
            "5335it [12:34,  6.53it/s]\u001b[A\n",
            "5336it [12:34,  6.47it/s]\u001b[A\n",
            "5337it [12:34,  6.47it/s]\u001b[A\n",
            "5338it [12:34,  6.48it/s]\u001b[A\n",
            "5339it [12:35,  6.57it/s]\u001b[A\n",
            "5340it [12:35,  6.70it/s]\u001b[A\n",
            "5341it [12:35,  6.83it/s]\u001b[A\n",
            "5342it [12:35,  6.95it/s]\u001b[A\n",
            "5343it [12:35,  6.78it/s]\u001b[A\n",
            "5344it [12:35,  6.83it/s]\u001b[A\n",
            "5345it [12:35,  6.91it/s]\u001b[A\n",
            "5346it [12:36,  6.91it/s]\u001b[A\n",
            "5347it [12:36,  6.91it/s]\u001b[A\n",
            "5348it [12:36,  7.02it/s]\u001b[A\n",
            "5349it [12:36,  7.06it/s]\u001b[A\n",
            "5350it [12:36,  6.97it/s]\u001b[A\n",
            "5351it [12:36,  7.07it/s]\u001b[A\n",
            "5352it [12:36,  7.08it/s]\u001b[A\n",
            "5353it [12:37,  7.09it/s]\u001b[A\n",
            "5354it [12:37,  6.93it/s]\u001b[A\n",
            "5355it [12:37,  6.95it/s]\u001b[A\n",
            "5356it [12:37,  6.95it/s]\u001b[A\n",
            "5357it [12:37,  6.87it/s]\u001b[A\n",
            "5358it [12:37,  6.90it/s]\u001b[A\n",
            "5359it [12:37,  6.81it/s]\u001b[A\n",
            "5360it [12:38,  6.78it/s]\u001b[A\n",
            "5361it [12:38,  6.89it/s]\u001b[A\n",
            "5362it [12:38,  6.90it/s]\u001b[A\n",
            "5363it [12:38,  6.91it/s]\u001b[A\n",
            "5364it [12:38,  6.84it/s]\u001b[A\n",
            "5365it [12:38,  7.00it/s]\u001b[A\n",
            "5366it [12:39,  6.98it/s]\u001b[A\n",
            "5367it [12:39,  6.85it/s]\u001b[A\n",
            "5368it [12:39,  6.80it/s]\u001b[A\n",
            "5369it [12:39,  6.77it/s]\u001b[A\n",
            "5370it [12:39,  6.62it/s]\u001b[A\n",
            "5371it [12:39,  6.50it/s]\u001b[A\n",
            "5372it [12:39,  6.48it/s]\u001b[A\n",
            "5373it [12:40,  6.65it/s]\u001b[A\n",
            "5374it [12:40,  6.79it/s]\u001b[A\n",
            "5375it [12:40,  6.88it/s]\u001b[A\n",
            "5376it [12:40,  7.01it/s]\u001b[A\n",
            "5377it [12:40,  7.07it/s]\u001b[A\n",
            "5378it [12:40,  6.85it/s]\u001b[A\n",
            "5379it [12:40,  6.80it/s]\u001b[A\n",
            "5380it [12:41,  6.64it/s]\u001b[A\n",
            "5381it [12:41,  6.71it/s]\u001b[A\n",
            "5382it [12:41,  6.79it/s]\u001b[A\n",
            "5383it [12:41,  6.90it/s]\u001b[A\n",
            "5384it [12:41,  6.93it/s]\u001b[A\n",
            "5385it [12:41,  6.87it/s]\u001b[A\n",
            "5386it [12:41,  6.94it/s]\u001b[A\n",
            "5387it [12:42,  7.04it/s]\u001b[A\n",
            "5388it [12:42,  7.04it/s]\u001b[A\n",
            "5389it [12:42,  7.03it/s]\u001b[A\n",
            "5390it [12:42,  7.00it/s]\u001b[A\n",
            "5391it [12:42,  7.00it/s]\u001b[A\n",
            "5392it [12:42,  6.94it/s]\u001b[A\n",
            "5393it [12:42,  6.94it/s]\u001b[A\n",
            "5394it [12:43,  6.93it/s]\u001b[A\n",
            "5395it [12:43,  6.72it/s]\u001b[A\n",
            "5396it [12:43,  6.63it/s]\u001b[A\n",
            "5397it [12:43,  6.58it/s]\u001b[A\n",
            "5398it [12:43,  6.49it/s]\u001b[A\n",
            "5399it [12:43,  6.40it/s]\u001b[A\n",
            "5400it [12:44,  6.55it/s]\u001b[A\n",
            "5401it [12:44,  6.65it/s]\u001b[A\n",
            "5402it [12:44,  6.59it/s]\u001b[A\n",
            "5403it [12:44,  6.57it/s]\u001b[A\n",
            "5404it [12:44,  6.51it/s]\u001b[A\n",
            "5405it [12:44,  6.40it/s]\u001b[A\n",
            "5406it [12:44,  6.47it/s]\u001b[A\n",
            "5407it [12:45,  6.44it/s]\u001b[A\n",
            "5408it [12:45,  6.58it/s]\u001b[A\n",
            "5409it [12:45,  6.51it/s]\u001b[A\n",
            "5410it [12:45,  6.51it/s]\u001b[A\n",
            "5411it [12:45,  6.59it/s]\u001b[A\n",
            "5412it [12:45,  6.43it/s]\u001b[A\n",
            "5413it [12:46,  6.44it/s]\u001b[A\n",
            "5414it [12:46,  6.59it/s]\u001b[A\n",
            "5415it [12:46,  6.69it/s]\u001b[A\n",
            "5416it [12:46,  6.83it/s]\u001b[A\n",
            "5417it [12:46,  6.97it/s]\u001b[A\n",
            "5418it [12:46,  6.90it/s]\u001b[A\n",
            "5419it [12:46,  6.82it/s]\u001b[A\n",
            "5420it [12:47,  6.80it/s]\u001b[A\n",
            "5421it [12:47,  6.76it/s]\u001b[A\n",
            "5422it [12:47,  6.72it/s]\u001b[A\n",
            "5423it [12:47,  6.64it/s]\u001b[A\n",
            "5424it [12:47,  6.58it/s]\u001b[A\n",
            "5425it [12:47,  6.49it/s]\u001b[A\n",
            "5426it [12:47,  6.67it/s]\u001b[A\n",
            "5427it [12:48,  6.81it/s]\u001b[A\n",
            "5428it [12:48,  6.84it/s]\u001b[A\n",
            "5429it [12:48,  6.69it/s]\u001b[A\n",
            "5430it [12:48,  6.64it/s]\u001b[A\n",
            "5431it [12:48,  6.58it/s]\u001b[A\n",
            "5432it [12:48,  6.44it/s]\u001b[A\n",
            "5433it [12:49,  6.51it/s]\u001b[A\n",
            "5434it [12:49,  6.54it/s]\u001b[A\n",
            "5435it [12:49,  6.52it/s]\u001b[A\n",
            "5436it [12:49,  6.48it/s]\u001b[A\n",
            "5437it [12:49,  6.48it/s]\u001b[A\n",
            "5438it [12:49,  6.55it/s]\u001b[A\n",
            "5439it [12:49,  6.37it/s]\u001b[A\n",
            "5440it [12:50,  6.56it/s]\u001b[A\n",
            "5441it [12:50,  6.68it/s]\u001b[A\n",
            "5442it [12:50,  6.77it/s]\u001b[A\n",
            "5443it [12:50,  6.82it/s]\u001b[A\n",
            "5444it [12:50,  6.89it/s]\u001b[A\n",
            "5445it [12:50,  6.99it/s]\u001b[A\n",
            "5446it [12:50,  6.85it/s]\u001b[A\n",
            "5447it [12:51,  6.75it/s]\u001b[A\n",
            "5448it [12:51,  6.82it/s]\u001b[A\n",
            "5449it [12:51,  6.85it/s]\u001b[A\n",
            "5450it [12:51,  6.98it/s]\u001b[A\n",
            "5451it [12:51,  6.97it/s]\u001b[A\n",
            "5452it [12:51,  7.05it/s]\u001b[A\n",
            "5453it [12:51,  7.05it/s]\u001b[A\n",
            "5454it [12:52,  6.96it/s]\u001b[A\n",
            "5455it [12:52,  7.04it/s]\u001b[A\n",
            "5456it [12:52,  7.03it/s]\u001b[A\n",
            "5457it [12:52,  7.04it/s]\u001b[A\n",
            "5458it [12:52,  7.11it/s]\u001b[A\n",
            "5459it [12:52,  7.05it/s]\u001b[A\n",
            "5460it [12:52,  7.02it/s]\u001b[A\n",
            "5461it [12:53,  6.95it/s]\u001b[A\n",
            "5462it [12:53,  6.80it/s]\u001b[A\n",
            "5463it [12:53,  6.82it/s]\u001b[A\n",
            "5464it [12:53,  6.93it/s]\u001b[A\n",
            "5465it [12:53,  6.99it/s]\u001b[A\n",
            "5466it [12:53,  7.02it/s]\u001b[A\n",
            "5467it [12:53,  6.88it/s]\u001b[A\n",
            "5468it [12:54,  6.86it/s]\u001b[A\n",
            "5469it [12:54,  6.83it/s]\u001b[A\n",
            "5470it [12:54,  6.98it/s]\u001b[A\n",
            "5471it [12:54,  6.98it/s]\u001b[A\n",
            "5472it [12:54,  6.88it/s]\u001b[A\n",
            "5473it [12:54,  6.99it/s]\u001b[A\n",
            "5474it [12:54,  6.92it/s]\u001b[A\n",
            "5475it [12:55,  6.93it/s]\u001b[A\n",
            "5476it [12:55,  6.97it/s]\u001b[A\n",
            "5477it [12:55,  6.94it/s]\u001b[A\n",
            "5478it [12:55,  6.99it/s]\u001b[A\n",
            "5479it [12:55,  7.00it/s]\u001b[A\n",
            "5480it [12:55,  7.05it/s]\u001b[A\n",
            "5481it [12:55,  6.98it/s]\u001b[A\n",
            "5482it [12:56,  7.00it/s]\u001b[A\n",
            "5483it [12:56,  6.86it/s]\u001b[A\n",
            "5484it [12:56,  6.95it/s]\u001b[A\n",
            "5485it [12:56,  7.10it/s]\u001b[A\n",
            "5486it [12:56,  7.14it/s]\u001b[A\n",
            "5487it [12:56,  7.18it/s]\u001b[A\n",
            "5488it [12:56,  6.97it/s]\u001b[A\n",
            "5489it [12:57,  6.82it/s]\u001b[A\n",
            "5490it [12:57,  6.88it/s]\u001b[A\n",
            "5491it [12:57,  6.93it/s]\u001b[A\n",
            "5492it [12:57,  6.96it/s]\u001b[A\n",
            "5493it [12:57,  7.02it/s]\u001b[A\n",
            "5494it [12:57,  7.01it/s]\u001b[A\n",
            "5495it [12:57,  6.94it/s]\u001b[A\n",
            "5496it [12:58,  7.00it/s]\u001b[A\n",
            "5497it [12:58,  6.95it/s]\u001b[A\n",
            "5498it [12:58,  6.96it/s]\u001b[A\n",
            "5499it [12:58,  6.96it/s]\u001b[A\n",
            "5500it [12:58,  7.06it/s]\u001b[A\n",
            "5501it [12:58,  7.03it/s]\u001b[A\n",
            "5502it [12:58,  6.92it/s]\u001b[A\n",
            "5503it [12:59,  6.89it/s]\u001b[A\n",
            "5504it [12:59,  6.79it/s]\u001b[A\n",
            "5505it [12:59,  6.81it/s]\u001b[A\n",
            "5506it [12:59,  6.83it/s]\u001b[A\n",
            "5507it [12:59,  6.71it/s]\u001b[A\n",
            "5508it [12:59,  6.81it/s]\u001b[A\n",
            "5509it [13:00,  6.76it/s]\u001b[A\n",
            "5510it [13:00,  6.73it/s]\u001b[A\n",
            "5511it [13:00,  6.72it/s]\u001b[A\n",
            "5512it [13:00,  6.61it/s]\u001b[A\n",
            "5513it [13:00,  6.54it/s]\u001b[A\n",
            "5514it [13:00,  6.47it/s]\u001b[A\n",
            "5515it [13:00,  6.53it/s]\u001b[A\n",
            "5516it [13:01,  6.44it/s]\u001b[A\n",
            "5517it [13:01,  6.65it/s]\u001b[A\n",
            "5518it [13:01,  6.63it/s]\u001b[A\n",
            "5519it [13:01,  6.59it/s]\u001b[A\n",
            "5520it [13:01,  6.55it/s]\u001b[A\n",
            "5521it [13:01,  6.49it/s]\u001b[A\n",
            "5522it [13:02,  6.58it/s]\u001b[A\n",
            "5523it [13:02,  6.67it/s]\u001b[A\n",
            "5524it [13:02,  6.78it/s]\u001b[A\n",
            "5525it [13:02,  6.92it/s]\u001b[A\n",
            "5526it [13:02,  6.82it/s]\u001b[A\n",
            "5527it [13:02,  6.78it/s]\u001b[A\n",
            "5528it [13:02,  6.69it/s]\u001b[A\n",
            "5529it [13:03,  6.57it/s]\u001b[A\n",
            "5530it [13:03,  6.61it/s]\u001b[A\n",
            "5531it [13:03,  6.59it/s]\u001b[A\n",
            "5532it [13:03,  6.52it/s]\u001b[A\n",
            "5533it [13:03,  6.51it/s]\u001b[A\n",
            "5534it [13:03,  6.46it/s]\u001b[A\n",
            "5535it [13:03,  6.54it/s]\u001b[A\n",
            "5536it [13:04,  6.54it/s]\u001b[A\n",
            "5537it [13:04,  6.55it/s]\u001b[A\n",
            "5538it [13:04,  6.45it/s]\u001b[A\n",
            "5539it [13:04,  6.44it/s]\u001b[A\n",
            "5540it [13:04,  6.50it/s]\u001b[A\n",
            "5541it [13:04,  6.49it/s]\u001b[A\n",
            "5542it [13:05,  6.42it/s]\u001b[A\n",
            "5543it [13:05,  6.61it/s]\u001b[A\n",
            "5544it [13:05,  6.71it/s]\u001b[A\n",
            "5545it [13:05,  6.80it/s]\u001b[A\n",
            "5546it [13:05,  6.87it/s]\u001b[A\n",
            "5547it [13:05,  6.93it/s]\u001b[A\n",
            "5548it [13:05,  6.97it/s]\u001b[A\n",
            "5549it [13:06,  6.96it/s]\u001b[A\n",
            "5550it [13:06,  6.88it/s]\u001b[A\n",
            "5551it [13:06,  7.00it/s]\u001b[A\n",
            "5552it [13:06,  6.91it/s]\u001b[A\n",
            "5553it [13:06,  6.95it/s]\u001b[A\n",
            "5554it [13:06,  6.77it/s]\u001b[A\n",
            "5555it [13:06,  6.85it/s]\u001b[A\n",
            "5556it [13:07,  6.71it/s]\u001b[A\n",
            "5557it [13:07,  6.74it/s]\u001b[A\n",
            "5558it [13:07,  6.81it/s]\u001b[A\n",
            "5559it [13:07,  6.86it/s]\u001b[A\n",
            "5560it [13:07,  7.00it/s]\u001b[A\n",
            "5561it [13:07,  7.02it/s]\u001b[A\n",
            "5562it [13:07,  7.01it/s]\u001b[A\n",
            "5563it [13:08,  7.04it/s]\u001b[A\n",
            "5564it [13:08,  6.96it/s]\u001b[A\n",
            "5565it [13:08,  6.99it/s]\u001b[A\n",
            "5566it [13:08,  6.94it/s]\u001b[A\n",
            "5567it [13:08,  7.01it/s]\u001b[A\n",
            "5568it [13:08,  7.02it/s]\u001b[A\n",
            "5569it [13:08,  6.99it/s]\u001b[A\n",
            "5570it [13:09,  7.03it/s]\u001b[A\n",
            "5571it [13:09,  6.91it/s]\u001b[A\n",
            "5572it [13:09,  6.87it/s]\u001b[A\n",
            "5573it [13:09,  6.83it/s]\u001b[A\n",
            "5574it [13:09,  6.88it/s]\u001b[A\n",
            "5575it [13:09,  6.96it/s]\u001b[A\n",
            "5576it [13:09,  6.97it/s]\u001b[A\n",
            "5577it [13:10,  7.00it/s]\u001b[A\n",
            "5578it [13:10,  6.92it/s]\u001b[A\n",
            "5579it [13:10,  6.99it/s]\u001b[A\n",
            "5580it [13:10,  7.05it/s]\u001b[A\n",
            "5581it [13:10,  7.00it/s]\u001b[A\n",
            "5582it [13:10,  6.97it/s]\u001b[A\n",
            "5583it [13:10,  7.01it/s]\u001b[A\n",
            "5584it [13:11,  6.81it/s]\u001b[A\n",
            "5585it [13:11,  6.60it/s]\u001b[A\n",
            "5586it [13:11,  6.58it/s]\u001b[A\n",
            "5587it [13:11,  6.54it/s]\u001b[A\n",
            "5588it [13:11,  6.55it/s]\u001b[A\n",
            "5589it [13:11,  6.52it/s]\u001b[A\n",
            "5590it [13:12,  6.66it/s]\u001b[A\n",
            "5591it [13:12,  6.78it/s]\u001b[A\n",
            "5592it [13:12,  6.86it/s]\u001b[A\n",
            "5593it [13:12,  6.89it/s]\u001b[A\n",
            "5594it [13:12,  6.95it/s]\u001b[A\n",
            "5595it [13:12,  6.98it/s]\u001b[A\n",
            "5596it [13:12,  6.87it/s]\u001b[A\n",
            "5597it [13:13,  6.75it/s]\u001b[A\n",
            "5598it [13:13,  6.69it/s]\u001b[A\n",
            "5599it [13:13,  6.61it/s]\u001b[A\n",
            "5600it [13:13,  6.50it/s]\u001b[A\n",
            "5601it [13:13,  6.25it/s]\u001b[A\n",
            "5602it [13:13,  6.23it/s]\u001b[A\n",
            "5603it [13:14,  6.33it/s]\u001b[A\n",
            "5604it [13:14,  6.47it/s]\u001b[A\n",
            "5605it [13:14,  6.32it/s]\u001b[A\n",
            "5606it [13:14,  6.34it/s]\u001b[A\n",
            "5607it [13:14,  6.38it/s]\u001b[A\n",
            "5608it [13:14,  6.36it/s]\u001b[A\n",
            "5609it [13:14,  6.28it/s]\u001b[A\n",
            "5610it [13:15,  6.32it/s]\u001b[A\n",
            "5611it [13:15,  6.29it/s]\u001b[A\n",
            "5612it [13:15,  6.33it/s]\u001b[A\n",
            "5613it [13:15,  6.33it/s]\u001b[A\n",
            "5614it [13:15,  6.35it/s]\u001b[A\n",
            "5615it [13:15,  6.34it/s]\u001b[A\n",
            "5616it [13:16,  6.48it/s]\u001b[A\n",
            "5617it [13:16,  6.63it/s]\u001b[A\n",
            "5618it [13:16,  6.69it/s]\u001b[A\n",
            "5619it [13:16,  6.72it/s]\u001b[A\n",
            "5620it [13:16,  6.76it/s]\u001b[A\n",
            "5621it [13:16,  6.83it/s]\u001b[A\n",
            "5622it [13:16,  6.84it/s]\u001b[A\n",
            "5623it [13:17,  6.76it/s]\u001b[A\n",
            "5624it [13:17,  6.65it/s]\u001b[A\n",
            "5625it [13:17,  6.49it/s]\u001b[A\n",
            "5626it [13:17,  6.47it/s]\u001b[A\n",
            "5627it [13:17,  6.37it/s]\u001b[A\n",
            "5628it [13:17,  6.38it/s]\u001b[A\n",
            "5629it [13:18,  6.52it/s]\u001b[A\n",
            "5630it [13:18,  6.61it/s]\u001b[A\n",
            "5631it [13:18,  6.45it/s]\u001b[A\n",
            "5632it [13:18,  6.43it/s]\u001b[A\n",
            "5633it [13:18,  6.39it/s]\u001b[A\n",
            "5634it [13:18,  6.39it/s]\u001b[A\n",
            "5635it [13:18,  6.38it/s]\u001b[A\n",
            "5636it [13:19,  6.41it/s]\u001b[A\n",
            "5637it [13:19,  6.43it/s]\u001b[A\n",
            "5638it [13:19,  6.33it/s]\u001b[A\n",
            "5639it [13:19,  6.36it/s]\u001b[A\n",
            "5640it [13:19,  6.42it/s]\u001b[A\n",
            "5641it [13:19,  6.43it/s]\u001b[A\n",
            "5642it [13:20,  6.48it/s]\u001b[A\n",
            "5643it [13:20,  6.64it/s]\u001b[A\n",
            "5644it [13:20,  6.47it/s]\u001b[A\n",
            "5645it [13:20,  6.44it/s]\u001b[A\n",
            "5646it [13:20,  6.53it/s]\u001b[A\n",
            "5647it [13:20,  6.53it/s]\u001b[A\n",
            "5648it [13:20,  6.61it/s]\u001b[A\n",
            "5649it [13:21,  6.52it/s]\u001b[A\n",
            "5650it [13:21,  6.66it/s]\u001b[A\n",
            "5651it [13:21,  6.75it/s]\u001b[A\n",
            "5652it [13:21,  6.86it/s]\u001b[A\n",
            "5653it [13:21,  6.93it/s]\u001b[A\n",
            "5654it [13:21,  6.99it/s]\u001b[A\n",
            "5655it [13:21,  6.95it/s]\u001b[A\n",
            "5656it [13:22,  6.99it/s]\u001b[A\n",
            "5657it [13:22,  6.97it/s]\u001b[A\n",
            "5658it [13:22,  6.90it/s]\u001b[A\n",
            "5659it [13:22,  6.94it/s]\u001b[A\n",
            "5660it [13:22,  6.91it/s]\u001b[A\n",
            "5661it [13:22,  6.97it/s]\u001b[A\n",
            "5662it [13:22,  7.03it/s]\u001b[A\n",
            "5663it [13:23,  6.96it/s]\u001b[A\n",
            "5664it [13:23,  6.79it/s]\u001b[A\n",
            "5665it [13:23,  6.61it/s]\u001b[A\n",
            "5666it [13:23,  6.54it/s]\u001b[A\n",
            "5667it [13:23,  6.56it/s]\u001b[A\n",
            "5668it [13:23,  6.59it/s]\u001b[A\n",
            "5669it [13:24,  6.51it/s]\u001b[A\n",
            "5670it [13:24,  6.55it/s]\u001b[A\n",
            "5671it [13:24,  6.62it/s]\u001b[A\n",
            "5672it [13:24,  6.65it/s]\u001b[A\n",
            "5673it [13:24,  6.73it/s]\u001b[A\n",
            "5674it [13:24,  6.90it/s]\u001b[A\n",
            "5675it [13:24,  6.87it/s]\u001b[A\n",
            "5676it [13:25,  6.72it/s]\u001b[A\n",
            "5677it [13:25,  6.74it/s]\u001b[A\n",
            "5678it [13:25,  6.84it/s]\u001b[A\n",
            "5679it [13:25,  6.75it/s]\u001b[A\n",
            "5680it [13:25,  6.79it/s]\u001b[A\n",
            "5681it [13:25,  6.85it/s]\u001b[A\n",
            "5682it [13:25,  6.87it/s]\u001b[A\n",
            "5683it [13:26,  6.98it/s]\u001b[A\n",
            "5684it [13:26,  6.89it/s]\u001b[A\n",
            "5685it [13:26,  6.92it/s]\u001b[A\n",
            "5686it [13:26,  6.84it/s]\u001b[A\n",
            "5687it [13:26,  6.90it/s]\u001b[A\n",
            "5688it [13:26,  6.87it/s]\u001b[A\n",
            "5689it [13:26,  6.88it/s]\u001b[A\n",
            "5690it [13:27,  6.92it/s]\u001b[A\n",
            "5691it [13:27,  6.91it/s]\u001b[A\n",
            "5692it [13:27,  6.99it/s]\u001b[A\n",
            "5693it [13:27,  6.84it/s]\u001b[A\n",
            "5694it [13:27,  6.85it/s]\u001b[A\n",
            "5695it [13:27,  6.85it/s]\u001b[A\n",
            "5696it [13:27,  6.88it/s]\u001b[A\n",
            "5697it [13:28,  6.90it/s]\u001b[A\n",
            "5698it [13:28,  6.73it/s]\u001b[A\n",
            "5699it [13:28,  6.73it/s]\u001b[A\n",
            "5700it [13:28,  6.54it/s]\u001b[A\n",
            "5701it [13:28,  6.52it/s]\u001b[A\n",
            "5702it [13:28,  6.47it/s]\u001b[A\n",
            "5703it [13:29,  6.39it/s]\u001b[A\n",
            "5704it [13:29,  6.39it/s]\u001b[A\n",
            "5705it [13:29,  6.48it/s]\u001b[A\n",
            "5706it [13:29,  6.38it/s]\u001b[A\n",
            "5707it [13:29,  6.32it/s]\u001b[A\n",
            "5708it [13:29,  6.35it/s]\u001b[A\n",
            "5709it [13:29,  6.45it/s]\u001b[A\n",
            "5710it [13:30,  6.57it/s]\u001b[A\n",
            "5711it [13:30,  6.61it/s]\u001b[A\n",
            "5712it [13:30,  6.48it/s]\u001b[A\n",
            "5713it [13:30,  6.43it/s]\u001b[A\n",
            "5714it [13:30,  6.45it/s]\u001b[A\n",
            "5715it [13:30,  6.45it/s]\u001b[A\n",
            "5716it [13:31,  6.50it/s]\u001b[A\n",
            "5717it [13:31,  6.55it/s]\u001b[A\n",
            "5718it [13:31,  6.77it/s]\u001b[A\n",
            "5719it [13:31,  6.54it/s]\u001b[A\n",
            "5720it [13:31,  6.46it/s]\u001b[A\n",
            "5721it [13:31,  6.48it/s]\u001b[A\n",
            "5722it [13:31,  6.39it/s]\u001b[A\n",
            "5723it [13:32,  6.55it/s]\u001b[A\n",
            "5724it [13:32,  6.58it/s]\u001b[A\n",
            "5725it [13:32,  6.52it/s]\u001b[A\n",
            "5726it [13:32,  6.41it/s]\u001b[A\n",
            "5727it [13:32,  6.29it/s]\u001b[A\n",
            "5728it [13:32,  6.36it/s]\u001b[A\n",
            "5729it [13:33,  6.40it/s]\u001b[A\n",
            "5730it [13:33,  6.64it/s]\u001b[A\n",
            "5731it [13:33,  6.72it/s]\u001b[A\n",
            "5732it [13:33,  6.87it/s]\u001b[A\n",
            "5733it [13:33,  6.81it/s]\u001b[A\n",
            "5734it [13:33,  6.82it/s]\u001b[A\n",
            "5735it [13:33,  6.90it/s]\u001b[A\n",
            "5736it [13:34,  6.86it/s]\u001b[A\n",
            "5737it [13:34,  6.67it/s]\u001b[A\n",
            "5738it [13:34,  6.79it/s]\u001b[A\n",
            "5739it [13:34,  6.81it/s]\u001b[A\n",
            "5740it [13:34,  6.76it/s]\u001b[A\n",
            "5741it [13:34,  6.82it/s]\u001b[A\n",
            "5742it [13:34,  6.80it/s]\u001b[A\n",
            "5743it [13:35,  6.69it/s]\u001b[A\n",
            "5744it [13:35,  6.65it/s]\u001b[A\n",
            "5745it [13:35,  6.70it/s]\u001b[A\n",
            "5746it [13:35,  6.83it/s]\u001b[A\n",
            "5747it [13:35,  6.77it/s]\u001b[A\n",
            "5748it [13:35,  6.83it/s]\u001b[A\n",
            "5749it [13:35,  6.88it/s]\u001b[A\n",
            "5750it [13:36,  6.82it/s]\u001b[A\n",
            "5751it [13:36,  6.86it/s]\u001b[A\n",
            "5752it [13:36,  6.91it/s]\u001b[A\n",
            "5753it [13:36,  6.71it/s]\u001b[A\n",
            "5754it [13:36,  6.53it/s]\u001b[A\n",
            "5755it [13:36,  6.42it/s]\u001b[A\n",
            "5756it [13:37,  6.47it/s]\u001b[A\n",
            "5757it [13:37,  6.58it/s]\u001b[A\n",
            "5758it [13:37,  6.72it/s]\u001b[A\n",
            "5759it [13:37,  6.78it/s]\u001b[A\n",
            "5760it [13:37,  6.76it/s]\u001b[A\n",
            "5761it [13:37,  6.89it/s]\u001b[A\n",
            "5762it [13:37,  6.88it/s]\u001b[A\n",
            "5763it [13:38,  6.82it/s]\u001b[A\n",
            "5764it [13:38,  6.86it/s]\u001b[A\n",
            "5765it [13:38,  6.84it/s]\u001b[A\n",
            "5766it [13:38,  6.84it/s]\u001b[A\n",
            "5767it [13:38,  6.77it/s]\u001b[A\n",
            "5768it [13:38,  6.78it/s]\u001b[A\n",
            "5769it [13:38,  6.77it/s]\u001b[A\n",
            "5770it [13:39,  6.70it/s]\u001b[A\n",
            "5771it [13:39,  6.48it/s]\u001b[A\n",
            "5772it [13:39,  6.36it/s]\u001b[A\n",
            "5773it [13:39,  6.37it/s]\u001b[A\n",
            "5774it [13:39,  6.39it/s]\u001b[A\n",
            "5775it [13:39,  6.42it/s]\u001b[A\n",
            "5776it [13:40,  6.59it/s]\u001b[A\n",
            "5777it [13:40,  6.74it/s]\u001b[A\n",
            "5778it [13:40,  6.72it/s]\u001b[A\n",
            "5779it [13:40,  6.65it/s]\u001b[A\n",
            "5780it [13:40,  6.56it/s]\u001b[A\n",
            "5781it [13:40,  6.67it/s]\u001b[A\n",
            "5782it [13:40,  6.68it/s]\u001b[A\n",
            "5783it [13:41,  6.54it/s]\u001b[A\n",
            "5784it [13:41,  6.73it/s]\u001b[A\n",
            "5785it [13:41,  6.79it/s]\u001b[A\n",
            "5786it [13:41,  6.86it/s]\u001b[A\n",
            "5787it [13:41,  6.80it/s]\u001b[A\n",
            "5788it [13:41,  6.96it/s]\u001b[A\n",
            "5789it [13:41,  7.05it/s]\u001b[A\n",
            "5790it [13:42,  7.08it/s]\u001b[A\n",
            "5791it [13:42,  7.10it/s]\u001b[A\n",
            "5792it [13:42,  7.07it/s]\u001b[A\n",
            "5793it [13:42,  7.02it/s]\u001b[A\n",
            "5794it [13:42,  7.04it/s]\u001b[A\n",
            "5795it [13:42,  7.01it/s]\u001b[A\n",
            "5796it [13:42,  7.02it/s]\u001b[A\n",
            "5797it [13:43,  6.77it/s]\u001b[A\n",
            "5798it [13:43,  6.65it/s]\u001b[A\n",
            "5799it [13:43,  6.63it/s]\u001b[A\n",
            "5800it [13:43,  6.53it/s]\u001b[A\n",
            "5801it [13:43,  6.45it/s]\u001b[A\n",
            "5802it [13:43,  6.46it/s]\u001b[A\n",
            "5803it [13:44,  6.57it/s]\u001b[A\n",
            "5804it [13:44,  6.71it/s]\u001b[A\n",
            "5805it [13:44,  6.81it/s]\u001b[A\n",
            "5806it [13:44,  6.85it/s]\u001b[A\n",
            "5807it [13:44,  6.92it/s]\u001b[A\n",
            "5808it [13:44,  6.84it/s]\u001b[A\n",
            "5809it [13:44,  6.92it/s]\u001b[A\n",
            "5810it [13:45,  6.82it/s]\u001b[A\n",
            "5811it [13:45,  6.85it/s]\u001b[A\n",
            "5812it [13:45,  6.90it/s]\u001b[A\n",
            "5813it [13:45,  6.89it/s]\u001b[A\n",
            "5814it [13:45,  6.91it/s]\u001b[A\n",
            "5815it [13:45,  6.82it/s]\u001b[A\n",
            "5816it [13:45,  6.89it/s]\u001b[A\n",
            "5817it [13:46,  6.93it/s]\u001b[A\n",
            "5818it [13:46,  6.94it/s]\u001b[A\n",
            "5819it [13:46,  7.04it/s]\u001b[A\n",
            "5820it [13:46,  7.02it/s]\u001b[A\n",
            "5821it [13:46,  7.02it/s]\u001b[A\n",
            "5822it [13:46,  6.99it/s]\u001b[A\n",
            "5823it [13:46,  6.99it/s]\u001b[A\n",
            "5824it [13:47,  6.90it/s]\u001b[A\n",
            "5825it [13:47,  6.78it/s]\u001b[A\n",
            "5826it [13:47,  6.80it/s]\u001b[A\n",
            "5827it [13:47,  6.59it/s]\u001b[A\n",
            "5828it [13:47,  6.65it/s]\u001b[A\n",
            "5829it [13:47,  6.49it/s]\u001b[A\n",
            "5830it [13:47,  6.51it/s]\u001b[A\n",
            "5831it [13:48,  6.61it/s]\u001b[A\n",
            "5832it [13:48,  6.68it/s]\u001b[A\n",
            "5833it [13:48,  6.63it/s]\u001b[A\n",
            "5834it [13:48,  6.63it/s]\u001b[A\n",
            "5835it [13:48,  6.64it/s]\u001b[A\n",
            "5836it [13:48,  6.44it/s]\u001b[A\n",
            "5837it [13:49,  6.47it/s]\u001b[A\n",
            "5838it [13:49,  6.60it/s]\u001b[A\n",
            "5839it [13:49,  6.72it/s]\u001b[A\n",
            "5840it [13:49,  6.80it/s]\u001b[A\n",
            "5841it [13:49,  6.87it/s]\u001b[A\n",
            "5842it [13:49,  6.98it/s]\u001b[A\n",
            "5843it [13:49,  6.88it/s]\u001b[A\n",
            "5844it [13:50,  6.93it/s]\u001b[A\n",
            "5845it [13:50,  7.03it/s]\u001b[A\n",
            "5846it [13:50,  7.13it/s]\u001b[A\n",
            "5847it [13:50,  7.08it/s]\u001b[A\n",
            "5848it [13:50,  7.08it/s]\u001b[A\n",
            "5849it [13:50,  7.11it/s]\u001b[A\n",
            "5850it [13:50,  6.96it/s]\u001b[A\n",
            "5851it [13:51,  6.78it/s]\u001b[A\n",
            "5852it [13:51,  6.73it/s]\u001b[A\n",
            "5853it [13:51,  6.78it/s]\u001b[A\n",
            "5854it [13:51,  6.88it/s]\u001b[A\n",
            "5855it [13:51,  6.95it/s]\u001b[A\n",
            "5856it [13:51,  6.94it/s]\u001b[A\n",
            "5857it [13:51,  6.84it/s]\u001b[A\n",
            "5858it [13:52,  6.96it/s]\u001b[A\n",
            "5859it [13:52,  6.99it/s]\u001b[A\n",
            "5860it [13:52,  6.99it/s]\u001b[A\n",
            "5861it [13:52,  7.00it/s]\u001b[A\n",
            "5862it [13:52,  7.03it/s]\u001b[A\n",
            "5863it [13:52,  7.06it/s]\u001b[A\n",
            "5864it [13:52,  6.89it/s]\u001b[A\n",
            "5865it [13:53,  6.76it/s]\u001b[A\n",
            "5866it [13:53,  6.84it/s]\u001b[A\n",
            "5867it [13:53,  6.89it/s]\u001b[A\n",
            "5868it [13:53,  6.95it/s]\u001b[A\n",
            "5869it [13:53,  6.95it/s]\u001b[A\n",
            "5870it [13:53,  7.06it/s]\u001b[A\n",
            "5871it [13:53,  6.98it/s]\u001b[A\n",
            "5872it [13:54,  6.97it/s]\u001b[A\n",
            "5873it [13:54,  6.92it/s]\u001b[A\n",
            "5874it [13:54,  6.93it/s]\u001b[A\n",
            "5875it [13:54,  6.94it/s]\u001b[A\n",
            "5876it [13:54,  6.99it/s]\u001b[A\n",
            "5877it [13:54,  6.94it/s]\u001b[A\n",
            "5878it [13:54,  6.77it/s]\u001b[A\n",
            "5879it [13:55,  6.78it/s]\u001b[A\n",
            "5880it [13:55,  6.75it/s]\u001b[A\n",
            "5881it [13:55,  6.65it/s]\u001b[A\n",
            "5882it [13:55,  6.60it/s]\u001b[A\n",
            "5883it [13:55,  6.54it/s]\u001b[A\n",
            "5884it [13:55,  6.45it/s]\u001b[A\n",
            "5885it [13:56,  6.55it/s]\u001b[A\n",
            "5886it [13:56,  6.68it/s]\u001b[A\n",
            "5887it [13:56,  6.79it/s]\u001b[A\n",
            "5888it [13:56,  6.91it/s]\u001b[A\n",
            "5889it [13:56,  7.01it/s]\u001b[A\n",
            "5890it [13:56,  6.99it/s]\u001b[A\n",
            "5891it [13:56,  7.03it/s]\u001b[A\n",
            "5892it [13:57,  6.86it/s]\u001b[A\n",
            "5893it [13:57,  6.93it/s]\u001b[A\n",
            "5894it [13:57,  6.93it/s]\u001b[A\n",
            "5895it [13:57,  6.73it/s]\u001b[A\n",
            "5896it [13:57,  6.89it/s]\u001b[A\n",
            "5897it [13:57,  6.93it/s]\u001b[A\n",
            "5898it [13:57,  6.97it/s]\u001b[A\n",
            "5899it [13:58,  6.90it/s]\u001b[A\n",
            "5900it [13:58,  6.93it/s]\u001b[A\n",
            "5901it [13:58,  6.96it/s]\u001b[A\n",
            "5902it [13:58,  7.05it/s]\u001b[A\n",
            "5903it [13:58,  7.12it/s]\u001b[A\n",
            "5904it [13:58,  7.11it/s]\u001b[A\n",
            "5905it [13:58,  7.09it/s]\u001b[A\n",
            "5906it [13:59,  6.75it/s]\u001b[A\n",
            "5907it [13:59,  6.71it/s]\u001b[A\n",
            "5908it [13:59,  6.71it/s]\u001b[A\n",
            "5909it [13:59,  6.83it/s]\u001b[A\n",
            "5910it [13:59,  6.90it/s]\u001b[A\n",
            "5911it [13:59,  6.95it/s]\u001b[A\n",
            "5912it [14:00,  4.49it/s]\u001b[A\n",
            "5913it [14:00,  5.04it/s]\u001b[A\n",
            "5914it [14:00,  5.55it/s]\u001b[A\n",
            "5915it [14:00,  5.94it/s]\u001b[A\n",
            "5916it [14:00,  6.16it/s]\u001b[A\n",
            "5917it [14:00,  6.28it/s]\u001b[A\n",
            "5918it [14:01,  6.34it/s]\u001b[A\n",
            "5919it [14:01,  6.46it/s]\u001b[A\n",
            "5920it [14:01,  6.58it/s]\u001b[A\n",
            "5921it [14:01,  6.75it/s]\u001b[A\n",
            "5922it [14:01,  6.83it/s]\u001b[A\n",
            "5923it [14:01,  6.92it/s]\u001b[A\n",
            "5924it [14:01,  7.06it/s]\u001b[A\n",
            "5925it [14:02,  7.03it/s]\u001b[A\n",
            "5926it [14:02,  7.02it/s]\u001b[A\n",
            "5927it [14:02,  6.84it/s]\u001b[A\n",
            "5928it [14:02,  6.72it/s]\u001b[A\n",
            "5929it [14:02,  6.63it/s]\u001b[A\n",
            "5930it [14:02,  6.62it/s]\u001b[A\n",
            "5931it [14:02,  6.68it/s]\u001b[A\n",
            "5932it [14:03,  6.64it/s]\u001b[A\n",
            "5933it [14:03,  6.63it/s]\u001b[A\n",
            "5934it [14:03,  6.67it/s]\u001b[A\n",
            "5935it [14:03,  6.69it/s]\u001b[A\n",
            "5936it [14:03,  6.63it/s]\u001b[A\n",
            "5937it [14:03,  6.61it/s]\u001b[A\n",
            "5938it [14:04,  6.64it/s]\u001b[A\n",
            "5939it [14:04,  6.69it/s]\u001b[A\n",
            "5940it [14:04,  6.79it/s]\u001b[A\n",
            "5941it [14:04,  6.93it/s]\u001b[A\n",
            "5942it [14:04,  6.95it/s]\u001b[A\n",
            "5943it [14:04,  6.98it/s]\u001b[A\n",
            "5944it [14:04,  6.95it/s]\u001b[A\n",
            "5945it [14:05,  6.79it/s]\u001b[A\n",
            "5946it [14:05,  6.58it/s]\u001b[A\n",
            "5947it [14:05,  6.60it/s]\u001b[A\n",
            "5948it [14:05,  6.54it/s]\u001b[A\n",
            "5949it [14:05,  6.64it/s]\u001b[A\n",
            "5950it [14:05,  6.77it/s]\u001b[A\n",
            "5951it [14:05,  6.89it/s]\u001b[A\n",
            "5952it [14:06,  6.83it/s]\u001b[A\n",
            "5953it [14:06,  6.73it/s]\u001b[A\n",
            "5954it [14:06,  6.83it/s]\u001b[A\n",
            "5955it [14:06,  6.89it/s]\u001b[A\n",
            "5956it [14:06,  6.86it/s]\u001b[A\n",
            "5957it [14:06,  6.93it/s]\u001b[A\n",
            "5958it [14:06,  6.92it/s]\u001b[A\n",
            "5959it [14:07,  6.87it/s]\u001b[A\n",
            "5960it [14:07,  6.83it/s]\u001b[A\n",
            "5961it [14:07,  6.95it/s]\u001b[A\n",
            "5962it [14:07,  6.99it/s]\u001b[A\n",
            "5963it [14:07,  7.04it/s]\u001b[A\n",
            "5964it [14:07,  7.01it/s]\u001b[A\n",
            "5965it [14:07,  7.00it/s]\u001b[A\n",
            "5966it [14:08,  6.86it/s]\u001b[A\n",
            "5967it [14:08,  6.84it/s]\u001b[A\n",
            "5968it [14:08,  6.73it/s]\u001b[A\n",
            "5969it [14:08,  6.74it/s]\u001b[A\n",
            "5970it [14:08,  6.64it/s]\u001b[A\n",
            "5971it [14:08,  6.56it/s]\u001b[A\n",
            "5972it [14:09,  6.52it/s]\u001b[A\n",
            "5973it [14:09,  6.43it/s]\u001b[A\n",
            "5974it [14:09,  6.53it/s]\u001b[A\n",
            "5975it [14:09,  6.59it/s]\u001b[A\n",
            "5976it [14:09,  6.51it/s]\u001b[A\n",
            "5977it [14:09,  6.40it/s]\u001b[A\n",
            "5978it [14:09,  6.43it/s]\u001b[A\n",
            "5979it [14:10,  6.46it/s]\u001b[A\n",
            "5980it [14:10,  6.60it/s]\u001b[A\n",
            "5981it [14:10,  6.72it/s]\u001b[A\n",
            "5982it [14:10,  6.80it/s]\u001b[A\n",
            "5983it [14:10,  6.91it/s]\u001b[A\n",
            "5984it [14:10,  6.93it/s]\u001b[A\n",
            "5985it [14:10,  6.97it/s]\u001b[A\n",
            "5986it [14:11,  6.99it/s]\u001b[A\n",
            "5987it [14:11,  6.59it/s]\u001b[A\n",
            "5988it [14:11,  6.64it/s]\u001b[A\n",
            "5989it [14:11,  6.77it/s]\u001b[A\n",
            "5990it [14:11,  6.84it/s]\u001b[A\n",
            "5991it [14:11,  6.92it/s]\u001b[A\n",
            "5992it [14:11,  6.94it/s]\u001b[A\n",
            "5993it [14:12,  6.95it/s]\u001b[A\n",
            "5994it [14:12,  6.80it/s]\u001b[A\n",
            "5995it [14:12,  6.91it/s]\u001b[A\n",
            "5996it [14:12,  7.01it/s]\u001b[A\n",
            "5997it [14:12,  6.97it/s]\u001b[A\n",
            "5998it [14:12,  7.04it/s]\u001b[A\n",
            "5999it [14:12,  7.03it/s]\u001b[A\n",
            "6000it [14:13,  6.87it/s]\u001b[A\n",
            "6001it [14:13,  6.84it/s]\u001b[A\n",
            "6002it [14:13,  6.97it/s]\u001b[A\n",
            "6003it [14:13,  7.03it/s]\u001b[A\n",
            "6004it [14:13,  6.83it/s]\u001b[A\n",
            "6005it [14:13,  6.71it/s]\u001b[A\n",
            "6006it [14:14,  6.85it/s]\u001b[A\n",
            "6007it [14:14,  6.87it/s]\u001b[A\n",
            "6008it [14:14,  6.55it/s]\u001b[A\n",
            "6009it [14:14,  6.56it/s]\u001b[A\n",
            "6010it [14:14,  6.45it/s]\u001b[A\n",
            "6011it [14:14,  6.39it/s]\u001b[A\n",
            "6012it [14:14,  6.37it/s]\u001b[A\n",
            "6013it [14:15,  6.46it/s]\u001b[A\n",
            "6014it [14:15,  6.45it/s]\u001b[A\n",
            "6015it [14:15,  6.45it/s]\u001b[A\n",
            "6016it [14:15,  6.39it/s]\u001b[A\n",
            "6017it [14:15,  6.48it/s]\u001b[A\n",
            "6018it [14:15,  6.47it/s]\u001b[A\n",
            "6019it [14:16,  6.39it/s]\u001b[A\n",
            "6020it [14:16,  6.54it/s]\u001b[A\n",
            "6021it [14:16,  6.58it/s]\u001b[A\n",
            "6022it [14:16,  6.77it/s]\u001b[A\n",
            "6023it [14:16,  6.88it/s]\u001b[A\n",
            "6024it [14:16,  6.95it/s]\u001b[A\n",
            "6025it [14:16,  7.04it/s]\u001b[A\n",
            "6026it [14:17,  6.92it/s]\u001b[A\n",
            "6027it [14:17,  6.86it/s]\u001b[A\n",
            "6028it [14:17,  6.64it/s]\u001b[A\n",
            "6029it [14:17,  6.66it/s]\u001b[A\n",
            "6030it [14:17,  6.76it/s]\u001b[A\n",
            "6031it [14:17,  6.78it/s]\u001b[A\n",
            "6032it [14:17,  6.85it/s]\u001b[A\n",
            "6033it [14:18,  6.82it/s]\u001b[A\n",
            "6034it [14:18,  6.94it/s]\u001b[A\n",
            "6035it [14:18,  6.88it/s]\u001b[A\n",
            "6036it [14:18,  6.93it/s]\u001b[A\n",
            "6037it [14:18,  6.91it/s]\u001b[A\n",
            "6038it [14:18,  6.92it/s]\u001b[A\n",
            "6039it [14:18,  6.96it/s]\u001b[A\n",
            "6040it [14:19,  6.90it/s]\u001b[A\n",
            "6041it [14:19,  6.82it/s]\u001b[A\n",
            "6042it [14:19,  6.61it/s]\u001b[A\n",
            "6043it [14:19,  6.45it/s]\u001b[A\n",
            "6044it [14:19,  6.44it/s]\u001b[A\n",
            "6045it [14:19,  6.43it/s]\u001b[A\n",
            "6046it [14:20,  6.50it/s]\u001b[A\n",
            "6047it [14:20,  6.58it/s]\u001b[A\n",
            "6048it [14:20,  6.56it/s]\u001b[A\n",
            "6049it [14:20,  6.65it/s]\u001b[A\n",
            "6050it [14:20,  6.79it/s]\u001b[A\n",
            "6051it [14:20,  6.73it/s]\u001b[A\n",
            "6052it [14:20,  6.60it/s]\u001b[A\n",
            "6053it [14:21,  6.65it/s]\u001b[A\n",
            "6054it [14:21,  6.69it/s]\u001b[A\n",
            "6055it [14:21,  6.74it/s]\u001b[A\n",
            "6056it [14:21,  6.80it/s]\u001b[A\n",
            "6057it [14:21,  6.80it/s]\u001b[A\n",
            "6058it [14:21,  6.73it/s]\u001b[A\n",
            "6059it [14:21,  6.60it/s]\u001b[A\n",
            "6060it [14:22,  6.70it/s]\u001b[A\n",
            "6061it [14:22,  6.62it/s]\u001b[A\n",
            "6062it [14:22,  6.50it/s]\u001b[A\n",
            "6063it [14:22,  6.44it/s]\u001b[A\n",
            "6064it [14:22,  6.43it/s]\u001b[A\n",
            "6065it [14:22,  6.44it/s]\u001b[A\n",
            "6066it [14:23,  6.35it/s]\u001b[A\n",
            "6067it [14:23,  6.45it/s]\u001b[A\n",
            "6068it [14:23,  6.49it/s]\u001b[A\n",
            "6069it [14:23,  6.61it/s]\u001b[A\n",
            "6070it [14:23,  6.69it/s]\u001b[A\n",
            "6071it [14:23,  6.81it/s]\u001b[A\n",
            "6072it [14:23,  6.69it/s]\u001b[A\n",
            "6073it [14:24,  6.76it/s]\u001b[A\n",
            "6074it [14:24,  6.85it/s]\u001b[A\n",
            "6075it [14:24,  6.53it/s]\u001b[A\n",
            "6076it [14:24,  6.48it/s]\u001b[A\n",
            "6077it [14:24,  6.52it/s]\u001b[A\n",
            "6078it [14:24,  6.45it/s]\u001b[A\n",
            "6079it [14:25,  6.45it/s]\u001b[A\n",
            "6080it [14:25,  6.52it/s]\u001b[A\n",
            "6081it [14:25,  6.53it/s]\u001b[A\n",
            "6082it [14:25,  6.40it/s]\u001b[A\n",
            "6083it [14:25,  6.36it/s]\u001b[A\n",
            "6084it [14:25,  6.36it/s]\u001b[A\n",
            "6085it [14:25,  6.38it/s]\u001b[A\n",
            "6086it [14:26,  6.49it/s]\u001b[A\n",
            "6087it [14:26,  6.67it/s]\u001b[A\n",
            "6088it [14:26,  6.78it/s]\u001b[A\n",
            "6089it [14:26,  6.91it/s]\u001b[A\n",
            "6090it [14:26,  7.00it/s]\u001b[A\n",
            "6091it [14:26,  7.04it/s]\u001b[A\n",
            "6092it [14:26,  7.04it/s]\u001b[A\n",
            "6093it [14:27,  7.01it/s]\u001b[A\n",
            "6094it [14:27,  7.02it/s]\u001b[A\n",
            "6095it [14:27,  7.02it/s]\u001b[A\n",
            "6096it [14:27,  6.86it/s]\u001b[A\n",
            "6097it [14:27,  6.94it/s]\u001b[A\n",
            "6098it [14:27,  6.97it/s]\u001b[A\n",
            "6099it [14:27,  7.03it/s]\u001b[A\n",
            "6100it [14:28,  6.98it/s]\u001b[A\n",
            "6101it [14:28,  6.91it/s]\u001b[A\n",
            "6102it [14:28,  6.77it/s]\u001b[A\n",
            "6103it [14:28,  6.60it/s]\u001b[A\n",
            "6104it [14:28,  6.53it/s]\u001b[A\n",
            "6105it [14:28,  6.49it/s]\u001b[A\n",
            "6106it [14:29,  6.43it/s]\u001b[A\n",
            "6107it [14:29,  6.52it/s]\u001b[A\n",
            "6108it [14:29,  6.70it/s]\u001b[A\n",
            "6109it [14:29,  6.66it/s]\u001b[A\n",
            "6110it [14:29,  6.71it/s]\u001b[A\n",
            "6111it [14:29,  6.86it/s]\u001b[A\n",
            "6112it [14:29,  6.92it/s]\u001b[A\n",
            "6113it [14:30,  6.90it/s]\u001b[A\n",
            "6114it [14:30,  6.91it/s]\u001b[A\n",
            "6115it [14:30,  6.96it/s]\u001b[A\n",
            "6116it [14:30,  6.91it/s]\u001b[A\n",
            "6117it [14:30,  6.87it/s]\u001b[A\n",
            "6118it [14:30,  6.88it/s]\u001b[A\n",
            "6119it [14:30,  6.90it/s]\u001b[A\n",
            "6120it [14:31,  6.77it/s]\u001b[A\n",
            "6121it [14:31,  6.88it/s]\u001b[A\n",
            "6122it [14:31,  6.74it/s]\u001b[A\n",
            "6123it [14:31,  6.60it/s]\u001b[A\n",
            "6124it [14:31,  6.55it/s]\u001b[A\n",
            "6125it [14:31,  6.54it/s]\u001b[A\n",
            "6126it [14:31,  6.53it/s]\u001b[A\n",
            "6127it [14:32,  6.67it/s]\u001b[A\n",
            "6128it [14:32,  6.72it/s]\u001b[A\n",
            "6129it [14:32,  6.61it/s]\u001b[A\n",
            "6130it [14:32,  6.41it/s]\u001b[A\n",
            "6131it [14:32,  6.41it/s]\u001b[A\n",
            "6132it [14:32,  6.40it/s]\u001b[A\n",
            "6133it [14:33,  6.43it/s]\u001b[A\n",
            "6134it [14:33,  6.50it/s]\u001b[A\n",
            "6135it [14:33,  6.50it/s]\u001b[A\n",
            "6136it [14:33,  6.36it/s]\u001b[A\n",
            "6137it [14:33,  6.42it/s]\u001b[A\n",
            "6138it [14:33,  6.34it/s]\u001b[A\n",
            "6139it [14:34,  6.40it/s]\u001b[A\n",
            "6140it [14:34,  6.54it/s]\u001b[A\n",
            "6141it [14:34,  6.62it/s]\u001b[A\n",
            "6142it [14:34,  6.73it/s]\u001b[A\n",
            "6143it [14:34,  6.77it/s]\u001b[A\n",
            "6144it [14:34,  6.86it/s]\u001b[A\n",
            "6145it [14:34,  6.99it/s]\u001b[A\n",
            "6146it [14:35,  6.80it/s]\u001b[A\n",
            "6147it [14:35,  6.53it/s]\u001b[A\n",
            "6148it [14:35,  6.65it/s]\u001b[A\n",
            "6149it [14:35,  6.75it/s]\u001b[A\n",
            "6150it [14:35,  6.70it/s]\u001b[A\n",
            "6151it [14:35,  6.76it/s]\u001b[A\n",
            "6152it [14:35,  6.81it/s]\u001b[A\n",
            "6153it [14:36,  6.83it/s]\u001b[A\n",
            "6154it [14:36,  6.91it/s]\u001b[A\n",
            "6155it [14:36,  6.95it/s]\u001b[A\n",
            "6156it [14:36,  7.01it/s]\u001b[A\n",
            "6157it [14:36,  6.97it/s]\u001b[A\n",
            "6158it [14:36,  6.99it/s]\u001b[A\n",
            "6159it [14:36,  7.00it/s]\u001b[A\n",
            "6160it [14:37,  7.03it/s]\u001b[A\n",
            "6161it [14:37,  6.93it/s]\u001b[A\n",
            "6162it [14:37,  6.73it/s]\u001b[A\n",
            "6163it [14:37,  6.71it/s]\u001b[A\n",
            "6164it [14:37,  6.54it/s]\u001b[A\n",
            "6165it [14:37,  6.47it/s]\u001b[A\n",
            "6166it [14:37,  6.54it/s]\u001b[A\n",
            "6167it [14:38,  6.74it/s]\u001b[A\n",
            "6168it [14:38,  6.66it/s]\u001b[A\n",
            "6169it [14:38,  6.52it/s]\u001b[A\n",
            "6170it [14:38,  6.35it/s]\u001b[A\n",
            "6171it [14:38,  6.41it/s]\u001b[A\n",
            "6172it [14:38,  6.43it/s]\u001b[A\n",
            "6173it [14:39,  6.38it/s]\u001b[A\n",
            "6174it [14:39,  6.50it/s]\u001b[A\n",
            "6175it [14:39,  6.68it/s]\u001b[A\n",
            "6176it [14:39,  6.84it/s]\u001b[A\n",
            "6177it [14:39,  6.79it/s]\u001b[A\n",
            "6178it [14:39,  6.93it/s]\u001b[A\n",
            "6179it [14:39,  6.97it/s]\u001b[A\n",
            "6180it [14:40,  6.97it/s]\u001b[A\n",
            "6181it [14:40,  6.99it/s]\u001b[A\n",
            "6182it [14:40,  7.02it/s]\u001b[A\n",
            "6183it [14:40,  7.04it/s]\u001b[A\n",
            "6184it [14:40,  6.97it/s]\u001b[A\n",
            "6185it [14:40,  7.01it/s]\u001b[A\n",
            "6186it [14:40,  6.96it/s]\u001b[A\n",
            "6187it [14:41,  6.83it/s]\u001b[A\n",
            "6188it [14:41,  6.86it/s]\u001b[A\n",
            "6189it [14:41,  6.54it/s]\u001b[A\n",
            "6190it [14:41,  6.51it/s]\u001b[A\n",
            "6191it [14:41,  6.35it/s]\u001b[A\n",
            "6192it [14:41,  6.34it/s]\u001b[A\n",
            "6193it [14:42,  6.47it/s]\u001b[A\n",
            "6194it [14:42,  6.55it/s]\u001b[A\n",
            "6195it [14:42,  6.62it/s]\u001b[A\n",
            "6196it [14:42,  6.79it/s]\u001b[A\n",
            "6197it [14:42,  6.88it/s]\u001b[A\n",
            "6198it [14:42,  6.82it/s]\u001b[A\n",
            "6199it [14:42,  6.95it/s]\u001b[A\n",
            "6200it [14:43,  6.96it/s]\u001b[A\n",
            "6201it [14:43,  6.94it/s]\u001b[A\n",
            "6202it [14:43,  6.99it/s]\u001b[A\n",
            "6203it [14:43,  7.00it/s]\u001b[A\n",
            "6204it [14:43,  7.00it/s]\u001b[A\n",
            "6205it [14:43,  6.93it/s]\u001b[A\n",
            "6206it [14:43,  7.02it/s]\u001b[A\n",
            "6207it [14:44,  6.92it/s]\u001b[A\n",
            "6208it [14:44,  6.97it/s]\u001b[A\n",
            "6209it [14:44,  6.85it/s]\u001b[A\n",
            "6210it [14:44,  6.67it/s]\u001b[A\n",
            "6211it [14:44,  6.68it/s]\u001b[A\n",
            "6212it [14:44,  6.50it/s]\u001b[A\n",
            "6213it [14:44,  6.52it/s]\u001b[A\n",
            "6214it [14:45,  6.45it/s]\u001b[A\n",
            "6215it [14:45,  6.51it/s]\u001b[A\n",
            "6216it [14:45,  6.40it/s]\u001b[A\n",
            "6217it [14:45,  6.47it/s]\u001b[A\n",
            "6218it [14:45,  6.21it/s]\u001b[A\n",
            "6219it [14:45,  6.16it/s]\u001b[A\n",
            "6220it [14:46,  6.27it/s]\u001b[A\n",
            "6221it [14:46,  6.45it/s]\u001b[A\n",
            "6222it [14:46,  6.57it/s]\u001b[A\n",
            "6223it [14:46,  6.68it/s]\u001b[A\n",
            "6224it [14:46,  6.74it/s]\u001b[A\n",
            "6225it [14:46,  6.71it/s]\u001b[A\n",
            "6226it [14:46,  6.78it/s]\u001b[A\n",
            "6227it [14:47,  6.86it/s]\u001b[A\n",
            "6228it [14:47,  6.96it/s]\u001b[A\n",
            "6229it [14:47,  6.90it/s]\u001b[A\n",
            "6230it [14:47,  6.97it/s]\u001b[A\n",
            "6231it [14:47,  6.88it/s]\u001b[A\n",
            "6232it [14:47,  6.79it/s]\u001b[A\n",
            "6233it [14:47,  6.84it/s]\u001b[A\n",
            "6234it [14:48,  6.89it/s]\u001b[A\n",
            "6235it [14:48,  6.98it/s]\u001b[A\n",
            "6236it [14:48,  6.97it/s]\u001b[A\n",
            "6237it [14:48,  6.94it/s]\u001b[A\n",
            "6238it [14:48,  6.90it/s]\u001b[A\n",
            "6239it [14:48,  6.82it/s]\u001b[A\n",
            "6240it [14:48,  6.82it/s]\u001b[A\n",
            "6241it [14:49,  6.69it/s]\u001b[A\n",
            "6242it [14:49,  6.65it/s]\u001b[A\n",
            "6243it [14:49,  6.63it/s]\u001b[A\n",
            "6244it [14:49,  6.51it/s]\u001b[A\n",
            "6245it [14:49,  6.48it/s]\u001b[A\n",
            "6246it [14:49,  6.50it/s]\u001b[A\n",
            "6247it [14:50,  6.51it/s]\u001b[A\n",
            "6248it [14:50,  6.66it/s]\u001b[A\n",
            "6249it [14:50,  6.75it/s]\u001b[A\n",
            "6250it [14:50,  6.78it/s]\u001b[A\n",
            "6251it [14:50,  6.84it/s]\u001b[A\n",
            "6252it [14:50,  6.91it/s]\u001b[A\n",
            "6253it [14:50,  6.89it/s]\u001b[A\n",
            "6254it [14:51,  6.92it/s]\u001b[A\n",
            "6255it [14:51,  6.85it/s]\u001b[A\n",
            "6256it [14:51,  6.86it/s]\u001b[A\n",
            "6257it [14:51,  6.86it/s]\u001b[A\n",
            "6258it [14:51,  6.93it/s]\u001b[A\n",
            "6259it [14:51,  6.78it/s]\u001b[A\n",
            "6260it [14:51,  6.87it/s]\u001b[A\n",
            "6261it [14:52,  6.88it/s]\u001b[A\n",
            "6262it [14:52,  6.81it/s]\u001b[A\n",
            "6263it [14:52,  6.88it/s]\u001b[A\n",
            "6264it [14:52,  6.78it/s]\u001b[A\n",
            "6265it [14:52,  6.54it/s]\u001b[A\n",
            "6266it [14:52,  6.56it/s]\u001b[A\n",
            "6267it [14:52,  6.59it/s]\u001b[A\n",
            "6268it [14:53,  6.59it/s]\u001b[A\n",
            "6269it [14:53,  6.47it/s]\u001b[A\n",
            "6270it [14:53,  6.41it/s]\u001b[A\n",
            "6271it [14:53,  6.38it/s]\u001b[A\n",
            "6272it [14:53,  6.35it/s]\u001b[A\n",
            "6273it [14:53,  6.41it/s]\u001b[A\n",
            "6274it [14:54,  6.53it/s]\u001b[A\n",
            "6275it [14:54,  6.61it/s]\u001b[A\n",
            "6276it [14:54,  6.71it/s]\u001b[A\n",
            "6277it [14:54,  6.79it/s]\u001b[A\n",
            "6278it [14:54,  6.84it/s]\u001b[A\n",
            "6279it [14:54,  6.93it/s]\u001b[A\n",
            "6280it [14:54,  6.91it/s]\u001b[A\n",
            "6281it [14:55,  6.79it/s]\u001b[A\n",
            "6282it [14:55,  6.71it/s]\u001b[A\n",
            "6283it [14:55,  6.61it/s]\u001b[A\n",
            "6284it [14:55,  6.43it/s]\u001b[A\n",
            "6285it [14:55,  6.35it/s]\u001b[A\n",
            "6286it [14:55,  6.23it/s]\u001b[A\n",
            "6287it [14:56,  6.28it/s]\u001b[A\n",
            "6288it [14:56,  6.45it/s]\u001b[A\n",
            "6289it [14:56,  6.55it/s]\u001b[A\n",
            "6290it [14:56,  6.64it/s]\u001b[A\n",
            "6291it [14:56,  6.72it/s]\u001b[A\n",
            "6292it [14:56,  6.75it/s]\u001b[A\n",
            "6293it [14:56,  6.57it/s]\u001b[A\n",
            "6294it [14:57,  6.62it/s]\u001b[A\n",
            "6295it [14:57,  6.70it/s]\u001b[A\n",
            "6296it [14:57,  6.76it/s]\u001b[A\n",
            "6297it [14:57,  6.81it/s]\u001b[A\n",
            "6298it [14:57,  6.82it/s]\u001b[A\n",
            "6299it [14:57,  6.90it/s]\u001b[A\n",
            "6300it [14:57,  6.79it/s]\u001b[A\n",
            "6301it [14:58,  6.88it/s]\u001b[A\n",
            "6302it [14:58,  6.87it/s]\u001b[A\n",
            "6303it [14:58,  6.82it/s]\u001b[A\n",
            "6304it [14:58,  6.80it/s]\u001b[A\n",
            "6305it [14:58,  6.79it/s]\u001b[A\n",
            "6306it [14:58,  6.84it/s]\u001b[A\n",
            "6307it [14:58,  6.77it/s]\u001b[A\n",
            "6308it [14:59,  6.68it/s]\u001b[A\n",
            "6309it [14:59,  6.59it/s]\u001b[A\n",
            "6310it [14:59,  6.48it/s]\u001b[A\n",
            "6311it [14:59,  6.40it/s]\u001b[A\n",
            "6312it [14:59,  6.41it/s]\u001b[A\n",
            "6313it [14:59,  6.32it/s]\u001b[A\n",
            "6314it [15:00,  6.58it/s]\u001b[A\n",
            "6315it [15:00,  6.60it/s]\u001b[A\n",
            "6316it [15:00,  6.50it/s]\u001b[A\n",
            "6317it [15:00,  6.47it/s]\u001b[A\n",
            "6318it [15:00,  6.40it/s]\u001b[A\n",
            "6319it [15:00,  6.54it/s]\u001b[A\n",
            "6320it [15:01,  6.40it/s]\u001b[A\n",
            "6321it [15:01,  6.52it/s]\u001b[A\n",
            "6322it [15:01,  6.64it/s]\u001b[A\n",
            "6323it [15:01,  6.72it/s]\u001b[A\n",
            "6324it [15:01,  6.73it/s]\u001b[A\n",
            "6325it [15:01,  6.66it/s]\u001b[A\n",
            "6326it [15:01,  6.57it/s]\u001b[A\n",
            "6327it [15:02,  6.38it/s]\u001b[A\n",
            "6328it [15:02,  6.46it/s]\u001b[A\n",
            "6329it [15:02,  6.47it/s]\u001b[A\n",
            "6330it [15:02,  6.43it/s]\u001b[A\n",
            "6331it [15:02,  6.21it/s]\u001b[A\n",
            "6332it [15:02,  6.27it/s]\u001b[A\n",
            "6333it [15:03,  6.24it/s]\u001b[A\n",
            "6334it [15:03,  6.41it/s]\u001b[A\n",
            "6335it [15:03,  6.44it/s]\u001b[A\n",
            "6336it [15:03,  6.42it/s]\u001b[A\n",
            "6337it [15:03,  6.38it/s]\u001b[A\n",
            "6338it [15:03,  6.43it/s]\u001b[A\n",
            "6339it [15:03,  6.51it/s]\u001b[A\n",
            "6340it [15:04,  6.47it/s]\u001b[A\n",
            "6341it [15:04,  6.64it/s]\u001b[A\n",
            "6342it [15:04,  6.74it/s]\u001b[A\n",
            "6343it [15:04,  6.84it/s]\u001b[A\n",
            "6344it [15:04,  6.85it/s]\u001b[A\n",
            "6345it [15:04,  6.86it/s]\u001b[A\n",
            "6346it [15:04,  6.88it/s]\u001b[A\n",
            "6347it [15:05,  6.62it/s]\u001b[A\n",
            "6348it [15:05,  6.57it/s]\u001b[A\n",
            "6349it [15:05,  6.46it/s]\u001b[A\n",
            "6350it [15:05,  6.45it/s]\u001b[A\n",
            "6351it [15:05,  6.45it/s]\u001b[A\n",
            "6352it [15:05,  6.52it/s]\u001b[A\n",
            "6353it [15:06,  6.50it/s]\u001b[A\n",
            "6354it [15:06,  6.60it/s]\u001b[A\n",
            "6355it [15:06,  6.52it/s]\u001b[A\n",
            "6356it [15:06,  6.59it/s]\u001b[A\n",
            "6357it [15:06,  6.52it/s]\u001b[A\n",
            "6358it [15:06,  6.50it/s]\u001b[A\n",
            "6359it [15:06,  6.54it/s]\u001b[A\n",
            "6360it [15:07,  6.47it/s]\u001b[A\n",
            "6361it [15:07,  6.47it/s]\u001b[A\n",
            "6362it [15:07,  6.48it/s]\u001b[A\n",
            "6363it [15:07,  6.46it/s]\u001b[A\n",
            "6364it [15:07,  6.44it/s]\u001b[A\n",
            "6365it [15:07,  6.48it/s]\u001b[A\n",
            "6366it [15:08,  6.53it/s]\u001b[A\n",
            "6367it [15:08,  6.70it/s]\u001b[A\n",
            "6368it [15:08,  6.84it/s]\u001b[A\n",
            "6369it [15:08,  6.88it/s]\u001b[A\n",
            "6370it [15:08,  6.94it/s]\u001b[A\n",
            "6371it [15:08,  6.94it/s]\u001b[A\n",
            "6372it [15:08,  6.71it/s]\u001b[A\n",
            "6373it [15:09,  6.58it/s]\u001b[A\n",
            "6374it [15:09,  6.65it/s]\u001b[A\n",
            "6375it [15:09,  6.69it/s]\u001b[A\n",
            "6376it [15:09,  6.80it/s]\u001b[A\n",
            "6377it [15:09,  6.75it/s]\u001b[A\n",
            "6378it [15:10,  4.64it/s]\u001b[A\n",
            "6379it [15:10,  5.05it/s]\u001b[A\n",
            "6380it [15:10,  5.54it/s]\u001b[A\n",
            "6381it [15:10,  5.93it/s]\u001b[A\n",
            "6382it [15:10,  6.27it/s]\u001b[A\n",
            "6383it [15:10,  6.55it/s]\u001b[A\n",
            "6384it [15:10,  6.72it/s]\u001b[A\n",
            "6385it [15:11,  6.89it/s]\u001b[A\n",
            "6386it [15:11,  6.84it/s]\u001b[A\n",
            "6387it [15:11,  6.73it/s]\u001b[A\n",
            "6388it [15:11,  6.77it/s]\u001b[A\n",
            "6389it [15:11,  6.84it/s]\u001b[A\n",
            "6390it [15:11,  6.82it/s]\u001b[A\n",
            "6391it [15:11,  6.86it/s]\u001b[A\n",
            "6392it [15:12,  6.67it/s]\u001b[A\n",
            "6393it [15:12,  6.64it/s]\u001b[A\n",
            "6394it [15:12,  6.78it/s]\u001b[A\n",
            "6395it [15:12,  6.89it/s]\u001b[A\n",
            "6396it [15:12,  6.98it/s]\u001b[A\n",
            "6397it [15:12,  7.03it/s]\u001b[A\n",
            "6398it [15:12,  7.14it/s]\u001b[A\n",
            "6399it [15:13,  7.07it/s]\u001b[A\n",
            "6400it [15:13,  6.71it/s]\u001b[A\n",
            "6401it [15:13,  6.65it/s]\u001b[A\n",
            "6402it [15:13,  6.69it/s]\u001b[A\n",
            "6403it [15:13,  6.61it/s]\u001b[A\n",
            "6404it [15:13,  6.38it/s]\u001b[A\n",
            "6405it [15:14,  6.36it/s]\u001b[A\n",
            "6406it [15:14,  6.38it/s]\u001b[A\n",
            "6407it [15:14,  6.61it/s]\u001b[A\n",
            "6408it [15:14,  6.73it/s]\u001b[A\n",
            "6409it [15:14,  6.75it/s]\u001b[A\n",
            "6410it [15:14,  6.88it/s]\u001b[A\n",
            "6411it [15:14,  6.92it/s]\u001b[A\n",
            "6412it [15:15,  7.03it/s]\u001b[A\n",
            "6413it [15:15,  6.79it/s]\u001b[A\n",
            "6414it [15:15,  6.69it/s]\u001b[A\n",
            "6415it [15:15,  6.63it/s]\u001b[A\n",
            "6416it [15:15,  6.65it/s]\u001b[A\n",
            "6417it [15:15,  6.58it/s]\u001b[A\n",
            "6418it [15:15,  6.57it/s]\u001b[A\n",
            "6419it [15:16,  6.72it/s]\u001b[A\n",
            "6420it [15:16,  6.61it/s]\u001b[A\n",
            "6421it [15:16,  6.50it/s]\u001b[A\n",
            "6422it [15:16,  6.47it/s]\u001b[A\n",
            "6423it [15:16,  6.44it/s]\u001b[A\n",
            "6424it [15:16,  6.42it/s]\u001b[A\n",
            "6425it [15:17,  6.42it/s]\u001b[A\n",
            "6426it [15:17,  6.33it/s]\u001b[A\n",
            "6427it [15:17,  6.43it/s]\u001b[A\n",
            "6428it [15:17,  6.49it/s]\u001b[A\n",
            "6429it [15:17,  6.43it/s]\u001b[A\n",
            "6430it [15:17,  6.39it/s]\u001b[A\n",
            "6431it [15:17,  6.44it/s]\u001b[A\n",
            "6432it [15:18,  6.63it/s]\u001b[A\n",
            "6433it [15:18,  6.61it/s]\u001b[A\n",
            "6434it [15:18,  6.71it/s]\u001b[A\n",
            "6435it [15:18,  6.69it/s]\u001b[A\n",
            "6436it [15:18,  6.69it/s]\u001b[A\n",
            "6437it [15:18,  6.75it/s]\u001b[A\n",
            "6438it [15:18,  6.84it/s]\u001b[A\n",
            "6439it [15:19,  6.67it/s]\u001b[A\n",
            "6440it [15:19,  6.69it/s]\u001b[A\n",
            "6441it [15:19,  6.78it/s]\u001b[A\n",
            "6442it [15:19,  6.92it/s]\u001b[A\n",
            "6443it [15:19,  6.88it/s]\u001b[A\n",
            "6444it [15:19,  6.91it/s]\u001b[A\n",
            "6445it [15:19,  6.97it/s]\u001b[A\n",
            "6446it [15:20,  6.83it/s]\u001b[A\n",
            "6447it [15:20,  6.71it/s]\u001b[A\n",
            "6448it [15:20,  6.87it/s]\u001b[A\n",
            "6449it [15:20,  6.87it/s]\u001b[A\n",
            "6450it [15:20,  6.94it/s]\u001b[A\n",
            "6451it [15:20,  7.02it/s]\u001b[A\n",
            "6452it [15:21,  6.85it/s]\u001b[A\n",
            "6453it [15:21,  6.85it/s]\u001b[A\n",
            "6454it [15:21,  6.63it/s]\u001b[A\n",
            "6455it [15:21,  6.58it/s]\u001b[A\n",
            "6456it [15:21,  6.48it/s]\u001b[A\n",
            "6457it [15:21,  6.45it/s]\u001b[A\n",
            "6458it [15:21,  6.46it/s]\u001b[A\n",
            "6459it [15:22,  6.56it/s]\u001b[A\n",
            "6460it [15:22,  6.48it/s]\u001b[A\n",
            "6461it [15:22,  6.48it/s]\u001b[A\n",
            "6462it [15:22,  6.49it/s]\u001b[A\n",
            "6463it [15:22,  6.45it/s]\u001b[A\n",
            "6464it [15:22,  6.49it/s]\u001b[A\n",
            "6465it [15:23,  6.50it/s]\u001b[A\n",
            "6466it [15:23,  6.47it/s]\u001b[A\n",
            "6467it [15:23,  6.43it/s]\u001b[A\n",
            "6468it [15:23,  6.56it/s]\u001b[A\n",
            "6469it [15:23,  6.67it/s]\u001b[A\n",
            "6470it [15:23,  6.78it/s]\u001b[A\n",
            "6471it [15:23,  6.94it/s]\u001b[A\n",
            "6472it [15:24,  6.95it/s]\u001b[A\n",
            "6473it [15:24,  6.95it/s]\u001b[A\n",
            "6474it [15:24,  6.78it/s]\u001b[A\n",
            "6475it [15:24,  6.83it/s]\u001b[A\n",
            "6476it [15:24,  6.89it/s]\u001b[A\n",
            "6477it [15:24,  6.87it/s]\u001b[A\n",
            "6478it [15:24,  6.96it/s]\u001b[A\n",
            "6479it [15:25,  6.81it/s]\u001b[A\n",
            "6480it [15:25,  6.89it/s]\u001b[A\n",
            "6481it [15:25,  6.81it/s]\u001b[A\n",
            "6482it [15:25,  6.93it/s]\u001b[A\n",
            "6483it [15:25,  7.04it/s]\u001b[A\n",
            "6484it [15:25,  7.10it/s]\u001b[A\n",
            "6485it [15:25,  7.13it/s]\u001b[A\n",
            "6486it [15:26,  7.19it/s]\u001b[A\n",
            "6487it [15:26,  7.13it/s]\u001b[A\n",
            "6488it [15:26,  7.09it/s]\u001b[A\n",
            "6489it [15:26,  7.02it/s]\u001b[A\n",
            "6490it [15:26,  7.08it/s]\u001b[A\n",
            "6491it [15:26,  7.05it/s]\u001b[A\n",
            "6492it [15:26,  7.06it/s]\u001b[A\n",
            "6493it [15:27,  6.89it/s]\u001b[A\n",
            "6494it [15:27,  6.89it/s]\u001b[A\n",
            "6495it [15:27,  6.93it/s]\u001b[A\n",
            "6496it [15:27,  7.03it/s]\u001b[A\n",
            "6497it [15:27,  7.00it/s]\u001b[A\n",
            "6498it [15:27,  7.08it/s]\u001b[A\n",
            "6499it [15:27,  7.10it/s]\u001b[A\n",
            "6500it [15:28,  7.08it/s]\u001b[A\n",
            "6501it [15:28,  6.95it/s]\u001b[A\n",
            "6502it [15:28,  6.87it/s]\u001b[A\n",
            "6503it [15:28,  6.94it/s]\u001b[A\n",
            "6504it [15:28,  6.93it/s]\u001b[A\n",
            "6505it [15:28,  7.05it/s]\u001b[A\n",
            "6506it [15:28,  7.03it/s]\u001b[A\n",
            "6507it [15:29,  7.04it/s]\u001b[A\n",
            "6508it [15:29,  6.95it/s]\u001b[A\n",
            "6509it [15:29,  6.75it/s]\u001b[A\n",
            "6510it [15:29,  6.65it/s]\u001b[A\n",
            "6511it [15:29,  6.59it/s]\u001b[A\n",
            "6512it [15:29,  6.54it/s]\u001b[A\n",
            "6513it [15:29,  6.59it/s]\u001b[A\n",
            "6514it [15:30,  6.66it/s]\u001b[A\n",
            "6515it [15:30,  6.72it/s]\u001b[A\n",
            "6516it [15:30,  6.70it/s]\u001b[A\n",
            "6517it [15:30,  6.82it/s]\u001b[A\n",
            "6518it [15:30,  6.84it/s]\u001b[A\n",
            "6519it [15:30,  6.97it/s]\u001b[A\n",
            "6520it [15:30,  7.00it/s]\u001b[A\n",
            "6521it [15:31,  6.99it/s]\u001b[A\n",
            "6522it [15:31,  6.96it/s]\u001b[A\n",
            "6523it [15:31,  6.88it/s]\u001b[A\n",
            "6524it [15:31,  6.92it/s]\u001b[A\n",
            "6525it [15:31,  6.95it/s]\u001b[A\n",
            "6526it [15:31,  7.02it/s]\u001b[A\n",
            "6527it [15:31,  7.06it/s]\u001b[A\n",
            "6528it [15:32,  7.11it/s]\u001b[A\n",
            "6529it [15:32,  6.98it/s]\u001b[A\n",
            "6530it [15:32,  6.98it/s]\u001b[A\n",
            "6531it [15:32,  6.94it/s]\u001b[A\n",
            "6532it [15:32,  6.91it/s]\u001b[A\n",
            "6533it [15:32,  6.98it/s]\u001b[A\n",
            "6534it [15:33,  6.86it/s]\u001b[A\n",
            "6535it [15:33,  6.87it/s]\u001b[A\n",
            "6536it [15:33,  6.91it/s]\u001b[A\n",
            "6537it [15:33,  6.86it/s]\u001b[A\n",
            "6538it [15:33,  6.91it/s]\u001b[A\n",
            "6539it [15:33,  6.94it/s]\u001b[A\n",
            "6540it [15:33,  7.04it/s]\u001b[A\n",
            "6541it [15:34,  7.07it/s]\u001b[A\n",
            "6542it [15:34,  7.03it/s]\u001b[A\n",
            "6543it [15:34,  7.07it/s]\u001b[A\n",
            "6544it [15:34,  6.95it/s]\u001b[A\n",
            "6545it [15:34,  6.95it/s]\u001b[A\n",
            "6546it [15:34,  6.99it/s]\u001b[A\n",
            "6547it [15:34,  6.98it/s]\u001b[A\n",
            "6548it [15:35,  6.92it/s]\u001b[A\n",
            "6549it [15:35,  6.87it/s]\u001b[A\n",
            "6550it [15:35,  6.72it/s]\u001b[A\n",
            "6551it [15:35,  6.54it/s]\u001b[A\n",
            "6552it [15:35,  6.45it/s]\u001b[A\n",
            "6553it [15:35,  6.46it/s]\u001b[A\n",
            "6554it [15:35,  6.50it/s]\u001b[A\n",
            "6555it [15:36,  6.61it/s]\u001b[A\n",
            "6556it [15:36,  6.81it/s]\u001b[A\n",
            "6557it [15:36,  6.91it/s]\u001b[A\n",
            "6558it [15:36,  6.89it/s]\u001b[A\n",
            "6559it [15:36,  6.93it/s]\u001b[A\n",
            "6560it [15:36,  6.96it/s]\u001b[A\n",
            "6561it [15:36,  6.94it/s]\u001b[A\n",
            "6562it [15:37,  6.91it/s]\u001b[A\n",
            "6563it [15:37,  6.84it/s]\u001b[A\n",
            "6564it [15:37,  6.70it/s]\u001b[A\n",
            "6565it [15:37,  6.59it/s]\u001b[A\n",
            "6566it [15:37,  6.50it/s]\u001b[A\n",
            "6567it [15:37,  6.66it/s]\u001b[A\n",
            "6568it [15:38,  6.76it/s]\u001b[A\n",
            "6569it [15:38,  6.87it/s]\u001b[A\n",
            "6570it [15:38,  6.83it/s]\u001b[A\n",
            "6571it [15:38,  6.77it/s]\u001b[A\n",
            "6572it [15:38,  6.63it/s]\u001b[A\n",
            "6573it [15:38,  6.57it/s]\u001b[A\n",
            "6574it [15:38,  6.58it/s]\u001b[A\n",
            "6575it [15:39,  6.57it/s]\u001b[A\n",
            "6576it [15:39,  6.58it/s]\u001b[A\n",
            "6577it [15:39,  6.57it/s]\u001b[A\n",
            "6578it [15:39,  6.60it/s]\u001b[A\n",
            "6579it [15:39,  6.75it/s]\u001b[A\n",
            "6580it [15:39,  6.85it/s]\u001b[A\n",
            "6581it [15:39,  6.87it/s]\u001b[A\n",
            "6582it [15:40,  6.89it/s]\u001b[A\n",
            "6583it [15:40,  6.79it/s]\u001b[A\n",
            "6584it [15:40,  6.84it/s]\u001b[A\n",
            "6585it [15:40,  6.84it/s]\u001b[A\n",
            "6586it [15:40,  6.84it/s]\u001b[A\n",
            "6587it [15:40,  6.95it/s]\u001b[A\n",
            "6588it [15:40,  6.86it/s]\u001b[A\n",
            "6589it [15:41,  6.82it/s]\u001b[A\n",
            "6590it [15:41,  6.89it/s]\u001b[A\n",
            "6591it [15:41,  6.83it/s]\u001b[A\n",
            "6592it [15:41,  6.61it/s]\u001b[A\n",
            "6593it [15:41,  6.72it/s]\u001b[A\n",
            "6594it [15:41,  6.88it/s]\u001b[A\n",
            "6595it [15:41,  6.98it/s]\u001b[A\n",
            "6596it [15:42,  6.94it/s]\u001b[A\n",
            "6597it [15:42,  6.89it/s]\u001b[A\n",
            "6598it [15:42,  6.72it/s]\u001b[A\n",
            "6599it [15:42,  6.53it/s]\u001b[A\n",
            "6600it [15:42,  6.50it/s]\u001b[A\n",
            "6601it [15:42,  6.55it/s]\u001b[A\n",
            "6602it [15:43,  6.55it/s]\u001b[A\n",
            "6603it [15:43,  6.65it/s]\u001b[A\n",
            "6604it [15:43,  6.78it/s]\u001b[A\n",
            "6605it [15:43,  6.91it/s]\u001b[A\n",
            "6606it [15:43,  6.92it/s]\u001b[A\n",
            "6607it [15:43,  6.92it/s]\u001b[A\n",
            "6608it [15:43,  6.99it/s]\u001b[A\n",
            "6609it [15:44,  7.00it/s]\u001b[A\n",
            "6610it [15:44,  6.90it/s]\u001b[A\n",
            "6611it [15:44,  6.93it/s]\u001b[A\n",
            "6612it [15:44,  6.92it/s]\u001b[A\n",
            "6613it [15:44,  6.69it/s]\u001b[A\n",
            "6614it [15:44,  6.74it/s]\u001b[A\n",
            "6615it [15:44,  6.77it/s]\u001b[A\n",
            "6616it [15:45,  6.64it/s]\u001b[A\n",
            "6617it [15:45,  6.73it/s]\u001b[A\n",
            "6618it [15:45,  6.90it/s]\u001b[A\n",
            "6619it [15:45,  6.95it/s]\u001b[A\n",
            "6620it [15:45,  6.89it/s]\u001b[A\n",
            "6621it [15:45,  6.97it/s]\u001b[A\n",
            "6622it [15:45,  6.80it/s]\u001b[A\n",
            "6623it [15:46,  6.79it/s]\u001b[A\n",
            "6624it [15:46,  6.67it/s]\u001b[A\n",
            "6625it [15:46,  6.61it/s]\u001b[A\n",
            "6626it [15:46,  6.56it/s]\u001b[A\n",
            "6627it [15:46,  6.36it/s]\u001b[A\n",
            "6628it [15:46,  6.37it/s]\u001b[A\n",
            "6629it [15:47,  6.49it/s]\u001b[A\n",
            "6630it [15:47,  6.66it/s]\u001b[A\n",
            "6631it [15:47,  6.79it/s]\u001b[A\n",
            "6632it [15:47,  6.89it/s]\u001b[A\n",
            "6633it [15:47,  6.97it/s]\u001b[A\n",
            "6634it [15:47,  6.88it/s]\u001b[A\n",
            "6635it [15:47,  6.98it/s]\u001b[A\n",
            "6636it [15:48,  7.05it/s]\u001b[A\n",
            "6637it [15:48,  7.09it/s]\u001b[A\n",
            "6638it [15:48,  7.10it/s]\u001b[A\n",
            "6639it [15:48,  7.08it/s]\u001b[A\n",
            "6640it [15:48,  7.02it/s]\u001b[A\n",
            "6641it [15:48,  6.88it/s]\u001b[A\n",
            "6642it [15:48,  6.96it/s]\u001b[A\n",
            "6643it [15:49,  6.90it/s]\u001b[A\n",
            "6644it [15:49,  6.97it/s]\u001b[A\n",
            "6645it [15:49,  6.85it/s]\u001b[A\n",
            "6646it [15:49,  6.76it/s]\u001b[A\n",
            "6647it [15:49,  6.64it/s]\u001b[A\n",
            "6648it [15:49,  6.47it/s]\u001b[A\n",
            "6649it [15:49,  6.50it/s]\u001b[A\n",
            "6650it [15:50,  6.65it/s]\u001b[A\n",
            "6651it [15:50,  6.66it/s]\u001b[A\n",
            "6652it [15:50,  6.61it/s]\u001b[A\n",
            "6653it [15:50,  6.68it/s]\u001b[A\n",
            "6654it [15:50,  6.53it/s]\u001b[A\n",
            "6655it [15:50,  6.52it/s]\u001b[A\n",
            "6656it [15:51,  6.49it/s]\u001b[A\n",
            "6657it [15:51,  6.56it/s]\u001b[A\n",
            "6658it [15:51,  6.59it/s]\u001b[A\n",
            "6659it [15:51,  6.53it/s]\u001b[A\n",
            "6660it [15:51,  6.62it/s]\u001b[A\n",
            "6661it [15:51,  6.42it/s]\u001b[A\n",
            "6662it [15:51,  6.47it/s]\u001b[A\n",
            "6663it [15:52,  6.62it/s]\u001b[A\n",
            "6664it [15:52,  6.75it/s]\u001b[A\n",
            "6665it [15:52,  6.66it/s]\u001b[A\n",
            "6666it [15:52,  6.63it/s]\u001b[A\n",
            "6667it [15:52,  6.49it/s]\u001b[A\n",
            "6668it [15:52,  6.43it/s]\u001b[A\n",
            "6669it [15:53,  6.41it/s]\u001b[A\n",
            "6670it [15:53,  6.56it/s]\u001b[A\n",
            "6671it [15:53,  6.63it/s]\u001b[A\n",
            "6672it [15:53,  6.58it/s]\u001b[A\n",
            "6673it [15:53,  6.55it/s]\u001b[A\n",
            "6674it [15:53,  6.38it/s]\u001b[A\n",
            "6675it [15:53,  6.35it/s]\u001b[A\n",
            "6676it [15:54,  6.40it/s]\u001b[A\n",
            "6677it [15:54,  6.50it/s]\u001b[A\n",
            "6678it [15:54,  6.53it/s]\u001b[A\n",
            "6679it [15:54,  6.58it/s]\u001b[A\n",
            "6680it [15:54,  6.64it/s]\u001b[A\n",
            "6681it [15:54,  6.49it/s]\u001b[A\n",
            "6682it [15:54,  6.57it/s]\u001b[A\n",
            "6683it [15:55,  6.61it/s]\u001b[A\n",
            "6684it [15:55,  6.67it/s]\u001b[A\n",
            "6685it [15:55,  6.76it/s]\u001b[A\n",
            "6686it [15:55,  4.39it/s]\u001b[A\n",
            "6687it [15:55,  4.92it/s]\u001b[A\n",
            "6688it [15:56,  5.37it/s]\u001b[A\n",
            "6689it [15:56,  5.74it/s]\u001b[A\n",
            "6690it [15:56,  6.07it/s]\u001b[A\n",
            "6691it [15:56,  6.28it/s]\u001b[A\n",
            "6692it [15:56,  6.43it/s]\u001b[A\n",
            "6693it [15:56,  6.57it/s]\u001b[A\n",
            "6694it [15:57,  6.69it/s]\u001b[A\n",
            "6695it [15:57,  6.75it/s]\u001b[A\n",
            "6696it [15:57,  6.93it/s]\u001b[A\n",
            "6697it [15:57,  6.94it/s]\u001b[A\n",
            "6698it [15:57,  6.99it/s]\u001b[A\n",
            "6699it [15:57,  7.08it/s]\u001b[A\n",
            "6700it [15:57,  7.03it/s]\u001b[A\n",
            "6701it [15:57,  7.03it/s]\u001b[A\n",
            "6702it [15:58,  6.98it/s]\u001b[A\n",
            "6703it [15:58,  7.07it/s]\u001b[A\n",
            "6704it [15:58,  7.02it/s]\u001b[A\n",
            "6705it [15:58,  7.09it/s]\u001b[A\n",
            "6706it [15:58,  7.05it/s]\u001b[A\n",
            "6707it [15:58,  6.93it/s]\u001b[A\n",
            "6708it [15:59,  6.94it/s]\u001b[A\n",
            "6709it [15:59,  7.03it/s]\u001b[A\n",
            "6710it [15:59,  7.03it/s]\u001b[A\n",
            "6711it [15:59,  7.07it/s]\u001b[A\n",
            "6712it [15:59,  7.09it/s]\u001b[A\n",
            "6713it [15:59,  7.01it/s]\u001b[A\n",
            "6714it [15:59,  7.01it/s]\u001b[A\n",
            "6715it [15:59,  7.10it/s]\u001b[A\n",
            "6716it [16:00,  7.10it/s]\u001b[A\n",
            "6717it [16:00,  7.08it/s]\u001b[A\n",
            "6718it [16:00,  6.93it/s]\u001b[A\n",
            "6719it [16:00,  6.94it/s]\u001b[A\n",
            "6720it [16:00,  6.91it/s]\u001b[A\n",
            "6721it [16:00,  6.61it/s]\u001b[A\n",
            "6722it [16:01,  6.63it/s]\u001b[A\n",
            "6723it [16:01,  6.70it/s]\u001b[A\n",
            "6724it [16:01,  6.70it/s]\u001b[A\n",
            "6725it [16:01,  6.67it/s]\u001b[A\n",
            "6726it [16:01,  6.57it/s]\u001b[A\n",
            "6727it [16:01,  6.51it/s]\u001b[A\n",
            "6728it [16:01,  6.42it/s]\u001b[A\n",
            "6729it [16:02,  6.47it/s]\u001b[A\n",
            "6730it [16:02,  6.60it/s]\u001b[A\n",
            "6731it [16:02,  6.70it/s]\u001b[A\n",
            "6732it [16:02,  6.80it/s]\u001b[A\n",
            "6733it [16:02,  6.83it/s]\u001b[A\n",
            "6734it [16:02,  6.90it/s]\u001b[A\n",
            "6735it [16:02,  6.84it/s]\u001b[A\n",
            "6736it [16:03,  6.82it/s]\u001b[A\n",
            "6737it [16:03,  6.84it/s]\u001b[A\n",
            "6738it [16:03,  6.90it/s]\u001b[A\n",
            "6739it [16:03,  6.91it/s]\u001b[A\n",
            "6740it [16:03,  7.02it/s]\u001b[A\n",
            "6741it [16:03,  6.91it/s]\u001b[A\n",
            "6742it [16:03,  6.84it/s]\u001b[A\n",
            "6743it [16:04,  6.90it/s]\u001b[A\n",
            "6744it [16:04,  6.95it/s]\u001b[A\n",
            "6745it [16:04,  6.95it/s]\u001b[A\n",
            "6746it [16:04,  6.93it/s]\u001b[A\n",
            "6747it [16:04,  6.98it/s]\u001b[A\n",
            "6748it [16:04,  7.00it/s]\u001b[A\n",
            "6749it [16:04,  6.87it/s]\u001b[A\n",
            "6750it [16:05,  6.82it/s]\u001b[A\n",
            "6751it [16:05,  6.85it/s]\u001b[A\n",
            "6752it [16:05,  6.91it/s]\u001b[A\n",
            "6753it [16:05,  7.02it/s]\u001b[A\n",
            "6754it [16:05,  6.98it/s]\u001b[A\n",
            "6755it [16:05,  7.13it/s]\u001b[A\n",
            "6756it [16:05,  7.06it/s]\u001b[A\n",
            "6757it [16:06,  7.06it/s]\u001b[A\n",
            "6758it [16:06,  6.90it/s]\u001b[A\n",
            "6759it [16:06,  6.86it/s]\u001b[A\n",
            "6760it [16:06,  6.80it/s]\u001b[A\n",
            "6761it [16:06,  6.61it/s]\u001b[A\n",
            "6762it [16:06,  6.56it/s]\u001b[A\n",
            "6763it [16:07,  6.47it/s]\u001b[A\n",
            "6764it [16:07,  6.63it/s]\u001b[A\n",
            "6765it [16:07,  6.52it/s]\u001b[A\n",
            "6766it [16:07,  6.54it/s]\u001b[A\n",
            "6767it [16:07,  6.49it/s]\u001b[A\n",
            "6768it [16:07,  6.49it/s]\u001b[A\n",
            "6769it [16:07,  6.40it/s]\u001b[A\n",
            "6770it [16:08,  6.42it/s]\u001b[A\n",
            "6771it [16:08,  6.38it/s]\u001b[A\n",
            "6772it [16:08,  6.44it/s]\u001b[A\n",
            "6773it [16:08,  6.44it/s]\u001b[A\n",
            "6774it [16:08,  6.47it/s]\u001b[A\n",
            "6775it [16:08,  6.50it/s]\u001b[A\n",
            "6776it [16:09,  6.36it/s]\u001b[A\n",
            "6777it [16:09,  6.38it/s]\u001b[A\n",
            "6778it [16:09,  6.37it/s]\u001b[A\n",
            "6779it [16:09,  6.39it/s]\u001b[A\n",
            "6780it [16:09,  6.48it/s]\u001b[A\n",
            "6781it [16:09,  6.47it/s]\u001b[A\n",
            "6782it [16:09,  6.47it/s]\u001b[A\n",
            "6783it [16:10,  6.60it/s]\u001b[A\n",
            "6784it [16:10,  6.69it/s]\u001b[A\n",
            "6785it [16:10,  6.74it/s]\u001b[A\n",
            "6786it [16:10,  6.81it/s]\u001b[A\n",
            "6787it [16:10,  6.88it/s]\u001b[A\n",
            "6788it [16:10,  6.89it/s]\u001b[A\n",
            "6789it [16:11,  6.85it/s]\u001b[A\n",
            "6790it [16:11,  6.87it/s]\u001b[A\n",
            "6791it [16:11,  6.93it/s]\u001b[A\n",
            "6792it [16:11,  6.85it/s]\u001b[A\n",
            "6793it [16:11,  6.78it/s]\u001b[A\n",
            "6794it [16:11,  6.78it/s]\u001b[A\n",
            "6795it [16:11,  6.81it/s]\u001b[A\n",
            "6796it [16:12,  6.76it/s]\u001b[A\n",
            "6797it [16:12,  6.91it/s]\u001b[A\n",
            "6798it [16:12,  7.01it/s]\u001b[A\n",
            "6799it [16:12,  6.96it/s]\u001b[A\n",
            "6800it [16:12,  7.04it/s]\u001b[A\n",
            "6801it [16:12,  7.04it/s]\u001b[A\n",
            "6802it [16:12,  6.99it/s]\u001b[A\n",
            "6803it [16:13,  6.88it/s]\u001b[A\n",
            "6804it [16:13,  6.72it/s]\u001b[A\n",
            "6805it [16:13,  6.86it/s]\u001b[A\n",
            "6806it [16:13,  6.86it/s]\u001b[A\n",
            "6807it [16:13,  6.94it/s]\u001b[A\n",
            "6808it [16:13,  6.90it/s]\u001b[A\n",
            "6809it [16:13,  6.77it/s]\u001b[A\n",
            "6810it [16:14,  6.75it/s]\u001b[A\n",
            "6811it [16:14,  6.68it/s]\u001b[A\n",
            "6812it [16:14,  6.66it/s]\u001b[A\n",
            "6813it [16:14,  6.61it/s]\u001b[A\n",
            "6814it [16:14,  6.46it/s]\u001b[A\n",
            "6815it [16:14,  6.41it/s]\u001b[A\n",
            "6816it [16:15,  6.32it/s]\u001b[A\n",
            "6817it [16:15,  6.24it/s]\u001b[A\n",
            "6818it [16:15,  6.36it/s]\u001b[A\n",
            "6819it [16:15,  6.36it/s]\u001b[A\n",
            "6820it [16:15,  6.32it/s]\u001b[A\n",
            "6821it [16:15,  6.34it/s]\u001b[A\n",
            "6822it [16:15,  6.35it/s]\u001b[A\n",
            "6823it [16:16,  6.42it/s]\u001b[A\n",
            "6824it [16:16,  6.63it/s]\u001b[A\n",
            "6825it [16:16,  6.76it/s]\u001b[A\n",
            "6826it [16:16,  6.83it/s]\u001b[A\n",
            "6827it [16:16,  6.87it/s]\u001b[A\n",
            "6828it [16:16,  6.82it/s]\u001b[A\n",
            "6829it [16:16,  6.84it/s]\u001b[A\n",
            "6830it [16:17,  6.66it/s]\u001b[A\n",
            "6831it [16:17,  6.60it/s]\u001b[A\n",
            "6832it [16:17,  6.58it/s]\u001b[A\n",
            "6833it [16:17,  6.52it/s]\u001b[A\n",
            "6834it [16:17,  6.57it/s]\u001b[A\n",
            "6835it [16:17,  6.54it/s]\u001b[A\n",
            "6836it [16:18,  6.58it/s]\u001b[A\n",
            "6837it [16:18,  6.56it/s]\u001b[A\n",
            "6838it [16:18,  6.75it/s]\u001b[A\n",
            "6839it [16:18,  6.78it/s]\u001b[A\n",
            "6840it [16:18,  6.85it/s]\u001b[A\n",
            "6841it [16:18,  6.94it/s]\u001b[A\n",
            "6842it [16:18,  6.99it/s]\u001b[A\n",
            "6843it [16:19,  7.06it/s]\u001b[A\n",
            "6844it [16:19,  7.03it/s]\u001b[A\n",
            "6845it [16:19,  7.04it/s]\u001b[A\n",
            "6846it [16:19,  7.08it/s]\u001b[A\n",
            "6847it [16:19,  7.04it/s]\u001b[A\n",
            "6848it [16:19,  7.00it/s]\u001b[A\n",
            "6849it [16:19,  6.95it/s]\u001b[A\n",
            "6850it [16:20,  6.90it/s]\u001b[A\n",
            "6851it [16:20,  6.71it/s]\u001b[A\n",
            "6852it [16:20,  6.80it/s]\u001b[A\n",
            "6853it [16:20,  6.87it/s]\u001b[A\n",
            "6854it [16:20,  6.97it/s]\u001b[A\n",
            "6855it [16:20,  6.97it/s]\u001b[A\n",
            "6856it [16:20,  6.93it/s]\u001b[A\n",
            "6857it [16:21,  6.85it/s]\u001b[A\n",
            "6858it [16:21,  6.83it/s]\u001b[A\n",
            "6859it [16:21,  6.91it/s]\u001b[A\n",
            "6860it [16:21,  6.98it/s]\u001b[A\n",
            "6861it [16:21,  7.03it/s]\u001b[A\n",
            "6862it [16:21,  7.04it/s]\u001b[A\n",
            "6863it [16:21,  7.05it/s]\u001b[A\n",
            "6864it [16:22,  6.85it/s]\u001b[A\n",
            "6865it [16:22,  6.62it/s]\u001b[A\n",
            "6866it [16:22,  6.61it/s]\u001b[A\n",
            "6867it [16:22,  6.64it/s]\u001b[A\n",
            "6868it [16:22,  6.65it/s]\u001b[A\n",
            "6869it [16:22,  6.65it/s]\u001b[A\n",
            "6870it [16:23,  6.60it/s]\u001b[A\n",
            "6871it [16:23,  6.70it/s]\u001b[A\n",
            "6872it [16:23,  6.60it/s]\u001b[A\n",
            "6873it [16:23,  6.47it/s]\u001b[A\n",
            "6874it [16:23,  6.39it/s]\u001b[A\n",
            "6875it [16:23,  6.43it/s]\u001b[A\n",
            "6876it [16:23,  6.47it/s]\u001b[A\n",
            "6877it [16:24,  6.52it/s]\u001b[A\n",
            "6878it [16:24,  6.49it/s]\u001b[A\n",
            "6879it [16:24,  6.54it/s]\u001b[A\n",
            "6880it [16:24,  6.63it/s]\u001b[A\n",
            "6881it [16:24,  6.68it/s]\u001b[A\n",
            "6882it [16:24,  6.78it/s]\u001b[A\n",
            "6883it [16:24,  6.84it/s]\u001b[A\n",
            "6884it [16:25,  6.97it/s]\u001b[A\n",
            "6885it [16:25,  6.74it/s]\u001b[A\n",
            "6886it [16:25,  6.72it/s]\u001b[A\n",
            "6887it [16:25,  6.65it/s]\u001b[A\n",
            "6888it [16:25,  6.68it/s]\u001b[A\n",
            "6889it [16:25,  6.63it/s]\u001b[A\n",
            "6890it [16:26,  6.73it/s]\u001b[A\n",
            "6891it [16:26,  6.71it/s]\u001b[A\n",
            "6892it [16:26,  6.74it/s]\u001b[A\n",
            "6893it [16:26,  6.89it/s]\u001b[A\n",
            "6894it [16:26,  6.98it/s]\u001b[A\n",
            "6895it [16:26,  7.12it/s]\u001b[A\n",
            "6896it [16:26,  7.08it/s]\u001b[A\n",
            "6897it [16:27,  6.98it/s]\u001b[A\n",
            "6898it [16:27,  6.97it/s]\u001b[A\n",
            "6899it [16:27,  6.76it/s]\u001b[A\n",
            "6900it [16:27,  6.64it/s]\u001b[A\n",
            "6901it [16:27,  6.65it/s]\u001b[A\n",
            "6902it [16:27,  6.42it/s]\u001b[A\n",
            "6903it [16:27,  6.47it/s]\u001b[A\n",
            "6904it [16:28,  6.62it/s]\u001b[A\n",
            "6905it [16:28,  6.69it/s]\u001b[A\n",
            "6906it [16:28,  6.57it/s]\u001b[A\n",
            "6907it [16:28,  6.59it/s]\u001b[A\n",
            "6908it [16:28,  6.57it/s]\u001b[A\n",
            "6909it [16:28,  6.58it/s]\u001b[A\n",
            "6910it [16:28,  6.50it/s]\u001b[A\n",
            "6911it [16:29,  6.53it/s]\u001b[A\n",
            "6912it [16:29,  6.54it/s]\u001b[A\n",
            "6913it [16:29,  6.52it/s]\u001b[A\n",
            "6914it [16:29,  6.55it/s]\u001b[A\n",
            "6915it [16:29,  6.48it/s]\u001b[A\n",
            "6916it [16:29,  6.48it/s]\u001b[A\n",
            "6917it [16:30,  6.54it/s]\u001b[A\n",
            "6918it [16:30,  6.69it/s]\u001b[A\n",
            "6919it [16:30,  6.65it/s]\u001b[A\n",
            "6920it [16:30,  6.72it/s]\u001b[A\n",
            "6921it [16:30,  6.77it/s]\u001b[A\n",
            "6922it [16:30,  6.85it/s]\u001b[A\n",
            "6923it [16:30,  6.91it/s]\u001b[A\n",
            "6924it [16:31,  6.81it/s]\u001b[A\n",
            "6925it [16:31,  6.83it/s]\u001b[A\n",
            "6926it [16:31,  6.62it/s]\u001b[A\n",
            "6927it [16:31,  6.53it/s]\u001b[A\n",
            "6928it [16:31,  6.58it/s]\u001b[A\n",
            "6929it [16:31,  6.64it/s]\u001b[A\n",
            "6930it [16:32,  6.66it/s]\u001b[A\n",
            "6931it [16:32,  6.72it/s]\u001b[A\n",
            "6932it [16:32,  6.76it/s]\u001b[A\n",
            "6933it [16:32,  6.66it/s]\u001b[A\n",
            "6934it [16:32,  6.65it/s]\u001b[A\n",
            "6935it [16:32,  6.54it/s]\u001b[A\n",
            "6936it [16:32,  6.61it/s]\u001b[A\n",
            "6937it [16:33,  6.55it/s]\u001b[A\n",
            "6938it [16:33,  6.74it/s]\u001b[A\n",
            "6939it [16:33,  6.75it/s]\u001b[A\n",
            "6940it [16:33,  6.80it/s]\u001b[A\n",
            "6941it [16:33,  6.88it/s]\u001b[A\n",
            "6942it [16:33,  6.91it/s]\u001b[A\n",
            "6943it [16:33,  7.06it/s]\u001b[A\n",
            "6944it [16:34,  7.10it/s]\u001b[A\n",
            "6945it [16:34,  7.08it/s]\u001b[A\n",
            "6946it [16:34,  7.13it/s]\u001b[A\n",
            "6947it [16:34,  7.05it/s]\u001b[A\n",
            "6948it [16:34,  7.06it/s]\u001b[A\n",
            "6949it [16:34,  7.05it/s]\u001b[A\n",
            "6950it [16:34,  7.12it/s]\u001b[A\n",
            "6951it [16:35,  6.94it/s]\u001b[A\n",
            "6952it [16:35,  6.98it/s]\u001b[A\n",
            "6953it [16:35,  6.82it/s]\u001b[A\n",
            "6954it [16:35,  6.57it/s]\u001b[A\n",
            "6955it [16:35,  6.59it/s]\u001b[A\n",
            "6956it [16:35,  6.46it/s]\u001b[A\n",
            "6957it [16:35,  6.50it/s]\u001b[A\n",
            "6958it [16:36,  6.67it/s]\u001b[A\n",
            "6959it [16:36,  6.73it/s]\u001b[A\n",
            "6960it [16:36,  6.56it/s]\u001b[A\n",
            "6961it [16:36,  6.59it/s]\u001b[A\n",
            "6962it [16:36,  6.64it/s]\u001b[A\n",
            "6963it [16:36,  6.63it/s]\u001b[A\n",
            "6964it [16:37,  6.67it/s]\u001b[A\n",
            "6965it [16:37,  6.73it/s]\u001b[A\n",
            "6966it [16:37,  6.64it/s]\u001b[A\n",
            "6967it [16:37,  6.35it/s]\u001b[A\n",
            "6968it [16:37,  6.33it/s]\u001b[A\n",
            "6969it [16:37,  6.29it/s]\u001b[A\n",
            "6970it [16:37,  6.38it/s]\u001b[A\n",
            "6971it [16:38,  6.61it/s]\u001b[A\n",
            "6972it [16:38,  6.70it/s]\u001b[A\n",
            "6973it [16:38,  6.79it/s]\u001b[A\n",
            "6974it [16:38,  6.78it/s]\u001b[A\n",
            "6975it [16:38,  6.77it/s]\u001b[A\n",
            "6976it [16:38,  6.78it/s]\u001b[A\n",
            "6977it [16:38,  6.85it/s]\u001b[A\n",
            "6978it [16:39,  6.83it/s]\u001b[A\n",
            "6979it [16:39,  6.98it/s]\u001b[A\n",
            "6980it [16:39,  7.06it/s]\u001b[A\n",
            "6981it [16:39,  7.00it/s]\u001b[A\n",
            "6982it [16:39,  7.02it/s]\u001b[A\n",
            "6983it [16:39,  7.10it/s]\u001b[A\n",
            "6984it [16:39,  7.04it/s]\u001b[A\n",
            "6985it [16:40,  7.06it/s]\u001b[A\n",
            "6986it [16:40,  6.98it/s]\u001b[A\n",
            "6987it [16:40,  6.99it/s]\u001b[A\n",
            "6988it [16:40,  6.84it/s]\u001b[A\n",
            "6989it [16:40,  6.89it/s]\u001b[A\n",
            "6990it [16:40,  6.90it/s]\u001b[A\n",
            "6991it [16:40,  6.81it/s]\u001b[A\n",
            "6992it [16:41,  6.83it/s]\u001b[A\n",
            "6993it [16:41,  6.76it/s]\u001b[A\n",
            "6994it [16:41,  6.64it/s]\u001b[A\n",
            "6995it [16:41,  6.45it/s]\u001b[A\n",
            "6996it [16:41,  6.43it/s]\u001b[A\n",
            "6997it [16:41,  6.47it/s]\u001b[A\n",
            "6998it [16:42,  6.68it/s]\u001b[A\n",
            "6999it [16:42,  6.77it/s]\u001b[A\n",
            "7000it [16:42,  6.91it/s]\u001b[A\n",
            "7001it [16:42,  7.02it/s]\u001b[A\n",
            "7002it [16:42,  6.88it/s]\u001b[A\n",
            "7003it [16:42,  6.89it/s]\u001b[A\n",
            "7004it [16:42,  6.95it/s]\u001b[A\n",
            "7005it [16:43,  6.95it/s]\u001b[A\n",
            "7006it [16:43,  6.84it/s]\u001b[A\n",
            "7007it [16:43,  6.79it/s]\u001b[A\n",
            "7008it [16:43,  6.46it/s]\u001b[A\n",
            "7009it [16:43,  6.44it/s]\u001b[A\n",
            "7010it [16:43,  6.50it/s]\u001b[A\n",
            "7011it [16:43,  6.61it/s]\u001b[A\n",
            "7012it [16:44,  6.81it/s]\u001b[A\n",
            "7013it [16:44,  6.83it/s]\u001b[A\n",
            "7014it [16:44,  6.88it/s]\u001b[A\n",
            "7015it [16:44,  6.86it/s]\u001b[A\n",
            "7016it [16:44,  6.94it/s]\u001b[A\n",
            "7017it [16:44,  6.94it/s]\u001b[A\n",
            "7018it [16:44,  6.96it/s]\u001b[A\n",
            "7019it [16:45,  6.77it/s]\u001b[A\n",
            "7020it [16:45,  6.71it/s]\u001b[A\n",
            "7021it [16:45,  6.75it/s]\u001b[A\n",
            "7022it [16:45,  6.77it/s]\u001b[A\n",
            "7023it [16:45,  6.88it/s]\u001b[A\n",
            "7024it [16:45,  6.92it/s]\u001b[A\n",
            "7025it [16:46,  6.88it/s]\u001b[A\n",
            "7026it [16:46,  6.86it/s]\u001b[A\n",
            "7027it [16:46,  6.87it/s]\u001b[A\n",
            "7028it [16:46,  6.98it/s]\u001b[A\n",
            "7029it [16:46,  6.94it/s]\u001b[A\n",
            "7030it [16:46,  6.93it/s]\u001b[A\n",
            "7031it [16:46,  6.93it/s]\u001b[A\n",
            "7032it [16:47,  6.90it/s]\u001b[A\n",
            "7033it [16:47,  6.89it/s]\u001b[A\n",
            "7034it [16:47,  6.96it/s]\u001b[A\n",
            "7035it [16:47,  6.90it/s]\u001b[A\n",
            "7036it [16:47,  6.89it/s]\u001b[A\n",
            "7037it [16:47,  6.97it/s]\u001b[A\n",
            "7038it [16:47,  6.84it/s]\u001b[A\n",
            "7039it [16:48,  6.89it/s]\u001b[A\n",
            "7040it [16:48,  6.97it/s]\u001b[A\n",
            "7041it [16:48,  7.01it/s]\u001b[A\n",
            "7042it [16:48,  7.07it/s]\u001b[A\n",
            "7043it [16:48,  6.96it/s]\u001b[A\n",
            "7044it [16:48,  6.91it/s]\u001b[A\n",
            "7045it [16:48,  6.91it/s]\u001b[A\n",
            "7046it [16:49,  6.81it/s]\u001b[A\n",
            "7047it [16:49,  6.92it/s]\u001b[A\n",
            "7048it [16:49,  6.96it/s]\u001b[A\n",
            "7049it [16:49,  7.02it/s]\u001b[A\n",
            "7050it [16:49,  6.74it/s]\u001b[A\n",
            "7051it [16:49,  6.63it/s]\u001b[A\n",
            "7052it [16:49,  6.52it/s]\u001b[A\n",
            "7053it [16:50,  6.44it/s]\u001b[A\n",
            "7054it [16:50,  6.38it/s]\u001b[A\n",
            "7055it [16:50,  6.50it/s]\u001b[A\n",
            "7056it [16:50,  6.66it/s]\u001b[A\n",
            "7057it [16:50,  6.65it/s]\u001b[A\n",
            "7058it [16:50,  6.75it/s]\u001b[A\n",
            "7059it [16:50,  6.82it/s]\u001b[A\n",
            "7060it [16:51,  6.85it/s]\u001b[A\n",
            "7061it [16:51,  6.75it/s]\u001b[A\n",
            "7062it [16:51,  6.84it/s]\u001b[A\n",
            "7063it [16:51,  6.89it/s]\u001b[A\n",
            "7064it [16:51,  6.81it/s]\u001b[A\n",
            "7065it [16:51,  6.85it/s]\u001b[A\n",
            "7066it [16:52,  6.92it/s]\u001b[A\n",
            "7067it [16:52,  6.90it/s]\u001b[A\n",
            "7068it [16:52,  6.96it/s]\u001b[A\n",
            "7069it [16:52,  6.88it/s]\u001b[A\n",
            "7070it [16:52,  6.93it/s]\u001b[A\n",
            "7071it [16:52,  6.88it/s]\u001b[A\n",
            "7072it [16:52,  6.97it/s]\u001b[A\n",
            "7073it [16:53,  6.89it/s]\u001b[A\n",
            "7074it [16:53,  6.84it/s]\u001b[A\n",
            "7075it [16:53,  6.75it/s]\u001b[A\n",
            "7076it [16:53,  6.54it/s]\u001b[A\n",
            "7077it [16:53,  6.49it/s]\u001b[A\n",
            "7078it [16:53,  6.34it/s]\u001b[A\n",
            "7079it [16:53,  6.38it/s]\u001b[A\n",
            "7080it [16:54,  6.55it/s]\u001b[A\n",
            "7081it [16:54,  6.77it/s]\u001b[A\n",
            "7082it [16:54,  6.84it/s]\u001b[A\n",
            "7083it [16:54,  6.89it/s]\u001b[A\n",
            "7084it [16:54,  6.81it/s]\u001b[A\n",
            "7085it [16:54,  6.74it/s]\u001b[A\n",
            "7086it [16:54,  6.80it/s]\u001b[A\n",
            "7087it [16:55,  6.69it/s]\u001b[A\n",
            "7088it [16:55,  6.73it/s]\u001b[A\n",
            "7089it [16:55,  6.66it/s]\u001b[A\n",
            "7090it [16:55,  6.61it/s]\u001b[A\n",
            "7091it [16:55,  6.50it/s]\u001b[A\n",
            "7092it [16:55,  6.42it/s]\u001b[A\n",
            "7093it [16:56,  6.56it/s]\u001b[A\n",
            "7094it [16:56,  6.61it/s]\u001b[A\n",
            "7095it [16:56,  6.58it/s]\u001b[A\n",
            "7096it [16:56,  6.60it/s]\u001b[A\n",
            "7097it [16:56,  6.59it/s]\u001b[A\n",
            "7098it [16:56,  6.47it/s]\u001b[A\n",
            "7099it [16:56,  6.50it/s]\u001b[A\n",
            "7100it [16:57,  6.56it/s]\u001b[A\n",
            "7101it [16:57,  6.46it/s]\u001b[A\n",
            "7102it [16:57,  6.55it/s]\u001b[A\n",
            "7103it [16:57,  6.47it/s]\u001b[A\n",
            "7104it [16:57,  6.44it/s]\u001b[A\n",
            "7105it [16:57,  6.32it/s]\u001b[A\n",
            "7106it [16:58,  6.51it/s]\u001b[A\n",
            "7107it [16:58,  6.71it/s]\u001b[A\n",
            "7108it [16:58,  6.55it/s]\u001b[A\n",
            "7109it [16:58,  6.53it/s]\u001b[A\n",
            "7110it [16:58,  6.55it/s]\u001b[A\n",
            "7111it [16:58,  6.43it/s]\u001b[A\n",
            "7112it [16:58,  6.50it/s]\u001b[A\n",
            "7113it [16:59,  6.50it/s]\u001b[A\n",
            "7114it [16:59,  6.45it/s]\u001b[A\n",
            "7115it [16:59,  6.44it/s]\u001b[A\n",
            "7116it [16:59,  6.43it/s]\u001b[A\n",
            "7117it [16:59,  6.47it/s]\u001b[A\n",
            "7118it [16:59,  6.41it/s]\u001b[A\n",
            "7119it [17:00,  6.40it/s]\u001b[A\n",
            "7120it [17:00,  6.30it/s]\u001b[A\n",
            "7121it [17:00,  6.37it/s]\u001b[A\n",
            "7122it [17:00,  6.55it/s]\u001b[A\n",
            "7123it [17:00,  6.77it/s]\u001b[A\n",
            "7124it [17:00,  6.78it/s]\u001b[A\n",
            "7125it [17:00,  6.80it/s]\u001b[A\n",
            "7126it [17:01,  6.85it/s]\u001b[A\n",
            "7127it [17:01,  6.36it/s]\u001b[A\n",
            "7128it [17:01,  6.42it/s]\u001b[A\n",
            "7129it [17:01,  6.44it/s]\u001b[A\n",
            "7130it [17:01,  6.46it/s]\u001b[A\n",
            "7131it [17:01,  6.45it/s]\u001b[A\n",
            "7132it [17:02,  6.51it/s]\u001b[A\n",
            "7133it [17:02,  6.52it/s]\u001b[A\n",
            "7134it [17:02,  6.68it/s]\u001b[A\n",
            "7135it [17:02,  6.73it/s]\u001b[A\n",
            "7136it [17:02,  6.85it/s]\u001b[A\n",
            "7137it [17:02,  6.94it/s]\u001b[A\n",
            "7138it [17:02,  6.88it/s]\u001b[A\n",
            "7139it [17:03,  6.68it/s]\u001b[A\n",
            "7140it [17:03,  6.71it/s]\u001b[A\n",
            "7141it [17:03,  6.87it/s]\u001b[A\n",
            "7142it [17:03,  6.94it/s]\u001b[A\n",
            "7143it [17:03,  6.95it/s]\u001b[A\n",
            "7144it [17:03,  7.00it/s]\u001b[A\n",
            "7145it [17:03,  6.91it/s]\u001b[A\n",
            "7146it [17:04,  6.96it/s]\u001b[A\n",
            "7147it [17:04,  6.82it/s]\u001b[A\n",
            "7148it [17:04,  6.70it/s]\u001b[A\n",
            "7149it [17:04,  6.69it/s]\u001b[A\n",
            "7150it [17:04,  6.71it/s]\u001b[A\n",
            "7151it [17:04,  6.59it/s]\u001b[A\n",
            "7152it [17:05,  6.40it/s]\u001b[A\n",
            "7153it [17:05,  6.45it/s]\u001b[A\n",
            "7154it [17:05,  6.47it/s]\u001b[A\n",
            "7155it [17:05,  6.49it/s]\u001b[A\n",
            "7156it [17:05,  6.43it/s]\u001b[A\n",
            "7157it [17:05,  6.39it/s]\u001b[A\n",
            "7158it [17:05,  6.38it/s]\u001b[A\n",
            "7159it [17:06,  6.29it/s]\u001b[A\n",
            "7160it [17:06,  6.33it/s]\u001b[A\n",
            "7161it [17:06,  6.53it/s]\u001b[A\n",
            "7162it [17:06,  6.72it/s]\u001b[A\n",
            "7163it [17:06,  6.73it/s]\u001b[A\n",
            "7164it [17:06,  6.61it/s]\u001b[A\n",
            "7165it [17:06,  6.53it/s]\u001b[A\n",
            "7166it [17:07,  6.48it/s]\u001b[A\n",
            "7167it [17:07,  6.54it/s]\u001b[A\n",
            "7168it [17:07,  6.72it/s]\u001b[A\n",
            "7169it [17:07,  6.87it/s]\u001b[A\n",
            "7170it [17:07,  6.96it/s]\u001b[A\n",
            "7171it [17:07,  6.90it/s]\u001b[A\n",
            "7172it [17:08,  6.73it/s]\u001b[A\n",
            "7173it [17:08,  6.85it/s]\u001b[A\n",
            "7174it [17:08,  6.90it/s]\u001b[A\n",
            "7175it [17:08,  6.94it/s]\u001b[A\n",
            "7176it [17:08,  6.96it/s]\u001b[A\n",
            "7177it [17:08,  7.05it/s]\u001b[A\n",
            "7178it [17:08,  6.98it/s]\u001b[A\n",
            "7179it [17:09,  6.85it/s]\u001b[A\n",
            "7180it [17:09,  6.79it/s]\u001b[A\n",
            "7181it [17:09,  6.70it/s]\u001b[A\n",
            "7182it [17:09,  6.55it/s]\u001b[A\n",
            "7183it [17:09,  6.53it/s]\u001b[A\n",
            "7184it [17:09,  6.49it/s]\u001b[A\n",
            "7185it [17:09,  6.46it/s]\u001b[A\n",
            "7186it [17:10,  6.58it/s]\u001b[A\n",
            "7187it [17:10,  6.64it/s]\u001b[A\n",
            "7188it [17:10,  6.81it/s]\u001b[A\n",
            "7189it [17:10,  6.91it/s]\u001b[A\n",
            "7190it [17:10,  6.98it/s]\u001b[A\n",
            "7191it [17:10,  7.01it/s]\u001b[A\n",
            "7192it [17:10,  6.93it/s]\u001b[A\n",
            "7193it [17:11,  6.81it/s]\u001b[A\n",
            "7194it [17:11,  6.76it/s]\u001b[A\n",
            "7195it [17:11,  6.84it/s]\u001b[A\n",
            "7196it [17:11,  6.74it/s]\u001b[A\n",
            "7197it [17:11,  6.59it/s]\u001b[A\n",
            "7198it [17:11,  6.74it/s]\u001b[A\n",
            "7199it [17:12,  6.72it/s]\u001b[A\n",
            "7200it [17:12,  6.77it/s]\u001b[A\n",
            "7201it [17:12,  6.72it/s]\u001b[A\n",
            "7202it [17:12,  6.63it/s]\u001b[A\n",
            "7203it [17:12,  6.58it/s]\u001b[A\n",
            "7204it [17:12,  6.55it/s]\u001b[A\n",
            "7205it [17:12,  6.59it/s]\u001b[A\n",
            "7206it [17:13,  6.47it/s]\u001b[A\n",
            "7207it [17:13,  6.64it/s]\u001b[A\n",
            "7208it [17:13,  6.86it/s]\u001b[A\n",
            "7209it [17:13,  6.89it/s]\u001b[A\n",
            "7210it [17:13,  6.94it/s]\u001b[A\n",
            "7211it [17:13,  6.97it/s]\u001b[A\n",
            "7212it [17:13,  6.81it/s]\u001b[A\n",
            "7213it [17:14,  6.68it/s]\u001b[A\n",
            "7214it [17:14,  6.74it/s]\u001b[A\n",
            "7215it [17:14,  6.85it/s]\u001b[A\n",
            "7216it [17:14,  6.82it/s]\u001b[A\n",
            "7217it [17:14,  6.80it/s]\u001b[A\n",
            "7218it [17:14,  6.82it/s]\u001b[A\n",
            "7219it [17:14,  6.98it/s]\u001b[A\n",
            "7220it [17:15,  6.79it/s]\u001b[A\n",
            "7221it [17:15,  6.85it/s]\u001b[A\n",
            "7222it [17:15,  6.96it/s]\u001b[A\n",
            "7223it [17:15,  7.02it/s]\u001b[A\n",
            "7224it [17:15,  7.01it/s]\u001b[A\n",
            "7225it [17:15,  7.05it/s]\u001b[A\n",
            "7226it [17:15,  7.06it/s]\u001b[A\n",
            "7227it [17:16,  6.80it/s]\u001b[A\n",
            "7228it [17:16,  6.74it/s]\u001b[A\n",
            "7229it [17:16,  6.65it/s]\u001b[A\n",
            "7230it [17:16,  6.55it/s]\u001b[A\n",
            "7231it [17:16,  6.52it/s]\u001b[A\n",
            "7232it [17:16,  6.18it/s]\u001b[A\n",
            "7233it [17:17,  6.22it/s]\u001b[A\n",
            "7234it [17:17,  6.18it/s]\u001b[A\n",
            "7235it [17:17,  6.19it/s]\u001b[A\n",
            "7236it [17:17,  6.11it/s]\u001b[A\n",
            "7237it [17:17,  6.23it/s]\u001b[A\n",
            "7238it [17:17,  6.27it/s]\u001b[A\n",
            "7239it [17:18,  6.50it/s]\u001b[A\n",
            "7240it [17:18,  6.54it/s]\u001b[A\n",
            "7241it [17:18,  6.69it/s]\u001b[A\n",
            "7242it [17:18,  6.88it/s]\u001b[A\n",
            "7243it [17:18,  6.90it/s]\u001b[A\n",
            "7244it [17:18,  6.84it/s]\u001b[A\n",
            "7245it [17:18,  6.84it/s]\u001b[A\n",
            "7246it [17:19,  6.74it/s]\u001b[A\n",
            "7247it [17:19,  6.72it/s]\u001b[A\n",
            "7248it [17:19,  6.63it/s]\u001b[A\n",
            "7249it [17:19,  6.52it/s]\u001b[A\n",
            "7250it [17:19,  6.50it/s]\u001b[A\n",
            "7251it [17:19,  6.40it/s]\u001b[A\n",
            "7252it [17:19,  6.40it/s]\u001b[A\n",
            "7253it [17:20,  6.46it/s]\u001b[A\n",
            "7254it [17:20,  6.54it/s]\u001b[A\n",
            "7255it [17:20,  6.59it/s]\u001b[A\n",
            "7256it [17:20,  6.65it/s]\u001b[A\n",
            "7257it [17:20,  6.55it/s]\u001b[A\n",
            "7258it [17:20,  6.53it/s]\u001b[A\n",
            "7259it [17:21,  6.46it/s]\u001b[A\n",
            "7260it [17:21,  6.41it/s]\u001b[A\n",
            "7261it [17:21,  6.42it/s]\u001b[A\n",
            "7262it [17:21,  6.50it/s]\u001b[A\n",
            "7263it [17:21,  6.47it/s]\u001b[A\n",
            "7264it [17:21,  6.42it/s]\u001b[A\n",
            "7265it [17:21,  6.50it/s]\u001b[A\n",
            "7266it [17:22,  6.66it/s]\u001b[A\n",
            "7267it [17:22,  6.50it/s]\u001b[A\n",
            "7268it [17:22,  6.49it/s]\u001b[A\n",
            "7269it [17:22,  6.53it/s]\u001b[A\n",
            "7270it [17:22,  6.45it/s]\u001b[A\n",
            "7271it [17:22,  6.33it/s]\u001b[A\n",
            "7272it [17:23,  6.42it/s]\u001b[A\n",
            "7273it [17:23,  6.33it/s]\u001b[A\n",
            "7274it [17:23,  6.37it/s]\u001b[A\n",
            "7275it [17:23,  6.25it/s]\u001b[A\n",
            "7276it [17:23,  6.30it/s]\u001b[A\n",
            "7277it [17:23,  6.40it/s]\u001b[A\n",
            "7278it [17:24,  6.29it/s]\u001b[A\n",
            "7279it [17:24,  6.24it/s]\u001b[A\n",
            "7280it [17:24,  6.38it/s]\u001b[A\n",
            "7281it [17:24,  6.55it/s]\u001b[A\n",
            "7282it [17:24,  6.60it/s]\u001b[A\n",
            "7283it [17:24,  6.75it/s]\u001b[A\n",
            "7284it [17:24,  6.78it/s]\u001b[A\n",
            "7285it [17:25,  6.75it/s]\u001b[A\n",
            "7286it [17:25,  6.72it/s]\u001b[A\n",
            "7287it [17:25,  6.67it/s]\u001b[A\n",
            "7288it [17:25,  6.49it/s]\u001b[A\n",
            "7289it [17:25,  6.53it/s]\u001b[A\n",
            "7290it [17:25,  6.46it/s]\u001b[A\n",
            "7291it [17:25,  6.57it/s]\u001b[A\n",
            "7292it [17:26,  6.74it/s]\u001b[A\n",
            "7293it [17:26,  6.69it/s]\u001b[A\n",
            "7294it [17:26,  6.66it/s]\u001b[A\n",
            "7295it [17:26,  6.62it/s]\u001b[A\n",
            "7296it [17:26,  6.79it/s]\u001b[A\n",
            "7297it [17:26,  6.87it/s]\u001b[A\n",
            "7298it [17:27,  6.92it/s]\u001b[A\n",
            "7299it [17:27,  6.90it/s]\u001b[A\n",
            "7300it [17:27,  6.75it/s]\u001b[A\n",
            "7301it [17:27,  6.70it/s]\u001b[A\n",
            "7302it [17:27,  6.60it/s]\u001b[A\n",
            "7303it [17:27,  6.57it/s]\u001b[A\n",
            "7304it [17:28,  3.99it/s]\u001b[A\n",
            "7305it [17:28,  4.60it/s]\u001b[A\n",
            "7306it [17:28,  5.10it/s]\u001b[A\n",
            "7307it [17:28,  5.51it/s]\u001b[A\n",
            "7308it [17:28,  5.88it/s]\u001b[A\n",
            "7309it [17:28,  6.19it/s]\u001b[A\n",
            "7310it [17:29,  6.31it/s]\u001b[A\n",
            "7311it [17:29,  6.32it/s]\u001b[A\n",
            "7312it [17:29,  6.35it/s]\u001b[A\n",
            "7313it [17:29,  6.43it/s]\u001b[A\n",
            "7314it [17:29,  6.44it/s]\u001b[A\n",
            "7315it [17:29,  6.42it/s]\u001b[A\n",
            "7316it [17:30,  6.52it/s]\u001b[A\n",
            "7317it [17:30,  6.70it/s]\u001b[A\n",
            "7318it [17:30,  6.55it/s]\u001b[A\n",
            "7319it [17:30,  6.49it/s]\u001b[A\n",
            "7320it [17:30,  6.46it/s]\u001b[A\n",
            "7321it [17:30,  6.44it/s]\u001b[A\n",
            "7322it [17:30,  6.41it/s]\u001b[A\n",
            "7323it [17:31,  6.50it/s]\u001b[A\n",
            "7324it [17:31,  6.67it/s]\u001b[A\n",
            "7325it [17:31,  6.66it/s]\u001b[A\n",
            "7326it [17:31,  6.78it/s]\u001b[A\n",
            "7327it [17:31,  6.80it/s]\u001b[A\n",
            "7328it [17:31,  6.86it/s]\u001b[A\n",
            "7329it [17:31,  6.90it/s]\u001b[A\n",
            "7330it [17:32,  6.93it/s]\u001b[A\n",
            "7331it [17:32,  6.66it/s]\u001b[A\n",
            "7332it [17:32,  6.55it/s]\u001b[A\n",
            "7333it [17:32,  6.49it/s]\u001b[A\n",
            "7334it [17:32,  6.46it/s]\u001b[A\n",
            "7335it [17:32,  6.47it/s]\u001b[A\n",
            "7336it [17:33,  6.50it/s]\u001b[A\n",
            "7337it [17:33,  6.61it/s]\u001b[A\n",
            "7338it [17:33,  6.60it/s]\u001b[A\n",
            "7339it [17:33,  6.74it/s]\u001b[A\n",
            "7340it [17:33,  6.78it/s]\u001b[A\n",
            "7341it [17:33,  6.84it/s]\u001b[A\n",
            "7342it [17:33,  6.71it/s]\u001b[A\n",
            "7343it [17:34,  6.73it/s]\u001b[A\n",
            "7344it [17:34,  6.66it/s]\u001b[A\n",
            "7345it [17:34,  6.48it/s]\u001b[A\n",
            "7346it [17:34,  6.47it/s]\u001b[A\n",
            "7347it [17:34,  6.44it/s]\u001b[A\n",
            "7348it [17:34,  6.42it/s]\u001b[A\n",
            "7349it [17:35,  6.45it/s]\u001b[A\n",
            "7350it [17:35,  6.54it/s]\u001b[A\n",
            "7351it [17:35,  6.43it/s]\u001b[A\n",
            "7352it [17:35,  6.44it/s]\u001b[A\n",
            "7353it [17:35,  6.46it/s]\u001b[A\n",
            "7354it [17:35,  6.25it/s]\u001b[A\n",
            "7355it [17:35,  6.31it/s]\u001b[A\n",
            "7356it [17:36,  6.35it/s]\u001b[A\n",
            "7357it [17:36,  6.44it/s]\u001b[A\n",
            "7358it [17:36,  6.40it/s]\u001b[A\n",
            "7359it [17:36,  6.55it/s]\u001b[A\n",
            "7360it [17:36,  6.72it/s]\u001b[A\n",
            "7361it [17:36,  6.83it/s]\u001b[A\n",
            "7362it [17:37,  6.73it/s]\u001b[A\n",
            "7363it [17:37,  6.62it/s]\u001b[A\n",
            "7364it [17:37,  6.54it/s]\u001b[A\n",
            "7365it [17:37,  6.41it/s]\u001b[A\n",
            "7366it [17:37,  6.30it/s]\u001b[A\n",
            "7367it [17:37,  6.31it/s]\u001b[A\n",
            "7368it [17:37,  6.39it/s]\u001b[A\n",
            "7369it [17:38,  6.58it/s]\u001b[A\n",
            "7370it [17:38,  6.71it/s]\u001b[A\n",
            "7371it [17:38,  6.74it/s]\u001b[A\n",
            "7372it [17:38,  6.82it/s]\u001b[A\n",
            "7373it [17:38,  6.97it/s]\u001b[A\n",
            "7374it [17:38,  6.95it/s]\u001b[A\n",
            "7375it [17:38,  6.98it/s]\u001b[A\n",
            "7376it [17:39,  6.85it/s]\u001b[A\n",
            "7377it [17:39,  6.74it/s]\u001b[A\n",
            "7378it [17:39,  6.54it/s]\u001b[A\n",
            "7379it [17:39,  6.49it/s]\u001b[A\n",
            "7380it [17:39,  6.48it/s]\u001b[A\n",
            "7381it [17:39,  6.48it/s]\u001b[A\n",
            "7382it [17:40,  6.64it/s]\u001b[A\n",
            "7383it [17:40,  6.67it/s]\u001b[A\n",
            "7384it [17:40,  6.65it/s]\u001b[A\n",
            "7385it [17:40,  6.51it/s]\u001b[A\n",
            "7386it [17:40,  6.43it/s]\u001b[A\n",
            "7387it [17:40,  6.43it/s]\u001b[A\n",
            "7388it [17:40,  6.43it/s]\u001b[A\n",
            "7389it [17:41,  6.47it/s]\u001b[A\n",
            "7390it [17:41,  6.34it/s]\u001b[A\n",
            "7391it [17:41,  6.28it/s]\u001b[A\n",
            "7392it [17:41,  6.31it/s]\u001b[A\n",
            "7393it [17:41,  6.18it/s]\u001b[A\n",
            "7394it [17:41,  6.28it/s]\u001b[A\n",
            "7395it [17:42,  6.50it/s]\u001b[A\n",
            "7396it [17:42,  6.67it/s]\u001b[A\n",
            "7397it [17:42,  6.80it/s]\u001b[A\n",
            "7398it [17:42,  6.75it/s]\u001b[A\n",
            "7399it [17:42,  6.77it/s]\u001b[A\n",
            "7400it [17:42,  6.93it/s]\u001b[A\n",
            "7401it [17:42,  6.96it/s]\u001b[A\n",
            "7402it [17:43,  6.81it/s]\u001b[A\n",
            "7403it [17:43,  6.82it/s]\u001b[A\n",
            "7404it [17:43,  6.88it/s]\u001b[A\n",
            "7405it [17:43,  6.89it/s]\u001b[A\n",
            "7406it [17:43,  6.95it/s]\u001b[A\n",
            "7407it [17:43,  6.99it/s]\u001b[A\n",
            "7408it [17:43,  7.01it/s]\u001b[A\n",
            "7409it [17:44,  7.01it/s]\u001b[A\n",
            "7410it [17:44,  6.84it/s]\u001b[A\n",
            "7411it [17:44,  6.80it/s]\u001b[A\n",
            "7412it [17:44,  6.67it/s]\u001b[A\n",
            "7413it [17:44,  6.54it/s]\u001b[A\n",
            "7414it [17:44,  6.46it/s]\u001b[A\n",
            "7415it [17:45,  6.42it/s]\u001b[A\n",
            "7416it [17:45,  6.50it/s]\u001b[A\n",
            "7417it [17:45,  6.66it/s]\u001b[A\n",
            "7418it [17:45,  6.81it/s]\u001b[A\n",
            "7419it [17:45,  6.78it/s]\u001b[A\n",
            "7420it [17:45,  6.76it/s]\u001b[A\n",
            "7421it [17:45,  6.80it/s]\u001b[A\n",
            "7422it [17:46,  6.90it/s]\u001b[A\n",
            "7423it [17:46,  6.84it/s]\u001b[A\n",
            "7424it [17:46,  7.01it/s]\u001b[A\n",
            "7425it [17:46,  6.96it/s]\u001b[A\n",
            "7426it [17:46,  6.82it/s]\u001b[A\n",
            "7427it [17:46,  6.97it/s]\u001b[A\n",
            "7428it [17:46,  6.98it/s]\u001b[A\n",
            "7429it [17:47,  6.88it/s]\u001b[A\n",
            "7430it [17:47,  6.82it/s]\u001b[A\n",
            "7431it [17:47,  6.71it/s]\u001b[A\n",
            "7432it [17:47,  6.46it/s]\u001b[A\n",
            "7433it [17:47,  6.39it/s]\u001b[A\n",
            "7434it [17:47,  6.40it/s]\u001b[A\n",
            "7435it [17:47,  6.49it/s]\u001b[A\n",
            "7436it [17:48,  6.67it/s]\u001b[A\n",
            "7437it [17:48,  6.73it/s]\u001b[A\n",
            "7438it [17:48,  6.85it/s]\u001b[A\n",
            "7439it [17:48,  6.78it/s]\u001b[A\n",
            "7440it [17:48,  6.92it/s]\u001b[A\n",
            "7441it [17:48,  7.06it/s]\u001b[A\n",
            "7442it [17:48,  7.04it/s]\u001b[A\n",
            "7443it [17:49,  6.85it/s]\u001b[A\n",
            "7444it [17:49,  6.73it/s]\u001b[A\n",
            "7445it [17:49,  6.67it/s]\u001b[A\n",
            "7446it [17:49,  6.43it/s]\u001b[A\n",
            "7447it [17:49,  6.38it/s]\u001b[A\n",
            "7448it [17:49,  6.38it/s]\u001b[A\n",
            "7449it [17:50,  6.58it/s]\u001b[A\n",
            "7450it [17:50,  6.61it/s]\u001b[A\n",
            "7451it [17:50,  6.68it/s]\u001b[A\n",
            "7452it [17:50,  6.76it/s]\u001b[A\n",
            "7453it [17:50,  6.60it/s]\u001b[A\n",
            "7454it [17:50,  6.70it/s]\u001b[A\n",
            "7455it [17:50,  6.80it/s]\u001b[A\n",
            "7456it [17:51,  6.78it/s]\u001b[A\n",
            "7457it [17:51,  6.75it/s]\u001b[A\n",
            "7458it [17:51,  6.72it/s]\u001b[A\n",
            "7459it [17:51,  6.65it/s]\u001b[A\n",
            "7460it [17:51,  6.41it/s]\u001b[A\n",
            "7461it [17:51,  6.37it/s]\u001b[A\n",
            "7462it [17:52,  6.44it/s]\u001b[A\n",
            "7463it [17:52,  6.56it/s]\u001b[A\n",
            "7464it [17:52,  6.57it/s]\u001b[A\n",
            "7465it [17:52,  6.60it/s]\u001b[A\n",
            "7466it [17:52,  6.44it/s]\u001b[A\n",
            "7467it [17:52,  6.49it/s]\u001b[A\n",
            "7468it [17:52,  6.43it/s]\u001b[A\n",
            "7469it [17:53,  6.54it/s]\u001b[A\n",
            "7470it [17:53,  6.67it/s]\u001b[A\n",
            "7471it [17:53,  6.75it/s]\u001b[A\n",
            "7472it [17:53,  6.86it/s]\u001b[A\n",
            "7473it [17:53,  6.78it/s]\u001b[A\n",
            "7474it [17:53,  6.92it/s]\u001b[A\n",
            "7475it [17:53,  7.00it/s]\u001b[A\n",
            "7476it [17:54,  7.01it/s]\u001b[A\n",
            "7477it [17:54,  7.08it/s]\u001b[A\n",
            "7478it [17:54,  7.04it/s]\u001b[A\n",
            "7479it [17:54,  7.13it/s]\u001b[A\n",
            "7480it [17:54,  7.03it/s]\u001b[A\n",
            "7481it [17:54,  6.97it/s]\u001b[A\n",
            "7482it [17:54,  6.95it/s]\u001b[A\n",
            "7483it [17:55,  6.95it/s]\u001b[A\n",
            "7484it [17:55,  6.96it/s]\u001b[A\n",
            "7485it [17:55,  7.01it/s]\u001b[A\n",
            "7486it [17:55,  6.89it/s]\u001b[A\n",
            "7487it [17:55,  6.85it/s]\u001b[A\n",
            "7488it [17:55,  6.88it/s]\u001b[A\n",
            "7489it [17:55,  6.94it/s]\u001b[A\n",
            "7490it [17:56,  6.97it/s]\u001b[A\n",
            "7491it [17:56,  6.82it/s]\u001b[A\n",
            "7492it [17:56,  6.70it/s]\u001b[A\n",
            "7493it [17:56,  6.36it/s]\u001b[A\n",
            "7494it [17:56,  6.27it/s]\u001b[A\n",
            "7495it [17:56,  6.29it/s]\u001b[A\n",
            "7496it [17:57,  6.40it/s]\u001b[A\n",
            "7497it [17:57,  6.53it/s]\u001b[A\n",
            "7498it [17:57,  6.72it/s]\u001b[A\n",
            "7499it [17:57,  6.82it/s]\u001b[A\n",
            "7500it [17:57,  6.90it/s]\u001b[A\n",
            "7501it [17:57,  6.76it/s]\u001b[A\n",
            "7502it [17:57,  6.83it/s]\u001b[A\n",
            "7503it [17:58,  6.92it/s]\u001b[A\n",
            "7504it [17:58,  6.77it/s]\u001b[A\n",
            "7505it [17:58,  6.55it/s]\u001b[A\n",
            "7506it [17:58,  6.49it/s]\u001b[A\n",
            "7507it [17:58,  6.45it/s]\u001b[A\n",
            "7508it [17:58,  6.45it/s]\u001b[A\n",
            "7509it [17:59,  6.38it/s]\u001b[A\n",
            "7510it [17:59,  6.44it/s]\u001b[A\n",
            "7511it [17:59,  6.41it/s]\u001b[A\n",
            "7512it [17:59,  6.51it/s]\u001b[A\n",
            "7513it [17:59,  6.54it/s]\u001b[A\n",
            "7514it [17:59,  6.62it/s]\u001b[A\n",
            "7515it [17:59,  6.69it/s]\u001b[A\n",
            "7516it [18:00,  6.64it/s]\u001b[A\n",
            "7517it [18:00,  6.61it/s]\u001b[A\n",
            "7518it [18:00,  6.78it/s]\u001b[A\n",
            "7519it [18:00,  6.81it/s]\u001b[A\n",
            "7520it [18:00,  6.84it/s]\u001b[A\n",
            "7521it [18:00,  6.59it/s]\u001b[A\n",
            "7522it [18:00,  6.54it/s]\u001b[A\n",
            "7523it [18:01,  6.66it/s]\u001b[A\n",
            "7524it [18:01,  6.78it/s]\u001b[A\n",
            "7525it [18:01,  6.91it/s]\u001b[A\n",
            "7526it [18:01,  6.89it/s]\u001b[A\n",
            "7527it [18:01,  6.92it/s]\u001b[A\n",
            "7528it [18:01,  6.72it/s]\u001b[A\n",
            "7529it [18:02,  6.80it/s]\u001b[A\n",
            "7530it [18:02,  6.85it/s]\u001b[A\n",
            "7531it [18:02,  6.95it/s]\u001b[A\n",
            "7532it [18:02,  6.99it/s]\u001b[A\n",
            "7533it [18:02,  7.00it/s]\u001b[A\n",
            "7534it [18:02,  7.04it/s]\u001b[A\n",
            "7535it [18:02,  6.97it/s]\u001b[A\n",
            "7536it [18:03,  6.88it/s]\u001b[A\n",
            "7537it [18:03,  6.88it/s]\u001b[A\n",
            "7538it [18:03,  6.84it/s]\u001b[A\n",
            "7539it [18:03,  6.71it/s]\u001b[A\n",
            "7540it [18:03,  6.67it/s]\u001b[A\n",
            "7541it [18:03,  6.55it/s]\u001b[A\n",
            "7542it [18:03,  6.45it/s]\u001b[A\n",
            "7543it [18:04,  6.54it/s]\u001b[A\n",
            "7544it [18:04,  6.61it/s]\u001b[A\n",
            "7545it [18:04,  6.76it/s]\u001b[A\n",
            "7546it [18:04,  6.82it/s]\u001b[A\n",
            "7547it [18:04,  6.79it/s]\u001b[A\n",
            "7548it [18:04,  6.90it/s]\u001b[A\n",
            "7549it [18:04,  6.88it/s]\u001b[A\n",
            "7550it [18:05,  6.80it/s]\u001b[A\n",
            "7551it [18:05,  6.93it/s]\u001b[A\n",
            "7552it [18:05,  6.92it/s]\u001b[A\n",
            "7553it [18:05,  6.94it/s]\u001b[A\n",
            "7554it [18:05,  7.02it/s]\u001b[A\n",
            "7555it [18:05,  7.01it/s]\u001b[A\n",
            "7556it [18:05,  6.94it/s]\u001b[A\n",
            "7557it [18:06,  6.98it/s]\u001b[A\n",
            "7558it [18:06,  6.80it/s]\u001b[A\n",
            "7559it [18:06,  6.72it/s]\u001b[A\n",
            "7560it [18:06,  6.66it/s]\u001b[A\n",
            "7561it [18:06,  6.62it/s]\u001b[A\n",
            "7562it [18:06,  6.51it/s]\u001b[A\n",
            "7563it [18:07,  6.41it/s]\u001b[A\n",
            "7564it [18:07,  6.50it/s]\u001b[A\n",
            "7565it [18:07,  6.46it/s]\u001b[A\n",
            "7566it [18:07,  6.48it/s]\u001b[A\n",
            "7567it [18:07,  6.40it/s]\u001b[A\n",
            "7568it [18:07,  6.42it/s]\u001b[A\n",
            "7569it [18:07,  6.33it/s]\u001b[A\n",
            "7570it [18:08,  6.41it/s]\u001b[A\n",
            "7571it [18:08,  6.51it/s]\u001b[A\n",
            "7572it [18:08,  6.47it/s]\u001b[A\n",
            "7573it [18:08,  6.49it/s]\u001b[A\n",
            "7574it [18:08,  6.60it/s]\u001b[A\n",
            "7575it [18:08,  6.71it/s]\u001b[A\n",
            "7576it [18:09,  6.64it/s]\u001b[A\n",
            "7577it [18:09,  6.58it/s]\u001b[A\n",
            "7578it [18:09,  6.51it/s]\u001b[A\n",
            "7579it [18:09,  6.45it/s]\u001b[A\n",
            "7580it [18:09,  6.54it/s]\u001b[A\n",
            "7581it [18:09,  6.73it/s]\u001b[A\n",
            "7582it [18:09,  6.52it/s]\u001b[A\n",
            "7583it [18:10,  6.72it/s]\u001b[A\n",
            "7584it [18:10,  6.78it/s]\u001b[A\n",
            "7585it [18:10,  6.64it/s]\u001b[A\n",
            "7586it [18:10,  6.56it/s]\u001b[A\n",
            "7587it [18:10,  6.54it/s]\u001b[A\n",
            "7588it [18:10,  6.50it/s]\u001b[A\n",
            "7589it [18:11,  6.39it/s]\u001b[A\n",
            "7590it [18:11,  6.48it/s]\u001b[A\n",
            "7591it [18:11,  6.50it/s]\u001b[A\n",
            "7592it [18:11,  6.59it/s]\u001b[A\n",
            "7593it [18:11,  6.50it/s]\u001b[A\n",
            "7594it [18:11,  6.36it/s]\u001b[A\n",
            "7595it [18:11,  6.31it/s]\u001b[A\n",
            "7596it [18:12,  6.38it/s]\u001b[A\n",
            "7597it [18:12,  6.58it/s]\u001b[A\n",
            "7598it [18:12,  6.74it/s]\u001b[A\n",
            "7599it [18:12,  6.79it/s]\u001b[A\n",
            "7600it [18:12,  6.83it/s]\u001b[A\n",
            "7601it [18:12,  6.87it/s]\u001b[A\n",
            "7602it [18:12,  6.87it/s]\u001b[A\n",
            "7603it [18:13,  6.65it/s]\u001b[A\n",
            "7604it [18:13,  6.68it/s]\u001b[A\n",
            "7605it [18:13,  6.71it/s]\u001b[A\n",
            "7606it [18:13,  6.60it/s]\u001b[A\n",
            "7607it [18:13,  6.52it/s]\u001b[A\n",
            "7608it [18:13,  6.50it/s]\u001b[A\n",
            "7609it [18:14,  6.37it/s]\u001b[A\n",
            "7610it [18:14,  6.43it/s]\u001b[A\n",
            "7611it [18:14,  6.56it/s]\u001b[A\n",
            "7612it [18:14,  6.65it/s]\u001b[A\n",
            "7613it [18:14,  4.85it/s]\u001b[A\n",
            "7614it [18:14,  5.28it/s]\u001b[A\n",
            "7615it [18:15,  5.60it/s]\u001b[A\n",
            "7616it [18:15,  5.97it/s]\u001b[A\n",
            "7617it [18:15,  6.25it/s]\u001b[A\n",
            "7618it [18:15,  6.47it/s]\u001b[A\n",
            "7619it [18:15,  6.62it/s]\u001b[A\n",
            "7620it [18:15,  6.77it/s]\u001b[A\n",
            "7621it [18:15,  6.86it/s]\u001b[A\n",
            "7622it [18:16,  6.81it/s]\u001b[A\n",
            "7623it [18:16,  6.94it/s]\u001b[A\n",
            "7624it [18:16,  7.00it/s]\u001b[A\n",
            "7625it [18:16,  7.03it/s]\u001b[A\n",
            "7626it [18:16,  7.03it/s]\u001b[A\n",
            "7627it [18:16,  7.02it/s]\u001b[A\n",
            "7628it [18:16,  6.92it/s]\u001b[A\n",
            "7629it [18:17,  6.80it/s]\u001b[A\n",
            "7630it [18:17,  6.60it/s]\u001b[A\n",
            "7631it [18:17,  6.54it/s]\u001b[A\n",
            "7632it [18:17,  6.55it/s]\u001b[A\n",
            "7633it [18:17,  6.60it/s]\u001b[A\n",
            "7634it [18:17,  6.50it/s]\u001b[A\n",
            "7635it [18:18,  6.52it/s]\u001b[A\n",
            "7636it [18:18,  6.69it/s]\u001b[A\n",
            "7637it [18:18,  6.88it/s]\u001b[A\n",
            "7638it [18:18,  6.92it/s]\u001b[A\n",
            "7639it [18:18,  6.95it/s]\u001b[A\n",
            "7640it [18:18,  6.95it/s]\u001b[A\n",
            "7641it [18:18,  7.06it/s]\u001b[A\n",
            "7642it [18:19,  6.70it/s]\u001b[A\n",
            "7643it [18:19,  6.62it/s]\u001b[A\n",
            "7644it [18:19,  6.64it/s]\u001b[A\n",
            "7645it [18:19,  6.61it/s]\u001b[A\n",
            "7646it [18:19,  6.52it/s]\u001b[A\n",
            "7647it [18:19,  6.62it/s]\u001b[A\n",
            "7648it [18:19,  6.71it/s]\u001b[A\n",
            "7649it [18:20,  6.70it/s]\u001b[A\n",
            "7650it [18:20,  6.77it/s]\u001b[A\n",
            "7651it [18:20,  6.92it/s]\u001b[A\n",
            "7652it [18:20,  7.09it/s]\u001b[A\n",
            "7653it [18:20,  7.06it/s]\u001b[A\n",
            "7654it [18:20,  6.87it/s]\u001b[A\n",
            "7655it [18:21,  6.53it/s]\u001b[A\n",
            "7656it [18:21,  6.44it/s]\u001b[A\n",
            "7657it [18:21,  6.45it/s]\u001b[A\n",
            "7658it [18:21,  6.47it/s]\u001b[A\n",
            "7659it [18:21,  6.54it/s]\u001b[A\n",
            "7660it [18:21,  6.51it/s]\u001b[A\n",
            "7661it [18:21,  6.50it/s]\u001b[A\n",
            "7662it [18:22,  6.69it/s]\u001b[A\n",
            "7663it [18:22,  6.57it/s]\u001b[A\n",
            "7664it [18:22,  6.65it/s]\u001b[A\n",
            "7665it [18:22,  6.83it/s]\u001b[A\n",
            "7666it [18:22,  6.89it/s]\u001b[A\n",
            "7667it [18:22,  6.98it/s]\u001b[A\n",
            "7668it [18:22,  7.00it/s]\u001b[A\n",
            "7669it [18:23,  6.94it/s]\u001b[A\n",
            "7670it [18:23,  6.76it/s]\u001b[A\n",
            "7671it [18:23,  6.69it/s]\u001b[A\n",
            "7672it [18:23,  6.72it/s]\u001b[A\n",
            "7673it [18:23,  6.65it/s]\u001b[A\n",
            "7674it [18:23,  6.58it/s]\u001b[A\n",
            "7675it [18:24,  6.57it/s]\u001b[A\n",
            "7676it [18:24,  6.57it/s]\u001b[A\n",
            "7677it [18:24,  6.65it/s]\u001b[A\n",
            "7678it [18:24,  6.75it/s]\u001b[A\n",
            "7679it [18:24,  6.70it/s]\u001b[A\n",
            "7680it [18:24,  6.63it/s]\u001b[A\n",
            "7681it [18:24,  6.68it/s]\u001b[A\n",
            "7682it [18:25,  6.69it/s]\u001b[A\n",
            "7683it [18:25,  6.53it/s]\u001b[A\n",
            "7684it [18:25,  6.63it/s]\u001b[A\n",
            "7685it [18:25,  6.75it/s]\u001b[A\n",
            "7686it [18:25,  6.89it/s]\u001b[A\n",
            "7687it [18:25,  6.99it/s]\u001b[A\n",
            "7688it [18:25,  7.10it/s]\u001b[A\n",
            "7689it [18:26,  7.00it/s]\u001b[A\n",
            "7690it [18:26,  6.85it/s]\u001b[A\n",
            "7691it [18:26,  7.01it/s]\u001b[A\n",
            "7692it [18:26,  7.10it/s]\u001b[A\n",
            "7693it [18:26,  7.03it/s]\u001b[A\n",
            "7694it [18:26,  7.10it/s]\u001b[A\n",
            "7695it [18:26,  7.14it/s]\u001b[A\n",
            "7696it [18:27,  6.98it/s]\u001b[A\n",
            "7697it [18:27,  6.89it/s]\u001b[A\n",
            "7698it [18:27,  6.98it/s]\u001b[A\n",
            "7699it [18:27,  7.03it/s]\u001b[A\n",
            "7700it [18:27,  7.07it/s]\u001b[A\n",
            "7701it [18:27,  7.02it/s]\u001b[A\n",
            "7702it [18:27,  7.01it/s]\u001b[A\n",
            "7703it [18:28,  7.07it/s]\u001b[A\n",
            "7704it [18:28,  7.04it/s]\u001b[A\n",
            "7705it [18:28,  6.98it/s]\u001b[A\n",
            "7706it [18:28,  7.09it/s]\u001b[A\n",
            "7707it [18:28,  7.11it/s]\u001b[A\n",
            "7708it [18:28,  7.09it/s]\u001b[A\n",
            "7709it [18:28,  7.11it/s]\u001b[A\n",
            "7710it [18:29,  7.02it/s]\u001b[A\n",
            "7711it [18:29,  6.97it/s]\u001b[A\n",
            "7712it [18:29,  6.83it/s]\u001b[A\n",
            "7713it [18:29,  6.73it/s]\u001b[A\n",
            "7714it [18:29,  6.63it/s]\u001b[A\n",
            "7715it [18:29,  6.41it/s]\u001b[A\n",
            "7716it [18:29,  6.34it/s]\u001b[A\n",
            "7717it [18:30,  6.43it/s]\u001b[A\n",
            "7718it [18:30,  6.46it/s]\u001b[A\n",
            "7719it [18:30,  6.48it/s]\u001b[A\n",
            "7720it [18:30,  6.54it/s]\u001b[A\n",
            "7721it [18:30,  6.50it/s]\u001b[A\n",
            "7722it [18:30,  6.53it/s]\u001b[A\n",
            "7723it [18:31,  6.61it/s]\u001b[A\n",
            "7724it [18:31,  6.59it/s]\u001b[A\n",
            "7725it [18:31,  6.54it/s]\u001b[A\n",
            "7726it [18:31,  6.54it/s]\u001b[A\n",
            "7727it [18:31,  6.53it/s]\u001b[A\n",
            "7728it [18:31,  6.63it/s]\u001b[A\n",
            "7729it [18:31,  6.60it/s]\u001b[A\n",
            "7730it [18:32,  6.67it/s]\u001b[A\n",
            "7731it [18:32,  6.73it/s]\u001b[A\n",
            "7732it [18:32,  6.69it/s]\u001b[A\n",
            "7733it [18:32,  6.84it/s]\u001b[A\n",
            "7734it [18:32,  6.97it/s]\u001b[A\n",
            "7735it [18:32,  7.09it/s]\u001b[A\n",
            "7736it [18:32,  7.01it/s]\u001b[A\n",
            "7737it [18:33,  6.93it/s]\u001b[A\n",
            "7738it [18:33,  6.57it/s]\u001b[A\n",
            "7739it [18:33,  6.46it/s]\u001b[A\n",
            "7740it [18:33,  6.44it/s]\u001b[A\n",
            "7741it [18:33,  6.42it/s]\u001b[A\n",
            "7742it [18:33,  6.49it/s]\u001b[A\n",
            "7743it [18:34,  6.64it/s]\u001b[A\n",
            "7744it [18:34,  6.75it/s]\u001b[A\n",
            "7745it [18:34,  6.57it/s]\u001b[A\n",
            "7746it [18:34,  6.53it/s]\u001b[A\n",
            "7747it [18:34,  6.50it/s]\u001b[A\n",
            "7748it [18:34,  6.52it/s]\u001b[A\n",
            "7749it [18:34,  6.48it/s]\u001b[A\n",
            "7750it [18:35,  6.57it/s]\u001b[A\n",
            "7751it [18:35,  6.56it/s]\u001b[A\n",
            "7752it [18:35,  6.45it/s]\u001b[A\n",
            "7753it [18:35,  6.51it/s]\u001b[A\n",
            "7754it [18:35,  6.46it/s]\u001b[A\n",
            "7755it [18:35,  6.55it/s]\u001b[A\n",
            "7756it [18:36,  6.66it/s]\u001b[A\n",
            "7757it [18:36,  6.83it/s]\u001b[A\n",
            "7758it [18:36,  6.87it/s]\u001b[A\n",
            "7759it [18:36,  6.76it/s]\u001b[A\n",
            "7760it [18:36,  6.91it/s]\u001b[A\n",
            "7761it [18:36,  7.00it/s]\u001b[A\n",
            "7762it [18:36,  7.14it/s]\u001b[A\n",
            "7763it [18:37,  7.05it/s]\u001b[A\n",
            "7764it [18:37,  7.00it/s]\u001b[A\n",
            "7765it [18:37,  6.93it/s]\u001b[A\n",
            "7766it [18:37,  6.85it/s]\u001b[A\n",
            "7767it [18:37,  6.96it/s]\u001b[A\n",
            "7768it [18:37,  6.78it/s]\u001b[A\n",
            "7769it [18:37,  6.72it/s]\u001b[A\n",
            "7770it [18:38,  4.32it/s]\u001b[A\n",
            "7771it [18:38,  4.81it/s]\u001b[A\n",
            "7772it [18:38,  5.32it/s]\u001b[A\n",
            "7773it [18:38,  5.78it/s]\u001b[A\n",
            "7774it [18:38,  6.16it/s]\u001b[A\n",
            "7775it [18:39,  6.27it/s]\u001b[A\n",
            "7776it [18:39,  6.38it/s]\u001b[A\n",
            "7777it [18:39,  6.64it/s]\u001b[A\n",
            "7778it [18:39,  6.63it/s]\u001b[A\n",
            "7779it [18:39,  6.61it/s]\u001b[A\n",
            "7780it [18:39,  6.72it/s]\u001b[A\n",
            "7781it [18:39,  6.77it/s]\u001b[A\n",
            "7782it [18:40,  6.85it/s]\u001b[A\n",
            "7783it [18:40,  6.98it/s]\u001b[A\n",
            "7784it [18:40,  7.03it/s]\u001b[A\n",
            "7785it [18:40,  6.96it/s]\u001b[A\n",
            "7786it [18:40,  6.97it/s]\u001b[A\n",
            "7787it [18:40,  7.01it/s]\u001b[A\n",
            "7788it [18:40,  6.96it/s]\u001b[A\n",
            "7789it [18:41,  6.82it/s]\u001b[A\n",
            "7790it [18:41,  6.84it/s]\u001b[A\n",
            "7791it [18:41,  6.70it/s]\u001b[A\n",
            "7792it [18:41,  6.55it/s]\u001b[A\n",
            "7793it [18:41,  6.40it/s]\u001b[A\n",
            "7794it [18:41,  6.23it/s]\u001b[A\n",
            "7795it [18:42,  6.38it/s]\u001b[A\n",
            "7796it [18:42,  6.58it/s]\u001b[A\n",
            "7797it [18:42,  6.71it/s]\u001b[A\n",
            "7798it [18:42,  6.65it/s]\u001b[A\n",
            "7799it [18:42,  6.76it/s]\u001b[A\n",
            "7800it [18:42,  6.81it/s]\u001b[A\n",
            "7801it [18:42,  6.89it/s]\u001b[A\n",
            "7802it [18:43,  6.87it/s]\u001b[A\n",
            "7803it [18:43,  6.81it/s]\u001b[A\n",
            "7804it [18:43,  6.79it/s]\u001b[A\n",
            "7805it [18:43,  6.85it/s]\u001b[A\n",
            "7806it [18:43,  6.83it/s]\u001b[A\n",
            "7807it [18:43,  6.90it/s]\u001b[A\n",
            "7808it [18:43,  6.93it/s]\u001b[A\n",
            "7809it [18:44,  6.88it/s]\u001b[A\n",
            "7810it [18:44,  6.94it/s]\u001b[A\n",
            "7811it [18:44,  6.87it/s]\u001b[A\n",
            "7812it [18:44,  6.85it/s]\u001b[A\n",
            "7813it [18:44,  6.76it/s]\u001b[A\n",
            "7814it [18:44,  6.75it/s]\u001b[A\n",
            "7815it [18:44,  6.86it/s]\u001b[A\n",
            "7816it [18:45,  6.94it/s]\u001b[A\n",
            "7817it [18:45,  7.06it/s]\u001b[A\n",
            "7818it [18:45,  6.92it/s]\u001b[A\n",
            "7819it [18:45,  6.85it/s]\u001b[A\n",
            "7820it [18:45,  6.90it/s]\u001b[A\n",
            "7821it [18:45,  7.05it/s]\u001b[A\n",
            "7822it [18:45,  7.06it/s]\u001b[A\n",
            "7823it [18:46,  7.07it/s]\u001b[A\n",
            "7824it [18:46,  7.07it/s]\u001b[A\n",
            "7825it [18:46,  6.99it/s]\u001b[A\n",
            "7826it [18:46,  6.94it/s]\u001b[A\n",
            "7827it [18:46,  7.07it/s]\u001b[A\n",
            "7828it [18:46,  7.11it/s]\u001b[A\n",
            "7829it [18:46,  7.14it/s]\u001b[A\n",
            "7830it [18:47,  6.97it/s]\u001b[A\n",
            "7831it [18:47,  6.94it/s]\u001b[A\n",
            "7832it [18:47,  6.83it/s]\u001b[A\n",
            "7833it [18:47,  6.69it/s]\u001b[A\n",
            "7834it [18:47,  6.70it/s]\u001b[A\n",
            "7835it [18:47,  6.62it/s]\u001b[A\n",
            "7836it [18:47,  6.54it/s]\u001b[A\n",
            "7837it [18:48,  6.68it/s]\u001b[A\n",
            "7838it [18:48,  6.49it/s]\u001b[A\n",
            "7839it [18:48,  6.44it/s]\u001b[A\n",
            "7840it [18:48,  6.44it/s]\u001b[A\n",
            "7841it [18:48,  6.47it/s]\u001b[A\n",
            "7842it [18:48,  6.48it/s]\u001b[A\n",
            "7843it [18:49,  6.45it/s]\u001b[A\n",
            "7844it [18:49,  6.59it/s]\u001b[A\n",
            "7845it [18:49,  6.74it/s]\u001b[A\n",
            "7846it [18:49,  6.87it/s]\u001b[A\n",
            "7847it [18:49,  6.96it/s]\u001b[A\n",
            "7848it [18:49,  6.98it/s]\u001b[A\n",
            "7849it [18:49,  7.02it/s]\u001b[A\n",
            "7850it [18:50,  6.90it/s]\u001b[A\n",
            "7851it [18:50,  6.91it/s]\u001b[A\n",
            "7852it [18:50,  6.73it/s]\u001b[A\n",
            "7853it [18:50,  6.70it/s]\u001b[A\n",
            "7854it [18:50,  6.53it/s]\u001b[A\n",
            "7855it [18:50,  6.55it/s]\u001b[A\n",
            "7856it [18:50,  6.51it/s]\u001b[A\n",
            "7857it [18:51,  6.60it/s]\u001b[A\n",
            "7858it [18:51,  6.56it/s]\u001b[A\n",
            "7859it [18:51,  6.50it/s]\u001b[A\n",
            "7860it [18:51,  6.39it/s]\u001b[A\n",
            "7861it [18:51,  6.38it/s]\u001b[A\n",
            "7862it [18:51,  6.42it/s]\u001b[A\n",
            "7863it [18:52,  6.54it/s]\u001b[A\n",
            "7864it [18:52,  6.61it/s]\u001b[A\n",
            "7865it [18:52,  6.60it/s]\u001b[A\n",
            "7866it [18:52,  6.54it/s]\u001b[A\n",
            "7867it [18:52,  6.46it/s]\u001b[A\n",
            "7868it [18:52,  6.45it/s]\u001b[A\n",
            "7869it [18:52,  6.46it/s]\u001b[A\n",
            "7870it [18:53,  6.61it/s]\u001b[A\n",
            "7871it [18:53,  6.79it/s]\u001b[A\n",
            "7872it [18:53,  6.87it/s]\u001b[A\n",
            "7873it [18:53,  6.89it/s]\u001b[A\n",
            "7874it [18:53,  6.89it/s]\u001b[A\n",
            "7875it [18:53,  6.95it/s]\u001b[A\n",
            "7876it [18:53,  7.03it/s]\u001b[A\n",
            "7877it [18:54,  7.07it/s]\u001b[A\n",
            "7878it [18:54,  7.08it/s]\u001b[A\n",
            "7879it [18:54,  7.07it/s]\u001b[A\n",
            "7880it [18:54,  7.00it/s]\u001b[A\n",
            "7881it [18:54,  6.91it/s]\u001b[A\n",
            "7882it [18:54,  6.97it/s]\u001b[A\n",
            "7883it [18:54,  6.94it/s]\u001b[A\n",
            "7884it [18:55,  6.87it/s]\u001b[A\n",
            "7885it [18:55,  6.80it/s]\u001b[A\n",
            "7886it [18:55,  6.76it/s]\u001b[A\n",
            "7887it [18:55,  6.64it/s]\u001b[A\n",
            "7888it [18:55,  6.29it/s]\u001b[A\n",
            "7889it [18:55,  6.40it/s]\u001b[A\n",
            "7890it [18:56,  6.55it/s]\u001b[A\n",
            "7891it [18:56,  6.72it/s]\u001b[A\n",
            "7892it [18:56,  6.82it/s]\u001b[A\n",
            "7893it [18:56,  6.81it/s]\u001b[A\n",
            "7894it [18:56,  6.54it/s]\u001b[A\n",
            "7895it [18:56,  6.73it/s]\u001b[A\n",
            "7896it [18:56,  6.80it/s]\u001b[A\n",
            "7897it [18:57,  6.83it/s]\u001b[A\n",
            "7898it [18:57,  6.90it/s]\u001b[A\n",
            "7899it [18:57,  7.02it/s]\u001b[A\n",
            "7900it [18:57,  7.05it/s]\u001b[A\n",
            "7901it [18:57,  7.00it/s]\u001b[A\n",
            "7902it [18:57,  6.94it/s]\u001b[A\n",
            "7903it [18:57,  6.99it/s]\u001b[A\n",
            "7904it [18:58,  6.96it/s]\u001b[A\n",
            "7905it [18:58,  7.00it/s]\u001b[A\n",
            "7906it [18:58,  6.96it/s]\u001b[A\n",
            "7907it [18:58,  7.04it/s]\u001b[A\n",
            "7908it [18:58,  7.08it/s]\u001b[A\n",
            "7909it [18:58,  7.08it/s]\u001b[A\n",
            "7910it [18:58,  7.07it/s]\u001b[A\n",
            "7911it [18:59,  7.04it/s]\u001b[A\n",
            "7912it [18:59,  7.10it/s]\u001b[A\n",
            "7913it [18:59,  6.94it/s]\u001b[A\n",
            "7914it [18:59,  6.83it/s]\u001b[A\n",
            "7915it [18:59,  6.70it/s]\u001b[A\n",
            "7916it [18:59,  6.50it/s]\u001b[A\n",
            "7917it [18:59,  6.58it/s]\u001b[A\n",
            "7918it [19:00,  6.73it/s]\u001b[A\n",
            "7919it [19:00,  6.76it/s]\u001b[A\n",
            "7920it [19:00,  6.72it/s]\u001b[A\n",
            "7921it [19:00,  6.64it/s]\u001b[A\n",
            "7922it [19:00,  6.45it/s]\u001b[A\n",
            "7923it [19:00,  6.43it/s]\u001b[A\n",
            "7924it [19:01,  6.49it/s]\u001b[A\n",
            "7925it [19:01,  6.53it/s]\u001b[A\n",
            "7926it [19:01,  6.69it/s]\u001b[A\n",
            "7927it [19:01,  6.83it/s]\u001b[A\n",
            "7928it [19:01,  6.97it/s]\u001b[A\n",
            "7929it [19:01,  6.91it/s]\u001b[A\n",
            "7930it [19:01,  7.06it/s]\u001b[A\n",
            "7931it [19:02,  7.05it/s]\u001b[A\n",
            "7932it [19:02,  7.08it/s]\u001b[A\n",
            "7933it [19:02,  7.06it/s]\u001b[A\n",
            "7934it [19:02,  7.02it/s]\u001b[A\n",
            "7935it [19:02,  6.97it/s]\u001b[A\n",
            "7936it [19:02,  6.70it/s]\u001b[A\n",
            "7937it [19:02,  6.74it/s]\u001b[A\n",
            "7938it [19:03,  6.71it/s]\u001b[A\n",
            "7939it [19:03,  6.68it/s]\u001b[A\n",
            "7940it [19:03,  6.57it/s]\u001b[A\n",
            "7941it [19:03,  6.62it/s]\u001b[A\n",
            "7942it [19:03,  6.51it/s]\u001b[A\n",
            "7943it [19:03,  6.41it/s]\u001b[A\n",
            "7944it [19:04,  6.46it/s]\u001b[A\n",
            "7945it [19:04,  6.58it/s]\u001b[A\n",
            "7946it [19:04,  6.73it/s]\u001b[A\n",
            "7947it [19:04,  6.86it/s]\u001b[A\n",
            "7948it [19:04,  6.92it/s]\u001b[A\n",
            "7949it [19:04,  7.08it/s]\u001b[A\n",
            "7950it [19:04,  7.05it/s]\u001b[A\n",
            "7951it [19:04,  7.09it/s]\u001b[A\n",
            "7952it [19:05,  7.08it/s]\u001b[A\n",
            "7953it [19:05,  7.03it/s]\u001b[A\n",
            "7954it [19:05,  7.05it/s]\u001b[A\n",
            "7955it [19:05,  7.09it/s]\u001b[A\n",
            "7956it [19:05,  7.10it/s]\u001b[A\n",
            "7957it [19:05,  7.02it/s]\u001b[A\n",
            "7958it [19:05,  6.94it/s]\u001b[A\n",
            "7959it [19:06,  6.96it/s]\u001b[A\n",
            "7960it [19:06,  6.77it/s]\u001b[A\n",
            "7961it [19:06,  6.77it/s]\u001b[A\n",
            "7962it [19:06,  6.63it/s]\u001b[A\n",
            "7963it [19:06,  6.63it/s]\u001b[A\n",
            "7964it [19:06,  6.53it/s]\u001b[A\n",
            "7965it [19:07,  6.57it/s]\u001b[A\n",
            "7966it [19:07,  6.60it/s]\u001b[A\n",
            "7967it [19:07,  6.57it/s]\u001b[A\n",
            "7968it [19:07,  6.55it/s]\u001b[A\n",
            "7969it [19:07,  6.58it/s]\u001b[A\n",
            "7970it [19:07,  6.58it/s]\u001b[A\n",
            "7971it [19:07,  6.52it/s]\u001b[A\n",
            "7972it [19:08,  6.62it/s]\u001b[A\n",
            "7973it [19:08,  6.70it/s]\u001b[A\n",
            "7974it [19:08,  6.57it/s]\u001b[A\n",
            "7975it [19:08,  6.71it/s]\u001b[A\n",
            "7976it [19:08,  6.89it/s]\u001b[A\n",
            "7977it [19:08,  7.02it/s]\u001b[A\n",
            "7978it [19:08,  6.89it/s]\u001b[A\n",
            "7979it [19:09,  6.75it/s]\u001b[A\n",
            "7980it [19:09,  6.65it/s]\u001b[A\n",
            "7981it [19:09,  6.64it/s]\u001b[A\n",
            "7982it [19:09,  6.69it/s]\u001b[A\n",
            "7983it [19:09,  6.72it/s]\u001b[A\n",
            "7984it [19:09,  6.53it/s]\u001b[A\n",
            "7985it [19:10,  6.68it/s]\u001b[A\n",
            "7986it [19:10,  6.68it/s]\u001b[A\n",
            "7987it [19:10,  6.89it/s]\u001b[A\n",
            "7988it [19:10,  6.92it/s]\u001b[A\n",
            "7989it [19:10,  6.96it/s]\u001b[A\n",
            "7990it [19:10,  7.04it/s]\u001b[A\n",
            "7991it [19:10,  6.98it/s]\u001b[A\n",
            "7992it [19:11,  7.01it/s]\u001b[A\n",
            "7993it [19:11,  6.97it/s]\u001b[A\n",
            "7994it [19:11,  6.86it/s]\u001b[A\n",
            "7995it [19:11,  6.88it/s]\u001b[A\n",
            "7996it [19:11,  6.79it/s]\u001b[A\n",
            "7997it [19:11,  6.71it/s]\u001b[A\n",
            "7998it [19:11,  6.52it/s]\u001b[A\n",
            "7999it [19:12,  6.54it/s]\u001b[A\n",
            "8000it [19:12,  6.70it/s]\u001b[A\n",
            "8001it [19:12,  6.90it/s]\u001b[A\n",
            "8002it [19:12,  6.96it/s]\u001b[A\n",
            "8003it [19:12,  7.09it/s]\u001b[A\n",
            "8004it [19:12,  7.17it/s]\u001b[A\n",
            "8005it [19:12,  7.13it/s]\u001b[A\n",
            "8006it [19:13,  7.05it/s]\u001b[A\n",
            "8007it [19:13,  7.03it/s]\u001b[A\n",
            "8008it [19:13,  6.90it/s]\u001b[A\n",
            "8009it [19:13,  6.77it/s]\u001b[A\n",
            "8010it [19:13,  6.65it/s]\u001b[A\n",
            "8011it [19:13,  6.64it/s]\u001b[A\n",
            "8012it [19:13,  6.47it/s]\u001b[A\n",
            "8013it [19:14,  6.42it/s]\u001b[A\n",
            "8014it [19:14,  6.53it/s]\u001b[A\n",
            "8015it [19:14,  6.66it/s]\u001b[A\n",
            "8016it [19:14,  6.79it/s]\u001b[A\n",
            "8017it [19:14,  6.89it/s]\u001b[A\n",
            "8018it [19:14,  6.89it/s]\u001b[A\n",
            "8019it [19:15,  6.84it/s]\u001b[A\n",
            "8020it [19:15,  6.89it/s]\u001b[A\n",
            "8021it [19:15,  6.82it/s]\u001b[A\n",
            "8022it [19:15,  6.79it/s]\u001b[A\n",
            "8023it [19:15,  6.75it/s]\u001b[A\n",
            "8024it [19:15,  6.70it/s]\u001b[A\n",
            "8025it [19:15,  6.67it/s]\u001b[A\n",
            "8026it [19:16,  6.69it/s]\u001b[A\n",
            "8027it [19:16,  6.75it/s]\u001b[A\n",
            "8028it [19:16,  6.68it/s]\u001b[A\n",
            "8029it [19:16,  6.68it/s]\u001b[A\n",
            "8030it [19:16,  6.69it/s]\u001b[A\n",
            "8031it [19:16,  6.64it/s]\u001b[A\n",
            "8032it [19:16,  6.54it/s]\u001b[A\n",
            "8033it [19:17,  6.65it/s]\u001b[A\n",
            "8034it [19:17,  6.88it/s]\u001b[A\n",
            "8035it [19:17,  6.99it/s]\u001b[A\n",
            "8036it [19:17,  7.06it/s]\u001b[A\n",
            "8037it [19:17,  7.10it/s]\u001b[A\n",
            "8038it [19:17,  7.15it/s]\u001b[A\n",
            "8039it [19:17,  7.12it/s]\u001b[A\n",
            "8040it [19:18,  6.93it/s]\u001b[A\n",
            "8041it [19:18,  6.90it/s]\u001b[A\n",
            "8042it [19:18,  6.98it/s]\u001b[A\n",
            "8043it [19:18,  7.07it/s]\u001b[A\n",
            "8044it [19:18,  7.07it/s]\u001b[A\n",
            "8045it [19:18,  6.74it/s]\u001b[A\n",
            "8046it [19:18,  6.81it/s]\u001b[A\n",
            "8047it [19:19,  6.77it/s]\u001b[A\n",
            "8048it [19:19,  6.92it/s]\u001b[A\n",
            "8049it [19:19,  7.10it/s]\u001b[A\n",
            "8050it [19:19,  7.16it/s]\u001b[A\n",
            "8051it [19:19,  7.17it/s]\u001b[A\n",
            "8052it [19:19,  7.19it/s]\u001b[A\n",
            "8053it [19:19,  7.04it/s]\u001b[A\n",
            "8054it [19:20,  6.74it/s]\u001b[A\n",
            "8055it [19:20,  6.92it/s]\u001b[A\n",
            "8056it [19:20,  7.00it/s]\u001b[A\n",
            "8057it [19:20,  7.03it/s]\u001b[A\n",
            "8058it [19:20,  7.13it/s]\u001b[A\n",
            "8059it [19:20,  7.09it/s]\u001b[A\n",
            "8060it [19:20,  7.03it/s]\u001b[A\n",
            "8061it [19:21,  6.85it/s]\u001b[A\n",
            "8062it [19:21,  6.97it/s]\u001b[A\n",
            "8063it [19:21,  7.05it/s]\u001b[A\n",
            "8064it [19:21,  7.15it/s]\u001b[A\n",
            "8065it [19:21,  7.17it/s]\u001b[A\n",
            "8066it [19:21,  7.19it/s]\u001b[A\n",
            "8067it [19:21,  7.23it/s]\u001b[A\n",
            "8068it [19:22,  7.05it/s]\u001b[A\n",
            "8069it [19:22,  7.05it/s]\u001b[A\n",
            "8070it [19:22,  6.87it/s]\u001b[A\n",
            "8071it [19:22,  6.79it/s]\u001b[A\n",
            "8072it [19:22,  6.70it/s]\u001b[A\n",
            "8073it [19:22,  6.69it/s]\u001b[A\n",
            "8074it [19:22,  6.56it/s]\u001b[A\n",
            "8075it [19:23,  6.68it/s]\u001b[A\n",
            "8076it [19:23,  6.73it/s]\u001b[A\n",
            "8077it [19:23,  6.74it/s]\u001b[A\n",
            "8078it [19:23,  6.65it/s]\u001b[A\n",
            "8079it [19:24,  3.91it/s]\u001b[A\n",
            "8080it [19:24,  4.49it/s]\u001b[A\n",
            "8081it [19:24,  5.01it/s]\u001b[A\n",
            "8082it [19:24,  5.51it/s]\u001b[A\n",
            "8083it [19:24,  5.81it/s]\u001b[A\n",
            "8084it [19:24,  6.08it/s]\u001b[A\n",
            "8085it [19:24,  6.36it/s]\u001b[A\n",
            "8086it [19:25,  6.55it/s]\u001b[A\n",
            "8087it [19:25,  6.73it/s]\u001b[A\n",
            "8088it [19:25,  6.84it/s]\u001b[A\n",
            "8089it [19:25,  6.94it/s]\u001b[A\n",
            "8090it [19:25,  6.94it/s]\u001b[A\n",
            "8091it [19:25,  6.96it/s]\u001b[A\n",
            "8092it [19:25,  7.00it/s]\u001b[A\n",
            "8093it [19:26,  6.93it/s]\u001b[A\n",
            "8094it [19:26,  6.93it/s]\u001b[A\n",
            "8095it [19:26,  6.92it/s]\u001b[A\n",
            "8096it [19:26,  6.96it/s]\u001b[A\n",
            "8097it [19:26,  6.94it/s]\u001b[A\n",
            "8098it [19:26,  6.97it/s]\u001b[A\n",
            "8099it [19:26,  7.09it/s]\u001b[A\n",
            "8100it [19:27,  7.19it/s]\u001b[A\n",
            "8101it [19:27,  7.02it/s]\u001b[A\n",
            "8102it [19:27,  6.85it/s]\u001b[A\n",
            "8103it [19:27,  6.79it/s]\u001b[A\n",
            "8104it [19:27,  6.82it/s]\u001b[A\n",
            "8105it [19:27,  6.93it/s]\u001b[A\n",
            "8106it [19:27,  6.94it/s]\u001b[A\n",
            "8107it [19:28,  6.99it/s]\u001b[A\n",
            "8108it [19:28,  6.84it/s]\u001b[A\n",
            "8109it [19:28,  6.96it/s]\u001b[A\n",
            "8110it [19:28,  7.05it/s]\u001b[A\n",
            "8111it [19:28,  7.06it/s]\u001b[A\n",
            "8112it [19:28,  7.08it/s]\u001b[A\n",
            "8113it [19:28,  7.05it/s]\u001b[A\n",
            "8114it [19:29,  6.96it/s]\u001b[A\n",
            "8115it [19:29,  6.80it/s]\u001b[A\n",
            "8116it [19:29,  6.73it/s]\u001b[A\n",
            "8117it [19:29,  6.61it/s]\u001b[A\n",
            "8118it [19:29,  6.50it/s]\u001b[A\n",
            "8119it [19:29,  6.47it/s]\u001b[A\n",
            "8120it [19:30,  6.46it/s]\u001b[A\n",
            "8121it [19:30,  6.61it/s]\u001b[A\n",
            "8122it [19:30,  6.57it/s]\u001b[A\n",
            "8123it [19:30,  6.60it/s]\u001b[A\n",
            "8124it [19:30,  6.56it/s]\u001b[A\n",
            "8125it [19:30,  6.53it/s]\u001b[A\n",
            "8126it [19:30,  6.52it/s]\u001b[A\n",
            "8127it [19:31,  6.61it/s]\u001b[A\n",
            "8128it [19:31,  6.51it/s]\u001b[A\n",
            "8129it [19:31,  6.59it/s]\u001b[A\n",
            "8130it [19:31,  6.36it/s]\u001b[A\n",
            "8131it [19:31,  6.47it/s]\u001b[A\n",
            "8132it [19:31,  6.53it/s]\u001b[A\n",
            "8133it [19:32,  6.66it/s]\u001b[A\n",
            "8134it [19:32,  6.83it/s]\u001b[A\n",
            "8135it [19:32,  6.71it/s]\u001b[A\n",
            "8136it [19:32,  6.67it/s]\u001b[A\n",
            "8137it [19:32,  6.64it/s]\u001b[A\n",
            "8138it [19:32,  6.60it/s]\u001b[A\n",
            "8139it [19:32,  6.62it/s]\u001b[A\n",
            "8140it [19:33,  6.55it/s]\u001b[A\n",
            "8141it [19:33,  6.54it/s]\u001b[A\n",
            "8142it [19:33,  6.53it/s]\u001b[A\n",
            "8143it [19:33,  6.56it/s]\u001b[A\n",
            "8144it [19:33,  6.58it/s]\u001b[A\n",
            "8145it [19:33,  6.57it/s]\u001b[A\n",
            "8146it [19:33,  6.63it/s]\u001b[A\n",
            "8147it [19:34,  6.77it/s]\u001b[A\n",
            "8148it [19:34,  6.72it/s]\u001b[A\n",
            "8149it [19:34,  6.79it/s]\u001b[A\n",
            "8150it [19:34,  6.90it/s]\u001b[A\n",
            "8151it [19:34,  6.98it/s]\u001b[A\n",
            "8152it [19:34,  7.05it/s]\u001b[A\n",
            "8153it [19:34,  7.10it/s]\u001b[A\n",
            "8154it [19:35,  7.06it/s]\u001b[A\n",
            "8155it [19:35,  6.85it/s]\u001b[A\n",
            "8156it [19:35,  6.63it/s]\u001b[A\n",
            "8157it [19:35,  6.45it/s]\u001b[A\n",
            "8158it [19:35,  6.44it/s]\u001b[A\n",
            "8159it [19:35,  6.43it/s]\u001b[A\n",
            "8160it [19:36,  6.50it/s]\u001b[A\n",
            "8161it [19:36,  6.66it/s]\u001b[A\n",
            "8162it [19:36,  6.75it/s]\u001b[A\n",
            "8163it [19:36,  6.82it/s]\u001b[A\n",
            "8164it [19:36,  6.76it/s]\u001b[A\n",
            "8165it [19:36,  6.71it/s]\u001b[A\n",
            "8166it [19:36,  6.64it/s]\u001b[A\n",
            "8167it [19:37,  6.67it/s]\u001b[A\n",
            "8168it [19:37,  6.78it/s]\u001b[A\n",
            "8169it [19:37,  6.61it/s]\u001b[A\n",
            "8170it [19:37,  6.71it/s]\u001b[A\n",
            "8171it [19:37,  6.82it/s]\u001b[A\n",
            "8172it [19:37,  7.01it/s]\u001b[A\n",
            "8173it [19:37,  7.01it/s]\u001b[A\n",
            "8174it [19:38,  7.06it/s]\u001b[A\n",
            "8175it [19:38,  6.98it/s]\u001b[A\n",
            "8176it [19:38,  6.99it/s]\u001b[A\n",
            "8177it [19:38,  7.06it/s]\u001b[A\n",
            "8178it [19:38,  7.11it/s]\u001b[A\n",
            "8179it [19:38,  7.08it/s]\u001b[A\n",
            "8180it [19:38,  7.09it/s]\u001b[A\n",
            "8181it [19:39,  7.12it/s]\u001b[A\n",
            "8182it [19:39,  6.94it/s]\u001b[A\n",
            "8183it [19:39,  6.76it/s]\u001b[A\n",
            "8184it [19:39,  6.64it/s]\u001b[A\n",
            "8185it [19:39,  6.63it/s]\u001b[A\n",
            "8186it [19:39,  6.77it/s]\u001b[A\n",
            "8187it [19:39,  6.93it/s]\u001b[A\n",
            "8188it [19:40,  7.10it/s]\u001b[A\n",
            "8189it [19:40,  7.20it/s]\u001b[A\n",
            "8190it [19:40,  7.08it/s]\u001b[A\n",
            "8191it [19:40,  7.05it/s]\u001b[A\n",
            "8192it [19:40,  7.10it/s]\u001b[A\n",
            "8193it [19:40,  7.02it/s]\u001b[A\n",
            "8194it [19:40,  6.83it/s]\u001b[A\n",
            "8195it [19:41,  6.86it/s]\u001b[A\n",
            "8196it [19:41,  6.94it/s]\u001b[A\n",
            "8197it [19:41,  6.88it/s]\u001b[A\n",
            "8198it [19:41,  6.98it/s]\u001b[A\n",
            "8199it [19:41,  6.96it/s]\u001b[A\n",
            "8200it [19:41,  7.03it/s]\u001b[A\n",
            "8201it [19:41,  6.98it/s]\u001b[A\n",
            "8202it [19:42,  7.00it/s]\u001b[A\n",
            "8203it [19:42,  7.00it/s]\u001b[A\n",
            "8204it [19:42,  6.91it/s]\u001b[A\n",
            "8205it [19:42,  6.93it/s]\u001b[A\n",
            "8206it [19:42,  7.01it/s]\u001b[A\n",
            "8207it [19:42,  7.11it/s]\u001b[A\n",
            "8208it [19:42,  7.05it/s]\u001b[A\n",
            "8209it [19:43,  6.94it/s]\u001b[A\n",
            "8210it [19:43,  6.91it/s]\u001b[A\n",
            "8211it [19:43,  6.91it/s]\u001b[A\n",
            "8212it [19:43,  6.88it/s]\u001b[A\n",
            "8213it [19:43,  6.93it/s]\u001b[A\n",
            "8214it [19:43,  6.97it/s]\u001b[A\n",
            "8215it [19:43,  7.08it/s]\u001b[A\n",
            "8216it [19:44,  7.03it/s]\u001b[A\n",
            "8217it [19:44,  7.07it/s]\u001b[A\n",
            "8218it [19:44,  6.97it/s]\u001b[A\n",
            "8219it [19:44,  7.04it/s]\u001b[A\n",
            "8220it [19:44,  7.08it/s]\u001b[A\n",
            "8221it [19:44,  7.15it/s]\u001b[A\n",
            "8222it [19:44,  7.16it/s]\u001b[A\n",
            "8223it [19:45,  7.07it/s]\u001b[A\n",
            "8224it [19:45,  7.00it/s]\u001b[A\n",
            "8225it [19:45,  6.75it/s]\u001b[A\n",
            "8226it [19:45,  6.77it/s]\u001b[A\n",
            "8227it [19:45,  6.93it/s]\u001b[A\n",
            "8228it [19:45,  7.01it/s]\u001b[A\n",
            "8229it [19:45,  7.01it/s]\u001b[A\n",
            "8230it [19:46,  6.95it/s]\u001b[A\n",
            "8231it [19:46,  6.97it/s]\u001b[A\n",
            "8232it [19:46,  6.97it/s]\u001b[A\n",
            "8233it [19:46,  7.05it/s]\u001b[A\n",
            "8234it [19:46,  7.06it/s]\u001b[A\n",
            "8235it [19:46,  7.14it/s]\u001b[A\n",
            "8236it [19:46,  7.11it/s]\u001b[A\n",
            "8237it [19:47,  7.06it/s]\u001b[A\n",
            "8238it [19:47,  7.20it/s]\u001b[A\n",
            "8239it [19:47,  7.16it/s]\u001b[A\n",
            "8240it [19:47,  7.08it/s]\u001b[A\n",
            "8241it [19:47,  7.16it/s]\u001b[A\n",
            "8242it [19:47,  7.24it/s]\u001b[A\n",
            "8243it [19:47,  7.20it/s]\u001b[A\n",
            "8244it [19:48,  7.16it/s]\u001b[A\n",
            "8245it [19:48,  7.11it/s]\u001b[A\n",
            "8246it [19:48,  7.04it/s]\u001b[A\n",
            "8247it [19:48,  6.77it/s]\u001b[A\n",
            "8248it [19:48,  6.72it/s]\u001b[A\n",
            "8249it [19:48,  6.69it/s]\u001b[A\n",
            "8250it [19:48,  6.65it/s]\u001b[A\n",
            "8251it [19:49,  6.66it/s]\u001b[A\n",
            "8252it [19:49,  6.74it/s]\u001b[A\n",
            "8253it [19:49,  6.64it/s]\u001b[A\n",
            "8254it [19:49,  6.72it/s]\u001b[A\n",
            "8255it [19:49,  6.89it/s]\u001b[A\n",
            "8256it [19:49,  7.06it/s]\u001b[A\n",
            "8257it [19:49,  7.04it/s]\u001b[A\n",
            "8258it [19:50,  7.07it/s]\u001b[A\n",
            "8259it [19:50,  6.86it/s]\u001b[A\n",
            "8260it [19:50,  6.79it/s]\u001b[A\n",
            "8261it [19:50,  6.73it/s]\u001b[A\n",
            "8262it [19:50,  6.67it/s]\u001b[A\n",
            "8263it [19:50,  6.65it/s]\u001b[A\n",
            "8264it [19:51,  6.42it/s]\u001b[A\n",
            "8265it [19:51,  6.56it/s]\u001b[A\n",
            "8266it [19:51,  6.57it/s]\u001b[A\n",
            "8267it [19:51,  6.53it/s]\u001b[A\n",
            "8268it [19:51,  6.54it/s]\u001b[A\n",
            "8269it [19:51,  6.55it/s]\u001b[A\n",
            "8270it [19:51,  6.59it/s]\u001b[A\n",
            "8271it [19:52,  6.62it/s]\u001b[A\n",
            "8272it [19:52,  6.74it/s]\u001b[A\n",
            "8273it [19:52,  6.89it/s]\u001b[A\n",
            "8274it [19:52,  6.66it/s]\u001b[A\n",
            "8275it [19:52,  6.65it/s]\u001b[A\n",
            "8276it [19:52,  6.63it/s]\u001b[A\n",
            "8277it [19:53,  6.62it/s]\u001b[A\n",
            "8278it [19:53,  6.78it/s]\u001b[A\n",
            "8279it [19:53,  6.74it/s]\u001b[A\n",
            "8280it [19:53,  6.81it/s]\u001b[A\n",
            "8281it [19:53,  6.81it/s]\u001b[A\n",
            "8282it [19:53,  6.54it/s]\u001b[A\n",
            "8283it [19:53,  6.55it/s]\u001b[A\n",
            "8284it [19:54,  6.67it/s]\u001b[A\n",
            "8285it [19:54,  6.78it/s]\u001b[A\n",
            "8286it [19:54,  6.84it/s]\u001b[A\n",
            "8287it [19:54,  6.93it/s]\u001b[A\n",
            "8288it [19:54,  6.81it/s]\u001b[A\n",
            "8289it [19:54,  6.89it/s]\u001b[A\n",
            "8290it [19:54,  7.00it/s]\u001b[A\n",
            "8291it [19:55,  7.01it/s]\u001b[A\n",
            "8292it [19:55,  7.04it/s]\u001b[A\n",
            "8293it [19:55,  6.85it/s]\u001b[A\n",
            "8294it [19:55,  6.92it/s]\u001b[A\n",
            "8295it [19:55,  6.88it/s]\u001b[A\n",
            "8296it [19:55,  6.97it/s]\u001b[A\n",
            "8297it [19:55,  7.04it/s]\u001b[A\n",
            "8298it [19:56,  7.05it/s]\u001b[A\n",
            "8299it [19:56,  6.93it/s]\u001b[A\n",
            "8300it [19:56,  6.98it/s]\u001b[A\n",
            "8301it [19:56,  7.08it/s]\u001b[A\n",
            "8302it [19:56,  6.94it/s]\u001b[A\n",
            "8303it [19:56,  6.79it/s]\u001b[A\n",
            "8304it [19:56,  6.72it/s]\u001b[A\n",
            "8305it [19:57,  6.71it/s]\u001b[A\n",
            "8306it [19:57,  6.67it/s]\u001b[A\n",
            "8307it [19:57,  6.73it/s]\u001b[A\n",
            "8308it [19:57,  6.70it/s]\u001b[A\n",
            "8309it [19:57,  6.58it/s]\u001b[A\n",
            "8310it [19:57,  6.55it/s]\u001b[A\n",
            "8311it [19:58,  6.69it/s]\u001b[A\n",
            "8312it [19:58,  6.79it/s]\u001b[A\n",
            "8313it [19:58,  6.75it/s]\u001b[A\n",
            "8314it [19:58,  6.65it/s]\u001b[A\n",
            "8315it [19:58,  6.82it/s]\u001b[A\n",
            "8316it [19:58,  6.79it/s]\u001b[A\n",
            "8317it [19:58,  6.87it/s]\u001b[A\n",
            "8318it [19:59,  6.81it/s]\u001b[A\n",
            "8319it [19:59,  6.61it/s]\u001b[A\n",
            "8320it [19:59,  6.70it/s]\u001b[A\n",
            "8321it [19:59,  6.87it/s]\u001b[A\n",
            "8322it [19:59,  6.94it/s]\u001b[A\n",
            "8323it [19:59,  6.88it/s]\u001b[A\n",
            "8324it [19:59,  6.95it/s]\u001b[A\n",
            "8325it [20:00,  6.98it/s]\u001b[A\n",
            "8326it [20:00,  6.79it/s]\u001b[A\n",
            "8327it [20:00,  6.72it/s]\u001b[A\n",
            "8328it [20:00,  6.73it/s]\u001b[A\n",
            "8329it [20:00,  6.60it/s]\u001b[A\n",
            "8330it [20:00,  6.63it/s]\u001b[A\n",
            "8331it [20:00,  6.54it/s]\u001b[A\n",
            "8332it [20:01,  6.53it/s]\u001b[A\n",
            "8333it [20:01,  6.56it/s]\u001b[A\n",
            "8334it [20:01,  6.56it/s]\u001b[A\n",
            "8335it [20:01,  6.73it/s]\u001b[A\n",
            "8336it [20:01,  6.81it/s]\u001b[A\n",
            "8337it [20:01,  6.93it/s]\u001b[A\n",
            "8338it [20:01,  7.02it/s]\u001b[A\n",
            "8339it [20:02,  7.06it/s]\u001b[A\n",
            "8340it [20:02,  7.02it/s]\u001b[A\n",
            "8341it [20:02,  6.89it/s]\u001b[A\n",
            "8342it [20:02,  6.83it/s]\u001b[A\n",
            "8343it [20:02,  6.70it/s]\u001b[A\n",
            "8344it [20:02,  6.65it/s]\u001b[A\n",
            "8345it [20:03,  6.55it/s]\u001b[A\n",
            "8346it [20:03,  6.55it/s]\u001b[A\n",
            "8347it [20:03,  6.45it/s]\u001b[A\n",
            "8348it [20:03,  6.36it/s]\u001b[A\n",
            "8349it [20:03,  6.51it/s]\u001b[A\n",
            "8350it [20:03,  6.42it/s]\u001b[A\n",
            "8351it [20:03,  6.55it/s]\u001b[A\n",
            "8352it [20:04,  6.51it/s]\u001b[A\n",
            "8353it [20:04,  6.60it/s]\u001b[A\n",
            "8354it [20:04,  6.79it/s]\u001b[A\n",
            "8355it [20:04,  6.86it/s]\u001b[A\n",
            "8356it [20:04,  6.89it/s]\u001b[A\n",
            "8357it [20:04,  6.79it/s]\u001b[A\n",
            "8358it [20:04,  6.66it/s]\u001b[A\n",
            "8359it [20:05,  6.48it/s]\u001b[A\n",
            "8360it [20:05,  6.40it/s]\u001b[A\n",
            "8361it [20:05,  6.35it/s]\u001b[A\n",
            "8362it [20:05,  6.28it/s]\u001b[A\n",
            "8363it [20:05,  6.31it/s]\u001b[A\n",
            "8364it [20:05,  6.37it/s]\u001b[A\n",
            "8365it [20:06,  6.55it/s]\u001b[A\n",
            "8366it [20:06,  6.55it/s]\u001b[A\n",
            "8367it [20:06,  6.69it/s]\u001b[A\n",
            "8368it [20:06,  6.74it/s]\u001b[A\n",
            "8369it [20:06,  6.76it/s]\u001b[A\n",
            "8370it [20:06,  6.80it/s]\u001b[A\n",
            "8371it [20:06,  6.84it/s]\u001b[A\n",
            "8372it [20:07,  6.90it/s]\u001b[A\n",
            "8373it [20:07,  6.95it/s]\u001b[A\n",
            "8374it [20:07,  6.90it/s]\u001b[A\n",
            "8375it [20:07,  6.95it/s]\u001b[A\n",
            "8376it [20:07,  6.94it/s]\u001b[A\n",
            "8377it [20:07,  6.87it/s]\u001b[A\n",
            "8378it [20:07,  6.86it/s]\u001b[A\n",
            "8379it [20:08,  6.90it/s]\u001b[A\n",
            "8380it [20:08,  6.87it/s]\u001b[A\n",
            "8381it [20:08,  6.80it/s]\u001b[A\n",
            "8382it [20:08,  6.78it/s]\u001b[A\n",
            "8383it [20:08,  6.91it/s]\u001b[A\n",
            "8384it [20:08,  6.84it/s]\u001b[A\n",
            "8385it [20:09,  6.75it/s]\u001b[A\n",
            "8386it [20:09,  6.71it/s]\u001b[A\n",
            "8387it [20:09,  6.53it/s]\u001b[A\n",
            "8388it [20:09,  6.49it/s]\u001b[A\n",
            "8389it [20:09,  6.63it/s]\u001b[A\n",
            "8390it [20:09,  6.73it/s]\u001b[A\n",
            "8391it [20:09,  6.68it/s]\u001b[A\n",
            "8392it [20:10,  6.72it/s]\u001b[A\n",
            "8393it [20:10,  6.63it/s]\u001b[A\n",
            "8394it [20:10,  6.51it/s]\u001b[A\n",
            "8395it [20:10,  6.39it/s]\u001b[A\n",
            "8396it [20:10,  6.48it/s]\u001b[A\n",
            "8397it [20:10,  6.36it/s]\u001b[A\n",
            "8398it [20:11,  6.38it/s]\u001b[A\n",
            "8399it [20:11,  6.54it/s]\u001b[A\n",
            "8400it [20:11,  6.76it/s]\u001b[A\n",
            "8401it [20:11,  6.79it/s]\u001b[A\n",
            "8402it [20:11,  6.87it/s]\u001b[A\n",
            "8403it [20:11,  6.96it/s]\u001b[A\n",
            "8404it [20:11,  6.88it/s]\u001b[A\n",
            "8405it [20:12,  6.82it/s]\u001b[A\n",
            "8406it [20:12,  6.81it/s]\u001b[A\n",
            "8407it [20:12,  6.85it/s]\u001b[A\n",
            "8408it [20:12,  6.91it/s]\u001b[A\n",
            "8409it [20:12,  7.00it/s]\u001b[A\n",
            "8410it [20:12,  6.93it/s]\u001b[A\n",
            "8411it [20:12,  6.75it/s]\u001b[A\n",
            "8412it [20:13,  6.57it/s]\u001b[A\n",
            "8413it [20:13,  6.61it/s]\u001b[A\n",
            "8414it [20:13,  6.70it/s]\u001b[A\n",
            "8415it [20:13,  6.63it/s]\u001b[A\n",
            "8416it [20:13,  6.71it/s]\u001b[A\n",
            "8417it [20:13,  6.91it/s]\u001b[A\n",
            "8418it [20:13,  6.86it/s]\u001b[A\n",
            "8419it [20:14,  6.89it/s]\u001b[A\n",
            "8420it [20:14,  6.94it/s]\u001b[A\n",
            "8421it [20:14,  7.00it/s]\u001b[A\n",
            "8422it [20:14,  7.02it/s]\u001b[A\n",
            "8423it [20:14,  7.06it/s]\u001b[A\n",
            "8424it [20:14,  7.12it/s]\u001b[A\n",
            "8425it [20:14,  7.08it/s]\u001b[A\n",
            "8426it [20:15,  6.80it/s]\u001b[A\n",
            "8427it [20:15,  6.80it/s]\u001b[A\n",
            "8428it [20:15,  6.83it/s]\u001b[A\n",
            "8429it [20:15,  6.88it/s]\u001b[A\n",
            "8430it [20:15,  6.97it/s]\u001b[A\n",
            "8431it [20:15,  7.00it/s]\u001b[A\n",
            "8432it [20:15,  6.83it/s]\u001b[A\n",
            "8433it [20:16,  6.87it/s]\u001b[A\n",
            "8434it [20:16,  6.89it/s]\u001b[A\n",
            "8435it [20:16,  6.92it/s]\u001b[A\n",
            "8436it [20:16,  6.99it/s]\u001b[A\n",
            "8437it [20:16,  7.11it/s]\u001b[A\n",
            "8438it [20:16,  7.12it/s]\u001b[A\n",
            "8439it [20:16,  6.99it/s]\u001b[A\n",
            "8440it [20:17,  6.75it/s]\u001b[A\n",
            "8441it [20:17,  6.72it/s]\u001b[A\n",
            "8442it [20:17,  6.73it/s]\u001b[A\n",
            "8443it [20:17,  6.68it/s]\u001b[A\n",
            "8444it [20:17,  6.47it/s]\u001b[A\n",
            "8445it [20:17,  6.54it/s]\u001b[A\n",
            "8446it [20:18,  6.28it/s]\u001b[A\n",
            "8447it [20:18,  6.43it/s]\u001b[A\n",
            "8448it [20:18,  6.47it/s]\u001b[A\n",
            "8449it [20:18,  6.49it/s]\u001b[A\n",
            "8450it [20:18,  6.57it/s]\u001b[A\n",
            "8451it [20:18,  6.56it/s]\u001b[A\n",
            "8452it [20:18,  6.54it/s]\u001b[A\n",
            "8453it [20:19,  6.47it/s]\u001b[A\n",
            "8454it [20:19,  6.48it/s]\u001b[A\n",
            "8455it [20:19,  6.50it/s]\u001b[A\n",
            "8456it [20:19,  6.54it/s]\u001b[A\n",
            "8457it [20:19,  6.58it/s]\u001b[A\n",
            "8458it [20:19,  6.61it/s]\u001b[A\n",
            "8459it [20:20,  6.70it/s]\u001b[A\n",
            "8460it [20:20,  6.82it/s]\u001b[A\n",
            "8461it [20:20,  6.89it/s]\u001b[A\n",
            "8462it [20:20,  6.95it/s]\u001b[A\n",
            "8463it [20:20,  6.92it/s]\u001b[A\n",
            "8464it [20:20,  6.86it/s]\u001b[A\n",
            "8465it [20:20,  7.02it/s]\u001b[A\n",
            "8466it [20:21,  6.87it/s]\u001b[A\n",
            "8467it [20:21,  6.84it/s]\u001b[A\n",
            "8468it [20:21,  6.78it/s]\u001b[A\n",
            "8469it [20:21,  6.85it/s]\u001b[A\n",
            "8470it [20:21,  6.92it/s]\u001b[A\n",
            "8471it [20:21,  7.04it/s]\u001b[A\n",
            "8472it [20:21,  7.10it/s]\u001b[A\n",
            "8473it [20:22,  6.87it/s]\u001b[A\n",
            "8474it [20:22,  6.92it/s]\u001b[A\n",
            "8475it [20:22,  7.00it/s]\u001b[A\n",
            "8476it [20:22,  6.93it/s]\u001b[A\n",
            "8477it [20:22,  7.00it/s]\u001b[A\n",
            "8478it [20:22,  6.98it/s]\u001b[A\n",
            "8479it [20:22,  7.08it/s]\u001b[A\n",
            "8480it [20:23,  6.89it/s]\u001b[A\n",
            "8481it [20:23,  6.96it/s]\u001b[A\n",
            "8482it [20:23,  7.00it/s]\u001b[A\n",
            "8483it [20:23,  7.03it/s]\u001b[A\n",
            "8484it [20:23,  7.08it/s]\u001b[A\n",
            "8485it [20:23,  7.18it/s]\u001b[A\n",
            "8486it [20:23,  7.27it/s]\u001b[A\n",
            "8487it [20:24,  7.06it/s]\u001b[A\n",
            "8488it [20:24,  7.00it/s]\u001b[A\n",
            "8489it [20:24,  6.96it/s]\u001b[A\n",
            "8490it [20:24,  7.02it/s]\u001b[A\n",
            "8491it [20:24,  7.00it/s]\u001b[A\n",
            "8492it [20:24,  7.09it/s]\u001b[A\n",
            "8493it [20:24,  7.10it/s]\u001b[A\n",
            "8494it [20:25,  7.08it/s]\u001b[A\n",
            "8495it [20:25,  7.06it/s]\u001b[A\n",
            "8496it [20:25,  7.08it/s]\u001b[A\n",
            "8497it [20:25,  7.15it/s]\u001b[A\n",
            "8498it [20:25,  7.26it/s]\u001b[A\n",
            "8499it [20:25,  7.27it/s]\u001b[A\n",
            "8500it [20:25,  7.28it/s]\u001b[A\n",
            "8501it [20:25,  7.26it/s]\u001b[A\n",
            "8502it [20:26,  7.00it/s]\u001b[A\n",
            "8503it [20:26,  6.98it/s]\u001b[A\n",
            "8504it [20:26,  6.86it/s]\u001b[A\n",
            "8505it [20:26,  6.80it/s]\u001b[A\n",
            "8506it [20:26,  6.76it/s]\u001b[A\n",
            "8507it [20:26,  6.76it/s]\u001b[A\n",
            "8508it [20:27,  6.83it/s]\u001b[A\n",
            "8509it [20:27,  6.81it/s]\u001b[A\n",
            "8510it [20:27,  6.84it/s]\u001b[A\n",
            "8511it [20:27,  6.61it/s]\u001b[A\n",
            "8512it [20:27,  6.43it/s]\u001b[A\n",
            "8513it [20:27,  6.53it/s]\u001b[A\n",
            "8514it [20:27,  6.54it/s]\u001b[A\n",
            "8515it [20:28,  6.62it/s]\u001b[A\n",
            "8516it [20:28,  6.70it/s]\u001b[A\n",
            "8517it [20:28,  6.72it/s]\u001b[A\n",
            "8518it [20:28,  6.70it/s]\u001b[A\n",
            "8519it [20:28,  6.63it/s]\u001b[A\n",
            "8520it [20:28,  6.61it/s]\u001b[A\n",
            "8521it [20:28,  6.68it/s]\u001b[A\n",
            "8522it [20:29,  6.59it/s]\u001b[A\n",
            "8523it [20:29,  6.72it/s]\u001b[A\n",
            "8524it [20:29,  6.77it/s]\u001b[A\n",
            "8525it [20:29,  6.67it/s]\u001b[A\n",
            "8526it [20:29,  6.63it/s]\u001b[A\n",
            "8527it [20:29,  6.67it/s]\u001b[A\n",
            "8528it [20:30,  6.78it/s]\u001b[A\n",
            "8529it [20:30,  6.76it/s]\u001b[A\n",
            "8530it [20:30,  6.74it/s]\u001b[A\n",
            "8531it [20:30,  6.62it/s]\u001b[A\n",
            "8532it [20:30,  6.62it/s]\u001b[A\n",
            "8533it [20:30,  6.61it/s]\u001b[A\n",
            "8534it [20:30,  6.46it/s]\u001b[A\n",
            "8535it [20:31,  6.53it/s]\u001b[A\n",
            "8536it [20:31,  6.50it/s]\u001b[A\n",
            "8537it [20:31,  6.74it/s]\u001b[A\n",
            "8538it [20:31,  6.88it/s]\u001b[A\n",
            "8539it [20:31,  6.97it/s]\u001b[A\n",
            "8540it [20:31,  6.91it/s]\u001b[A\n",
            "8541it [20:31,  6.93it/s]\u001b[A\n",
            "8542it [20:32,  6.92it/s]\u001b[A\n",
            "8543it [20:32,  6.78it/s]\u001b[A\n",
            "8544it [20:32,  6.72it/s]\u001b[A\n",
            "8545it [20:32,  6.71it/s]\u001b[A\n",
            "8546it [20:32,  6.64it/s]\u001b[A\n",
            "8547it [20:32,  6.61it/s]\u001b[A\n",
            "8548it [20:33,  6.58it/s]\u001b[A\n",
            "8549it [20:33,  6.59it/s]\u001b[A\n",
            "8550it [20:33,  6.61it/s]\u001b[A\n",
            "8551it [20:33,  6.61it/s]\u001b[A\n",
            "8552it [20:33,  6.66it/s]\u001b[A\n",
            "8553it [20:33,  6.63it/s]\u001b[A\n",
            "8554it [20:33,  6.70it/s]\u001b[A\n",
            "8555it [20:34,  6.85it/s]\u001b[A\n",
            "8556it [20:34,  6.88it/s]\u001b[A\n",
            "8557it [20:34,  6.76it/s]\u001b[A\n",
            "8558it [20:34,  6.70it/s]\u001b[A\n",
            "8559it [20:34,  6.68it/s]\u001b[A\n",
            "8560it [20:34,  6.73it/s]\u001b[A\n",
            "8561it [20:34,  6.95it/s]\u001b[A\n",
            "8562it [20:35,  6.89it/s]\u001b[A\n",
            "8563it [20:35,  6.87it/s]\u001b[A\n",
            "8564it [20:35,  6.79it/s]\u001b[A\n",
            "8565it [20:35,  6.59it/s]\u001b[A\n",
            "8566it [20:35,  6.51it/s]\u001b[A\n",
            "8567it [20:35,  6.50it/s]\u001b[A\n",
            "8568it [20:36,  6.46it/s]\u001b[A\n",
            "8569it [20:36,  6.61it/s]\u001b[A\n",
            "8570it [20:36,  6.52it/s]\u001b[A\n",
            "8571it [20:36,  6.55it/s]\u001b[A\n",
            "8572it [20:36,  6.62it/s]\u001b[A\n",
            "8573it [20:36,  6.64it/s]\u001b[A\n",
            "8574it [20:36,  6.64it/s]\u001b[A\n",
            "8575it [20:37,  6.59it/s]\u001b[A\n",
            "8576it [20:37,  6.74it/s]\u001b[A\n",
            "8577it [20:37,  6.80it/s]\u001b[A\n",
            "8578it [20:37,  6.85it/s]\u001b[A\n",
            "8579it [20:37,  6.94it/s]\u001b[A\n",
            "8580it [20:37,  7.02it/s]\u001b[A\n",
            "8581it [20:37,  6.94it/s]\u001b[A\n",
            "8582it [20:38,  6.93it/s]\u001b[A\n",
            "8583it [20:38,  6.98it/s]\u001b[A\n",
            "8584it [20:38,  6.92it/s]\u001b[A\n",
            "8585it [20:38,  6.94it/s]\u001b[A\n",
            "8586it [20:38,  6.93it/s]\u001b[A\n",
            "8587it [20:38,  7.08it/s]\u001b[A\n",
            "8588it [20:38,  7.12it/s]\u001b[A\n",
            "8589it [20:39,  7.02it/s]\u001b[A\n",
            "8590it [20:39,  7.01it/s]\u001b[A\n",
            "8591it [20:39,  6.96it/s]\u001b[A\n",
            "8592it [20:39,  7.04it/s]\u001b[A\n",
            "8593it [20:39,  6.86it/s]\u001b[A\n",
            "8594it [20:39,  6.85it/s]\u001b[A\n",
            "8595it [20:39,  6.91it/s]\u001b[A\n",
            "8596it [20:40,  6.95it/s]\u001b[A\n",
            "8597it [20:40,  6.99it/s]\u001b[A\n",
            "8598it [20:40,  6.94it/s]\u001b[A\n",
            "8599it [20:40,  7.06it/s]\u001b[A\n",
            "8600it [20:40,  7.14it/s]\u001b[A\n",
            "8601it [20:40,  7.10it/s]\u001b[A\n",
            "8602it [20:40,  7.07it/s]\u001b[A\n",
            "8603it [20:41,  6.91it/s]\u001b[A\n",
            "8604it [20:41,  6.93it/s]\u001b[A\n",
            "8605it [20:41,  6.71it/s]\u001b[A\n",
            "8606it [20:41,  6.75it/s]\u001b[A\n",
            "8607it [20:41,  6.61it/s]\u001b[A\n",
            "8608it [20:41,  6.55it/s]\u001b[A\n",
            "8609it [20:41,  6.65it/s]\u001b[A\n",
            "8610it [20:42,  6.70it/s]\u001b[A\n",
            "8611it [20:42,  6.83it/s]\u001b[A\n",
            "8612it [20:42,  6.88it/s]\u001b[A\n",
            "8613it [20:42,  6.96it/s]\u001b[A\n",
            "8614it [20:42,  7.11it/s]\u001b[A\n",
            "8615it [20:42,  7.16it/s]\u001b[A\n",
            "8616it [20:42,  7.09it/s]\u001b[A\n",
            "8617it [20:43,  7.04it/s]\u001b[A\n",
            "8618it [20:43,  6.95it/s]\u001b[A\n",
            "8619it [20:43,  6.91it/s]\u001b[A\n",
            "8620it [20:43,  6.99it/s]\u001b[A\n",
            "8621it [20:43,  7.00it/s]\u001b[A\n",
            "8622it [20:43,  7.05it/s]\u001b[A\n",
            "8623it [20:43,  7.13it/s]\u001b[A\n",
            "8624it [20:44,  6.96it/s]\u001b[A\n",
            "8625it [20:44,  6.76it/s]\u001b[A\n",
            "8626it [20:44,  6.64it/s]\u001b[A\n",
            "8627it [20:44,  6.64it/s]\u001b[A\n",
            "8628it [20:44,  6.57it/s]\u001b[A\n",
            "8629it [20:44,  6.54it/s]\u001b[A\n",
            "8630it [20:45,  6.52it/s]\u001b[A\n",
            "8631it [20:45,  6.65it/s]\u001b[A\n",
            "8632it [20:45,  6.80it/s]\u001b[A\n",
            "8633it [20:45,  6.80it/s]\u001b[A\n",
            "8634it [20:45,  6.88it/s]\u001b[A\n",
            "8635it [20:45,  6.92it/s]\u001b[A\n",
            "8636it [20:45,  6.99it/s]\u001b[A\n",
            "8637it [20:46,  7.10it/s]\u001b[A\n",
            "8638it [20:46,  7.15it/s]\u001b[A\n",
            "8639it [20:46,  7.15it/s]\u001b[A\n",
            "8640it [20:46,  6.97it/s]\u001b[A\n",
            "8641it [20:46,  6.99it/s]\u001b[A\n",
            "8642it [20:46,  7.01it/s]\u001b[A\n",
            "8643it [20:46,  7.11it/s]\u001b[A\n",
            "8644it [20:47,  7.03it/s]\u001b[A\n",
            "8645it [20:47,  6.98it/s]\u001b[A\n",
            "8646it [20:47,  6.82it/s]\u001b[A\n",
            "8647it [20:47,  6.59it/s]\u001b[A\n",
            "8648it [20:47,  6.57it/s]\u001b[A\n",
            "8649it [20:47,  6.63it/s]\u001b[A\n",
            "8650it [20:47,  6.59it/s]\u001b[A\n",
            "8651it [20:48,  6.84it/s]\u001b[A\n",
            "8652it [20:48,  6.72it/s]\u001b[A\n",
            "8653it [20:48,  6.71it/s]\u001b[A\n",
            "8654it [20:48,  6.65it/s]\u001b[A\n",
            "8655it [20:48,  6.59it/s]\u001b[A\n",
            "8656it [20:48,  6.56it/s]\u001b[A\n",
            "8657it [20:48,  6.66it/s]\u001b[A\n",
            "8658it [20:49,  6.55it/s]\u001b[A\n",
            "8659it [20:49,  6.51it/s]\u001b[A\n",
            "8660it [20:49,  6.49it/s]\u001b[A\n",
            "8661it [20:49,  6.51it/s]\u001b[A\n",
            "8662it [20:49,  6.50it/s]\u001b[A\n",
            "8663it [20:49,  6.57it/s]\u001b[A\n",
            "8664it [20:50,  6.76it/s]\u001b[A\n",
            "8665it [20:50,  6.85it/s]\u001b[A\n",
            "8666it [20:50,  6.86it/s]\u001b[A\n",
            "8667it [20:50,  6.81it/s]\u001b[A\n",
            "8668it [20:50,  6.87it/s]\u001b[A\n",
            "8669it [20:50,  6.93it/s]\u001b[A\n",
            "8670it [20:50,  6.96it/s]\u001b[A\n",
            "8671it [20:51,  6.89it/s]\u001b[A\n",
            "8672it [20:51,  6.96it/s]\u001b[A\n",
            "8673it [20:51,  7.09it/s]\u001b[A\n",
            "8674it [20:51,  7.05it/s]\u001b[A\n",
            "8675it [20:51,  7.11it/s]\u001b[A\n",
            "8676it [20:51,  7.15it/s]\u001b[A\n",
            "8677it [20:51,  7.21it/s]\u001b[A\n",
            "8678it [20:52,  7.16it/s]\u001b[A\n",
            "8679it [20:52,  6.93it/s]\u001b[A\n",
            "8680it [20:52,  6.95it/s]\u001b[A\n",
            "8681it [20:52,  7.00it/s]\u001b[A\n",
            "8682it [20:52,  7.06it/s]\u001b[A\n",
            "8683it [20:52,  7.07it/s]\u001b[A\n",
            "8684it [20:52,  7.09it/s]\u001b[A\n",
            "8685it [20:53,  7.14it/s]\u001b[A\n",
            "8686it [20:53,  6.87it/s]\u001b[A\n",
            "8687it [20:53,  6.78it/s]\u001b[A\n",
            "8688it [20:53,  6.62it/s]\u001b[A\n",
            "8689it [20:53,  6.67it/s]\u001b[A\n",
            "8690it [20:53,  6.62it/s]\u001b[A\n",
            "8691it [20:53,  6.62it/s]\u001b[A\n",
            "8692it [20:54,  6.62it/s]\u001b[A\n",
            "8693it [20:54,  6.73it/s]\u001b[A\n",
            "8694it [20:54,  6.86it/s]\u001b[A\n",
            "8695it [20:54,  6.89it/s]\u001b[A\n",
            "8696it [20:54,  7.05it/s]\u001b[A\n",
            "8697it [20:54,  7.15it/s]\u001b[A\n",
            "8698it [20:54,  7.21it/s]\u001b[A\n",
            "8699it [20:55,  7.15it/s]\u001b[A\n",
            "8700it [20:55,  6.97it/s]\u001b[A\n",
            "8701it [20:55,  6.82it/s]\u001b[A\n",
            "8702it [20:55,  6.66it/s]\u001b[A\n",
            "8703it [20:55,  6.68it/s]\u001b[A\n",
            "8704it [20:55,  6.66it/s]\u001b[A\n",
            "8705it [20:55,  6.68it/s]\u001b[A\n",
            "8706it [20:56,  6.72it/s]\u001b[A\n",
            "8707it [20:56,  6.69it/s]\u001b[A\n",
            "8708it [20:56,  6.80it/s]\u001b[A\n",
            "8709it [20:56,  6.76it/s]\u001b[A\n",
            "8710it [20:56,  6.84it/s]\u001b[A\n",
            "8711it [20:56,  6.89it/s]\u001b[A\n",
            "8712it [20:57,  6.88it/s]\u001b[A\n",
            "8713it [20:57,  6.77it/s]\u001b[A\n",
            "8714it [20:57,  6.67it/s]\u001b[A\n",
            "8715it [20:57,  6.72it/s]\u001b[A\n",
            "8716it [20:57,  6.57it/s]\u001b[A\n",
            "8717it [20:57,  6.56it/s]\u001b[A\n",
            "8718it [20:57,  6.58it/s]\u001b[A\n",
            "8719it [20:58,  6.76it/s]\u001b[A\n",
            "8720it [20:58,  6.78it/s]\u001b[A\n",
            "8721it [20:58,  6.70it/s]\u001b[A\n",
            "8722it [20:58,  6.81it/s]\u001b[A\n",
            "8723it [20:58,  6.79it/s]\u001b[A\n",
            "8724it [20:58,  6.87it/s]\u001b[A\n",
            "8725it [20:58,  6.99it/s]\u001b[A\n",
            "8726it [20:59,  7.00it/s]\u001b[A\n",
            "8727it [20:59,  6.86it/s]\u001b[A\n",
            "8728it [20:59,  6.69it/s]\u001b[A\n",
            "8729it [20:59,  6.68it/s]\u001b[A\n",
            "8730it [20:59,  6.55it/s]\u001b[A\n",
            "8731it [20:59,  6.54it/s]\u001b[A\n",
            "8732it [20:59,  6.64it/s]\u001b[A\n",
            "8733it [21:00,  6.79it/s]\u001b[A\n",
            "8734it [21:00,  6.80it/s]\u001b[A\n",
            "8735it [21:00,  6.90it/s]\u001b[A\n",
            "8736it [21:00,  7.01it/s]\u001b[A\n",
            "8737it [21:00,  6.95it/s]\u001b[A\n",
            "8738it [21:00,  6.93it/s]\u001b[A\n",
            "8739it [21:01,  6.82it/s]\u001b[A\n",
            "8740it [21:01,  6.76it/s]\u001b[A\n",
            "8741it [21:01,  6.77it/s]\u001b[A\n",
            "8742it [21:01,  6.96it/s]\u001b[A\n",
            "8743it [21:01,  6.96it/s]\u001b[A\n",
            "8744it [21:01,  6.84it/s]\u001b[A\n",
            "8745it [21:01,  6.83it/s]\u001b[A\n",
            "8746it [21:02,  6.80it/s]\u001b[A\n",
            "8747it [21:02,  6.81it/s]\u001b[A\n",
            "8748it [21:02,  6.75it/s]\u001b[A\n",
            "8749it [21:02,  6.80it/s]\u001b[A\n",
            "8750it [21:02,  6.89it/s]\u001b[A\n",
            "8751it [21:02,  6.90it/s]\u001b[A\n",
            "8752it [21:02,  6.97it/s]\u001b[A\n",
            "8753it [21:03,  6.82it/s]\u001b[A\n",
            "8754it [21:03,  6.89it/s]\u001b[A\n",
            "8755it [21:03,  6.76it/s]\u001b[A\n",
            "8756it [21:03,  6.65it/s]\u001b[A\n",
            "8757it [21:03,  6.51it/s]\u001b[A\n",
            "8758it [21:03,  6.55it/s]\u001b[A\n",
            "8759it [21:03,  6.62it/s]\u001b[A\n",
            "8760it [21:04,  6.78it/s]\u001b[A\n",
            "8761it [21:04,  6.67it/s]\u001b[A\n",
            "8762it [21:04,  6.72it/s]\u001b[A\n",
            "8763it [21:04,  6.70it/s]\u001b[A\n",
            "8764it [21:04,  6.55it/s]\u001b[A\n",
            "8765it [21:04,  6.53it/s]\u001b[A\n",
            "8766it [21:05,  6.54it/s]\u001b[A\n",
            "8767it [21:05,  6.58it/s]\u001b[A\n",
            "8768it [21:05,  6.60it/s]\u001b[A\n",
            "8769it [21:05,  6.60it/s]\u001b[A\n",
            "8770it [21:05,  6.54it/s]\u001b[A\n",
            "8771it [21:05,  6.51it/s]\u001b[A\n",
            "8772it [21:05,  6.70it/s]\u001b[A\n",
            "8773it [21:06,  6.83it/s]\u001b[A\n",
            "8774it [21:06,  6.86it/s]\u001b[A\n",
            "8775it [21:06,  6.75it/s]\u001b[A\n",
            "8776it [21:06,  6.68it/s]\u001b[A\n",
            "8777it [21:06,  6.72it/s]\u001b[A\n",
            "8778it [21:06,  6.60it/s]\u001b[A\n",
            "8779it [21:06,  6.73it/s]\u001b[A\n",
            "8780it [21:07,  6.83it/s]\u001b[A\n",
            "8781it [21:07,  6.88it/s]\u001b[A\n",
            "8782it [21:07,  7.00it/s]\u001b[A\n",
            "8783it [21:07,  7.07it/s]\u001b[A\n",
            "8784it [21:07,  7.16it/s]\u001b[A\n",
            "8785it [21:07,  7.10it/s]\u001b[A\n",
            "8786it [21:07,  6.99it/s]\u001b[A\n",
            "8787it [21:08,  7.11it/s]\u001b[A\n",
            "8788it [21:08,  7.06it/s]\u001b[A\n",
            "8789it [21:08,  7.09it/s]\u001b[A\n",
            "8790it [21:08,  7.08it/s]\u001b[A\n",
            "8791it [21:08,  7.12it/s]\u001b[A\n",
            "8792it [21:08,  7.01it/s]\u001b[A\n",
            "8793it [21:08,  7.03it/s]\u001b[A\n",
            "8794it [21:09,  6.93it/s]\u001b[A\n",
            "8795it [21:09,  6.95it/s]\u001b[A\n",
            "8796it [21:09,  6.86it/s]\u001b[A\n",
            "8797it [21:09,  6.70it/s]\u001b[A\n",
            "8798it [21:09,  6.73it/s]\u001b[A\n",
            "8799it [21:09,  6.58it/s]\u001b[A\n",
            "8800it [21:09,  6.60it/s]\u001b[A\n",
            "8801it [21:10,  6.76it/s]\u001b[A\n",
            "8802it [21:10,  6.74it/s]\u001b[A\n",
            "8803it [21:10,  6.68it/s]\u001b[A\n",
            "8804it [21:10,  6.61it/s]\u001b[A\n",
            "8805it [21:10,  6.67it/s]\u001b[A\n",
            "8806it [21:10,  6.54it/s]\u001b[A\n",
            "8807it [21:11,  6.54it/s]\u001b[A\n",
            "8808it [21:11,  6.65it/s]\u001b[A\n",
            "8809it [21:11,  6.69it/s]\u001b[A\n",
            "8810it [21:11,  6.64it/s]\u001b[A\n",
            "8811it [21:11,  6.68it/s]\u001b[A\n",
            "8812it [21:11,  6.55it/s]\u001b[A\n",
            "8813it [21:11,  6.61it/s]\u001b[A\n",
            "8814it [21:12,  6.58it/s]\u001b[A\n",
            "8815it [21:12,  6.62it/s]\u001b[A\n",
            "8816it [21:12,  6.60it/s]\u001b[A\n",
            "8817it [21:12,  6.57it/s]\u001b[A\n",
            "8818it [21:12,  6.53it/s]\u001b[A\n",
            "8819it [21:12,  6.45it/s]\u001b[A\n",
            "8820it [21:13,  6.43it/s]\u001b[A\n",
            "8821it [21:13,  6.32it/s]\u001b[A\n",
            "8822it [21:13,  6.40it/s]\u001b[A\n",
            "8823it [21:13,  6.45it/s]\u001b[A\n",
            "8824it [21:13,  6.52it/s]\u001b[A\n",
            "8825it [21:13,  6.39it/s]\u001b[A\n",
            "8826it [21:13,  6.42it/s]\u001b[A\n",
            "8827it [21:14,  6.53it/s]\u001b[A\n",
            "8828it [21:14,  6.46it/s]\u001b[A\n",
            "8829it [21:14,  6.35it/s]\u001b[A\n",
            "8830it [21:14,  6.36it/s]\u001b[A\n",
            "8831it [21:14,  6.36it/s]\u001b[A\n",
            "8832it [21:14,  6.09it/s]\u001b[A\n",
            "8833it [21:15,  6.21it/s]\u001b[A\n",
            "8834it [21:15,  6.49it/s]\u001b[A\n",
            "8835it [21:15,  6.73it/s]\u001b[A\n",
            "8836it [21:15,  6.87it/s]\u001b[A\n",
            "8837it [21:15,  6.96it/s]\u001b[A\n",
            "8838it [21:15,  6.98it/s]\u001b[A\n",
            "8839it [21:15,  6.96it/s]\u001b[A\n",
            "8840it [21:16,  7.02it/s]\u001b[A\n",
            "8841it [21:16,  7.03it/s]\u001b[A\n",
            "8842it [21:16,  7.04it/s]\u001b[A\n",
            "8843it [21:16,  7.02it/s]\u001b[A\n",
            "8844it [21:16,  7.08it/s]\u001b[A\n",
            "8845it [21:16,  7.10it/s]\u001b[A\n",
            "8846it [21:16,  7.02it/s]\u001b[A\n",
            "8847it [21:17,  6.87it/s]\u001b[A\n",
            "8848it [21:17,  7.00it/s]\u001b[A\n",
            "8849it [21:17,  6.95it/s]\u001b[A\n",
            "8850it [21:17,  6.82it/s]\u001b[A\n",
            "8851it [21:17,  6.75it/s]\u001b[A\n",
            "8852it [21:17,  6.71it/s]\u001b[A\n",
            "8853it [21:18,  4.82it/s]\u001b[A\n",
            "8854it [21:18,  4.06it/s]\u001b[A\n",
            "8855it [21:18,  4.67it/s]\u001b[A\n",
            "8856it [21:18,  5.24it/s]\u001b[A\n",
            "8857it [21:18,  5.53it/s]\u001b[A\n",
            "8858it [21:19,  5.76it/s]\u001b[A\n",
            "8859it [21:19,  5.96it/s]\u001b[A\n",
            "8860it [21:19,  6.01it/s]\u001b[A\n",
            "8861it [21:19,  5.98it/s]\u001b[A\n",
            "8862it [21:19,  6.15it/s]\u001b[A\n",
            "8863it [21:19,  6.13it/s]\u001b[A\n",
            "8864it [21:20,  6.16it/s]\u001b[A\n",
            "8865it [21:20,  6.36it/s]\u001b[A\n",
            "8866it [21:20,  6.42it/s]\u001b[A\n",
            "8867it [21:20,  6.47it/s]\u001b[A\n",
            "8868it [21:20,  6.51it/s]\u001b[A\n",
            "8869it [21:20,  6.67it/s]\u001b[A\n",
            "8870it [21:20,  6.54it/s]\u001b[A\n",
            "8871it [21:21,  6.65it/s]\u001b[A\n",
            "8872it [21:21,  6.61it/s]\u001b[A\n",
            "8873it [21:21,  6.60it/s]\u001b[A\n",
            "8874it [21:21,  6.61it/s]\u001b[A\n",
            "8875it [21:21,  6.57it/s]\u001b[A\n",
            "8876it [21:21,  6.51it/s]\u001b[A\n",
            "8877it [21:22,  6.35it/s]\u001b[A\n",
            "8878it [21:22,  6.46it/s]\u001b[A\n",
            "8879it [21:22,  6.65it/s]\u001b[A\n",
            "8880it [21:22,  6.80it/s]\u001b[A\n",
            "8881it [21:22,  6.88it/s]\u001b[A\n",
            "8882it [21:22,  6.94it/s]\u001b[A\n",
            "8883it [21:22,  7.00it/s]\u001b[A\n",
            "8884it [21:23,  6.92it/s]\u001b[A\n",
            "8885it [21:23,  6.81it/s]\u001b[A\n",
            "8886it [21:23,  6.72it/s]\u001b[A\n",
            "8887it [21:23,  6.71it/s]\u001b[A\n",
            "8888it [21:23,  6.57it/s]\u001b[A\n",
            "8889it [21:23,  6.62it/s]\u001b[A\n",
            "8890it [21:23,  6.51it/s]\u001b[A\n",
            "8891it [21:24,  6.34it/s]\u001b[A\n",
            "8892it [21:24,  6.43it/s]\u001b[A\n",
            "8893it [21:24,  6.54it/s]\u001b[A\n",
            "8894it [21:24,  6.69it/s]\u001b[A\n",
            "8895it [21:24,  6.84it/s]\u001b[A\n",
            "8896it [21:24,  6.95it/s]\u001b[A\n",
            "8897it [21:24,  6.94it/s]\u001b[A\n",
            "8898it [21:25,  6.83it/s]\u001b[A\n",
            "8899it [21:25,  6.94it/s]\u001b[A\n",
            "8900it [21:25,  7.07it/s]\u001b[A\n",
            "8901it [21:25,  7.13it/s]\u001b[A\n",
            "8902it [21:25,  7.16it/s]\u001b[A\n",
            "8903it [21:25,  7.22it/s]\u001b[A\n",
            "8904it [21:25,  7.21it/s]\u001b[A\n",
            "8905it [21:26,  7.07it/s]\u001b[A\n",
            "8906it [21:26,  6.89it/s]\u001b[A\n",
            "8907it [21:26,  6.76it/s]\u001b[A\n",
            "8908it [21:26,  6.78it/s]\u001b[A\n",
            "8909it [21:26,  6.72it/s]\u001b[A\n",
            "8910it [21:26,  6.63it/s]\u001b[A\n",
            "8911it [21:27,  6.63it/s]\u001b[A\n",
            "8912it [21:27,  6.64it/s]\u001b[A\n",
            "8913it [21:27,  6.70it/s]\u001b[A\n",
            "8914it [21:27,  6.85it/s]\u001b[A\n",
            "8915it [21:27,  6.93it/s]\u001b[A\n",
            "8916it [21:27,  6.99it/s]\u001b[A\n",
            "8917it [21:27,  7.05it/s]\u001b[A\n",
            "8918it [21:28,  7.00it/s]\u001b[A\n",
            "8919it [21:28,  6.95it/s]\u001b[A\n",
            "8920it [21:28,  6.98it/s]\u001b[A\n",
            "8921it [21:28,  7.07it/s]\u001b[A\n",
            "8922it [21:28,  7.15it/s]\u001b[A\n",
            "8923it [21:28,  7.11it/s]\u001b[A\n",
            "8924it [21:28,  7.07it/s]\u001b[A\n",
            "8925it [21:28,  6.97it/s]\u001b[A\n",
            "8926it [21:29,  6.91it/s]\u001b[A\n",
            "8927it [21:29,  6.85it/s]\u001b[A\n",
            "8928it [21:29,  6.85it/s]\u001b[A\n",
            "8929it [21:29,  6.77it/s]\u001b[A\n",
            "8930it [21:29,  6.69it/s]\u001b[A\n",
            "8931it [21:29,  6.63it/s]\u001b[A\n",
            "8932it [21:30,  6.40it/s]\u001b[A\n",
            "8933it [21:30,  6.57it/s]\u001b[A\n",
            "8934it [21:30,  6.68it/s]\u001b[A\n",
            "8935it [21:30,  6.88it/s]\u001b[A\n",
            "8936it [21:30,  6.96it/s]\u001b[A\n",
            "8937it [21:30,  6.98it/s]\u001b[A\n",
            "8938it [21:30,  6.97it/s]\u001b[A\n",
            "8939it [21:31,  7.02it/s]\u001b[A\n",
            "8940it [21:31,  6.79it/s]\u001b[A\n",
            "8941it [21:31,  6.88it/s]\u001b[A\n",
            "8942it [21:31,  6.93it/s]\u001b[A\n",
            "8943it [21:31,  6.94it/s]\u001b[A\n",
            "8944it [21:31,  6.95it/s]\u001b[A\n",
            "8945it [21:31,  7.02it/s]\u001b[A\n",
            "8946it [21:32,  7.02it/s]\u001b[A\n",
            "8947it [21:32,  6.93it/s]\u001b[A\n",
            "8948it [21:32,  6.94it/s]\u001b[A\n",
            "8949it [21:32,  6.97it/s]\u001b[A\n",
            "8950it [21:32,  6.99it/s]\u001b[A\n",
            "8951it [21:32,  7.02it/s]\u001b[A\n",
            "8952it [21:32,  7.07it/s]\u001b[A\n",
            "8953it [21:33,  7.03it/s]\u001b[A\n",
            "8954it [21:33,  6.92it/s]\u001b[A\n",
            "8955it [21:33,  6.92it/s]\u001b[A\n",
            "8956it [21:33,  6.91it/s]\u001b[A\n",
            "8957it [21:33,  6.97it/s]\u001b[A\n",
            "8958it [21:33,  7.04it/s]\u001b[A\n",
            "8959it [21:33,  7.09it/s]\u001b[A\n",
            "8960it [21:34,  6.95it/s]\u001b[A\n",
            "8961it [21:34,  6.89it/s]\u001b[A\n",
            "8962it [21:34,  6.90it/s]\u001b[A\n",
            "8963it [21:34,  6.97it/s]\u001b[A\n",
            "8964it [21:34,  7.05it/s]\u001b[A\n",
            "8965it [21:34,  7.07it/s]\u001b[A\n",
            "8966it [21:34,  7.03it/s]\u001b[A\n",
            "8967it [21:35,  7.03it/s]\u001b[A\n",
            "8968it [21:35,  6.84it/s]\u001b[A\n",
            "8969it [21:35,  6.75it/s]\u001b[A\n",
            "8970it [21:35,  6.81it/s]\u001b[A\n",
            "8971it [21:35,  6.90it/s]\u001b[A\n",
            "8972it [21:35,  6.93it/s]\u001b[A\n",
            "8973it [21:35,  6.93it/s]\u001b[A\n",
            "8974it [21:36,  6.96it/s]\u001b[A\n",
            "8975it [21:36,  6.76it/s]\u001b[A\n",
            "8976it [21:36,  6.77it/s]\u001b[A\n",
            "8977it [21:36,  6.79it/s]\u001b[A\n",
            "8978it [21:36,  6.89it/s]\u001b[A\n",
            "8979it [21:36,  6.98it/s]\u001b[A\n",
            "8980it [21:36,  6.88it/s]\u001b[A\n",
            "8981it [21:37,  6.84it/s]\u001b[A\n",
            "8982it [21:37,  6.73it/s]\u001b[A\n",
            "8983it [21:37,  6.83it/s]\u001b[A\n",
            "8984it [21:37,  6.89it/s]\u001b[A\n",
            "8985it [21:37,  6.99it/s]\u001b[A\n",
            "8986it [21:37,  6.97it/s]\u001b[A\n",
            "8987it [21:37,  7.06it/s]\u001b[A\n",
            "8988it [21:38,  7.08it/s]\u001b[A\n",
            "8989it [21:38,  6.87it/s]\u001b[A\n",
            "8990it [21:38,  6.70it/s]\u001b[A\n",
            "8991it [21:38,  6.61it/s]\u001b[A\n",
            "8992it [21:38,  6.63it/s]\u001b[A\n",
            "8993it [21:38,  6.61it/s]\u001b[A\n",
            "8994it [21:39,  6.60it/s]\u001b[A\n",
            "8995it [21:39,  6.64it/s]\u001b[A\n",
            "8996it [21:39,  6.59it/s]\u001b[A\n",
            "8997it [21:39,  6.74it/s]\u001b[A\n",
            "8998it [21:39,  6.87it/s]\u001b[A\n",
            "8999it [21:39,  7.02it/s]\u001b[A\n",
            "9000it [21:39,  7.03it/s]\u001b[A\n",
            "9001it [21:40,  6.99it/s]\u001b[A\n",
            "9002it [21:40,  6.90it/s]\u001b[A\n",
            "9003it [21:40,  6.77it/s]\u001b[A\n",
            "9004it [21:40,  6.69it/s]\u001b[A\n",
            "9005it [21:40,  6.58it/s]\u001b[A\n",
            "9006it [21:40,  6.63it/s]\u001b[A\n",
            "9007it [21:40,  6.56it/s]\u001b[A\n",
            "9008it [21:41,  6.54it/s]\u001b[A\n",
            "9009it [21:41,  6.43it/s]\u001b[A\n",
            "9010it [21:41,  6.42it/s]\u001b[A\n",
            "9011it [21:41,  6.47it/s]\u001b[A\n",
            "9012it [21:41,  6.50it/s]\u001b[A\n",
            "9013it [21:41,  6.48it/s]\u001b[A\n",
            "9014it [21:42,  6.68it/s]\u001b[A\n",
            "9015it [21:42,  6.74it/s]\u001b[A\n",
            "9016it [21:42,  6.75it/s]\u001b[A\n",
            "9017it [21:42,  6.91it/s]\u001b[A\n",
            "9018it [21:42,  7.05it/s]\u001b[A\n",
            "9019it [21:42,  6.97it/s]\u001b[A\n",
            "9020it [21:42,  6.99it/s]\u001b[A\n",
            "9021it [21:43,  6.94it/s]\u001b[A\n",
            "9022it [21:43,  6.97it/s]\u001b[A\n",
            "9023it [21:43,  6.70it/s]\u001b[A\n",
            "9024it [21:43,  6.69it/s]\u001b[A\n",
            "9025it [21:43,  6.60it/s]\u001b[A\n",
            "9026it [21:43,  6.66it/s]\u001b[A\n",
            "9027it [21:43,  6.63it/s]\u001b[A\n",
            "9028it [21:44,  6.74it/s]\u001b[A\n",
            "9029it [21:44,  6.82it/s]\u001b[A\n",
            "9030it [21:44,  6.82it/s]\u001b[A\n",
            "9031it [21:44,  6.87it/s]\u001b[A\n",
            "9032it [21:44,  6.95it/s]\u001b[A\n",
            "9033it [21:44,  7.03it/s]\u001b[A\n",
            "9034it [21:44,  7.02it/s]\u001b[A\n",
            "9035it [21:45,  6.95it/s]\u001b[A\n",
            "9036it [21:45,  6.95it/s]\u001b[A\n",
            "9037it [21:45,  6.71it/s]\u001b[A\n",
            "9038it [21:45,  6.72it/s]\u001b[A\n",
            "9039it [21:45,  6.52it/s]\u001b[A\n",
            "9040it [21:45,  6.51it/s]\u001b[A\n",
            "9041it [21:46,  6.59it/s]\u001b[A\n",
            "9042it [21:46,  6.74it/s]\u001b[A\n",
            "9043it [21:46,  6.82it/s]\u001b[A\n",
            "9044it [21:46,  6.86it/s]\u001b[A\n",
            "9045it [21:46,  6.98it/s]\u001b[A\n",
            "9046it [21:46,  6.95it/s]\u001b[A\n",
            "9047it [21:46,  7.01it/s]\u001b[A\n",
            "9048it [21:47,  7.00it/s]\u001b[A\n",
            "9049it [21:47,  6.99it/s]\u001b[A\n",
            "9050it [21:47,  7.04it/s]\u001b[A\n",
            "9051it [21:47,  7.04it/s]\u001b[A\n",
            "9052it [21:47,  6.84it/s]\u001b[A\n",
            "9053it [21:47,  6.93it/s]\u001b[A\n",
            "9054it [21:47,  6.98it/s]\u001b[A\n",
            "9055it [21:48,  7.05it/s]\u001b[A\n",
            "9056it [21:48,  6.90it/s]\u001b[A\n",
            "9057it [21:48,  6.78it/s]\u001b[A\n",
            "9058it [21:48,  6.74it/s]\u001b[A\n",
            "9059it [21:48,  6.85it/s]\u001b[A\n",
            "9060it [21:48,  6.95it/s]\u001b[A\n",
            "9061it [21:48,  7.02it/s]\u001b[A\n",
            "9062it [21:49,  7.01it/s]\u001b[A\n",
            "9063it [21:49,  6.92it/s]\u001b[A\n",
            "9064it [21:49,  7.01it/s]\u001b[A\n",
            "9065it [21:49,  6.92it/s]\u001b[A\n",
            "9066it [21:49,  7.00it/s]\u001b[A\n",
            "9067it [21:49,  6.97it/s]\u001b[A\n",
            "9068it [21:49,  7.05it/s]\u001b[A\n",
            "9069it [21:50,  6.99it/s]\u001b[A\n",
            "9070it [21:50,  7.02it/s]\u001b[A\n",
            "9071it [21:50,  7.08it/s]\u001b[A\n",
            "9072it [21:50,  7.05it/s]\u001b[A\n",
            "9073it [21:50,  7.10it/s]\u001b[A\n",
            "9074it [21:50,  7.11it/s]\u001b[A\n",
            "9075it [21:50,  7.12it/s]\u001b[A\n",
            "9076it [21:51,  7.12it/s]\u001b[A\n",
            "9077it [21:51,  6.95it/s]\u001b[A\n",
            "9078it [21:51,  7.00it/s]\u001b[A\n",
            "9079it [21:51,  6.88it/s]\u001b[A\n",
            "9080it [21:51,  6.84it/s]\u001b[A\n",
            "9081it [21:51,  6.75it/s]\u001b[A\n",
            "9082it [21:51,  6.69it/s]\u001b[A\n",
            "9083it [21:52,  6.79it/s]\u001b[A\n",
            "9084it [21:52,  6.86it/s]\u001b[A\n",
            "9085it [21:52,  6.70it/s]\u001b[A\n",
            "9086it [21:52,  6.63it/s]\u001b[A\n",
            "9087it [21:52,  6.76it/s]\u001b[A\n",
            "9088it [21:52,  6.81it/s]\u001b[A\n",
            "9089it [21:52,  6.95it/s]\u001b[A\n",
            "9090it [21:53,  6.87it/s]\u001b[A\n",
            "9091it [21:53,  6.86it/s]\u001b[A\n",
            "9092it [21:53,  6.85it/s]\u001b[A\n",
            "9093it [21:53,  6.85it/s]\u001b[A\n",
            "9094it [21:53,  6.98it/s]\u001b[A\n",
            "9095it [21:53,  7.05it/s]\u001b[A\n",
            "9096it [21:53,  7.11it/s]\u001b[A\n",
            "9097it [21:54,  6.90it/s]\u001b[A\n",
            "9098it [21:54,  6.93it/s]\u001b[A\n",
            "9099it [21:54,  6.96it/s]\u001b[A\n",
            "9100it [21:54,  7.00it/s]\u001b[A\n",
            "9101it [21:54,  7.10it/s]\u001b[A\n",
            "9102it [21:54,  7.16it/s]\u001b[A\n",
            "9103it [21:54,  6.96it/s]\u001b[A\n",
            "9104it [21:55,  6.81it/s]\u001b[A\n",
            "9105it [21:55,  6.74it/s]\u001b[A\n",
            "9106it [21:55,  6.86it/s]\u001b[A\n",
            "9107it [21:55,  6.91it/s]\u001b[A\n",
            "9108it [21:55,  6.92it/s]\u001b[A\n",
            "9109it [21:55,  7.01it/s]\u001b[A\n",
            "9110it [21:55,  7.01it/s]\u001b[A\n",
            "9111it [21:56,  7.05it/s]\u001b[A\n",
            "9112it [21:56,  7.09it/s]\u001b[A\n",
            "9113it [21:56,  7.09it/s]\u001b[A\n",
            "9114it [21:56,  7.04it/s]\u001b[A\n",
            "9115it [21:56,  7.04it/s]\u001b[A\n",
            "9116it [21:56,  7.08it/s]\u001b[A\n",
            "9117it [21:56,  7.15it/s]\u001b[A\n",
            "9118it [21:57,  7.10it/s]\u001b[A\n",
            "9119it [21:57,  7.12it/s]\u001b[A\n",
            "9120it [21:57,  7.15it/s]\u001b[A\n",
            "9121it [21:57,  7.07it/s]\u001b[A\n",
            "9122it [21:57,  6.91it/s]\u001b[A\n",
            "9123it [21:57,  6.81it/s]\u001b[A\n",
            "9124it [21:57,  6.97it/s]\u001b[A\n",
            "9125it [21:58,  7.03it/s]\u001b[A\n",
            "9126it [21:58,  7.04it/s]\u001b[A\n",
            "9127it [21:58,  7.01it/s]\u001b[A\n",
            "9128it [21:58,  7.13it/s]\u001b[A\n",
            "9129it [21:58,  7.14it/s]\u001b[A\n",
            "9130it [21:58,  7.22it/s]\u001b[A\n",
            "9131it [21:58,  7.19it/s]\u001b[A\n",
            "9132it [21:59,  7.06it/s]\u001b[A\n",
            "9133it [21:59,  7.03it/s]\u001b[A\n",
            "9134it [21:59,  6.82it/s]\u001b[A\n",
            "9135it [21:59,  6.80it/s]\u001b[A\n",
            "9136it [21:59,  6.58it/s]\u001b[A\n",
            "9137it [21:59,  6.58it/s]\u001b[A\n",
            "9138it [21:59,  6.57it/s]\u001b[A\n",
            "9139it [22:00,  6.78it/s]\u001b[A\n",
            "9140it [22:00,  6.87it/s]\u001b[A\n",
            "9141it [22:00,  7.00it/s]\u001b[A\n",
            "9142it [22:00,  7.02it/s]\u001b[A\n",
            "9143it [22:00,  6.92it/s]\u001b[A\n",
            "9144it [22:00,  6.85it/s]\u001b[A\n",
            "9145it [22:00,  6.69it/s]\u001b[A\n",
            "9146it [22:01,  6.80it/s]\u001b[A\n",
            "9147it [22:01,  6.61it/s]\u001b[A\n",
            "9148it [22:01,  6.64it/s]\u001b[A\n",
            "9149it [22:01,  6.49it/s]\u001b[A\n",
            "9150it [22:01,  6.53it/s]\u001b[A\n",
            "9151it [22:01,  6.56it/s]\u001b[A\n",
            "9152it [22:02,  6.64it/s]\u001b[A\n",
            "9153it [22:02,  6.78it/s]\u001b[A\n",
            "9154it [22:02,  6.62it/s]\u001b[A\n",
            "9155it [22:02,  6.59it/s]\u001b[A\n",
            "9156it [22:02,  6.50it/s]\u001b[A\n",
            "9157it [22:02,  6.52it/s]\u001b[A\n",
            "9158it [22:02,  6.50it/s]\u001b[A\n",
            "9159it [22:03,  6.56it/s]\u001b[A\n",
            "9160it [22:03,  6.67it/s]\u001b[A\n",
            "9161it [22:03,  6.75it/s]\u001b[A\n",
            "9162it [22:03,  4.43it/s]\u001b[A\n",
            "9163it [22:03,  5.00it/s]\u001b[A\n",
            "9164it [22:04,  5.47it/s]\u001b[A\n",
            "9165it [22:04,  5.90it/s]\u001b[A\n",
            "9166it [22:04,  6.22it/s]\u001b[A\n",
            "9167it [22:04,  6.49it/s]\u001b[A\n",
            "9168it [22:04,  6.64it/s]\u001b[A\n",
            "9169it [22:04,  6.85it/s]\u001b[A\n",
            "9170it [22:04,  6.97it/s]\u001b[A\n",
            "9171it [22:05,  6.90it/s]\u001b[A\n",
            "9172it [22:05,  7.01it/s]\u001b[A\n",
            "9173it [22:05,  7.06it/s]\u001b[A\n",
            "9174it [22:05,  7.10it/s]\u001b[A\n",
            "9175it [22:05,  6.97it/s]\u001b[A\n",
            "9176it [22:05,  6.96it/s]\u001b[A\n",
            "9177it [22:05,  6.63it/s]\u001b[A\n",
            "9178it [22:06,  6.64it/s]\u001b[A\n",
            "9179it [22:06,  6.72it/s]\u001b[A\n",
            "9180it [22:06,  6.75it/s]\u001b[A\n",
            "9181it [22:06,  6.85it/s]\u001b[A\n",
            "9182it [22:06,  6.88it/s]\u001b[A\n",
            "9183it [22:06,  6.91it/s]\u001b[A\n",
            "9184it [22:06,  6.92it/s]\u001b[A\n",
            "9185it [22:07,  6.93it/s]\u001b[A\n",
            "9186it [22:07,  6.88it/s]\u001b[A\n",
            "9187it [22:07,  6.98it/s]\u001b[A\n",
            "9188it [22:07,  7.07it/s]\u001b[A\n",
            "9189it [22:07,  6.97it/s]\u001b[A\n",
            "9190it [22:07,  7.04it/s]\u001b[A\n",
            "9191it [22:07,  6.94it/s]\u001b[A\n",
            "9192it [22:08,  7.02it/s]\u001b[A\n",
            "9193it [22:08,  6.98it/s]\u001b[A\n",
            "9194it [22:08,  7.05it/s]\u001b[A\n",
            "9195it [22:08,  7.10it/s]\u001b[A\n",
            "9196it [22:08,  7.13it/s]\u001b[A\n",
            "9197it [22:08,  7.13it/s]\u001b[A\n",
            "9198it [22:08,  7.15it/s]\u001b[A\n",
            "9199it [22:09,  7.17it/s]\u001b[A\n",
            "9200it [22:09,  6.90it/s]\u001b[A\n",
            "9201it [22:09,  6.92it/s]\u001b[A\n",
            "9202it [22:09,  7.00it/s]\u001b[A\n",
            "9203it [22:09,  7.07it/s]\u001b[A\n",
            "9204it [22:09,  6.98it/s]\u001b[A\n",
            "9205it [22:09,  6.92it/s]\u001b[A\n",
            "9206it [22:10,  7.02it/s]\u001b[A\n",
            "9207it [22:10,  7.02it/s]\u001b[A\n",
            "9208it [22:10,  7.07it/s]\u001b[A\n",
            "9209it [22:10,  7.12it/s]\u001b[A\n",
            "9210it [22:10,  7.15it/s]\u001b[A\n",
            "9211it [22:10,  7.12it/s]\u001b[A\n",
            "9212it [22:10,  7.09it/s]\u001b[A\n",
            "9213it [22:11,  7.12it/s]\u001b[A\n",
            "9214it [22:11,  7.08it/s]\u001b[A\n",
            "9215it [22:11,  6.99it/s]\u001b[A\n",
            "9216it [22:11,  6.92it/s]\u001b[A\n",
            "9217it [22:11,  6.75it/s]\u001b[A\n",
            "9218it [22:11,  6.55it/s]\u001b[A\n",
            "9219it [22:11,  6.53it/s]\u001b[A\n",
            "9220it [22:12,  6.61it/s]\u001b[A\n",
            "9221it [22:12,  6.59it/s]\u001b[A\n",
            "9222it [22:12,  6.72it/s]\u001b[A\n",
            "9223it [22:12,  6.84it/s]\u001b[A\n",
            "9224it [22:12,  6.81it/s]\u001b[A\n",
            "9225it [22:12,  6.83it/s]\u001b[A\n",
            "9226it [22:12,  6.97it/s]\u001b[A\n",
            "9227it [22:13,  7.02it/s]\u001b[A\n",
            "9228it [22:13,  6.92it/s]\u001b[A\n",
            "9229it [22:13,  6.98it/s]\u001b[A\n",
            "9230it [22:13,  7.06it/s]\u001b[A\n",
            "9231it [22:13,  7.07it/s]\u001b[A\n",
            "9232it [22:13,  7.09it/s]\u001b[A\n",
            "9233it [22:13,  6.99it/s]\u001b[A\n",
            "9234it [22:14,  6.97it/s]\u001b[A\n",
            "9235it [22:14,  6.78it/s]\u001b[A\n",
            "9236it [22:14,  6.70it/s]\u001b[A\n",
            "9237it [22:14,  6.75it/s]\u001b[A\n",
            "9238it [22:14,  6.95it/s]\u001b[A\n",
            "9239it [22:14,  6.91it/s]\u001b[A\n",
            "9240it [22:15,  6.84it/s]\u001b[A\n",
            "9241it [22:15,  6.95it/s]\u001b[A\n",
            "9242it [22:15,  7.00it/s]\u001b[A\n",
            "9243it [22:15,  7.05it/s]\u001b[A\n",
            "9244it [22:15,  7.12it/s]\u001b[A\n",
            "9245it [22:15,  7.09it/s]\u001b[A\n",
            "9246it [22:15,  7.05it/s]\u001b[A\n",
            "9247it [22:16,  7.05it/s]\u001b[A\n",
            "9248it [22:16,  7.06it/s]\u001b[A\n",
            "9249it [22:16,  7.03it/s]\u001b[A\n",
            "9250it [22:16,  7.12it/s]\u001b[A\n",
            "9251it [22:16,  7.16it/s]\u001b[A\n",
            "9252it [22:16,  7.23it/s]\u001b[A\n",
            "9253it [22:16,  7.05it/s]\u001b[A\n",
            "9254it [22:17,  6.95it/s]\u001b[A\n",
            "9255it [22:17,  6.89it/s]\u001b[A\n",
            "9256it [22:17,  6.94it/s]\u001b[A\n",
            "9257it [22:17,  7.09it/s]\u001b[A\n",
            "9258it [22:17,  7.11it/s]\u001b[A\n",
            "9259it [22:17,  7.05it/s]\u001b[A\n",
            "9260it [22:17,  7.10it/s]\u001b[A\n",
            "9261it [22:17,  7.20it/s]\u001b[A\n",
            "9262it [22:18,  7.25it/s]\u001b[A\n",
            "9263it [22:18,  7.16it/s]\u001b[A\n",
            "9264it [22:18,  7.11it/s]\u001b[A\n",
            "9265it [22:18,  7.15it/s]\u001b[A\n",
            "9266it [22:18,  7.16it/s]\u001b[A\n",
            "9267it [22:18,  7.20it/s]\u001b[A\n",
            "9268it [22:18,  7.09it/s]\u001b[A\n",
            "9269it [22:19,  6.98it/s]\u001b[A\n",
            "9270it [22:19,  6.85it/s]\u001b[A\n",
            "9271it [22:19,  6.72it/s]\u001b[A\n",
            "9272it [22:19,  6.65it/s]\u001b[A\n",
            "9273it [22:19,  6.66it/s]\u001b[A\n",
            "9274it [22:19,  6.57it/s]\u001b[A\n",
            "9275it [22:20,  6.66it/s]\u001b[A\n",
            "9276it [22:20,  6.83it/s]\u001b[A\n",
            "9277it [22:20,  7.01it/s]\u001b[A\n",
            "9278it [22:20,  6.98it/s]\u001b[A\n",
            "9279it [22:20,  6.85it/s]\u001b[A\n",
            "9280it [22:20,  6.86it/s]\u001b[A\n",
            "9281it [22:20,  6.76it/s]\u001b[A\n",
            "9282it [22:21,  6.75it/s]\u001b[A\n",
            "9283it [22:21,  6.67it/s]\u001b[A\n",
            "9284it [22:21,  6.39it/s]\u001b[A\n",
            "9285it [22:21,  6.42it/s]\u001b[A\n",
            "9286it [22:21,  6.47it/s]\u001b[A\n",
            "9287it [22:21,  6.57it/s]\u001b[A\n",
            "9288it [22:21,  6.48it/s]\u001b[A\n",
            "9289it [22:22,  6.63it/s]\u001b[A\n",
            "9290it [22:22,  6.61it/s]\u001b[A\n",
            "9291it [22:22,  6.77it/s]\u001b[A\n",
            "9292it [22:22,  6.83it/s]\u001b[A\n",
            "9293it [22:22,  6.90it/s]\u001b[A\n",
            "9294it [22:22,  7.00it/s]\u001b[A\n",
            "9295it [22:22,  6.77it/s]\u001b[A\n",
            "9296it [22:23,  6.81it/s]\u001b[A\n",
            "9297it [22:23,  6.85it/s]\u001b[A\n",
            "9298it [22:23,  6.83it/s]\u001b[A\n",
            "9299it [22:23,  6.74it/s]\u001b[A\n",
            "9300it [22:23,  6.68it/s]\u001b[A\n",
            "9301it [22:23,  6.72it/s]\u001b[A\n",
            "9302it [22:24,  6.63it/s]\u001b[A\n",
            "9303it [22:24,  6.58it/s]\u001b[A\n",
            "9304it [22:24,  6.62it/s]\u001b[A\n",
            "9305it [22:24,  6.79it/s]\u001b[A\n",
            "9306it [22:24,  6.97it/s]\u001b[A\n",
            "9307it [22:24,  6.96it/s]\u001b[A\n",
            "9308it [22:24,  7.02it/s]\u001b[A\n",
            "9309it [22:25,  6.84it/s]\u001b[A\n",
            "9310it [22:25,  6.77it/s]\u001b[A\n",
            "9311it [22:25,  6.75it/s]\u001b[A\n",
            "9312it [22:25,  6.81it/s]\u001b[A\n",
            "9313it [22:25,  6.96it/s]\u001b[A\n",
            "9314it [22:25,  7.09it/s]\u001b[A\n",
            "9315it [22:25,  7.04it/s]\u001b[A\n",
            "9316it [22:26,  6.89it/s]\u001b[A\n",
            "9317it [22:26,  6.90it/s]\u001b[A\n",
            "9318it [22:26,  6.75it/s]\u001b[A\n",
            "9319it [22:26,  6.96it/s]\u001b[A\n",
            "9320it [22:26,  7.11it/s]\u001b[A\n",
            "9321it [22:26,  7.13it/s]\u001b[A\n",
            "9322it [22:26,  7.17it/s]\u001b[A\n",
            "9323it [22:27,  6.91it/s]\u001b[A\n",
            "9324it [22:27,  7.05it/s]\u001b[A\n",
            "9325it [22:27,  6.93it/s]\u001b[A\n",
            "9326it [22:27,  6.80it/s]\u001b[A\n",
            "9327it [22:27,  6.75it/s]\u001b[A\n",
            "9328it [22:27,  6.86it/s]\u001b[A\n",
            "9329it [22:27,  6.97it/s]\u001b[A\n",
            "9330it [22:28,  6.92it/s]\u001b[A\n",
            "9331it [22:28,  6.96it/s]\u001b[A\n",
            "9332it [22:28,  6.93it/s]\u001b[A\n",
            "9333it [22:28,  7.06it/s]\u001b[A\n",
            "9334it [22:28,  7.19it/s]\u001b[A\n",
            "9335it [22:28,  6.91it/s]\u001b[A\n",
            "9336it [22:28,  6.81it/s]\u001b[A\n",
            "9337it [22:29,  6.67it/s]\u001b[A\n",
            "9338it [22:29,  6.72it/s]\u001b[A\n",
            "9339it [22:29,  6.86it/s]\u001b[A\n",
            "9340it [22:29,  6.93it/s]\u001b[A\n",
            "9341it [22:29,  6.98it/s]\u001b[A\n",
            "9342it [22:29,  7.08it/s]\u001b[A\n",
            "9343it [22:29,  7.25it/s]\u001b[A\n",
            "9344it [22:30,  7.11it/s]\u001b[A\n",
            "9345it [22:30,  7.14it/s]\u001b[A\n",
            "9346it [22:30,  7.00it/s]\u001b[A\n",
            "9347it [22:30,  6.99it/s]\u001b[A\n",
            "9348it [22:30,  7.03it/s]\u001b[A\n",
            "9349it [22:30,  7.08it/s]\u001b[A\n",
            "9350it [22:30,  7.15it/s]\u001b[A\n",
            "9351it [22:31,  7.11it/s]\u001b[A\n",
            "9352it [22:31,  7.10it/s]\u001b[A\n",
            "9353it [22:31,  6.93it/s]\u001b[A\n",
            "9354it [22:31,  6.83it/s]\u001b[A\n",
            "9355it [22:31,  6.67it/s]\u001b[A\n",
            "9356it [22:31,  6.66it/s]\u001b[A\n",
            "9357it [22:31,  6.70it/s]\u001b[A\n",
            "9358it [22:32,  6.76it/s]\u001b[A\n",
            "9359it [22:32,  6.79it/s]\u001b[A\n",
            "9360it [22:32,  6.62it/s]\u001b[A\n",
            "9361it [22:32,  6.54it/s]\u001b[A\n",
            "9362it [22:32,  6.65it/s]\u001b[A\n",
            "9363it [22:32,  6.58it/s]\u001b[A\n",
            "9364it [22:33,  6.59it/s]\u001b[A\n",
            "9365it [22:33,  6.61it/s]\u001b[A\n",
            "9366it [22:33,  6.83it/s]\u001b[A\n",
            "9367it [22:33,  6.97it/s]\u001b[A\n",
            "9368it [22:33,  7.02it/s]\u001b[A\n",
            "9369it [22:33,  7.03it/s]\u001b[A\n",
            "9370it [22:33,  7.09it/s]\u001b[A\n",
            "9371it [22:34,  7.06it/s]\u001b[A\n",
            "9372it [22:34,  7.02it/s]\u001b[A\n",
            "9373it [22:34,  7.12it/s]\u001b[A\n",
            "9374it [22:34,  7.05it/s]\u001b[A\n",
            "9375it [22:34,  7.06it/s]\u001b[A\n",
            "9376it [22:34,  7.08it/s]\u001b[A\n",
            "9377it [22:34,  7.12it/s]\u001b[A\n",
            "9378it [22:35,  7.07it/s]\u001b[A\n",
            "9379it [22:35,  6.92it/s]\u001b[A\n",
            "9380it [22:35,  6.87it/s]\u001b[A\n",
            "9381it [22:35,  6.77it/s]\u001b[A\n",
            "9382it [22:35,  6.73it/s]\u001b[A\n",
            "9383it [22:35,  6.63it/s]\u001b[A\n",
            "9384it [22:35,  6.63it/s]\u001b[A\n",
            "9385it [22:36,  6.77it/s]\u001b[A\n",
            "9386it [22:36,  6.79it/s]\u001b[A\n",
            "9387it [22:36,  6.99it/s]\u001b[A\n",
            "9388it [22:36,  6.99it/s]\u001b[A\n",
            "9389it [22:36,  6.93it/s]\u001b[A\n",
            "9390it [22:36,  6.81it/s]\u001b[A\n",
            "9391it [22:36,  6.77it/s]\u001b[A\n",
            "9392it [22:37,  6.75it/s]\u001b[A\n",
            "9393it [22:37,  6.62it/s]\u001b[A\n",
            "9394it [22:37,  6.76it/s]\u001b[A\n",
            "9395it [22:37,  6.79it/s]\u001b[A\n",
            "9396it [22:37,  6.90it/s]\u001b[A\n",
            "9397it [22:37,  6.99it/s]\u001b[A\n",
            "9398it [22:37,  7.00it/s]\u001b[A\n",
            "9399it [22:38,  7.00it/s]\u001b[A\n",
            "9400it [22:38,  6.85it/s]\u001b[A\n",
            "9401it [22:38,  6.72it/s]\u001b[A\n",
            "9402it [22:38,  6.71it/s]\u001b[A\n",
            "9403it [22:38,  6.66it/s]\u001b[A\n",
            "9404it [22:38,  6.59it/s]\u001b[A\n",
            "9405it [22:39,  6.69it/s]\u001b[A\n",
            "9406it [22:39,  6.61it/s]\u001b[A\n",
            "9407it [22:39,  6.78it/s]\u001b[A\n",
            "9408it [22:39,  6.84it/s]\u001b[A\n",
            "9409it [22:39,  7.00it/s]\u001b[A\n",
            "9410it [22:39,  7.12it/s]\u001b[A\n",
            "9411it [22:39,  7.20it/s]\u001b[A\n",
            "9412it [22:39,  7.18it/s]\u001b[A\n",
            "9413it [22:40,  7.12it/s]\u001b[A\n",
            "9414it [22:40,  6.70it/s]\u001b[A\n",
            "9415it [22:40,  6.66it/s]\u001b[A\n",
            "9416it [22:40,  6.82it/s]\u001b[A\n",
            "9417it [22:40,  6.69it/s]\u001b[A\n",
            "9418it [22:40,  6.63it/s]\u001b[A\n",
            "9419it [22:41,  6.66it/s]\u001b[A\n",
            "9420it [22:41,  6.61it/s]\u001b[A\n",
            "9421it [22:41,  6.74it/s]\u001b[A\n",
            "9422it [22:41,  6.81it/s]\u001b[A\n",
            "9423it [22:41,  6.97it/s]\u001b[A\n",
            "9424it [22:41,  7.00it/s]\u001b[A\n",
            "9425it [22:41,  6.99it/s]\u001b[A\n",
            "9426it [22:42,  7.02it/s]\u001b[A\n",
            "9427it [22:42,  7.01it/s]\u001b[A\n",
            "9428it [22:42,  6.81it/s]\u001b[A\n",
            "9429it [22:42,  6.87it/s]\u001b[A\n",
            "9430it [22:42,  6.99it/s]\u001b[A\n",
            "9431it [22:42,  6.98it/s]\u001b[A\n",
            "9432it [22:42,  7.08it/s]\u001b[A\n",
            "9433it [22:43,  7.07it/s]\u001b[A\n",
            "9434it [22:43,  7.09it/s]\u001b[A\n",
            "9435it [22:43,  7.03it/s]\u001b[A\n",
            "9436it [22:43,  7.04it/s]\u001b[A\n",
            "9437it [22:43,  7.12it/s]\u001b[A\n",
            "9438it [22:43,  7.10it/s]\u001b[A\n",
            "9439it [22:43,  7.13it/s]\u001b[A\n",
            "9440it [22:44,  7.20it/s]\u001b[A\n",
            "9441it [22:44,  7.22it/s]\u001b[A\n",
            "9442it [22:44,  7.02it/s]\u001b[A\n",
            "9443it [22:44,  6.94it/s]\u001b[A\n",
            "9444it [22:44,  6.76it/s]\u001b[A\n",
            "9445it [22:44,  6.56it/s]\u001b[A\n",
            "9446it [22:44,  6.55it/s]\u001b[A\n",
            "9447it [22:45,  6.40it/s]\u001b[A\n",
            "9448it [22:45,  6.47it/s]\u001b[A\n",
            "9449it [22:45,  6.46it/s]\u001b[A\n",
            "9450it [22:45,  6.46it/s]\u001b[A\n",
            "9451it [22:45,  6.52it/s]\u001b[A\n",
            "9452it [22:45,  6.46it/s]\u001b[A\n",
            "9453it [22:46,  6.61it/s]\u001b[A\n",
            "9454it [22:46,  6.76it/s]\u001b[A\n",
            "9455it [22:46,  6.71it/s]\u001b[A\n",
            "9456it [22:46,  6.84it/s]\u001b[A\n",
            "9457it [22:46,  6.89it/s]\u001b[A\n",
            "9458it [22:46,  6.97it/s]\u001b[A\n",
            "9459it [22:46,  7.04it/s]\u001b[A\n",
            "9460it [22:47,  6.96it/s]\u001b[A\n",
            "9461it [22:47,  6.86it/s]\u001b[A\n",
            "9462it [22:47,  6.81it/s]\u001b[A\n",
            "9463it [22:47,  6.87it/s]\u001b[A\n",
            "9464it [22:47,  6.93it/s]\u001b[A\n",
            "9465it [22:47,  7.01it/s]\u001b[A\n",
            "9466it [22:47,  7.05it/s]\u001b[A\n",
            "9467it [22:48,  7.04it/s]\u001b[A\n",
            "9468it [22:48,  7.00it/s]\u001b[A\n",
            "9469it [22:48,  6.79it/s]\u001b[A\n",
            "9470it [22:48,  6.66it/s]\u001b[A\n",
            "9471it [22:48,  3.89it/s]\u001b[A\n",
            "9472it [22:49,  4.48it/s]\u001b[A\n",
            "9473it [22:49,  5.06it/s]\u001b[A\n",
            "9474it [22:49,  5.50it/s]\u001b[A\n",
            "9475it [22:49,  5.93it/s]\u001b[A\n",
            "9476it [22:49,  6.22it/s]\u001b[A\n",
            "9477it [22:49,  6.52it/s]\u001b[A\n",
            "9478it [22:49,  6.64it/s]\u001b[A\n",
            "9479it [22:50,  6.76it/s]\u001b[A\n",
            "9480it [22:50,  6.92it/s]\u001b[A\n",
            "9481it [22:50,  6.89it/s]\u001b[A\n",
            "9482it [22:50,  6.99it/s]\u001b[A\n",
            "9483it [22:50,  7.06it/s]\u001b[A\n",
            "9484it [22:50,  7.00it/s]\u001b[A\n",
            "9485it [22:50,  7.04it/s]\u001b[A\n",
            "9486it [22:51,  6.81it/s]\u001b[A\n",
            "9487it [22:51,  6.75it/s]\u001b[A\n",
            "9488it [22:51,  6.48it/s]\u001b[A\n",
            "9489it [22:51,  6.54it/s]\u001b[A\n",
            "9490it [22:51,  6.53it/s]\u001b[A\n",
            "9491it [22:51,  6.46it/s]\u001b[A\n",
            "9492it [22:52,  6.57it/s]\u001b[A\n",
            "9493it [22:52,  6.71it/s]\u001b[A\n",
            "9494it [22:52,  6.88it/s]\u001b[A\n",
            "9495it [22:52,  6.76it/s]\u001b[A\n",
            "9496it [22:52,  6.82it/s]\u001b[A\n",
            "9497it [22:52,  6.91it/s]\u001b[A\n",
            "9498it [22:52,  7.03it/s]\u001b[A\n",
            "9499it [22:53,  6.98it/s]\u001b[A\n",
            "9500it [22:53,  6.79it/s]\u001b[A\n",
            "9501it [22:53,  6.55it/s]\u001b[A\n",
            "9502it [22:53,  6.53it/s]\u001b[A\n",
            "9503it [22:53,  6.58it/s]\u001b[A\n",
            "9504it [22:53,  6.50it/s]\u001b[A\n",
            "9505it [22:53,  6.55it/s]\u001b[A\n",
            "9506it [22:54,  6.70it/s]\u001b[A\n",
            "9507it [22:54,  6.55it/s]\u001b[A\n",
            "9508it [22:54,  6.32it/s]\u001b[A\n",
            "9509it [22:54,  6.39it/s]\u001b[A\n",
            "9510it [22:54,  6.41it/s]\u001b[A\n",
            "9511it [22:54,  6.47it/s]\u001b[A\n",
            "9512it [22:55,  6.43it/s]\u001b[A\n",
            "9513it [22:55,  6.58it/s]\u001b[A\n",
            "9514it [22:55,  6.57it/s]\u001b[A\n",
            "9515it [22:55,  6.47it/s]\u001b[A\n",
            "9516it [22:55,  6.54it/s]\u001b[A\n",
            "9517it [22:55,  6.51it/s]\u001b[A\n",
            "9518it [22:55,  6.48it/s]\u001b[A\n",
            "9519it [22:56,  6.38it/s]\u001b[A\n",
            "9520it [22:56,  6.45it/s]\u001b[A\n",
            "9521it [22:56,  6.56it/s]\u001b[A\n",
            "9522it [22:56,  6.73it/s]\u001b[A\n",
            "9523it [22:56,  6.80it/s]\u001b[A\n",
            "9524it [22:56,  6.91it/s]\u001b[A\n",
            "9525it [22:57,  6.81it/s]\u001b[A\n",
            "9526it [22:57,  6.78it/s]\u001b[A\n",
            "9527it [22:57,  6.85it/s]\u001b[A\n",
            "9528it [22:57,  6.83it/s]\u001b[A\n",
            "9529it [22:57,  6.89it/s]\u001b[A\n",
            "9530it [22:57,  6.92it/s]\u001b[A\n",
            "9531it [22:57,  7.01it/s]\u001b[A\n",
            "9532it [22:58,  7.02it/s]\u001b[A\n",
            "9533it [22:58,  7.11it/s]\u001b[A\n",
            "9534it [22:58,  6.90it/s]\u001b[A\n",
            "9535it [22:58,  6.69it/s]\u001b[A\n",
            "9536it [22:58,  6.73it/s]\u001b[A\n",
            "9537it [22:58,  6.63it/s]\u001b[A\n",
            "9538it [22:58,  6.57it/s]\u001b[A\n",
            "9539it [22:59,  6.60it/s]\u001b[A\n",
            "9540it [22:59,  6.57it/s]\u001b[A\n",
            "9541it [22:59,  6.59it/s]\u001b[A\n",
            "9542it [22:59,  6.49it/s]\u001b[A\n",
            "9543it [22:59,  6.49it/s]\u001b[A\n",
            "9544it [22:59,  6.46it/s]\u001b[A\n",
            "9545it [22:59,  6.63it/s]\u001b[A\n",
            "9546it [23:00,  6.72it/s]\u001b[A\n",
            "9547it [23:00,  6.60it/s]\u001b[A\n",
            "9548it [23:00,  6.53it/s]\u001b[A\n",
            "9549it [23:00,  6.37it/s]\u001b[A\n",
            "9550it [23:00,  6.31it/s]\u001b[A\n",
            "9551it [23:00,  6.46it/s]\u001b[A\n",
            "9552it [23:01,  6.47it/s]\u001b[A\n",
            "9553it [23:01,  6.57it/s]\u001b[A\n",
            "9554it [23:01,  6.67it/s]\u001b[A\n",
            "9555it [23:01,  6.56it/s]\u001b[A\n",
            "9556it [23:01,  6.52it/s]\u001b[A\n",
            "9557it [23:01,  6.54it/s]\u001b[A\n",
            "9558it [23:01,  6.68it/s]\u001b[A\n",
            "9559it [23:02,  6.78it/s]\u001b[A\n",
            "9560it [23:02,  6.72it/s]\u001b[A\n",
            "9561it [23:02,  6.74it/s]\u001b[A\n",
            "9562it [23:02,  6.62it/s]\u001b[A\n",
            "9563it [23:02,  6.60it/s]\u001b[A\n",
            "9564it [23:02,  6.62it/s]\u001b[A\n",
            "9565it [23:03,  6.61it/s]\u001b[A\n",
            "9566it [23:03,  6.57it/s]\u001b[A\n",
            "9567it [23:03,  6.61it/s]\u001b[A\n",
            "9568it [23:03,  6.49it/s]\u001b[A\n",
            "9569it [23:03,  6.38it/s]\u001b[A\n",
            "9570it [23:03,  6.52it/s]\u001b[A\n",
            "9571it [23:03,  6.55it/s]\u001b[A\n",
            "9572it [23:04,  6.69it/s]\u001b[A\n",
            "9573it [23:04,  6.81it/s]\u001b[A\n",
            "9574it [23:04,  6.97it/s]\u001b[A\n",
            "9575it [23:04,  7.07it/s]\u001b[A\n",
            "9576it [23:04,  7.01it/s]\u001b[A\n",
            "9577it [23:04,  6.99it/s]\u001b[A\n",
            "9578it [23:04,  6.82it/s]\u001b[A\n",
            "9579it [23:05,  6.86it/s]\u001b[A\n",
            "9580it [23:05,  6.99it/s]\u001b[A\n",
            "9581it [23:05,  7.02it/s]\u001b[A\n",
            "9582it [23:05,  7.15it/s]\u001b[A\n",
            "9583it [23:05,  7.07it/s]\u001b[A\n",
            "9584it [23:05,  7.04it/s]\u001b[A\n",
            "9585it [23:05,  7.13it/s]\u001b[A\n",
            "9586it [23:06,  7.14it/s]\u001b[A\n",
            "9587it [23:06,  7.05it/s]\u001b[A\n",
            "9588it [23:06,  6.95it/s]\u001b[A\n",
            "9589it [23:06,  6.83it/s]\u001b[A\n",
            "9590it [23:06,  6.75it/s]\u001b[A\n",
            "9591it [23:06,  6.73it/s]\u001b[A\n",
            "9592it [23:06,  6.58it/s]\u001b[A\n",
            "9593it [23:07,  6.67it/s]\u001b[A\n",
            "9594it [23:07,  6.57it/s]\u001b[A\n",
            "9595it [23:07,  6.32it/s]\u001b[A\n",
            "9596it [23:07,  6.41it/s]\u001b[A\n",
            "9597it [23:07,  6.44it/s]\u001b[A\n",
            "9598it [23:07,  6.49it/s]\u001b[A\n",
            "9599it [23:08,  6.62it/s]\u001b[A\n",
            "9600it [23:08,  6.60it/s]\u001b[A\n",
            "9601it [23:08,  6.81it/s]\u001b[A\n",
            "9602it [23:08,  6.85it/s]\u001b[A\n",
            "9603it [23:08,  6.87it/s]\u001b[A\n",
            "9604it [23:08,  6.84it/s]\u001b[A\n",
            "9605it [23:08,  6.92it/s]\u001b[A\n",
            "9606it [23:09,  6.92it/s]\u001b[A\n",
            "9607it [23:09,  7.00it/s]\u001b[A\n",
            "9608it [23:09,  7.00it/s]\u001b[A\n",
            "9609it [23:09,  6.98it/s]\u001b[A\n",
            "9610it [23:09,  6.98it/s]\u001b[A\n",
            "9611it [23:09,  7.03it/s]\u001b[A\n",
            "9612it [23:09,  7.01it/s]\u001b[A\n",
            "9613it [23:10,  6.98it/s]\u001b[A\n",
            "9614it [23:10,  6.97it/s]\u001b[A\n",
            "9615it [23:10,  7.08it/s]\u001b[A\n",
            "9616it [23:10,  7.00it/s]\u001b[A\n",
            "9617it [23:10,  6.98it/s]\u001b[A\n",
            "9618it [23:10,  7.00it/s]\u001b[A\n",
            "9619it [23:10,  7.05it/s]\u001b[A\n",
            "9620it [23:11,  6.91it/s]\u001b[A\n",
            "9621it [23:11,  6.93it/s]\u001b[A\n",
            "9622it [23:11,  7.06it/s]\u001b[A\n",
            "9623it [23:11,  7.05it/s]\u001b[A\n",
            "9624it [23:11,  7.04it/s]\u001b[A\n",
            "9625it [23:11,  6.96it/s]\u001b[A\n",
            "9626it [23:11,  6.94it/s]\u001b[A\n",
            "9627it [23:12,  6.93it/s]\u001b[A\n",
            "9628it [23:12,  7.04it/s]\u001b[A\n",
            "9629it [23:12,  6.99it/s]\u001b[A\n",
            "9630it [23:12,  6.88it/s]\u001b[A\n",
            "9631it [23:12,  6.94it/s]\u001b[A\n",
            "9632it [23:12,  6.90it/s]\u001b[A\n",
            "9633it [23:12,  6.92it/s]\u001b[A\n",
            "9634it [23:13,  6.86it/s]\u001b[A\n",
            "9635it [23:13,  6.88it/s]\u001b[A\n",
            "9636it [23:13,  6.84it/s]\u001b[A\n",
            "9637it [23:13,  6.78it/s]\u001b[A\n",
            "9638it [23:13,  6.72it/s]\u001b[A\n",
            "9639it [23:13,  6.53it/s]\u001b[A\n",
            "9640it [23:13,  6.61it/s]\u001b[A\n",
            "9641it [23:14,  6.75it/s]\u001b[A\n",
            "9642it [23:14,  6.84it/s]\u001b[A\n",
            "9643it [23:14,  6.77it/s]\u001b[A\n",
            "9644it [23:14,  6.87it/s]\u001b[A\n",
            "9645it [23:14,  6.83it/s]\u001b[A\n",
            "9646it [23:14,  6.87it/s]\u001b[A\n",
            "9647it [23:14,  6.97it/s]\u001b[A\n",
            "9648it [23:15,  6.94it/s]\u001b[A\n",
            "9649it [23:15,  6.85it/s]\u001b[A\n",
            "9650it [23:15,  6.73it/s]\u001b[A\n",
            "9651it [23:15,  6.63it/s]\u001b[A\n",
            "9652it [23:15,  6.50it/s]\u001b[A\n",
            "9653it [23:15,  6.52it/s]\u001b[A\n",
            "9654it [23:16,  6.71it/s]\u001b[A\n",
            "9655it [23:16,  6.87it/s]\u001b[A\n",
            "9656it [23:16,  6.92it/s]\u001b[A\n",
            "9657it [23:16,  6.96it/s]\u001b[A\n",
            "9658it [23:16,  7.05it/s]\u001b[A\n",
            "9659it [23:16,  7.07it/s]\u001b[A\n",
            "9660it [23:16,  7.12it/s]\u001b[A\n",
            "9661it [23:17,  7.14it/s]\u001b[A\n",
            "9662it [23:17,  7.17it/s]\u001b[A\n",
            "9663it [23:17,  7.28it/s]\u001b[A\n",
            "9664it [23:17,  7.10it/s]\u001b[A\n",
            "9665it [23:17,  7.11it/s]\u001b[A\n",
            "9666it [23:17,  7.01it/s]\u001b[A\n",
            "9667it [23:17,  6.76it/s]\u001b[A\n",
            "9668it [23:18,  6.82it/s]\u001b[A\n",
            "9669it [23:18,  6.90it/s]\u001b[A\n",
            "9670it [23:18,  7.03it/s]\u001b[A\n",
            "9671it [23:18,  7.15it/s]\u001b[A\n",
            "9672it [23:18,  7.19it/s]\u001b[A\n",
            "9673it [23:18,  7.17it/s]\u001b[A\n",
            "9674it [23:18,  6.97it/s]\u001b[A\n",
            "9675it [23:19,  7.05it/s]\u001b[A\n",
            "9676it [23:19,  7.03it/s]\u001b[A\n",
            "9677it [23:19,  6.88it/s]\u001b[A\n",
            "9678it [23:19,  6.81it/s]\u001b[A\n",
            "9679it [23:19,  6.55it/s]\u001b[A\n",
            "9680it [23:19,  6.46it/s]\u001b[A\n",
            "9681it [23:19,  6.48it/s]\u001b[A\n",
            "9682it [23:20,  6.53it/s]\u001b[A\n",
            "9683it [23:20,  6.56it/s]\u001b[A\n",
            "9684it [23:20,  6.62it/s]\u001b[A\n",
            "9685it [23:20,  6.54it/s]\u001b[A\n",
            "9686it [23:20,  6.48it/s]\u001b[A\n",
            "9687it [23:20,  6.35it/s]\u001b[A\n",
            "9688it [23:21,  6.40it/s]\u001b[A\n",
            "9689it [23:21,  6.48it/s]\u001b[A\n",
            "9690it [23:21,  6.67it/s]\u001b[A\n",
            "9691it [23:21,  6.84it/s]\u001b[A\n",
            "9692it [23:21,  6.98it/s]\u001b[A\n",
            "9693it [23:21,  7.01it/s]\u001b[A\n",
            "9694it [23:21,  6.95it/s]\u001b[A\n",
            "9695it [23:22,  7.09it/s]\u001b[A\n",
            "9696it [23:22,  7.11it/s]\u001b[A\n",
            "9697it [23:22,  7.17it/s]\u001b[A\n",
            "9698it [23:22,  7.15it/s]\u001b[A\n",
            "9699it [23:22,  7.19it/s]\u001b[A\n",
            "9700it [23:22,  7.10it/s]\u001b[A\n",
            "9701it [23:22,  7.04it/s]\u001b[A\n",
            "9702it [23:23,  7.07it/s]\u001b[A\n",
            "9703it [23:23,  7.06it/s]\u001b[A\n",
            "9704it [23:23,  6.89it/s]\u001b[A\n",
            "9705it [23:23,  6.83it/s]\u001b[A\n",
            "9706it [23:23,  6.67it/s]\u001b[A\n",
            "9707it [23:23,  6.61it/s]\u001b[A\n",
            "9708it [23:23,  6.53it/s]\u001b[A\n",
            "9709it [23:24,  6.63it/s]\u001b[A\n",
            "9710it [23:24,  6.67it/s]\u001b[A\n",
            "9711it [23:24,  6.81it/s]\u001b[A\n",
            "9712it [23:24,  6.84it/s]\u001b[A\n",
            "9713it [23:24,  6.96it/s]\u001b[A\n",
            "9714it [23:24,  7.04it/s]\u001b[A\n",
            "9715it [23:24,  6.96it/s]\u001b[A\n",
            "9716it [23:25,  7.08it/s]\u001b[A\n",
            "9717it [23:25,  7.02it/s]\u001b[A\n",
            "9718it [23:25,  7.09it/s]\u001b[A\n",
            "9719it [23:25,  7.11it/s]\u001b[A\n",
            "9720it [23:25,  7.13it/s]\u001b[A\n",
            "9721it [23:25,  7.11it/s]\u001b[A\n",
            "9722it [23:25,  7.04it/s]\u001b[A\n",
            "9723it [23:26,  7.09it/s]\u001b[A\n",
            "9724it [23:26,  7.09it/s]\u001b[A\n",
            "9725it [23:26,  7.06it/s]\u001b[A\n",
            "9726it [23:26,  6.82it/s]\u001b[A\n",
            "9727it [23:26,  6.92it/s]\u001b[A\n",
            "9728it [23:26,  6.99it/s]\u001b[A\n",
            "9729it [23:26,  6.97it/s]\u001b[A\n",
            "9730it [23:27,  6.85it/s]\u001b[A\n",
            "9731it [23:27,  6.91it/s]\u001b[A\n",
            "9732it [23:27,  6.93it/s]\u001b[A\n",
            "9733it [23:27,  7.00it/s]\u001b[A\n",
            "9734it [23:27,  7.05it/s]\u001b[A\n",
            "9735it [23:27,  7.08it/s]\u001b[A\n",
            "9736it [23:27,  7.09it/s]\u001b[A\n",
            "9737it [23:28,  7.08it/s]\u001b[A\n",
            "9738it [23:28,  7.03it/s]\u001b[A\n",
            "9739it [23:28,  7.14it/s]\u001b[A\n",
            "9740it [23:28,  7.17it/s]\u001b[A\n",
            "9741it [23:28,  7.14it/s]\u001b[A\n",
            "9742it [23:28,  7.16it/s]\u001b[A\n",
            "9743it [23:28,  7.14it/s]\u001b[A\n",
            "9744it [23:29,  6.94it/s]\u001b[A\n",
            "9745it [23:29,  6.91it/s]\u001b[A\n",
            "9746it [23:29,  6.79it/s]\u001b[A\n",
            "9747it [23:29,  6.70it/s]\u001b[A\n",
            "9748it [23:29,  6.81it/s]\u001b[A\n",
            "9749it [23:29,  6.98it/s]\u001b[A\n",
            "9750it [23:29,  7.02it/s]\u001b[A\n",
            "9751it [23:30,  6.94it/s]\u001b[A\n",
            "9752it [23:30,  7.02it/s]\u001b[A\n",
            "9753it [23:30,  6.92it/s]\u001b[A\n",
            "9754it [23:30,  6.73it/s]\u001b[A\n",
            "9755it [23:30,  6.63it/s]\u001b[A\n",
            "9756it [23:30,  6.46it/s]\u001b[A\n",
            "9757it [23:30,  6.41it/s]\u001b[A\n",
            "9758it [23:31,  6.58it/s]\u001b[A\n",
            "9759it [23:31,  6.78it/s]\u001b[A\n",
            "9760it [23:31,  6.66it/s]\u001b[A\n",
            "9761it [23:31,  6.66it/s]\u001b[A\n",
            "9762it [23:31,  6.68it/s]\u001b[A\n",
            "9763it [23:31,  6.64it/s]\u001b[A\n",
            "9764it [23:32,  6.58it/s]\u001b[A\n",
            "9765it [23:32,  6.66it/s]\u001b[A\n",
            "9766it [23:32,  6.69it/s]\u001b[A\n",
            "9767it [23:32,  6.63it/s]\u001b[A\n",
            "9768it [23:32,  6.61it/s]\u001b[A\n",
            "9769it [23:32,  6.60it/s]\u001b[A\n",
            "9770it [23:32,  6.65it/s]\u001b[A\n",
            "9771it [23:33,  6.58it/s]\u001b[A\n",
            "9772it [23:33,  6.65it/s]\u001b[A\n",
            "9773it [23:33,  6.77it/s]\u001b[A\n",
            "9774it [23:33,  6.80it/s]\u001b[A\n",
            "9775it [23:33,  6.90it/s]\u001b[A\n",
            "9776it [23:33,  6.96it/s]\u001b[A\n",
            "9777it [23:33,  6.91it/s]\u001b[A\n",
            "9778it [23:34,  6.95it/s]\u001b[A\n",
            "9779it [23:34,  7.02it/s]\u001b[A\n",
            "9780it [23:34,  7.06it/s]\u001b[A\n",
            "9781it [23:34,  7.09it/s]\u001b[A\n",
            "9782it [23:34,  7.14it/s]\u001b[A\n",
            "9783it [23:34,  7.16it/s]\u001b[A\n",
            "9784it [23:34,  7.24it/s]\u001b[A\n",
            "9785it [23:35,  6.89it/s]\u001b[A\n",
            "9786it [23:35,  6.94it/s]\u001b[A\n",
            "9787it [23:35,  7.00it/s]\u001b[A\n",
            "9788it [23:35,  7.05it/s]\u001b[A\n",
            "9789it [23:35,  7.05it/s]\u001b[A\n",
            "9790it [23:35,  6.91it/s]\u001b[A\n",
            "9791it [23:35,  6.89it/s]\u001b[A\n",
            "9792it [23:36,  6.84it/s]\u001b[A\n",
            "9793it [23:36,  6.93it/s]\u001b[A\n",
            "9794it [23:36,  6.81it/s]\u001b[A\n",
            "9795it [23:36,  6.72it/s]\u001b[A\n",
            "9796it [23:36,  6.69it/s]\u001b[A\n",
            "9797it [23:36,  6.72it/s]\u001b[A\n",
            "9798it [23:36,  6.68it/s]\u001b[A\n",
            "9799it [23:37,  6.58it/s]\u001b[A\n",
            "9800it [23:37,  6.75it/s]\u001b[A\n",
            "9801it [23:37,  6.88it/s]\u001b[A\n",
            "9802it [23:37,  6.97it/s]\u001b[A\n",
            "9803it [23:37,  7.01it/s]\u001b[A\n",
            "9804it [23:37,  7.16it/s]\u001b[A\n",
            "9805it [23:37,  7.22it/s]\u001b[A\n",
            "9806it [23:38,  7.12it/s]\u001b[A\n",
            "9807it [23:38,  7.17it/s]\u001b[A\n",
            "9808it [23:38,  7.19it/s]\u001b[A\n",
            "9809it [23:38,  7.16it/s]\u001b[A\n",
            "9810it [23:38,  7.16it/s]\u001b[A\n",
            "9811it [23:38,  7.11it/s]\u001b[A\n",
            "9812it [23:38,  7.06it/s]\u001b[A\n",
            "9813it [23:39,  6.92it/s]\u001b[A\n",
            "9814it [23:39,  7.01it/s]\u001b[A\n",
            "9815it [23:39,  7.07it/s]\u001b[A\n",
            "9816it [23:39,  7.07it/s]\u001b[A\n",
            "9817it [23:39,  7.06it/s]\u001b[A\n",
            "9818it [23:39,  7.05it/s]\u001b[A\n",
            "9819it [23:39,  7.13it/s]\u001b[A\n",
            "9820it [23:40,  7.08it/s]\u001b[A\n",
            "9821it [23:40,  7.13it/s]\u001b[A\n",
            "9822it [23:40,  7.09it/s]\u001b[A\n",
            "9823it [23:40,  7.05it/s]\u001b[A\n",
            "9824it [23:40,  7.09it/s]\u001b[A\n",
            "9825it [23:40,  7.10it/s]\u001b[A\n",
            "9826it [23:40,  7.08it/s]\u001b[A\n",
            "9827it [23:41,  6.98it/s]\u001b[A\n",
            "9828it [23:41,  6.75it/s]\u001b[A\n",
            "9829it [23:41,  6.67it/s]\u001b[A\n",
            "9830it [23:41,  6.70it/s]\u001b[A\n",
            "9831it [23:41,  6.75it/s]\u001b[A\n",
            "9832it [23:41,  6.59it/s]\u001b[A\n",
            "9833it [23:41,  6.62it/s]\u001b[A\n",
            "9834it [23:42,  6.75it/s]\u001b[A\n",
            "9835it [23:42,  6.89it/s]\u001b[A\n",
            "9836it [23:42,  6.98it/s]\u001b[A\n",
            "9837it [23:42,  7.00it/s]\u001b[A\n",
            "9838it [23:42,  7.07it/s]\u001b[A\n",
            "9839it [23:42,  7.17it/s]\u001b[A\n",
            "9840it [23:42,  7.04it/s]\u001b[A\n",
            "9841it [23:43,  6.84it/s]\u001b[A\n",
            "9842it [23:43,  6.73it/s]\u001b[A\n",
            "9843it [23:43,  6.71it/s]\u001b[A\n",
            "9844it [23:43,  6.65it/s]\u001b[A\n",
            "9845it [23:43,  6.73it/s]\u001b[A\n",
            "9846it [23:43,  6.69it/s]\u001b[A\n",
            "9847it [23:44,  6.70it/s]\u001b[A\n",
            "9848it [23:44,  6.78it/s]\u001b[A\n",
            "9849it [23:44,  6.87it/s]\u001b[A\n",
            "9850it [23:44,  6.91it/s]\u001b[A\n",
            "9851it [23:44,  7.04it/s]\u001b[A\n",
            "9852it [23:44,  7.01it/s]\u001b[A\n",
            "9853it [23:44,  6.94it/s]\u001b[A\n",
            "9854it [23:45,  6.74it/s]\u001b[A\n",
            "9855it [23:45,  6.67it/s]\u001b[A\n",
            "9856it [23:45,  6.63it/s]\u001b[A\n",
            "9857it [23:45,  6.58it/s]\u001b[A\n",
            "9858it [23:45,  6.69it/s]\u001b[A\n",
            "9859it [23:45,  6.79it/s]\u001b[A\n",
            "9860it [23:45,  6.94it/s]\u001b[A\n",
            "9861it [23:46,  6.88it/s]\u001b[A\n",
            "9862it [23:46,  6.84it/s]\u001b[A\n",
            "9863it [23:46,  6.98it/s]\u001b[A\n",
            "9864it [23:46,  6.97it/s]\u001b[A\n",
            "9865it [23:46,  6.93it/s]\u001b[A\n",
            "9866it [23:46,  6.96it/s]\u001b[A\n",
            "9867it [23:46,  7.00it/s]\u001b[A\n",
            "9868it [23:47,  6.92it/s]\u001b[A\n",
            "9869it [23:47,  6.86it/s]\u001b[A\n",
            "9870it [23:47,  6.91it/s]\u001b[A\n",
            "9871it [23:47,  6.98it/s]\u001b[A\n",
            "9872it [23:47,  6.95it/s]\u001b[A\n",
            "9873it [23:47,  6.97it/s]\u001b[A\n",
            "9874it [23:47,  6.98it/s]\u001b[A\n",
            "9875it [23:48,  7.07it/s]\u001b[A\n",
            "9876it [23:48,  6.92it/s]\u001b[A\n",
            "9877it [23:48,  6.78it/s]\u001b[A\n",
            "9878it [23:48,  6.69it/s]\u001b[A\n",
            "9879it [23:48,  6.64it/s]\u001b[A\n",
            "9880it [23:48,  6.60it/s]\u001b[A\n",
            "9881it [23:49,  6.50it/s]\u001b[A\n",
            "9882it [23:49,  6.60it/s]\u001b[A\n",
            "9883it [23:49,  6.56it/s]\u001b[A\n",
            "9884it [23:49,  6.58it/s]\u001b[A\n",
            "9885it [23:49,  6.49it/s]\u001b[A\n",
            "9886it [23:49,  6.47it/s]\u001b[A\n",
            "9887it [23:49,  6.43it/s]\u001b[A\n",
            "9888it [23:50,  6.54it/s]\u001b[A\n",
            "9889it [23:50,  6.55it/s]\u001b[A\n",
            "9890it [23:50,  6.69it/s]\u001b[A\n",
            "9891it [23:50,  6.79it/s]\u001b[A\n",
            "9892it [23:50,  6.88it/s]\u001b[A\n",
            "9893it [23:50,  6.86it/s]\u001b[A\n",
            "9894it [23:50,  7.01it/s]\u001b[A\n",
            "9895it [23:51,  6.86it/s]\u001b[A\n",
            "9896it [23:51,  6.70it/s]\u001b[A\n",
            "9897it [23:51,  6.63it/s]\u001b[A\n",
            "9898it [23:51,  6.62it/s]\u001b[A\n",
            "9899it [23:51,  6.68it/s]\u001b[A\n",
            "9900it [23:51,  6.82it/s]\u001b[A\n",
            "9901it [23:51,  6.78it/s]\u001b[A\n",
            "9902it [23:52,  6.84it/s]\u001b[A\n",
            "9903it [23:52,  6.86it/s]\u001b[A\n",
            "9904it [23:52,  6.96it/s]\u001b[A\n",
            "9905it [23:52,  7.10it/s]\u001b[A\n",
            "9906it [23:52,  7.17it/s]\u001b[A\n",
            "9907it [23:52,  7.19it/s]\u001b[A\n",
            "9908it [23:52,  7.22it/s]\u001b[A\n",
            "9909it [23:53,  7.12it/s]\u001b[A\n",
            "9910it [23:53,  6.94it/s]\u001b[A\n",
            "9911it [23:53,  6.85it/s]\u001b[A\n",
            "9912it [23:53,  6.81it/s]\u001b[A\n",
            "9913it [23:53,  6.80it/s]\u001b[A\n",
            "9914it [23:53,  6.57it/s]\u001b[A\n",
            "9915it [23:54,  6.66it/s]\u001b[A\n",
            "9916it [23:54,  6.81it/s]\u001b[A\n",
            "9917it [23:54,  6.84it/s]\u001b[A\n",
            "9918it [23:54,  6.91it/s]\u001b[A\n",
            "9919it [23:54,  7.03it/s]\u001b[A\n",
            "9920it [23:54,  7.19it/s]\u001b[A\n",
            "9921it [23:54,  7.23it/s]\u001b[A\n",
            "9922it [23:54,  7.21it/s]\u001b[A\n",
            "9923it [23:55,  7.20it/s]\u001b[A\n",
            "9924it [23:55,  7.22it/s]\u001b[A\n",
            "9925it [23:55,  7.09it/s]\u001b[A\n",
            "9926it [23:55,  6.85it/s]\u001b[A\n",
            "9927it [23:55,  6.93it/s]\u001b[A\n",
            "9928it [23:55,  6.89it/s]\u001b[A\n",
            "9929it [23:56,  6.88it/s]\u001b[A\n",
            "9930it [23:56,  6.79it/s]\u001b[A\n",
            "9931it [23:56,  6.82it/s]\u001b[A\n",
            "9932it [23:56,  6.83it/s]\u001b[A\n",
            "9933it [23:56,  6.92it/s]\u001b[A\n",
            "9934it [23:56,  7.00it/s]\u001b[A\n",
            "9935it [23:56,  7.06it/s]\u001b[A\n",
            "9936it [23:57,  7.11it/s]\u001b[A\n",
            "9937it [23:57,  6.95it/s]\u001b[A\n",
            "9938it [23:57,  6.94it/s]\u001b[A\n",
            "9939it [23:57,  6.73it/s]\u001b[A\n",
            "9940it [23:57,  6.74it/s]\u001b[A\n",
            "9941it [23:57,  6.65it/s]\u001b[A\n",
            "9942it [23:57,  6.62it/s]\u001b[A\n",
            "9943it [23:58,  6.73it/s]\u001b[A\n",
            "9944it [23:58,  6.78it/s]\u001b[A\n",
            "9945it [23:58,  6.92it/s]\u001b[A\n",
            "9946it [23:58,  6.83it/s]\u001b[A\n",
            "9947it [23:58,  6.94it/s]\u001b[A\n",
            "9948it [23:58,  7.06it/s]\u001b[A\n",
            "9949it [23:58,  7.11it/s]\u001b[A\n",
            "9950it [23:59,  7.09it/s]\u001b[A\n",
            "9951it [23:59,  7.15it/s]\u001b[A\n",
            "9952it [23:59,  6.82it/s]\u001b[A\n",
            "9953it [23:59,  6.63it/s]\u001b[A\n",
            "9954it [23:59,  6.86it/s]\u001b[A\n",
            "9955it [23:59,  6.86it/s]\u001b[A\n",
            "9956it [23:59,  6.98it/s]\u001b[A\n",
            "9957it [24:00,  7.05it/s]\u001b[A\n",
            "9958it [24:00,  7.12it/s]\u001b[A\n",
            "9959it [24:00,  7.14it/s]\u001b[A\n",
            "9960it [24:00,  7.08it/s]\u001b[A\n",
            "9961it [24:00,  7.07it/s]\u001b[A\n",
            "9962it [24:00,  7.06it/s]\u001b[A\n",
            "9963it [24:00,  6.76it/s]\u001b[A\n",
            "9964it [24:01,  6.61it/s]\u001b[A\n",
            "9965it [24:01,  6.72it/s]\u001b[A\n",
            "9966it [24:01,  6.74it/s]\u001b[A\n",
            "9967it [24:01,  6.72it/s]\u001b[A\n",
            "9968it [24:01,  6.63it/s]\u001b[A\n",
            "9969it [24:01,  6.72it/s]\u001b[A\n",
            "9970it [24:01,  6.81it/s]\u001b[A\n",
            "9971it [24:02,  6.92it/s]\u001b[A\n",
            "9972it [24:02,  7.03it/s]\u001b[A\n",
            "9973it [24:02,  7.01it/s]\u001b[A\n",
            "9974it [24:02,  6.97it/s]\u001b[A\n",
            "9975it [24:02,  7.06it/s]\u001b[A\n",
            "9976it [24:02,  7.07it/s]\u001b[A\n",
            "9977it [24:02,  7.07it/s]\u001b[A\n",
            "9978it [24:03,  7.05it/s]\u001b[A\n",
            "9979it [24:03,  6.97it/s]\u001b[A\n",
            "9980it [24:03,  7.00it/s]\u001b[A\n",
            "9981it [24:03,  6.85it/s]\u001b[A\n",
            "9982it [24:03,  6.92it/s]\u001b[A\n",
            "9983it [24:03,  6.94it/s]\u001b[A\n",
            "9984it [24:03,  7.05it/s]\u001b[A\n",
            "9985it [24:04,  7.11it/s]\u001b[A\n",
            "9986it [24:04,  7.15it/s]\u001b[A\n",
            "9987it [24:04,  7.18it/s]\u001b[A\n",
            "9988it [24:04,  7.15it/s]\u001b[A\n",
            "9989it [24:04,  7.27it/s]\u001b[A\n",
            "9990it [24:04,  7.11it/s]\u001b[A\n",
            "9991it [24:04,  7.15it/s]\u001b[A\n",
            "9992it [24:05,  6.97it/s]\u001b[A\n",
            "9993it [24:05,  7.06it/s]\u001b[A\n",
            "9994it [24:05,  7.15it/s]\u001b[A\n",
            "9995it [24:05,  7.06it/s]\u001b[A\n",
            "9996it [24:05,  7.09it/s]\u001b[A\n",
            "9997it [24:05,  7.10it/s]\u001b[A\n",
            "9998it [24:05,  6.92it/s]\u001b[A\n",
            "9999it [24:06,  6.99it/s]\u001b[A\n",
            "10000it [24:06,  6.91it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhRlBHslYhSG"
      },
      "source": [
        "pickle_out = open(\"sm_all_wt_3an.pickle\",\"wb\")\n",
        "pickle.dump(max_sm_all_wt_3an, pickle_out)\n",
        "pickle_out.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ov0IPFNIYhSH"
      },
      "source": [
        "pickle_in = open(\"sm_all_wt_3an.pickle\",\"rb\")\n",
        "max_sm_all_wt_3an = pickle.load(pickle_in)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLuE6sQTKf4f",
        "outputId": "bdb9ddd6-6dc0-4408-dd24-39e9a8f63f69"
      },
      "source": [
        "for data, lbl, p, a_l, e_ in max_sm_all_wt_3an:\n",
        "  print(p, lbl, a_l)\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[7, 7, 7, 7, 7, 7, 9, 7, 7] 1 7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pf37Pl7cYhSH",
        "outputId": "3cdf1438-4ede-4a64-d1ef-765cc5a2ae69"
      },
      "source": [
        "accuracy = 0.0\n",
        "count_in = 0\n",
        "count_ood = 0\n",
        "acc_in = 0.0\n",
        "acc_ood = 0.0\n",
        "tp = 0.0\n",
        "tn = 0.0\n",
        "fp = 0.0\n",
        "fn = 0.0\n",
        "y_true = []\n",
        "y_pred = []\n",
        "sim_score = []\n",
        "sim_score_ = []\n",
        "\n",
        "for data, lbl, p, a_l, e_ in max_sm_all_wt_3an:\n",
        "\n",
        "  score = 0.0\n",
        "  for d in data:\n",
        "    score = score + d\n",
        "  score = score / len(data)\n",
        "  sim_score.append(score)\n",
        "\n",
        "  dist_ood = np.linalg.norm(np.array(data) - np.array(ref_vect_out_3an[0])) \n",
        "  dist_in = np.linalg.norm(np.array(data) - np.array(ref_vect_in_3an[0]))\n",
        "\n",
        "  dist_ood2 = np.linalg.norm(np.array(e_) - np.array(entropy_out_3an[0])) \n",
        "  dist_in2 = np.linalg.norm(np.array(e_) - np.array(entropy_in_3an[0]))\n",
        "\n",
        "  dist_in = dist_in / (dist_in + dist_ood)\n",
        "  dist_ood = dist_ood / (dist_in + dist_ood)\n",
        "\n",
        "  dist_in2 = dist_in2 / (dist_in2 + dist_ood2)\n",
        "  dist_ood2 = dist_ood2 / (dist_in2 + dist_ood2)\n",
        "\n",
        "  sim_in = 1 / (1 + dist_in)\n",
        "  sim_ood = 1 / (1 + dist_ood)\n",
        "\n",
        "  sim_in2 = 1 / (1 + dist_in2)\n",
        "  sim_ood2 = 1 / (1 + dist_ood2)\n",
        "\n",
        "  sim_in = sim_in + sim_in2\n",
        "#  sim_ood = sim_ood + sim_ood2\n",
        "\n",
        "  sim_score_.append(sim_ood)\n",
        "\n",
        "  values, counts = np.unique(p, return_counts=True)\n",
        "#  print(values, counts)\n",
        "  #print(sim_in, sim_ood, lbl, e_)\n",
        "\n",
        "\n",
        "  if sim_in >= sim_ood:\n",
        "    y_ = ind    \n",
        "    if np.max(counts) >= 8:\n",
        "      y_ = ind\n",
        "    else:\n",
        "      y_ = ood\n",
        "  else:\n",
        "    y_ = ood\n",
        "\n",
        "\n",
        "  y_pred.append(y_)\n",
        "  if lbl == 1:\n",
        "    y_true.append(0)\n",
        "  else:\n",
        "    y_true.append(1)\n",
        "#  y_true.append(lbl)\n",
        "\n",
        "\n",
        "  if lbl == ind:\n",
        "    count_in = count_in + 1\n",
        "  else:\n",
        "    count_ood = count_ood + 1\n",
        "\n",
        "  if y_ == lbl:\n",
        "    #sim_score_.append(1)\n",
        "    accuracy = accuracy + 1\n",
        "    if y_ == ind:\n",
        "      acc_in = acc_in + 1\n",
        "      tp = tp + 1\n",
        "    else:\n",
        "      acc_ood = acc_ood + 1\n",
        "      tn = tn + 1\n",
        "  else:\n",
        "    #sim_score_.append(0)\n",
        "    if y_ == ind:\n",
        "      fp = fp + 1\n",
        "    else:\n",
        "      fn = fn + 1\n",
        "\n",
        "\n",
        "print(\"Total Accuracy: \", accuracy/len(max_sm_all_wt_3an)) \n",
        "print(\"Accuracy of determining ID data: \", acc_in/count_in)\n",
        "print(\"Accuracy of determining OOD data: \", acc_ood/count_ood)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Accuracy:  0.9252\n",
            "Accuracy of determining ID data:  0.9407119021134595\n",
            "Accuracy of determining OOD data:  0.7871287128712872\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v4D2ebV7YhSH",
        "outputId": "f6b251a8-7abd-45cd-b7d7-7be4eb7e59e5"
      },
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "roc_auc_score(y_true, sim_score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9341258163636164"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-gM0goBYhSH",
        "outputId": "a36a2fcb-de97-4cbd-c8fa-a048b02d1830"
      },
      "source": [
        "roc_auc_score(y_true, y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8945252701020937"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oSU_Ls2eYhSI",
        "outputId": "2ecb484b-517b-46c1-f5a8-e4d6398727f0"
      },
      "source": [
        "roc_auc_score(y_true, sim_score_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8732751462020506"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 209
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AG6TujRh9rdY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWUZh-rpilra"
      },
      "source": [
        "# 4 as anomaly"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "994CV1LJitBO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKWI-6MYi9jo"
      },
      "source": [
        "new_train_images, new_train_labels, new_val_images, new_val_labels = separate_class(4, train_images, train_labels, val_images, val_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVywcw0di9j6"
      },
      "source": [
        "model0 = Model(name='4anomaly:classifier0')\n",
        "model1 = Model(name='4anomaly:classifier1')\n",
        "model2 = Model(name='4anomaly:classifier2')\n",
        "model3 = Model(name='4anomaly:classifier3')\n",
        "model4 = Model(name='4anomaly:classifier4')\n",
        "model5 = Model(name='4anomaly:classifier5')\n",
        "model6 = Model(name='4anomaly:classifier6')\n",
        "model7 = Model(name='4anomaly:classifier7')\n",
        "model8 = Model(name='4anomaly:classifier8')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tL_SSgKXi9j7"
      },
      "source": [
        "class_0 = model0.build()\n",
        "class_1 = model1.build()\n",
        "class_2 = model2.build()\n",
        "class_3 = model3.build()\n",
        "class_4 = model4.build()\n",
        "class_5 = model5.build()\n",
        "class_6 = model6.build()\n",
        "class_7 = model7.build()\n",
        "class_8 = model8.build()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PQwqlY5Zi9j8",
        "outputId": "f45893de-99e5-4255-fcea-386eb537639c"
      },
      "source": [
        "train_imgs0, train_lbls0 = get_train_data(0, new_train_images, new_train_labels)\n",
        "val_imgs0, val_lbls0 = get_train_data(0, new_val_images, new_val_labels)\n",
        "class_0 = model0.build()\n",
        "model0.train2(train_imgs0, train_lbls0, val_imgs0, val_lbls0)\n",
        "#model0.train(train_data0)\n",
        "model0.save_model(\"final_models/4anomaly-classifier0\")\n",
        "print('Model 0 saved')\n",
        "\n",
        "train_imgs1, train_lbls1 = get_train_data(1, new_train_images, new_train_labels)\n",
        "val_imgs1, val_lbls1 = get_train_data(1, new_val_images, new_val_labels)\n",
        "class_1 = model1.build()\n",
        "model1.train2(train_imgs1, train_lbls1, val_imgs1, val_lbls1)\n",
        "#model1.train(train_data1)\n",
        "model1.save_model(\"final_models/4anomaly-classifier1\")\n",
        "print('Model 1 saved')\n",
        "\n",
        "#train_data2 = get_train_data(2, new_train_images)\n",
        "train_imgs2, train_lbls2 = get_train_data(2, new_train_images, new_train_labels)\n",
        "val_imgs2, val_lbls2 = get_train_data(2, new_val_images, new_val_labels)\n",
        "class_2 = model2.build()\n",
        "model2.train2(train_imgs2, train_lbls2, val_imgs2, val_lbls2)\n",
        "#model2.train(train_data2)\n",
        "model2.save_model(\"final_models/4anomaly-classifier2\")\n",
        "print('Model 2 saved')\n",
        "\n",
        "#train_data3 = get_train_data(3, new_train_images)\n",
        "train_imgs3, train_lbls3 = get_train_data(3, new_train_images, new_train_labels)\n",
        "val_imgs3, val_lbls3 = get_train_data(3, new_val_images, new_val_labels)\n",
        "class_3 = model3.build()\n",
        "model3.train2(train_imgs3, train_lbls3, val_imgs3, val_lbls3)\n",
        "#model3.train(train_data3)\n",
        "model3.save_model(\"final_models/4anomaly-classifier3\")\n",
        "print('Model 3 saved')\n",
        "\n",
        "#train_data4 = get_train_data(4, new_train_images)\n",
        "train_imgs4, train_lbls4 = get_train_data(5, new_train_images, new_train_labels)\n",
        "val_imgs4, val_lbls4 = get_train_data(5, new_val_images, new_val_labels)\n",
        "class_4 = model4.build()\n",
        "model4.train2(train_imgs4, train_lbls4, val_imgs4, val_lbls4)\n",
        "#model4.train(train_data4)\n",
        "model4.save_model(\"final_models/4anomaly-classifier4\")\n",
        "print('Model 4 saved')\n",
        "\n",
        "#train_data5 = get_train_data(5, new_train_images)\n",
        "train_imgs5, train_lbls5 = get_train_data(6, new_train_images, new_train_labels)\n",
        "val_imgs5, val_lbls5 = get_train_data(6, new_val_images, new_val_labels)\n",
        "class_5 = model5.build()\n",
        "model5.train2(train_imgs5, train_lbls5, val_imgs5, val_lbls5)\n",
        "#model5.train(train_data5)\n",
        "model5.save_model(\"final_models/4anomaly-classifier5\")\n",
        "print('Model 5 saved')\n",
        "\n",
        "#train_data6 = get_train_data(6, new_train_images)\n",
        "train_imgs6, train_lbls6 = get_train_data(7, new_train_images, new_train_labels)\n",
        "val_imgs6, val_lbls6 = get_train_data(7, new_val_images, new_val_labels)\n",
        "class_6 = model6.build()\n",
        "model6.train2(train_imgs6, train_lbls6, val_imgs6, val_lbls6)\n",
        "#model6.train(train_data6)\n",
        "model6.save_model(\"final_models/4anomaly-classifier6\")\n",
        "print('Model 6 saved')\n",
        "\n",
        "#train_data7 = get_train_data(7, new_train_images)\n",
        "train_imgs7, train_lbls7 = get_train_data(8, new_train_images, new_train_labels)\n",
        "val_imgs7, val_lbls7 = get_train_data(8, new_val_images, new_val_labels)\n",
        "class_7 = model7.build()\n",
        "#model7.train(train_data7)\n",
        "model7.train2(train_imgs7, train_lbls7, val_imgs7, val_lbls7)\n",
        "model7.save_model(\"final_models/4anomaly-classifier7\")\n",
        "print('Model 7 saved')\n",
        "\n",
        "#train_data8 = get_train_data(8, new_train_images)\n",
        "train_imgs8, train_lbls8 = get_train_data(9, new_train_images, new_train_labels)\n",
        "val_imgs8, val_lbls8 = get_train_data(9, new_val_images, new_val_labels)\n",
        "class_8 = model8.build()\n",
        "#model8.train(train_data8)\n",
        "model8.train2(train_imgs8, train_lbls8, val_imgs8, val_lbls8)\n",
        "model8.save_model(\"final_models/4anomaly-classifier8\")\n",
        "print('Model 8 saved')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{1: 0, 2: 1, 3: 2, 5: 3, 6: 4, 7: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(38586,)\n",
            "{1: 0, 2: 1, 3: 2, 5: 3, 6: 4, 7: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9649,)\n",
            "Epoch 1/20\n",
            "1206/1206 [==============================] - 39s 31ms/step - loss: 6.1452 - accuracy: 0.8297 - val_loss: 0.2764 - val_accuracy: 0.9518\n",
            "Epoch 2/20\n",
            "1206/1206 [==============================] - 38s 32ms/step - loss: 0.1667 - accuracy: 0.9666 - val_loss: 0.1649 - val_accuracy: 0.9626\n",
            "Epoch 3/20\n",
            "1206/1206 [==============================] - 39s 32ms/step - loss: 0.0720 - accuracy: 0.9792 - val_loss: 0.1293 - val_accuracy: 0.9620\n",
            "Epoch 4/20\n",
            "1206/1206 [==============================] - 38s 32ms/step - loss: 0.0554 - accuracy: 0.9839 - val_loss: 0.1428 - val_accuracy: 0.9645\n",
            "Epoch 5/20\n",
            "1206/1206 [==============================] - 39s 32ms/step - loss: 0.0510 - accuracy: 0.9848 - val_loss: 0.1995 - val_accuracy: 0.9412\n",
            "Epoch 6/20\n",
            "1206/1206 [==============================] - 39s 32ms/step - loss: 0.0483 - accuracy: 0.9848 - val_loss: 0.3544 - val_accuracy: 0.9081\n",
            "Epoch 7/20\n",
            "1206/1206 [==============================] - 39s 32ms/step - loss: 0.0481 - accuracy: 0.9849 - val_loss: 0.1185 - val_accuracy: 0.9716\n",
            "Epoch 8/20\n",
            "1206/1206 [==============================] - 39s 32ms/step - loss: 0.0387 - accuracy: 0.9881 - val_loss: 0.1688 - val_accuracy: 0.9620\n",
            "Epoch 9/20\n",
            "1206/1206 [==============================] - 39s 32ms/step - loss: 0.0359 - accuracy: 0.9889 - val_loss: 0.1592 - val_accuracy: 0.9588\n",
            "Epoch 10/20\n",
            "1206/1206 [==============================] - 39s 32ms/step - loss: 0.0375 - accuracy: 0.9886 - val_loss: 0.1217 - val_accuracy: 0.9708\n",
            "Epoch 11/20\n",
            "1206/1206 [==============================] - 39s 32ms/step - loss: 0.0375 - accuracy: 0.9876 - val_loss: 0.1190 - val_accuracy: 0.9728\n",
            "Epoch 12/20\n",
            "1206/1206 [==============================] - 39s 32ms/step - loss: 0.0272 - accuracy: 0.9915 - val_loss: 0.0654 - val_accuracy: 0.9844\n",
            "Epoch 13/20\n",
            "1206/1206 [==============================] - 39s 32ms/step - loss: 0.0279 - accuracy: 0.9912 - val_loss: 0.1323 - val_accuracy: 0.9688\n",
            "Epoch 14/20\n",
            "1206/1206 [==============================] - 39s 32ms/step - loss: 0.0198 - accuracy: 0.9930 - val_loss: 0.1214 - val_accuracy: 0.9742\n",
            "Epoch 15/20\n",
            "1206/1206 [==============================] - 39s 32ms/step - loss: 0.0205 - accuracy: 0.9927 - val_loss: 0.1208 - val_accuracy: 0.9765\n",
            "Epoch 16/20\n",
            "1206/1206 [==============================] - 39s 32ms/step - loss: 0.0172 - accuracy: 0.9944 - val_loss: 0.0827 - val_accuracy: 0.9819\n",
            "Epoch 17/20\n",
            "1206/1206 [==============================] - 38s 32ms/step - loss: 0.0235 - accuracy: 0.9928 - val_loss: 0.1069 - val_accuracy: 0.9814\n",
            "Epoch 18/20\n",
            "1206/1206 [==============================] - 39s 32ms/step - loss: 0.0182 - accuracy: 0.9947 - val_loss: 0.1397 - val_accuracy: 0.9688\n",
            "Epoch 19/20\n",
            "1206/1206 [==============================] - 39s 32ms/step - loss: 0.0172 - accuracy: 0.9945 - val_loss: 0.0724 - val_accuracy: 0.9857\n",
            "Epoch 20/20\n",
            "1206/1206 [==============================] - 38s 32ms/step - loss: 0.0152 - accuracy: 0.9950 - val_loss: 0.0765 - val_accuracy: 0.9847\n",
            "INFO:tensorflow:Assets written to: final_models/4anomaly-classifier0/assets\n",
            "Model 0 saved\n",
            "{0: 0, 2: 1, 3: 2, 5: 3, 6: 4, 7: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(37914,)\n",
            "{0: 0, 2: 1, 3: 2, 5: 3, 6: 4, 7: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9502,)\n",
            "Epoch 1/20\n",
            "1185/1185 [==============================] - 40s 32ms/step - loss: 4.6249 - accuracy: 0.8377 - val_loss: 0.1779 - val_accuracy: 0.9678\n",
            "Epoch 2/20\n",
            "1185/1185 [==============================] - 38s 32ms/step - loss: 0.1118 - accuracy: 0.9732 - val_loss: 0.0843 - val_accuracy: 0.9772\n",
            "Epoch 3/20\n",
            "1185/1185 [==============================] - 38s 32ms/step - loss: 0.0656 - accuracy: 0.9810 - val_loss: 0.1313 - val_accuracy: 0.9711\n",
            "Epoch 4/20\n",
            "1185/1185 [==============================] - 38s 32ms/step - loss: 0.0643 - accuracy: 0.9824 - val_loss: 0.2777 - val_accuracy: 0.9427\n",
            "Epoch 5/20\n",
            "1185/1185 [==============================] - 38s 32ms/step - loss: 0.0569 - accuracy: 0.9829 - val_loss: 0.0969 - val_accuracy: 0.9751\n",
            "Epoch 6/20\n",
            "1185/1185 [==============================] - 38s 32ms/step - loss: 0.0532 - accuracy: 0.9830 - val_loss: 0.2102 - val_accuracy: 0.9569\n",
            "Epoch 7/20\n",
            "1185/1185 [==============================] - 38s 32ms/step - loss: 0.0538 - accuracy: 0.9832 - val_loss: 0.0876 - val_accuracy: 0.9758\n",
            "Epoch 8/20\n",
            "1185/1185 [==============================] - 38s 32ms/step - loss: 0.0464 - accuracy: 0.9853 - val_loss: 0.4561 - val_accuracy: 0.9212\n",
            "Epoch 9/20\n",
            "1185/1185 [==============================] - 38s 32ms/step - loss: 0.0394 - accuracy: 0.9879 - val_loss: 0.1858 - val_accuracy: 0.9569\n",
            "Epoch 10/20\n",
            "1185/1185 [==============================] - 38s 32ms/step - loss: 0.0313 - accuracy: 0.9902 - val_loss: 0.0942 - val_accuracy: 0.9782\n",
            "Epoch 11/20\n",
            "1185/1185 [==============================] - 38s 32ms/step - loss: 0.0367 - accuracy: 0.9882 - val_loss: 0.1478 - val_accuracy: 0.9756\n",
            "Epoch 12/20\n",
            "1185/1185 [==============================] - 38s 32ms/step - loss: 0.0248 - accuracy: 0.9925 - val_loss: 0.0740 - val_accuracy: 0.9778\n",
            "Epoch 13/20\n",
            "1185/1185 [==============================] - 38s 32ms/step - loss: 0.0270 - accuracy: 0.9917 - val_loss: 0.0763 - val_accuracy: 0.9816\n",
            "Epoch 14/20\n",
            "1185/1185 [==============================] - 38s 32ms/step - loss: 0.0243 - accuracy: 0.9919 - val_loss: 0.0897 - val_accuracy: 0.9799\n",
            "Epoch 15/20\n",
            "1185/1185 [==============================] - 38s 32ms/step - loss: 0.0170 - accuracy: 0.9942 - val_loss: 0.1444 - val_accuracy: 0.9701\n",
            "Epoch 16/20\n",
            "1185/1185 [==============================] - 38s 32ms/step - loss: 0.0211 - accuracy: 0.9931 - val_loss: 0.0684 - val_accuracy: 0.9847\n",
            "Epoch 17/20\n",
            "1185/1185 [==============================] - 38s 32ms/step - loss: 0.0173 - accuracy: 0.9944 - val_loss: 0.0824 - val_accuracy: 0.9820\n",
            "Epoch 18/20\n",
            "1185/1185 [==============================] - 38s 32ms/step - loss: 0.0153 - accuracy: 0.9950 - val_loss: 0.1084 - val_accuracy: 0.9804\n",
            "Epoch 19/20\n",
            "1185/1185 [==============================] - 38s 32ms/step - loss: 0.0162 - accuracy: 0.9951 - val_loss: 0.1455 - val_accuracy: 0.9733\n",
            "Epoch 20/20\n",
            "1185/1185 [==============================] - 38s 32ms/step - loss: 0.0122 - accuracy: 0.9964 - val_loss: 0.1158 - val_accuracy: 0.9778\n",
            "INFO:tensorflow:Assets written to: final_models/4anomaly-classifier1/assets\n",
            "Model 1 saved\n",
            "{0: 0, 1: 1, 3: 2, 5: 3, 6: 4, 7: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(38550,)\n",
            "{0: 0, 1: 1, 3: 2, 5: 3, 6: 4, 7: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9650,)\n",
            "Epoch 1/20\n",
            "1205/1205 [==============================] - 40s 32ms/step - loss: 3.8961 - accuracy: 0.8276 - val_loss: 0.5430 - val_accuracy: 0.9447\n",
            "Epoch 2/20\n",
            "1205/1205 [==============================] - 38s 32ms/step - loss: 0.1778 - accuracy: 0.9665 - val_loss: 0.1503 - val_accuracy: 0.9627\n",
            "Epoch 3/20\n",
            "1205/1205 [==============================] - 39s 32ms/step - loss: 0.0878 - accuracy: 0.9776 - val_loss: 0.1091 - val_accuracy: 0.9719\n",
            "Epoch 4/20\n",
            "1205/1205 [==============================] - 39s 32ms/step - loss: 0.0565 - accuracy: 0.9844 - val_loss: 2.2567 - val_accuracy: 0.7907\n",
            "Epoch 5/20\n",
            "1205/1205 [==============================] - 39s 32ms/step - loss: 0.0512 - accuracy: 0.9853 - val_loss: 0.0909 - val_accuracy: 0.9766\n",
            "Epoch 6/20\n",
            "1205/1205 [==============================] - 38s 32ms/step - loss: 0.0451 - accuracy: 0.9865 - val_loss: 0.2708 - val_accuracy: 0.9429\n",
            "Epoch 7/20\n",
            "1205/1205 [==============================] - 39s 32ms/step - loss: 0.0424 - accuracy: 0.9865 - val_loss: 0.0533 - val_accuracy: 0.9856\n",
            "Epoch 8/20\n",
            "1205/1205 [==============================] - 39s 32ms/step - loss: 0.0386 - accuracy: 0.9887 - val_loss: 0.1517 - val_accuracy: 0.9622\n",
            "Epoch 9/20\n",
            "1205/1205 [==============================] - 39s 32ms/step - loss: 0.0379 - accuracy: 0.9889 - val_loss: 0.0603 - val_accuracy: 0.9832\n",
            "Epoch 10/20\n",
            "1205/1205 [==============================] - 39s 32ms/step - loss: 0.0325 - accuracy: 0.9901 - val_loss: 0.3412 - val_accuracy: 0.9365\n",
            "Epoch 11/20\n",
            "1205/1205 [==============================] - 39s 32ms/step - loss: 0.0246 - accuracy: 0.9925 - val_loss: 0.1012 - val_accuracy: 0.9770\n",
            "Epoch 12/20\n",
            "1205/1205 [==============================] - 39s 32ms/step - loss: 0.0274 - accuracy: 0.9915 - val_loss: 0.0539 - val_accuracy: 0.9872\n",
            "Epoch 13/20\n",
            "1205/1205 [==============================] - 38s 32ms/step - loss: 0.0214 - accuracy: 0.9934 - val_loss: 0.0856 - val_accuracy: 0.9798\n",
            "Epoch 14/20\n",
            "1205/1205 [==============================] - 39s 32ms/step - loss: 0.0211 - accuracy: 0.9933 - val_loss: 0.1260 - val_accuracy: 0.9756\n",
            "Epoch 15/20\n",
            "1205/1205 [==============================] - 39s 32ms/step - loss: 0.0192 - accuracy: 0.9936 - val_loss: 0.0667 - val_accuracy: 0.9873\n",
            "Epoch 16/20\n",
            "1205/1205 [==============================] - 39s 32ms/step - loss: 0.0175 - accuracy: 0.9945 - val_loss: 0.0613 - val_accuracy: 0.9877\n",
            "Epoch 17/20\n",
            "1205/1205 [==============================] - 39s 32ms/step - loss: 0.0168 - accuracy: 0.9946 - val_loss: 0.0515 - val_accuracy: 0.9897\n",
            "Epoch 18/20\n",
            "1205/1205 [==============================] - 38s 32ms/step - loss: 0.0183 - accuracy: 0.9945 - val_loss: 0.2172 - val_accuracy: 0.9570\n",
            "Epoch 19/20\n",
            "1205/1205 [==============================] - 39s 32ms/step - loss: 0.0148 - accuracy: 0.9953 - val_loss: 0.1068 - val_accuracy: 0.9781\n",
            "Epoch 20/20\n",
            "1205/1205 [==============================] - 39s 32ms/step - loss: 0.0133 - accuracy: 0.9957 - val_loss: 0.1049 - val_accuracy: 0.9784\n",
            "INFO:tensorflow:Assets written to: final_models/4anomaly-classifier2/assets\n",
            "Model 2 saved\n",
            "{0: 0, 1: 1, 2: 2, 5: 3, 6: 4, 7: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(38422,)\n",
            "{0: 0, 1: 1, 2: 2, 5: 3, 6: 4, 7: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9605,)\n",
            "Epoch 1/20\n",
            "1201/1201 [==============================] - 40s 32ms/step - loss: 4.7056 - accuracy: 0.8365 - val_loss: 0.3475 - val_accuracy: 0.9164\n",
            "Epoch 2/20\n",
            "1201/1201 [==============================] - 38s 32ms/step - loss: 0.1149 - accuracy: 0.9727 - val_loss: 0.1169 - val_accuracy: 0.9690\n",
            "Epoch 3/20\n",
            "1201/1201 [==============================] - 38s 32ms/step - loss: 0.0667 - accuracy: 0.9812 - val_loss: 0.1782 - val_accuracy: 0.9615\n",
            "Epoch 4/20\n",
            "1201/1201 [==============================] - 38s 32ms/step - loss: 0.0570 - accuracy: 0.9841 - val_loss: 0.0541 - val_accuracy: 0.9850\n",
            "Epoch 5/20\n",
            "1201/1201 [==============================] - 38s 32ms/step - loss: 0.0622 - accuracy: 0.9811 - val_loss: 0.0938 - val_accuracy: 0.9756\n",
            "Epoch 6/20\n",
            "1201/1201 [==============================] - 38s 32ms/step - loss: 0.0521 - accuracy: 0.9845 - val_loss: 0.1743 - val_accuracy: 0.9577\n",
            "Epoch 7/20\n",
            "1201/1201 [==============================] - 38s 32ms/step - loss: 0.0499 - accuracy: 0.9849 - val_loss: 0.1084 - val_accuracy: 0.9752\n",
            "Epoch 8/20\n",
            "1201/1201 [==============================] - 38s 32ms/step - loss: 0.0401 - accuracy: 0.9875 - val_loss: 0.1835 - val_accuracy: 0.9618\n",
            "Epoch 9/20\n",
            "1201/1201 [==============================] - 38s 32ms/step - loss: 0.0391 - accuracy: 0.9888 - val_loss: 0.2022 - val_accuracy: 0.9583\n",
            "Epoch 10/20\n",
            "1201/1201 [==============================] - 38s 32ms/step - loss: 0.0357 - accuracy: 0.9896 - val_loss: 0.1048 - val_accuracy: 0.9769\n",
            "Epoch 11/20\n",
            "1201/1201 [==============================] - 38s 32ms/step - loss: 0.0298 - accuracy: 0.9902 - val_loss: 0.1305 - val_accuracy: 0.9717\n",
            "Epoch 12/20\n",
            "1201/1201 [==============================] - 38s 32ms/step - loss: 0.0309 - accuracy: 0.9896 - val_loss: 0.1569 - val_accuracy: 0.9696\n",
            "Epoch 13/20\n",
            "1201/1201 [==============================] - 38s 32ms/step - loss: 0.0264 - accuracy: 0.9921 - val_loss: 0.2281 - val_accuracy: 0.9614\n",
            "Epoch 14/20\n",
            "1201/1201 [==============================] - 38s 32ms/step - loss: 0.0198 - accuracy: 0.9935 - val_loss: 0.0743 - val_accuracy: 0.9842\n",
            "Epoch 15/20\n",
            "1201/1201 [==============================] - 38s 32ms/step - loss: 0.0202 - accuracy: 0.9935 - val_loss: 0.1122 - val_accuracy: 0.9778\n",
            "Epoch 16/20\n",
            "1201/1201 [==============================] - 38s 32ms/step - loss: 0.0183 - accuracy: 0.9936 - val_loss: 0.1255 - val_accuracy: 0.9758\n",
            "Epoch 17/20\n",
            "1201/1201 [==============================] - 38s 32ms/step - loss: 0.0187 - accuracy: 0.9942 - val_loss: 0.0719 - val_accuracy: 0.9877\n",
            "Epoch 18/20\n",
            "1201/1201 [==============================] - 38s 32ms/step - loss: 0.0169 - accuracy: 0.9944 - val_loss: 0.1050 - val_accuracy: 0.9822\n",
            "Epoch 19/20\n",
            "1201/1201 [==============================] - 38s 32ms/step - loss: 0.0128 - accuracy: 0.9959 - val_loss: 0.1026 - val_accuracy: 0.9813\n",
            "Epoch 20/20\n",
            "1201/1201 [==============================] - 38s 32ms/step - loss: 0.0128 - accuracy: 0.9956 - val_loss: 0.1717 - val_accuracy: 0.9722\n",
            "INFO:tensorflow:Assets written to: final_models/4anomaly-classifier3/assets\n",
            "Model 3 saved\n",
            "{0: 0, 1: 1, 2: 2, 3: 3, 6: 4, 7: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(39017,)\n",
            "{0: 0, 1: 1, 2: 2, 3: 3, 6: 4, 7: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9720,)\n",
            "Epoch 1/20\n",
            "1220/1220 [==============================] - 41s 32ms/step - loss: 6.1526 - accuracy: 0.8222 - val_loss: 0.1541 - val_accuracy: 0.9719\n",
            "Epoch 2/20\n",
            "1220/1220 [==============================] - 39s 32ms/step - loss: 0.1465 - accuracy: 0.9745 - val_loss: 0.1285 - val_accuracy: 0.9706\n",
            "Epoch 3/20\n",
            "1220/1220 [==============================] - 39s 32ms/step - loss: 0.0627 - accuracy: 0.9842 - val_loss: 0.7756 - val_accuracy: 0.8794\n",
            "Epoch 4/20\n",
            "1220/1220 [==============================] - 39s 32ms/step - loss: 0.0596 - accuracy: 0.9831 - val_loss: 0.1050 - val_accuracy: 0.9733\n",
            "Epoch 5/20\n",
            "1220/1220 [==============================] - 39s 32ms/step - loss: 0.0490 - accuracy: 0.9855 - val_loss: 0.1053 - val_accuracy: 0.9746\n",
            "Epoch 6/20\n",
            "1220/1220 [==============================] - 39s 32ms/step - loss: 0.0489 - accuracy: 0.9854 - val_loss: 0.1266 - val_accuracy: 0.9730\n",
            "Epoch 7/20\n",
            "1220/1220 [==============================] - 39s 32ms/step - loss: 0.0473 - accuracy: 0.9864 - val_loss: 0.1685 - val_accuracy: 0.9658\n",
            "Epoch 8/20\n",
            "1220/1220 [==============================] - 39s 32ms/step - loss: 0.0403 - accuracy: 0.9879 - val_loss: 0.1291 - val_accuracy: 0.9713\n",
            "Epoch 9/20\n",
            "1220/1220 [==============================] - 39s 32ms/step - loss: 0.0370 - accuracy: 0.9885 - val_loss: 0.0567 - val_accuracy: 0.9868\n",
            "Epoch 10/20\n",
            "1220/1220 [==============================] - 39s 32ms/step - loss: 0.0373 - accuracy: 0.9894 - val_loss: 0.0589 - val_accuracy: 0.9846\n",
            "Epoch 11/20\n",
            "1220/1220 [==============================] - 39s 32ms/step - loss: 0.0305 - accuracy: 0.9903 - val_loss: 0.1044 - val_accuracy: 0.9777\n",
            "Epoch 12/20\n",
            "1220/1220 [==============================] - 39s 32ms/step - loss: 0.0231 - accuracy: 0.9927 - val_loss: 0.0709 - val_accuracy: 0.9830\n",
            "Epoch 13/20\n",
            "1220/1220 [==============================] - 39s 32ms/step - loss: 0.0245 - accuracy: 0.9926 - val_loss: 0.0785 - val_accuracy: 0.9825\n",
            "Epoch 14/20\n",
            "1220/1220 [==============================] - 39s 32ms/step - loss: 0.0182 - accuracy: 0.9942 - val_loss: 0.0744 - val_accuracy: 0.9837\n",
            "Epoch 15/20\n",
            "1220/1220 [==============================] - 39s 32ms/step - loss: 0.0216 - accuracy: 0.9934 - val_loss: 0.0894 - val_accuracy: 0.9831\n",
            "Epoch 16/20\n",
            "1220/1220 [==============================] - 39s 32ms/step - loss: 0.0194 - accuracy: 0.9945 - val_loss: 0.0694 - val_accuracy: 0.9851\n",
            "Epoch 17/20\n",
            "1220/1220 [==============================] - 39s 32ms/step - loss: 0.0140 - accuracy: 0.9957 - val_loss: 0.1422 - val_accuracy: 0.9737\n",
            "Epoch 18/20\n",
            "1220/1220 [==============================] - 39s 32ms/step - loss: 0.0165 - accuracy: 0.9951 - val_loss: 0.1058 - val_accuracy: 0.9811\n",
            "Epoch 19/20\n",
            "1220/1220 [==============================] - 39s 32ms/step - loss: 0.0144 - accuracy: 0.9950 - val_loss: 0.0772 - val_accuracy: 0.9837\n",
            "Epoch 20/20\n",
            "1220/1220 [==============================] - 39s 32ms/step - loss: 0.0132 - accuracy: 0.9955 - val_loss: 0.0766 - val_accuracy: 0.9876\n",
            "INFO:tensorflow:Assets written to: final_models/4anomaly-classifier4/assets\n",
            "Model 4 saved\n",
            "{0: 0, 1: 1, 2: 2, 3: 3, 5: 4, 7: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(38593,)\n",
            "{0: 0, 1: 1, 2: 2, 3: 3, 5: 4, 7: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9647,)\n",
            "Epoch 1/20\n",
            "1207/1207 [==============================] - 40s 32ms/step - loss: 5.8971 - accuracy: 0.8273 - val_loss: 0.1702 - val_accuracy: 0.9576\n",
            "Epoch 2/20\n",
            "1207/1207 [==============================] - 39s 32ms/step - loss: 0.1119 - accuracy: 0.9713 - val_loss: 0.1212 - val_accuracy: 0.9694\n",
            "Epoch 3/20\n",
            "1207/1207 [==============================] - 39s 32ms/step - loss: 0.0720 - accuracy: 0.9787 - val_loss: 0.0733 - val_accuracy: 0.9797\n",
            "Epoch 4/20\n",
            "1207/1207 [==============================] - 39s 32ms/step - loss: 0.0646 - accuracy: 0.9812 - val_loss: 0.2468 - val_accuracy: 0.9491\n",
            "Epoch 5/20\n",
            "1207/1207 [==============================] - 39s 32ms/step - loss: 0.0614 - accuracy: 0.9812 - val_loss: 0.0899 - val_accuracy: 0.9745\n",
            "Epoch 6/20\n",
            "1207/1207 [==============================] - 39s 32ms/step - loss: 0.0449 - accuracy: 0.9869 - val_loss: 0.1309 - val_accuracy: 0.9631\n",
            "Epoch 7/20\n",
            "1207/1207 [==============================] - 39s 32ms/step - loss: 0.0494 - accuracy: 0.9841 - val_loss: 0.1061 - val_accuracy: 0.9777\n",
            "Epoch 8/20\n",
            "1207/1207 [==============================] - 39s 32ms/step - loss: 0.0462 - accuracy: 0.9856 - val_loss: 0.1608 - val_accuracy: 0.9667\n",
            "Epoch 9/20\n",
            "1207/1207 [==============================] - 39s 32ms/step - loss: 0.0437 - accuracy: 0.9866 - val_loss: 0.0763 - val_accuracy: 0.9777\n",
            "Epoch 10/20\n",
            "1207/1207 [==============================] - 39s 32ms/step - loss: 0.0316 - accuracy: 0.9902 - val_loss: 0.2622 - val_accuracy: 0.9586\n",
            "Epoch 11/20\n",
            "1207/1207 [==============================] - 39s 32ms/step - loss: 0.0305 - accuracy: 0.9908 - val_loss: 0.1112 - val_accuracy: 0.9791\n",
            "Epoch 12/20\n",
            "1207/1207 [==============================] - 39s 32ms/step - loss: 0.0272 - accuracy: 0.9914 - val_loss: 0.0884 - val_accuracy: 0.9804\n",
            "Epoch 13/20\n",
            "1207/1207 [==============================] - 39s 32ms/step - loss: 0.0236 - accuracy: 0.9927 - val_loss: 0.0967 - val_accuracy: 0.9790\n",
            "Epoch 14/20\n",
            "1207/1207 [==============================] - 39s 32ms/step - loss: 0.0241 - accuracy: 0.9923 - val_loss: 0.0987 - val_accuracy: 0.9817\n",
            "Epoch 15/20\n",
            "1207/1207 [==============================] - 39s 32ms/step - loss: 0.0179 - accuracy: 0.9944 - val_loss: 0.1113 - val_accuracy: 0.9790\n",
            "Epoch 16/20\n",
            "1207/1207 [==============================] - 39s 32ms/step - loss: 0.0180 - accuracy: 0.9946 - val_loss: 0.1095 - val_accuracy: 0.9767\n",
            "Epoch 17/20\n",
            "1207/1207 [==============================] - 39s 32ms/step - loss: 0.0185 - accuracy: 0.9944 - val_loss: 0.1500 - val_accuracy: 0.9725\n",
            "Epoch 18/20\n",
            "1207/1207 [==============================] - 39s 32ms/step - loss: 0.0208 - accuracy: 0.9934 - val_loss: 0.0731 - val_accuracy: 0.9850\n",
            "Epoch 19/20\n",
            "1207/1207 [==============================] - 39s 32ms/step - loss: 0.0110 - accuracy: 0.9964 - val_loss: 0.1208 - val_accuracy: 0.9761\n",
            "Epoch 20/20\n",
            "1207/1207 [==============================] - 39s 32ms/step - loss: 0.0159 - accuracy: 0.9944 - val_loss: 0.1545 - val_accuracy: 0.9764\n",
            "INFO:tensorflow:Assets written to: final_models/4anomaly-classifier5/assets\n",
            "Model 5 saved\n",
            "{0: 0, 1: 1, 2: 2, 3: 3, 5: 4, 6: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(38368,)\n",
            "{0: 0, 1: 1, 2: 2, 3: 3, 5: 4, 6: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9525,)\n",
            "Epoch 1/20\n",
            "1199/1199 [==============================] - 40s 33ms/step - loss: 4.2121 - accuracy: 0.8562 - val_loss: 0.3233 - val_accuracy: 0.9519\n",
            "Epoch 2/20\n",
            "1199/1199 [==============================] - 39s 32ms/step - loss: 0.1127 - accuracy: 0.9744 - val_loss: 0.3622 - val_accuracy: 0.9070\n",
            "Epoch 3/20\n",
            "1199/1199 [==============================] - 39s 32ms/step - loss: 0.0657 - accuracy: 0.9819 - val_loss: 0.1037 - val_accuracy: 0.9679\n",
            "Epoch 4/20\n",
            "1199/1199 [==============================] - 39s 32ms/step - loss: 0.0608 - accuracy: 0.9828 - val_loss: 0.1633 - val_accuracy: 0.9686\n",
            "Epoch 5/20\n",
            "1199/1199 [==============================] - 39s 32ms/step - loss: 0.0637 - accuracy: 0.9819 - val_loss: 0.1502 - val_accuracy: 0.9604\n",
            "Epoch 6/20\n",
            "1199/1199 [==============================] - 39s 32ms/step - loss: 0.0554 - accuracy: 0.9832 - val_loss: 0.1420 - val_accuracy: 0.9729\n",
            "Epoch 7/20\n",
            "1199/1199 [==============================] - 38s 32ms/step - loss: 0.0395 - accuracy: 0.9879 - val_loss: 0.2341 - val_accuracy: 0.9605\n",
            "Epoch 8/20\n",
            "1199/1199 [==============================] - 39s 32ms/step - loss: 0.0404 - accuracy: 0.9877 - val_loss: 0.0557 - val_accuracy: 0.9847\n",
            "Epoch 9/20\n",
            "1199/1199 [==============================] - 39s 32ms/step - loss: 0.0362 - accuracy: 0.9887 - val_loss: 0.1089 - val_accuracy: 0.9787\n",
            "Epoch 10/20\n",
            "1199/1199 [==============================] - 39s 32ms/step - loss: 0.0347 - accuracy: 0.9891 - val_loss: 0.0675 - val_accuracy: 0.9826\n",
            "Epoch 11/20\n",
            "1199/1199 [==============================] - 39s 32ms/step - loss: 0.0308 - accuracy: 0.9904 - val_loss: 0.0556 - val_accuracy: 0.9869\n",
            "Epoch 12/20\n",
            "1199/1199 [==============================] - 39s 32ms/step - loss: 0.0272 - accuracy: 0.9919 - val_loss: 0.0438 - val_accuracy: 0.9897\n",
            "Epoch 13/20\n",
            "1199/1199 [==============================] - 38s 32ms/step - loss: 0.0193 - accuracy: 0.9934 - val_loss: 0.0621 - val_accuracy: 0.9852\n",
            "Epoch 14/20\n",
            "1199/1199 [==============================] - 39s 32ms/step - loss: 0.0230 - accuracy: 0.9933 - val_loss: 0.0415 - val_accuracy: 0.9894\n",
            "Epoch 15/20\n",
            "1199/1199 [==============================] - 39s 32ms/step - loss: 0.0217 - accuracy: 0.9938 - val_loss: 0.0530 - val_accuracy: 0.9880\n",
            "Epoch 16/20\n",
            "1199/1199 [==============================] - 39s 32ms/step - loss: 0.0239 - accuracy: 0.9936 - val_loss: 0.0573 - val_accuracy: 0.9873\n",
            "Epoch 17/20\n",
            "1199/1199 [==============================] - 39s 32ms/step - loss: 0.0194 - accuracy: 0.9945 - val_loss: 0.2689 - val_accuracy: 0.9566\n",
            "Epoch 18/20\n",
            "1199/1199 [==============================] - 39s 32ms/step - loss: 0.0144 - accuracy: 0.9952 - val_loss: 0.0815 - val_accuracy: 0.9850\n",
            "Epoch 19/20\n",
            "1199/1199 [==============================] - 39s 32ms/step - loss: 0.0199 - accuracy: 0.9938 - val_loss: 0.1462 - val_accuracy: 0.9763\n",
            "Epoch 20/20\n",
            "1199/1199 [==============================] - 39s 32ms/step - loss: 0.0131 - accuracy: 0.9960 - val_loss: 0.0560 - val_accuracy: 0.9888\n",
            "INFO:tensorflow:Assets written to: final_models/4anomaly-classifier6/assets\n",
            "Model 6 saved\n",
            "{0: 0, 1: 1, 2: 2, 3: 3, 5: 4, 6: 5, 7: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(38643,)\n",
            "{0: 0, 1: 1, 2: 2, 3: 3, 5: 4, 6: 5, 7: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9664,)\n",
            "Epoch 1/20\n",
            "1208/1208 [==============================] - 40s 32ms/step - loss: 3.5009 - accuracy: 0.8739 - val_loss: 0.1353 - val_accuracy: 0.9704\n",
            "Epoch 2/20\n",
            "1208/1208 [==============================] - 39s 32ms/step - loss: 0.0896 - accuracy: 0.9790 - val_loss: 0.1080 - val_accuracy: 0.9740\n",
            "Epoch 3/20\n",
            "1208/1208 [==============================] - 39s 32ms/step - loss: 0.0583 - accuracy: 0.9838 - val_loss: 0.2996 - val_accuracy: 0.9389\n",
            "Epoch 4/20\n",
            "1208/1208 [==============================] - 39s 32ms/step - loss: 0.0568 - accuracy: 0.9831 - val_loss: 0.2102 - val_accuracy: 0.9506\n",
            "Epoch 5/20\n",
            "1208/1208 [==============================] - 39s 32ms/step - loss: 0.0597 - accuracy: 0.9835 - val_loss: 0.1058 - val_accuracy: 0.9751\n",
            "Epoch 6/20\n",
            "1208/1208 [==============================] - 39s 32ms/step - loss: 0.0489 - accuracy: 0.9851 - val_loss: 0.1214 - val_accuracy: 0.9722\n",
            "Epoch 7/20\n",
            "1208/1208 [==============================] - 39s 32ms/step - loss: 0.0446 - accuracy: 0.9867 - val_loss: 0.0963 - val_accuracy: 0.9776\n",
            "Epoch 8/20\n",
            "1208/1208 [==============================] - 38s 32ms/step - loss: 0.0396 - accuracy: 0.9881 - val_loss: 0.0939 - val_accuracy: 0.9767\n",
            "Epoch 9/20\n",
            "1208/1208 [==============================] - 39s 32ms/step - loss: 0.0315 - accuracy: 0.9900 - val_loss: 0.0646 - val_accuracy: 0.9829\n",
            "Epoch 10/20\n",
            "1208/1208 [==============================] - 39s 32ms/step - loss: 0.0321 - accuracy: 0.9893 - val_loss: 0.1128 - val_accuracy: 0.9756\n",
            "Epoch 11/20\n",
            "1208/1208 [==============================] - 39s 32ms/step - loss: 0.0313 - accuracy: 0.9901 - val_loss: 0.1075 - val_accuracy: 0.9764\n",
            "Epoch 12/20\n",
            "1208/1208 [==============================] - 39s 32ms/step - loss: 0.0246 - accuracy: 0.9923 - val_loss: 0.1176 - val_accuracy: 0.9720\n",
            "Epoch 13/20\n",
            "1208/1208 [==============================] - 39s 32ms/step - loss: 0.0249 - accuracy: 0.9920 - val_loss: 0.0919 - val_accuracy: 0.9815\n",
            "Epoch 14/20\n",
            "1208/1208 [==============================] - 39s 32ms/step - loss: 0.0200 - accuracy: 0.9934 - val_loss: 0.1002 - val_accuracy: 0.9826\n",
            "Epoch 15/20\n",
            "1208/1208 [==============================] - 39s 32ms/step - loss: 0.0229 - accuracy: 0.9931 - val_loss: 0.0729 - val_accuracy: 0.9820\n",
            "Epoch 16/20\n",
            "1208/1208 [==============================] - 39s 32ms/step - loss: 0.0159 - accuracy: 0.9947 - val_loss: 0.0678 - val_accuracy: 0.9853\n",
            "Epoch 17/20\n",
            "1208/1208 [==============================] - 39s 32ms/step - loss: 0.0157 - accuracy: 0.9950 - val_loss: 0.1274 - val_accuracy: 0.9771\n",
            "Epoch 18/20\n",
            "1208/1208 [==============================] - 39s 32ms/step - loss: 0.0175 - accuracy: 0.9947 - val_loss: 0.0571 - val_accuracy: 0.9878\n",
            "Epoch 19/20\n",
            "1208/1208 [==============================] - 39s 32ms/step - loss: 0.0126 - accuracy: 0.9958 - val_loss: 0.0794 - val_accuracy: 0.9851\n",
            "Epoch 20/20\n",
            "1208/1208 [==============================] - 39s 32ms/step - loss: 0.0186 - accuracy: 0.9939 - val_loss: 0.1053 - val_accuracy: 0.9816\n",
            "INFO:tensorflow:Assets written to: final_models/4anomaly-classifier7/assets\n",
            "Model 7 saved\n",
            "{0: 0, 1: 1, 2: 2, 3: 3, 5: 4, 6: 5, 7: 6, 8: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(38579,)\n",
            "{0: 0, 1: 1, 2: 2, 3: 3, 5: 4, 6: 5, 7: 6, 8: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9630,)\n",
            "Epoch 1/20\n",
            "1206/1206 [==============================] - 40s 32ms/step - loss: 5.0096 - accuracy: 0.8097 - val_loss: 0.2247 - val_accuracy: 0.9639\n",
            "Epoch 2/20\n",
            "1206/1206 [==============================] - 39s 32ms/step - loss: 0.1494 - accuracy: 0.9745 - val_loss: 0.1175 - val_accuracy: 0.9683\n",
            "Epoch 3/20\n",
            "1206/1206 [==============================] - 39s 32ms/step - loss: 0.0590 - accuracy: 0.9837 - val_loss: 0.1061 - val_accuracy: 0.9739\n",
            "Epoch 4/20\n",
            "1206/1206 [==============================] - 39s 32ms/step - loss: 0.0543 - accuracy: 0.9828 - val_loss: 0.2944 - val_accuracy: 0.9439\n",
            "Epoch 5/20\n",
            "1206/1206 [==============================] - 39s 32ms/step - loss: 0.0558 - accuracy: 0.9832 - val_loss: 0.2728 - val_accuracy: 0.9427\n",
            "Epoch 6/20\n",
            "1206/1206 [==============================] - 39s 32ms/step - loss: 0.0562 - accuracy: 0.9825 - val_loss: 0.0917 - val_accuracy: 0.9766\n",
            "Epoch 7/20\n",
            "1206/1206 [==============================] - 39s 32ms/step - loss: 0.0416 - accuracy: 0.9876 - val_loss: 0.1755 - val_accuracy: 0.9610\n",
            "Epoch 8/20\n",
            "1206/1206 [==============================] - 39s 32ms/step - loss: 0.0452 - accuracy: 0.9859 - val_loss: 0.1293 - val_accuracy: 0.9737\n",
            "Epoch 9/20\n",
            "1206/1206 [==============================] - 39s 32ms/step - loss: 0.0386 - accuracy: 0.9877 - val_loss: 0.1292 - val_accuracy: 0.9666\n",
            "Epoch 10/20\n",
            "1206/1206 [==============================] - 39s 32ms/step - loss: 0.0355 - accuracy: 0.9885 - val_loss: 0.4433 - val_accuracy: 0.9197\n",
            "Epoch 11/20\n",
            "1206/1206 [==============================] - 39s 32ms/step - loss: 0.0293 - accuracy: 0.9917 - val_loss: 0.0913 - val_accuracy: 0.9817\n",
            "Epoch 12/20\n",
            "1206/1206 [==============================] - 39s 32ms/step - loss: 0.0275 - accuracy: 0.9907 - val_loss: 0.1017 - val_accuracy: 0.9771\n",
            "Epoch 13/20\n",
            "1206/1206 [==============================] - 39s 32ms/step - loss: 0.0236 - accuracy: 0.9920 - val_loss: 0.1119 - val_accuracy: 0.9779\n",
            "Epoch 14/20\n",
            "1206/1206 [==============================] - 39s 32ms/step - loss: 0.0244 - accuracy: 0.9917 - val_loss: 0.1292 - val_accuracy: 0.9700\n",
            "Epoch 15/20\n",
            "1206/1206 [==============================] - 39s 32ms/step - loss: 0.0235 - accuracy: 0.9921 - val_loss: 0.1233 - val_accuracy: 0.9733\n",
            "Epoch 16/20\n",
            "1206/1206 [==============================] - 39s 32ms/step - loss: 0.0179 - accuracy: 0.9931 - val_loss: 0.1578 - val_accuracy: 0.9655\n",
            "Epoch 17/20\n",
            "1206/1206 [==============================] - 39s 32ms/step - loss: 0.0160 - accuracy: 0.9953 - val_loss: 0.1669 - val_accuracy: 0.9691\n",
            "Epoch 18/20\n",
            "1206/1206 [==============================] - 39s 32ms/step - loss: 0.0158 - accuracy: 0.9952 - val_loss: 0.2359 - val_accuracy: 0.9609\n",
            "Epoch 19/20\n",
            "1206/1206 [==============================] - 39s 32ms/step - loss: 0.0177 - accuracy: 0.9946 - val_loss: 0.1571 - val_accuracy: 0.9668\n",
            "Epoch 20/20\n",
            "1206/1206 [==============================] - 39s 32ms/step - loss: 0.0141 - accuracy: 0.9957 - val_loss: 0.1608 - val_accuracy: 0.9736\n",
            "INFO:tensorflow:Assets written to: final_models/4anomaly-classifier8/assets\n",
            "Model 8 saved\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxFnCc16i9j-"
      },
      "source": [
        "class_0 = model0.load_model(\"final_models/4anomaly-classifier0\")\n",
        "class_1 = model1.load_model(\"final_models/4anomaly-classifier1\")\n",
        "class_2 = model2.load_model(\"final_models/4anomaly-classifier2\")\n",
        "class_3 = model3.load_model(\"final_models/4anomaly-classifier3\")\n",
        "class_4 = model4.load_model(\"final_models/4anomaly-classifier4\")\n",
        "class_5 = model5.load_model(\"final_models/4anomaly-classifier5\")\n",
        "class_6 = model6.load_model(\"final_models/4anomaly-classifier6\")\n",
        "class_7 = model7.load_model(\"final_models/4anomaly-classifier7\")\n",
        "class_8 = model8.load_model(\"final_models/4anomaly-classifier8\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6TTEKTq9i9j_",
        "outputId": "4e581e50-cca8-4468-ed7e-57b6a32ec8a7"
      },
      "source": [
        "layer_name_list = []\n",
        "\n",
        "layer_name_list.append(class_0.layers[-2:][0].name)\n",
        "layer_name_list.append(class_1.layers[-2:][0].name)\n",
        "layer_name_list.append(class_2.layers[-2:][0].name)\n",
        "layer_name_list.append(class_3.layers[-2:][0].name)\n",
        "layer_name_list.append(class_4.layers[-2:][0].name)\n",
        "layer_name_list.append(class_5.layers[-2:][0].name)\n",
        "layer_name_list.append(class_6.layers[-2:][0].name)\n",
        "layer_name_list.append(class_7.layers[-2:][0].name)\n",
        "layer_name_list.append(class_8.layers[-2:][0].name)\n",
        "\n",
        "print(layer_name_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['dense_39', 'dense_41', 'dense_43', 'dense_45', 'dense_47', 'dense_49', 'dense_51', 'dense_53', 'dense_55']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngLraT8zi9kA"
      },
      "source": [
        "from keras import Model\n",
        "model_dict = {}\n",
        "model_output0 = class_0.get_layer(layer_name_list[0]).output\n",
        "m0 = Model(inputs=class_0.input, outputs=model_output0)\n",
        "model_dict[0] = m0\n",
        "\n",
        "model_output1 = class_1.get_layer(layer_name_list[1]).output\n",
        "m1 = Model(inputs=class_1.input, outputs=model_output1)\n",
        "model_dict[1] = m1\n",
        "\n",
        "model_output2 = class_2.get_layer(layer_name_list[2]).output\n",
        "m2 = Model(inputs=class_2.input, outputs=model_output2)\n",
        "model_dict[2] = m2\n",
        "\n",
        "model_output3 = class_3.get_layer(layer_name_list[3]).output\n",
        "m3 = Model(inputs=class_3.input, outputs=model_output3)\n",
        "model_dict[3] = m3\n",
        "\n",
        "model_output4 = class_4.get_layer(layer_name_list[4]).output\n",
        "m4 = Model(inputs=class_4.input, outputs=model_output4)\n",
        "model_dict[4] = m4\n",
        "\n",
        "model_output5 = class_5.get_layer(layer_name_list[5]).output\n",
        "m5 = Model(inputs=class_5.input, outputs=model_output5)\n",
        "model_dict[5] = m5\n",
        "\n",
        "model_output6 = class_6.get_layer(layer_name_list[6]).output\n",
        "m6 = Model(inputs=class_6.input, outputs=model_output6)\n",
        "model_dict[6] = m6\n",
        "\n",
        "model_output7 = class_7.get_layer(layer_name_list[7]).output\n",
        "m7 = Model(inputs=class_7.input, outputs=model_output7)\n",
        "model_dict[7] = m7\n",
        "\n",
        "model_output8 = class_8.get_layer(layer_name_list[8]).output\n",
        "m8 = Model(inputs=class_8.input, outputs=model_output8)\n",
        "model_dict[8] = m8\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sBbjnatp-20z",
        "outputId": "c27bfefb-5a60-494d-83cc-510a155bc2b5"
      },
      "source": [
        "set(new_val_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0, 1, 2, 3, 5, 6, 7, 8, 9}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g6i6qlgQi9kB",
        "outputId": "58ff66c8-25c8-48c5-8c77-93560d18bd9d"
      },
      "source": [
        "temp_val = []\n",
        "y_pred = []\n",
        "labels = set(new_val_labels)\n",
        "for i, lo in zip(range(9), labels):\n",
        "  m = model_dict[i]\n",
        "  val_imgs_, val_lbls_ = get_train_data(lo, new_val_images, new_val_labels)\n",
        "  y_p = m.predict(val_imgs_)\n",
        "  y_pred.append(y_p)\n",
        "  temp = temp_cal(y_p, val_lbls_)\n",
        "  temp_val.append(temp)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{1: 0, 2: 1, 3: 2, 5: 3, 6: 4, 7: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9649,)\n",
            "Temperature Initial value: 1.0\n",
            "Temperature Final value: 2.173856735229492\n",
            "{0: 0, 2: 1, 3: 2, 5: 3, 6: 4, 7: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9502,)\n",
            "Temperature Initial value: 1.0\n",
            "Temperature Final value: 2.337050676345825\n",
            "{0: 0, 1: 1, 3: 2, 5: 3, 6: 4, 7: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9650,)\n",
            "Temperature Initial value: 1.0\n",
            "Temperature Final value: 2.1365163326263428\n",
            "{0: 0, 1: 1, 2: 2, 5: 3, 6: 4, 7: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9605,)\n",
            "Temperature Initial value: 1.0\n",
            "Temperature Final value: 2.4419920444488525\n",
            "{0: 0, 1: 1, 2: 2, 3: 3, 6: 4, 7: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9720,)\n",
            "Temperature Initial value: 1.0\n",
            "Temperature Final value: 2.2172510623931885\n",
            "{0: 0, 1: 1, 2: 2, 3: 3, 5: 4, 7: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9647,)\n",
            "Temperature Initial value: 1.0\n",
            "Temperature Final value: 2.4548637866973877\n",
            "{0: 0, 1: 1, 2: 2, 3: 3, 5: 4, 6: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9525,)\n",
            "Temperature Initial value: 1.0\n",
            "Temperature Final value: 2.180988311767578\n",
            "{0: 0, 1: 1, 2: 2, 3: 3, 5: 4, 6: 5, 7: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9664,)\n",
            "Temperature Initial value: 1.0\n",
            "Temperature Final value: 2.343066930770874\n",
            "{0: 0, 1: 1, 2: 2, 3: 3, 5: 4, 6: 5, 7: 6, 8: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9630,)\n",
            "Temperature Initial value: 1.0\n",
            "Temperature Final value: 2.4618613719940186\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qM3_Hdh3i9kE",
        "outputId": "9de1380e-954e-4782-a867-4584b3c10f11"
      },
      "source": [
        "temp_val"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=2.1738567>,\n",
              " <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=2.3370507>,\n",
              " <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=2.1365163>,\n",
              " <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=2.441992>,\n",
              " <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=2.217251>,\n",
              " <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=2.4548638>,\n",
              " <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=2.1809883>,\n",
              " <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=2.343067>,\n",
              " <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=2.4618614>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AaR5bQ-bi9kF",
        "outputId": "d4765263-fc98-438f-d059-e62c631612b4"
      },
      "source": [
        "from tqdm import tqdm\n",
        "avg = [0,0,0,0,0,0,0,0,0]\n",
        "count = [0,0,0,0,0,0,0,0,0]\n",
        "entropy_list = [0,0,0,0,0,0,0,0,0]\n",
        "for img, lbl in tqdm(zip(new_val_images,new_val_labels)):\n",
        "  img = img.reshape([-1, 28, 28, 1])\n",
        "  if not lbl == 0:\n",
        "    logits = model_dict[0](img)\n",
        "    logits = tf.math.divide(logits, temp_val[0])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e0 = entropy(pred[0])\n",
        "    entropy_list[0] = entropy_list[0] + e0\n",
        "    max_val0 = np.max(pred)\n",
        "    avg[0] = avg[0] + max_val0\n",
        "    count[0] = count[0] + 1\n",
        "  if not lbl == 1:\n",
        "    logits = model_dict[1](img)\n",
        "    logits = tf.math.divide(logits, temp_val[1])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e1 = entropy(pred[0])\n",
        "    entropy_list[1] = entropy_list[1] + e1\n",
        "    max_val1 = np.max(pred)\n",
        "    avg[1] = avg[1] + max_val1\n",
        "    count[1] = count[1] + 1\n",
        "  if not lbl == 2:\n",
        "    logits = model_dict[2](img)\n",
        "    logits = tf.math.divide(logits, temp_val[2])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e2 = entropy(pred[0])\n",
        "    entropy_list[2] = entropy_list[2] + e2\n",
        "    max_val2 = np.max(pred)\n",
        "    avg[2] = avg[2] + max_val2\n",
        "    count[2] = count[2] + 1\n",
        "  if not lbl == 3:\n",
        "    logits = model_dict[3](img)\n",
        "    logits = tf.math.divide(logits, temp_val[3])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e3 = entropy(pred[0])\n",
        "    entropy_list[3] = entropy_list[3] + e3\n",
        "    max_val3 = np.max(pred)  \n",
        "    avg[3] = avg[3] + max_val3\n",
        "    count[3] = count[3] + 1\n",
        "  if not lbl == 5:\n",
        "    logits = model_dict[4](img)\n",
        "    logits = tf.math.divide(logits, temp_val[4])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e4 = entropy(pred[0])\n",
        "    entropy_list[4] = entropy_list[4] + e4\n",
        "    max_val4 = np.max(pred)\n",
        "    avg[4] = avg[4] + max_val4\n",
        "    count[4] = count[4] + 1\n",
        "  if not lbl == 6:\n",
        "    logits = model_dict[5](img)\n",
        "    logits = tf.math.divide(logits, temp_val[5])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e5 = entropy(pred[0])\n",
        "    entropy_list[5] = entropy_list[5] + e5\n",
        "    max_val5 = np.max(pred)\n",
        "    avg[5] = avg[5] + max_val5\n",
        "    count[5] = count[5] + 1\n",
        "  if not lbl == 7:\n",
        "    logits = model_dict[6](img)\n",
        "    logits = tf.math.divide(logits, temp_val[6])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e6 = entropy(pred[0])\n",
        "    entropy_list[6] = entropy_list[6] + e6\n",
        "    max_val6 = np.max(pred)\n",
        "    avg[6] = avg[6] + max_val6\n",
        "    count[6] = count[6] + 1\n",
        "  if not lbl == 8:\n",
        "    logits = model_dict[7](img)\n",
        "    logits = tf.math.divide(logits, temp_val[7])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e7 = entropy(pred[0])\n",
        "    entropy_list[7] = entropy_list[7] + e7\n",
        "    max_val7 = np.max(pred)\n",
        "    avg[7] = avg[7] + max_val7\n",
        "    count[7] = count[7] + 1\n",
        "  if not lbl == 9:\n",
        "    logits = model_dict[8](img)\n",
        "    logits = tf.math.divide(logits, temp_val[8])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e8 = entropy(pred[0])\n",
        "    entropy_list[8] = entropy_list[8] + e8\n",
        "    max_val8 = np.max(pred)\n",
        "    avg[8] = avg[8] + max_val8\n",
        "    count[8] = count[8] + 1\n",
        "\n",
        "print(avg)\n",
        "print(count)\n",
        "print(entropy_list)\n",
        "\n",
        "entropy_avg_t = [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]\n",
        "for i in range(9):\n",
        "  entropy_avg_t[i] = entropy_list[i]/count[i]\n",
        "\n",
        "entropy_value_t = 0.0\n",
        "for i in range(9):\n",
        "  entropy_value_t = entropy_value_t + entropy_avg_t[i]\n",
        "\n",
        "entropy_t = entropy_value_t/len(entropy_avg_t)\n",
        "\n",
        "print('Entropy:', entropy_t)\n",
        "\n",
        "classifier_avg_t = [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]\n",
        "for i in range(9):\n",
        "  classifier_avg_t[i] = avg[i]/count[i]\n",
        "\n",
        "print('Each Classifier Average: ',classifier_avg_t)\n",
        "\n",
        "treshold_value = 0.0\n",
        "for i in range(9):\n",
        "  treshold_value = treshold_value + classifier_avg_t[i]\n",
        "\n",
        "treshold_t = treshold_value/len(classifier_avg_t)\n",
        "\n",
        "print('Threshold:', treshold_t)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10824it [13:03, 13.81it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[9500.433717489243, 9309.620541930199, 9436.483246862888, 9380.95329490304, 9589.341369599104, 9441.919467359781, 9414.486594974995, 9492.813774943352, 9409.799656361341]\n",
            "[9649, 9502, 9650, 9605, 9720, 9647, 9525, 9664, 9630]\n",
            "[464.3935592266183, 576.7322754964854, 660.4414740861491, 696.0975343614757, 436.36395912858495, 619.2559443452235, 337.89602810794224, 526.2041780826671, 642.5170021022818]\n",
            "Entropy: 0.057274044994271946\n",
            "Each Classifier Average:  [0.9846029347589639, 0.9797537930888444, 0.9778739115920092, 0.9766739505364955, 0.9865577540739819, 0.9787415224795046, 0.988397542779527, 0.9822861935992707, 0.9771339207021124]\n",
            "Threshold: 0.9813357248456344\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jsrFNs49i9kG",
        "outputId": "508adfe2-1c13-41de-e4c3-b42da1d8dc3c"
      },
      "source": [
        "ref_vect_in_4an = []\n",
        "ref_vect_in_4an.append(classifier_avg_t)\n",
        "\n",
        "threshold_in_4an = []\n",
        "threshold_in_4an.append(treshold_t)\n",
        "\n",
        "entropy_in_4an = []\n",
        "entropy_in_4an.append(entropy_t)\n",
        "\n",
        "print(entropy_in_4an)\n",
        "print(ref_vect_in_4an)\n",
        "print(threshold_in_4an)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.057274044994271946]\n",
            "[[0.9846029347589639, 0.9797537930888444, 0.9778739115920092, 0.9766739505364955, 0.9865577540739819, 0.9787415224795046, 0.988397542779527, 0.9822861935992707, 0.9771339207021124]]\n",
            "[0.9813357248456344]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJEu4sgMFn8M"
      },
      "source": [
        "entropy_in_4an = [0.057274044994271946]\n",
        "ref_vect_in_4an = [[0.9846029347589639, 0.9797537930888444, 0.9778739115920092, 0.9766739505364955, 0.9865577540739819, 0.9787415224795046, 0.988397542779527, 0.9822861935992707, 0.9771339207021124]]\n",
        "threshold_in_4an = [0.9813357248456344]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JFwNsU5zi9kG",
        "outputId": "e387295c-349b-4871-dfc8-6c2f7c6c3aac"
      },
      "source": [
        "from tqdm import tqdm\n",
        "avg = [0,0,0,0,0,0,0,0,0]\n",
        "count = [0,0,0,0,0,0,0,0,0]\n",
        "entropy_list = [0,0,0,0,0,0,0,0,0]\n",
        "\n",
        "for img, lbl in tqdm(zip(new_val_images,new_val_labels)):\n",
        "  img = img.reshape([-1, 28, 28, 1])\n",
        "  if lbl == 0:\n",
        "    logits = model_dict[0](img)\n",
        "    logits = tf.math.divide(logits, temp_val[0])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e0 = entropy(pred[0])\n",
        "    entropy_list[0] = entropy_list[0] + e0\n",
        "    max_val0 = np.max(pred)\n",
        "    avg[0] = avg[0] + max_val0\n",
        "    count[0] = count[0] + 1\n",
        "  if lbl == 1:\n",
        "    logits = model_dict[1](img)\n",
        "    logits = tf.math.divide(logits, temp_val[1])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e1 = entropy(pred[0])\n",
        "    entropy_list[1] = entropy_list[1] + e1\n",
        "    max_val1 = np.max(pred)\n",
        "    avg[1] = avg[1] + max_val1\n",
        "    count[1] = count[1] + 1\n",
        "  if lbl == 2:\n",
        "    logits = model_dict[2](img)\n",
        "    logits = tf.math.divide(logits, temp_val[2])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e2 = entropy(pred[0])\n",
        "    entropy_list[2] = entropy_list[2] + e2\n",
        "    max_val2 = np.max(pred)\n",
        "    avg[2] = avg[2] + max_val2\n",
        "    count[2] = count[2] + 1\n",
        "  if lbl == 3:\n",
        "    logits = model_dict[3](img)\n",
        "    logits = tf.math.divide(logits, temp_val[3])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e3 = entropy(pred[0])\n",
        "    entropy_list[3] = entropy_list[3] + e3\n",
        "    max_val3 = np.max(pred)  \n",
        "    avg[3] = avg[3] + max_val3\n",
        "    count[3] = count[3] + 1\n",
        "  if lbl == 5:\n",
        "    logits = model_dict[4](img)\n",
        "    logits = tf.math.divide(logits, temp_val[4])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e4 = entropy(pred[0])\n",
        "    entropy_list[4] = entropy_list[4] + e4\n",
        "    max_val4 = np.max(pred)\n",
        "    avg[4] = avg[4] + max_val4\n",
        "    count[4] = count[4] + 1\n",
        "  if lbl == 6:\n",
        "    logits = model_dict[5](img)\n",
        "    logits = tf.math.divide(logits, temp_val[5])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e5 = entropy(pred[0])\n",
        "    entropy_list[5] = entropy_list[5] + e5\n",
        "    max_val5 = np.max(pred)\n",
        "    avg[5] = avg[5] + max_val5\n",
        "    count[5] = count[5] + 1\n",
        "  if lbl == 7:\n",
        "    logits = model_dict[6](img)\n",
        "    logits = tf.math.divide(logits, temp_val[6])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e6 = entropy(pred[0])\n",
        "    entropy_list[6] = entropy_list[6] + e6\n",
        "    max_val6 = np.max(pred)\n",
        "    avg[6] = avg[6] + max_val6\n",
        "    count[6] = count[6] + 1\n",
        "  if lbl == 8:\n",
        "    logits = model_dict[7](img)\n",
        "    logits = tf.math.divide(logits, temp_val[7])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e7 = entropy(pred[0])\n",
        "    entropy_list[7] = entropy_list[7] + e7\n",
        "    max_val7 = np.max(pred)\n",
        "    avg[7] = avg[7] + max_val7\n",
        "    count[7] = count[7] + 1\n",
        "  if lbl == 9:\n",
        "    logits = model_dict[8](img)\n",
        "    logits = tf.math.divide(logits, temp_val[8])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e8 = entropy(pred[0])\n",
        "    entropy_list[8] = entropy_list[8] + e8\n",
        "    max_val8 = np.max(pred)\n",
        "    avg[8] = avg[8] + max_val8\n",
        "    count[8] = count[8] + 1\n",
        "\n",
        "print(avg)\n",
        "print(count)\n",
        "print(entropy_list)\n",
        "\n",
        "entropy_avg_t = [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]\n",
        "for i in range(9):\n",
        "  entropy_avg_t[i] = entropy_list[i]/count[i]\n",
        "\n",
        "entropy_value_t = 0.0\n",
        "for i in range(9):\n",
        "  entropy_value_t = entropy_value_t + entropy_avg_t[i]\n",
        "\n",
        "entropy_t = entropy_value_t/len(entropy_avg_t)\n",
        "\n",
        "print('Entropy:', entropy_t)\n",
        "\n",
        "classifier_avg_t = [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]\n",
        "for i in range(9):\n",
        "  classifier_avg_t[i] = avg[i]/count[i]\n",
        "\n",
        "print('Each Classifier Average: ',classifier_avg_t)\n",
        "\n",
        "treshold_value = 0.0\n",
        "for i in range(9):\n",
        "  treshold_value = treshold_value + classifier_avg_t[i]\n",
        "\n",
        "treshold_t = treshold_value/len(classifier_avg_t)\n",
        "\n",
        "print('Threshold:', treshold_t)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10824it [01:38, 109.75it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[1013.7186418324709, 1118.7598364055157, 935.0846498310566, 867.7272661179304, 833.4998598992825, 964.6141183376312, 1123.734256207943, 937.2166780531406, 911.3080673217773]\n",
            "[1175, 1322, 1174, 1219, 1104, 1177, 1299, 1160, 1194]\n",
            "[415.5636234981016, 633.170321919024, 634.4051616337965, 945.1361446573865, 701.7003532266244, 586.3620913837574, 459.16280535294715, 580.1264853518418, 756.3519456838559]\n",
            "Entropy: 0.5299068746094104\n",
            "Each Classifier Average:  [0.8627392696446561, 0.8462631137711919, 0.7964945909974929, 0.711835329054906, 0.7549817571551471, 0.8195532016462457, 0.8650764097058837, 0.8079454121147764, 0.7632395873716729]\n",
            "Threshold: 0.8031254079402191\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQIbVQ5Si9kH",
        "outputId": "bf2f1e9e-104d-447b-e965-ecb252bb1fcb"
      },
      "source": [
        "ref_vect_out_4an = []\n",
        "ref_vect_out_4an.append(classifier_avg_t)\n",
        "\n",
        "threshold_out_4an = []\n",
        "threshold_out_4an.append(treshold_t)\n",
        "\n",
        "entropy_out_4an = []\n",
        "entropy_out_4an.append(entropy_t)\n",
        "\n",
        "print(entropy_out_4an)\n",
        "print(ref_vect_out_4an)\n",
        "print(threshold_out_4an)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.5299068746094104]\n",
            "[[0.8627392696446561, 0.8462631137711919, 0.7964945909974929, 0.711835329054906, 0.7549817571551471, 0.8195532016462457, 0.8650764097058837, 0.8079454121147764, 0.7632395873716729]]\n",
            "[0.8031254079402191]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUtWFmEiF0R4"
      },
      "source": [
        "entropy_out_4an = [0.5299068746094104]\n",
        "ref_vect_out_4an = [[0.8627392696446561, 0.8462631137711919, 0.7964945909974929, 0.711835329054906, 0.7549817571551471, 0.8195532016462457, 0.8650764097058837, 0.8079454121147764, 0.7632395873716729]]\n",
        "threshold_out_4an = [0.8031254079402191]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2e_h7YO_i9kH"
      },
      "source": [
        "def get_max_pred_value(model, img, temp):\n",
        "  logits = model(img)\n",
        "  logits = tf.math.divide(logits, temp)\n",
        "  pred = tf.nn.softmax(logits)\n",
        "  e = entropy(pred[0])\n",
        "\n",
        "  return np.max(pred), tf.argmax(pred[0]).numpy(), e"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqgWpwJ5i9kI"
      },
      "source": [
        "def get_mapping(leave_out_class, anomaly_class):\n",
        "  mapping = {}\n",
        "\n",
        "  labels = set(train_labels)\n",
        "  labels.remove(anomaly_class)\n",
        "  labels.remove(leave_out_class)\n",
        "  labels = sorted(labels)\n",
        "\n",
        "  for i,j in enumerate(labels):\n",
        "    mapping[i] = j\n",
        "\n",
        "  return mapping\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zGvb4IDPi9kI"
      },
      "source": [
        "ood = 0\n",
        "ind = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbSqle7gi9kI",
        "outputId": "b46544fe-c778-43a2-b235-b7fe7a1a1d24"
      },
      "source": [
        "max_sm_all_wt_4an = []\n",
        "for data, label in tqdm(zip(test_imgs, test_lbls)):\n",
        "  img = data.reshape([-1, 28, 28, 1])\n",
        "  ref_value = []\n",
        "  \n",
        "  if label == 4:\n",
        "    lbl = ood\n",
        "  else:\n",
        "    lbl = ind\n",
        "\n",
        "\n",
        "  max0, pred_0, e0 = get_max_pred_value(model_dict[0], img, temp=temp_val[0])\n",
        "  map0 = get_mapping(0, 4)\n",
        "  pred_0 = map0[pred_0]\n",
        "\n",
        "  max1, pred_1, e1 = get_max_pred_value(model_dict[1], img, temp=temp_val[1])\n",
        "  map1 = get_mapping(1, 4)\n",
        "  pred_1 = map1[pred_1]\n",
        "\n",
        "  max2, pred_2, e2 = get_max_pred_value(model_dict[2], img, temp=temp_val[2])\n",
        "  map2 = get_mapping(2, 4)\n",
        "  pred_2 = map2[pred_2]\n",
        "\n",
        "  max3, pred_3, e3 = get_max_pred_value(model_dict[3], img, temp=temp_val[3])\n",
        "  map3 = get_mapping(3, 4)\n",
        "  pred_3 = map3[pred_3]\n",
        "\n",
        "  max4, pred_4, e4 = get_max_pred_value(model_dict[4], img, temp=temp_val[4])\n",
        "  map4 = get_mapping(5, 4)\n",
        "  pred_4 = map4[pred_4]\n",
        "\n",
        "  max5, pred_5, e5 = get_max_pred_value(model_dict[5], img, temp=temp_val[5])\n",
        "  map5 = get_mapping(6, 4)\n",
        "  pred_5 = map5[pred_5]\n",
        "\n",
        "  max6, pred_6, e6 = get_max_pred_value(model_dict[6], img, temp=temp_val[6])\n",
        "  map6 = get_mapping(7, 4)\n",
        "  pred_6 = map6[pred_6]\n",
        "\n",
        "  max7, pred_7, e7 = get_max_pred_value(model_dict[7], img, temp=temp_val[7])\n",
        "  map7 = get_mapping(8, 4)\n",
        "  pred_7 = map7[pred_7]\n",
        "\n",
        "  max8, pred_8, e8 = get_max_pred_value(model_dict[8], img, temp=temp_val[8])\n",
        "  map8 = get_mapping(9, 4)\n",
        "  pred_8 = map8[pred_8]\n",
        "\n",
        "  ref_value =[max0, max1, max2, max3, max4, max5, max6, max7, max8]\n",
        "  pred_value = [pred_0, pred_1, pred_2, pred_3, pred_4, pred_5, pred_6, pred_7, pred_8]\n",
        "  e_value = [e0, e1, e2, e3, e4, e5, e6, e7, e8]\n",
        "  e_ = 0.0\n",
        "  for  e in e_value:\n",
        "    e_ = e_ + e\n",
        "  e_ = e_/len(e_value)\n",
        "  max_sm_all_wt_4an.append([ref_value, lbl, pred_value, label, e_])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000it [21:18,  7.82it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2cjzBi-i9kJ"
      },
      "source": [
        "pickle_out = open(\"sm_all_wt_4an.pickle\",\"wb\")\n",
        "pickle.dump(max_sm_all_wt_4an, pickle_out)\n",
        "pickle_out.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IyYPeaVHi9kJ"
      },
      "source": [
        "pickle_in = open(\"sm_all_wt_4an.pickle\",\"rb\")\n",
        "max_sm_all_wt_4an = pickle.load(pickle_in)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7pssqlxxEg65",
        "outputId": "8b5bb271-5367-44a6-a527-5a62fc39735d"
      },
      "source": [
        "for data, lbl, p, a_l, e_ in max_sm_all_wt_4an:\n",
        "  print(p, lbl, a_l)\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[7, 7, 7, 7, 7, 7, 2, 7, 7] 1 7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGHPEqkPi9kJ",
        "outputId": "10113965-2a89-4777-b98f-bfe4a31d7c28"
      },
      "source": [
        "accuracy = 0.0\n",
        "count_in = 0\n",
        "count_ood = 0\n",
        "acc_in = 0.0\n",
        "acc_ood = 0.0\n",
        "tp = 0.0\n",
        "tn = 0.0\n",
        "fp = 0.0\n",
        "fn = 0.0\n",
        "y_true = []\n",
        "y_pred = []\n",
        "sim_score = []\n",
        "sim_score_ = []\n",
        "\n",
        "for data, lbl, p, a_l, e_ in max_sm_all_wt_4an:\n",
        "\n",
        "  score = 0.0\n",
        "  for d in data:\n",
        "    score = score + d\n",
        "  score = score / len(data)\n",
        "  sim_score.append(score)\n",
        "\n",
        "  dist_ood = np.linalg.norm(np.array(data) - np.array(ref_vect_out_4an[0])) \n",
        "  dist_in = np.linalg.norm(np.array(data) - np.array(ref_vect_in_4an[0]))\n",
        "\n",
        "  dist_ood2 = np.linalg.norm(np.array(e_) - np.array(entropy_out_4an[0])) \n",
        "  dist_in2 = np.linalg.norm(np.array(e_) - np.array(entropy_in_4an[0]))\n",
        "\n",
        "  dist_in = dist_in / (dist_in + dist_ood)\n",
        "  dist_ood = dist_ood / (dist_in + dist_ood)\n",
        "\n",
        "  dist_in2 = dist_in2 / (dist_in2 + dist_ood2)\n",
        "  dist_ood2 = dist_ood2 / (dist_in2 + dist_ood2)\n",
        "\n",
        "  sim_in = 1 / (1 + dist_in)\n",
        "  sim_ood = 1 / (1 + dist_ood)\n",
        "\n",
        "  sim_in2 = 1 / (1 + dist_in2)\n",
        "  sim_ood2 = 1 / (1 + dist_ood2)\n",
        "\n",
        "  sim_in = sim_in + sim_in2\n",
        "  sim_ood = sim_ood + sim_ood2\n",
        "\n",
        "  sim_score_.append(sim_ood)\n",
        "\n",
        "  values, counts = np.unique(p, return_counts=True)\n",
        "#  print(values, counts)\n",
        "  #print(sim_in, sim_ood, lbl, e_)\n",
        "\n",
        "\n",
        "  if sim_in >= sim_ood:\n",
        "    y_ = ind    \n",
        "    if np.max(counts) >= 8:\n",
        "      y_ = ind\n",
        "    else:\n",
        "      y_ = ood\n",
        "  else:\n",
        "    y_ = ood\n",
        "\n",
        "\n",
        "  y_pred.append(y_)\n",
        "  if lbl == 1:\n",
        "    y_true.append(0)\n",
        "  else:\n",
        "    y_true.append(1)\n",
        "#  y_true.append(lbl)\n",
        "\n",
        "\n",
        "  if lbl == ind:\n",
        "    count_in = count_in + 1\n",
        "  else:\n",
        "    count_ood = count_ood + 1\n",
        "\n",
        "  if y_ == lbl:\n",
        "    #sim_score_.append(1)\n",
        "    accuracy = accuracy + 1\n",
        "    if y_ == ind:\n",
        "      acc_in = acc_in + 1\n",
        "      tp = tp + 1\n",
        "    else:\n",
        "      acc_ood = acc_ood + 1\n",
        "      tn = tn + 1\n",
        "  else:\n",
        "    #sim_score_.append(0)\n",
        "    if y_ == ind:\n",
        "      fp = fp + 1\n",
        "    else:\n",
        "      fn = fn + 1\n",
        "\n",
        "\n",
        "print(\"Total Accuracy: \", accuracy/len(max_sm_all_wt_4an)) \n",
        "print(\"Accuracy of determining ID data: \", acc_in/count_in)\n",
        "print(\"Accuracy of determining OOD data: \", acc_ood/count_ood)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Accuracy:  0.8812\n",
            "Accuracy of determining ID data:  0.9045242847638058\n",
            "Accuracy of determining OOD data:  0.6670061099796334\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nVoXNFTLi9kK",
        "outputId": "fe098bdc-0790-464d-c61a-3e0e9b7fb905"
      },
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "roc_auc_score(y_true, sim_score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8662938888008098"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V1V6Ixa_i9kK",
        "outputId": "dd0a4496-cd40-4a05-8a0d-b578a949410b"
      },
      "source": [
        "roc_auc_score(y_true, y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7655492364445131"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wkMiroTUi9kK",
        "outputId": "25f65329-a0bb-4b13-cdd9-b1d1cc39447b"
      },
      "source": [
        "roc_auc_score(y_true, sim_score_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8635207521142373"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 227
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IT-_bkJDICbY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-I-BAayAR2nP"
      },
      "source": [
        "# 5 as anomaly"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ieeX8CWkR5kJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DH3O_C9SKaP"
      },
      "source": [
        "new_train_images, new_train_labels, new_val_images, new_val_labels = separate_class(5, train_images, train_labels, val_images, val_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnZH6AUKSKaU"
      },
      "source": [
        "model0 = Model(name='5anomaly:classifier0')\n",
        "model1 = Model(name='5anomaly:classifier1')\n",
        "model2 = Model(name='5anomaly:classifier2')\n",
        "model3 = Model(name='5anomaly:classifier3')\n",
        "model4 = Model(name='5anomaly:classifier4')\n",
        "model5 = Model(name='5anomaly:classifier5')\n",
        "model6 = Model(name='5anomaly:classifier6')\n",
        "model7 = Model(name='5anomaly:classifier7')\n",
        "model8 = Model(name='5anomaly:classifier8')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lp97aJ9zSKaV"
      },
      "source": [
        "class_0 = model0.build()\n",
        "class_1 = model1.build()\n",
        "class_2 = model2.build()\n",
        "class_3 = model3.build()\n",
        "class_4 = model4.build()\n",
        "class_5 = model5.build()\n",
        "class_6 = model6.build()\n",
        "class_7 = model7.build()\n",
        "class_8 = model8.build()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OaSNhfPNSKaV",
        "outputId": "aa7770a6-00de-4a47-fcf5-03f5e403372d"
      },
      "source": [
        "train_imgs0, train_lbls0 = get_train_data(0, new_train_images, new_train_labels)\n",
        "val_imgs0, val_lbls0 = get_train_data(0, new_val_images, new_val_labels)\n",
        "class_0 = model0.build()\n",
        "model0.train2(train_imgs0, train_lbls0, val_imgs0, val_lbls0)\n",
        "#model0.train(train_data0)\n",
        "model0.save_model(\"final_models/5anomaly-classifier0\")\n",
        "print('Model 0 saved')\n",
        "\n",
        "train_imgs1, train_lbls1 = get_train_data(1, new_train_images, new_train_labels)\n",
        "val_imgs1, val_lbls1 = get_train_data(1, new_val_images, new_val_labels)\n",
        "class_1 = model1.build()\n",
        "model1.train2(train_imgs1, train_lbls1, val_imgs1, val_lbls1)\n",
        "#model1.train(train_data1)\n",
        "model1.save_model(\"final_models/5anomaly-classifier1\")\n",
        "print('Model 1 saved')\n",
        "\n",
        "#train_data2 = get_train_data(2, new_train_images)\n",
        "train_imgs2, train_lbls2 = get_train_data(2, new_train_images, new_train_labels)\n",
        "val_imgs2, val_lbls2 = get_train_data(2, new_val_images, new_val_labels)\n",
        "class_2 = model2.build()\n",
        "model2.train2(train_imgs2, train_lbls2, val_imgs2, val_lbls2)\n",
        "#model2.train(train_data2)\n",
        "model2.save_model(\"final_models/5anomaly-classifier2\")\n",
        "print('Model 2 saved')\n",
        "\n",
        "#train_data3 = get_train_data(3, new_train_images)\n",
        "train_imgs3, train_lbls3 = get_train_data(3, new_train_images, new_train_labels)\n",
        "val_imgs3, val_lbls3 = get_train_data(3, new_val_images, new_val_labels)\n",
        "class_3 = model3.build()\n",
        "model3.train2(train_imgs3, train_lbls3, val_imgs3, val_lbls3)\n",
        "#model3.train(train_data3)\n",
        "model3.save_model(\"final_models/5anomaly-classifier3\")\n",
        "print('Model 3 saved')\n",
        "\n",
        "#train_data4 = get_train_data(4, new_train_images)\n",
        "train_imgs4, train_lbls4 = get_train_data(4, new_train_images, new_train_labels)\n",
        "val_imgs4, val_lbls4 = get_train_data(4, new_val_images, new_val_labels)\n",
        "class_4 = model4.build()\n",
        "model4.train2(train_imgs4, train_lbls4, val_imgs4, val_lbls4)\n",
        "#model4.train(train_data4)\n",
        "model4.save_model(\"final_models/5anomaly-classifier4\")\n",
        "print('Model 4 saved')\n",
        "\n",
        "#train_data5 = get_train_data(5, new_train_images)\n",
        "train_imgs5, train_lbls5 = get_train_data(6, new_train_images, new_train_labels)\n",
        "val_imgs5, val_lbls5 = get_train_data(6, new_val_images, new_val_labels)\n",
        "class_5 = model5.build()\n",
        "model5.train2(train_imgs5, train_lbls5, val_imgs5, val_lbls5)\n",
        "#model5.train(train_data5)\n",
        "model5.save_model(\"final_models/5anomaly-classifier5\")\n",
        "print('Model 5 saved')\n",
        "\n",
        "#train_data6 = get_train_data(6, new_train_images)\n",
        "train_imgs6, train_lbls6 = get_train_data(7, new_train_images, new_train_labels)\n",
        "val_imgs6, val_lbls6 = get_train_data(7, new_val_images, new_val_labels)\n",
        "class_6 = model6.build()\n",
        "model6.train2(train_imgs6, train_lbls6, val_imgs6, val_lbls6)\n",
        "#model6.train(train_data6)\n",
        "model6.save_model(\"final_models/5anomaly-classifier6\")\n",
        "print('Model 6 saved')\n",
        "\n",
        "#train_data7 = get_train_data(7, new_train_images)\n",
        "train_imgs7, train_lbls7 = get_train_data(8, new_train_images, new_train_labels)\n",
        "val_imgs7, val_lbls7 = get_train_data(8, new_val_images, new_val_labels)\n",
        "class_7 = model7.build()\n",
        "#model7.train(train_data7)\n",
        "model7.train2(train_imgs7, train_lbls7, val_imgs7, val_lbls7)\n",
        "model7.save_model(\"final_models/5anomaly-classifier7\")\n",
        "print('Model 7 saved')\n",
        "\n",
        "#train_data8 = get_train_data(8, new_train_images)\n",
        "train_imgs8, train_lbls8 = get_train_data(9, new_train_images, new_train_labels)\n",
        "val_imgs8, val_lbls8 = get_train_data(9, new_val_images, new_val_labels)\n",
        "class_8 = model8.build()\n",
        "#model8.train(train_data8)\n",
        "model8.train2(train_imgs8, train_lbls8, val_imgs8, val_lbls8)\n",
        "model8.save_model(\"final_models/5anomaly-classifier8\")\n",
        "print('Model 8 saved')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{1: 0, 2: 1, 3: 2, 4: 3, 6: 4, 7: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(38935,)\n",
            "{1: 0, 2: 1, 3: 2, 4: 3, 6: 4, 7: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9721,)\n",
            "Epoch 1/20\n",
            "1217/1217 [==============================] - 38s 31ms/step - loss: 4.4210 - accuracy: 0.8301 - val_loss: 0.1378 - val_accuracy: 0.9621\n",
            "Epoch 2/20\n",
            "1217/1217 [==============================] - 37s 31ms/step - loss: 0.1204 - accuracy: 0.9665 - val_loss: 0.1882 - val_accuracy: 0.9388\n",
            "Epoch 3/20\n",
            "1217/1217 [==============================] - 38s 31ms/step - loss: 0.0802 - accuracy: 0.9769 - val_loss: 0.1277 - val_accuracy: 0.9697\n",
            "Epoch 4/20\n",
            "1217/1217 [==============================] - 38s 31ms/step - loss: 0.0655 - accuracy: 0.9799 - val_loss: 0.1438 - val_accuracy: 0.9671\n",
            "Epoch 5/20\n",
            "1217/1217 [==============================] - 38s 31ms/step - loss: 0.0599 - accuracy: 0.9829 - val_loss: 0.1481 - val_accuracy: 0.9647\n",
            "Epoch 6/20\n",
            "1217/1217 [==============================] - 38s 31ms/step - loss: 0.0593 - accuracy: 0.9821 - val_loss: 0.0503 - val_accuracy: 0.9850\n",
            "Epoch 7/20\n",
            "1217/1217 [==============================] - 38s 32ms/step - loss: 0.0521 - accuracy: 0.9852 - val_loss: 0.1898 - val_accuracy: 0.9644\n",
            "Epoch 8/20\n",
            "1217/1217 [==============================] - 39s 32ms/step - loss: 0.0435 - accuracy: 0.9869 - val_loss: 0.0923 - val_accuracy: 0.9752\n",
            "Epoch 9/20\n",
            "1217/1217 [==============================] - 39s 32ms/step - loss: 0.0378 - accuracy: 0.9881 - val_loss: 0.0825 - val_accuracy: 0.9787\n",
            "Epoch 10/20\n",
            "1217/1217 [==============================] - 39s 32ms/step - loss: 0.0296 - accuracy: 0.9901 - val_loss: 0.0707 - val_accuracy: 0.9820\n",
            "Epoch 11/20\n",
            "1217/1217 [==============================] - 39s 32ms/step - loss: 0.0282 - accuracy: 0.9910 - val_loss: 0.1994 - val_accuracy: 0.9626\n",
            "Epoch 12/20\n",
            "1217/1217 [==============================] - 39s 32ms/step - loss: 0.0254 - accuracy: 0.9923 - val_loss: 0.1321 - val_accuracy: 0.9723\n",
            "Epoch 13/20\n",
            "1217/1217 [==============================] - 39s 32ms/step - loss: 0.0269 - accuracy: 0.9916 - val_loss: 0.1085 - val_accuracy: 0.9745\n",
            "Epoch 14/20\n",
            "1217/1217 [==============================] - 39s 32ms/step - loss: 0.0196 - accuracy: 0.9932 - val_loss: 0.0742 - val_accuracy: 0.9815\n",
            "Epoch 15/20\n",
            "1217/1217 [==============================] - 39s 32ms/step - loss: 0.0187 - accuracy: 0.9934 - val_loss: 0.0625 - val_accuracy: 0.9864\n",
            "Epoch 16/20\n",
            "1217/1217 [==============================] - 39s 32ms/step - loss: 0.0202 - accuracy: 0.9942 - val_loss: 0.1951 - val_accuracy: 0.9625\n",
            "Epoch 17/20\n",
            "1217/1217 [==============================] - 39s 32ms/step - loss: 0.0192 - accuracy: 0.9940 - val_loss: 0.0815 - val_accuracy: 0.9820\n",
            "Epoch 18/20\n",
            "1217/1217 [==============================] - 39s 32ms/step - loss: 0.0158 - accuracy: 0.9952 - val_loss: 0.0434 - val_accuracy: 0.9890\n",
            "Epoch 19/20\n",
            "1217/1217 [==============================] - 39s 32ms/step - loss: 0.0162 - accuracy: 0.9948 - val_loss: 0.1379 - val_accuracy: 0.9742\n",
            "Epoch 20/20\n",
            "1217/1217 [==============================] - 39s 32ms/step - loss: 0.0126 - accuracy: 0.9956 - val_loss: 0.0565 - val_accuracy: 0.9879\n",
            "INFO:tensorflow:Assets written to: final_models/5anomaly-classifier0/assets\n",
            "Model 0 saved\n",
            "{0: 0, 2: 1, 3: 2, 4: 3, 6: 4, 7: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(38263,)\n",
            "{0: 0, 2: 1, 3: 2, 4: 3, 6: 4, 7: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9574,)\n",
            "Epoch 1/20\n",
            "1196/1196 [==============================] - 40s 32ms/step - loss: 5.1799 - accuracy: 0.8164 - val_loss: 1.5174 - val_accuracy: 0.8923\n",
            "Epoch 2/20\n",
            "1196/1196 [==============================] - 38s 32ms/step - loss: 0.1334 - accuracy: 0.9680 - val_loss: 0.2015 - val_accuracy: 0.9647\n",
            "Epoch 3/20\n",
            "1196/1196 [==============================] - 38s 32ms/step - loss: 0.0893 - accuracy: 0.9771 - val_loss: 0.2423 - val_accuracy: 0.9624\n",
            "Epoch 4/20\n",
            "1196/1196 [==============================] - 38s 32ms/step - loss: 0.0778 - accuracy: 0.9788 - val_loss: 0.3083 - val_accuracy: 0.9450\n",
            "Epoch 5/20\n",
            "1196/1196 [==============================] - 38s 32ms/step - loss: 0.0624 - accuracy: 0.9821 - val_loss: 0.2084 - val_accuracy: 0.9596\n",
            "Epoch 6/20\n",
            "1196/1196 [==============================] - 38s 32ms/step - loss: 0.0520 - accuracy: 0.9841 - val_loss: 0.1930 - val_accuracy: 0.9590\n",
            "Epoch 7/20\n",
            "1196/1196 [==============================] - 38s 32ms/step - loss: 0.0451 - accuracy: 0.9865 - val_loss: 0.5721 - val_accuracy: 0.9154\n",
            "Epoch 8/20\n",
            "1196/1196 [==============================] - 38s 32ms/step - loss: 0.0506 - accuracy: 0.9852 - val_loss: 0.1916 - val_accuracy: 0.9561\n",
            "Epoch 9/20\n",
            "1196/1196 [==============================] - 38s 32ms/step - loss: 0.0417 - accuracy: 0.9860 - val_loss: 0.2006 - val_accuracy: 0.9630\n",
            "Epoch 10/20\n",
            "1196/1196 [==============================] - 38s 32ms/step - loss: 0.0376 - accuracy: 0.9887 - val_loss: 0.0492 - val_accuracy: 0.9884\n",
            "Epoch 11/20\n",
            "1196/1196 [==============================] - 38s 32ms/step - loss: 0.0279 - accuracy: 0.9910 - val_loss: 0.0988 - val_accuracy: 0.9766\n",
            "Epoch 12/20\n",
            "1196/1196 [==============================] - 38s 32ms/step - loss: 0.0284 - accuracy: 0.9908 - val_loss: 0.0461 - val_accuracy: 0.9874\n",
            "Epoch 13/20\n",
            "1196/1196 [==============================] - 38s 32ms/step - loss: 0.0228 - accuracy: 0.9930 - val_loss: 0.0587 - val_accuracy: 0.9876\n",
            "Epoch 14/20\n",
            "1196/1196 [==============================] - 38s 32ms/step - loss: 0.0268 - accuracy: 0.9923 - val_loss: 0.1229 - val_accuracy: 0.9729\n",
            "Epoch 15/20\n",
            "1196/1196 [==============================] - 38s 32ms/step - loss: 0.0208 - accuracy: 0.9930 - val_loss: 0.0749 - val_accuracy: 0.9839\n",
            "Epoch 16/20\n",
            "1196/1196 [==============================] - 38s 32ms/step - loss: 0.0188 - accuracy: 0.9939 - val_loss: 0.0577 - val_accuracy: 0.9874\n",
            "Epoch 17/20\n",
            "1196/1196 [==============================] - 38s 32ms/step - loss: 0.0202 - accuracy: 0.9942 - val_loss: 0.0973 - val_accuracy: 0.9821\n",
            "Epoch 18/20\n",
            "1196/1196 [==============================] - 38s 32ms/step - loss: 0.0190 - accuracy: 0.9939 - val_loss: 0.0512 - val_accuracy: 0.9885\n",
            "Epoch 19/20\n",
            "1196/1196 [==============================] - 38s 32ms/step - loss: 0.0158 - accuracy: 0.9955 - val_loss: 0.0714 - val_accuracy: 0.9857\n",
            "Epoch 20/20\n",
            "1196/1196 [==============================] - 38s 32ms/step - loss: 0.0156 - accuracy: 0.9953 - val_loss: 0.0581 - val_accuracy: 0.9885\n",
            "INFO:tensorflow:Assets written to: final_models/5anomaly-classifier1/assets\n",
            "Model 1 saved\n",
            "{0: 0, 1: 1, 3: 2, 4: 3, 6: 4, 7: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(38899,)\n",
            "{0: 0, 1: 1, 3: 2, 4: 3, 6: 4, 7: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9722,)\n",
            "Epoch 1/20\n",
            "1216/1216 [==============================] - 40s 32ms/step - loss: 4.7777 - accuracy: 0.8379 - val_loss: 0.2391 - val_accuracy: 0.9575\n",
            "Epoch 2/20\n",
            "1216/1216 [==============================] - 39s 32ms/step - loss: 0.1270 - accuracy: 0.9758 - val_loss: 0.1286 - val_accuracy: 0.9678\n",
            "Epoch 3/20\n",
            "1216/1216 [==============================] - 39s 32ms/step - loss: 0.0638 - accuracy: 0.9821 - val_loss: 0.1471 - val_accuracy: 0.9693\n",
            "Epoch 4/20\n",
            "1216/1216 [==============================] - 39s 32ms/step - loss: 0.0582 - accuracy: 0.9828 - val_loss: 0.1619 - val_accuracy: 0.9611\n",
            "Epoch 5/20\n",
            "1216/1216 [==============================] - 39s 32ms/step - loss: 0.0611 - accuracy: 0.9818 - val_loss: 0.2146 - val_accuracy: 0.9459\n",
            "Epoch 6/20\n",
            "1216/1216 [==============================] - 39s 32ms/step - loss: 0.0481 - accuracy: 0.9857 - val_loss: 0.1086 - val_accuracy: 0.9716\n",
            "Epoch 7/20\n",
            "1216/1216 [==============================] - 39s 32ms/step - loss: 0.0469 - accuracy: 0.9858 - val_loss: 0.0763 - val_accuracy: 0.9804\n",
            "Epoch 8/20\n",
            "1216/1216 [==============================] - 39s 32ms/step - loss: 0.0432 - accuracy: 0.9883 - val_loss: 0.1016 - val_accuracy: 0.9754\n",
            "Epoch 9/20\n",
            "1216/1216 [==============================] - 39s 32ms/step - loss: 0.0364 - accuracy: 0.9887 - val_loss: 0.0564 - val_accuracy: 0.9848\n",
            "Epoch 10/20\n",
            "1216/1216 [==============================] - 39s 32ms/step - loss: 0.0359 - accuracy: 0.9890 - val_loss: 0.0602 - val_accuracy: 0.9844\n",
            "Epoch 11/20\n",
            "1216/1216 [==============================] - 39s 32ms/step - loss: 0.0307 - accuracy: 0.9902 - val_loss: 0.0639 - val_accuracy: 0.9827\n",
            "Epoch 12/20\n",
            "1216/1216 [==============================] - 39s 32ms/step - loss: 0.0288 - accuracy: 0.9916 - val_loss: 0.1052 - val_accuracy: 0.9801\n",
            "Epoch 13/20\n",
            "1216/1216 [==============================] - 39s 32ms/step - loss: 0.0281 - accuracy: 0.9919 - val_loss: 0.1101 - val_accuracy: 0.9759\n",
            "Epoch 14/20\n",
            "1216/1216 [==============================] - 39s 32ms/step - loss: 0.0315 - accuracy: 0.9905 - val_loss: 0.0630 - val_accuracy: 0.9861\n",
            "Epoch 15/20\n",
            "1216/1216 [==============================] - 39s 32ms/step - loss: 0.0226 - accuracy: 0.9933 - val_loss: 0.0708 - val_accuracy: 0.9849\n",
            "Epoch 16/20\n",
            "1216/1216 [==============================] - 39s 32ms/step - loss: 0.0172 - accuracy: 0.9943 - val_loss: 0.0715 - val_accuracy: 0.9848\n",
            "Epoch 17/20\n",
            "1216/1216 [==============================] - 39s 32ms/step - loss: 0.0180 - accuracy: 0.9941 - val_loss: 0.0963 - val_accuracy: 0.9810\n",
            "Epoch 18/20\n",
            "1216/1216 [==============================] - 39s 32ms/step - loss: 0.0163 - accuracy: 0.9954 - val_loss: 0.0793 - val_accuracy: 0.9839\n",
            "Epoch 19/20\n",
            "1216/1216 [==============================] - 39s 32ms/step - loss: 0.0176 - accuracy: 0.9944 - val_loss: 0.0659 - val_accuracy: 0.9885\n",
            "Epoch 20/20\n",
            "1216/1216 [==============================] - 39s 32ms/step - loss: 0.0135 - accuracy: 0.9961 - val_loss: 0.1126 - val_accuracy: 0.9812\n",
            "INFO:tensorflow:Assets written to: final_models/5anomaly-classifier2/assets\n",
            "Model 2 saved\n",
            "{0: 0, 1: 1, 2: 2, 4: 3, 6: 4, 7: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(38771,)\n",
            "{0: 0, 1: 1, 2: 2, 4: 3, 6: 4, 7: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9677,)\n",
            "Epoch 1/20\n",
            "1212/1212 [==============================] - 40s 32ms/step - loss: 6.6274 - accuracy: 0.8436 - val_loss: 0.2819 - val_accuracy: 0.9577\n",
            "Epoch 2/20\n",
            "1212/1212 [==============================] - 39s 32ms/step - loss: 0.2436 - accuracy: 0.9676 - val_loss: 0.1618 - val_accuracy: 0.9607\n",
            "Epoch 3/20\n",
            "1212/1212 [==============================] - 39s 32ms/step - loss: 0.0673 - accuracy: 0.9824 - val_loss: 0.2264 - val_accuracy: 0.9516\n",
            "Epoch 4/20\n",
            "1212/1212 [==============================] - 39s 32ms/step - loss: 0.0592 - accuracy: 0.9818 - val_loss: 0.4198 - val_accuracy: 0.9104\n",
            "Epoch 5/20\n",
            "1212/1212 [==============================] - 39s 32ms/step - loss: 0.0527 - accuracy: 0.9850 - val_loss: 0.3504 - val_accuracy: 0.9242\n",
            "Epoch 6/20\n",
            "1212/1212 [==============================] - 39s 32ms/step - loss: 0.0533 - accuracy: 0.9840 - val_loss: 0.2288 - val_accuracy: 0.9580\n",
            "Epoch 7/20\n",
            "1212/1212 [==============================] - 39s 32ms/step - loss: 0.0509 - accuracy: 0.9842 - val_loss: 0.0867 - val_accuracy: 0.9753\n",
            "Epoch 8/20\n",
            "1212/1212 [==============================] - 39s 32ms/step - loss: 0.0496 - accuracy: 0.9863 - val_loss: 0.0841 - val_accuracy: 0.9783\n",
            "Epoch 9/20\n",
            "1212/1212 [==============================] - 39s 32ms/step - loss: 0.0404 - accuracy: 0.9868 - val_loss: 0.0862 - val_accuracy: 0.9759\n",
            "Epoch 10/20\n",
            "1212/1212 [==============================] - 39s 32ms/step - loss: 0.0371 - accuracy: 0.9885 - val_loss: 0.0733 - val_accuracy: 0.9817\n",
            "Epoch 11/20\n",
            "1212/1212 [==============================] - 39s 32ms/step - loss: 0.0349 - accuracy: 0.9890 - val_loss: 0.0700 - val_accuracy: 0.9825\n",
            "Epoch 12/20\n",
            "1212/1212 [==============================] - 39s 32ms/step - loss: 0.0274 - accuracy: 0.9914 - val_loss: 0.0886 - val_accuracy: 0.9780\n",
            "Epoch 13/20\n",
            "1212/1212 [==============================] - 39s 32ms/step - loss: 0.0282 - accuracy: 0.9906 - val_loss: 0.0654 - val_accuracy: 0.9847\n",
            "Epoch 14/20\n",
            "1212/1212 [==============================] - 39s 32ms/step - loss: 0.0261 - accuracy: 0.9921 - val_loss: 0.0656 - val_accuracy: 0.9853\n",
            "Epoch 15/20\n",
            "1212/1212 [==============================] - 39s 32ms/step - loss: 0.0252 - accuracy: 0.9919 - val_loss: 0.1068 - val_accuracy: 0.9798\n",
            "Epoch 16/20\n",
            "1212/1212 [==============================] - 39s 32ms/step - loss: 0.0219 - accuracy: 0.9933 - val_loss: 0.0650 - val_accuracy: 0.9859\n",
            "Epoch 17/20\n",
            "1212/1212 [==============================] - 39s 32ms/step - loss: 0.0220 - accuracy: 0.9934 - val_loss: 0.1152 - val_accuracy: 0.9788\n",
            "Epoch 18/20\n",
            "1212/1212 [==============================] - 39s 32ms/step - loss: 0.0181 - accuracy: 0.9935 - val_loss: 0.0724 - val_accuracy: 0.9851\n",
            "Epoch 19/20\n",
            "1212/1212 [==============================] - 39s 32ms/step - loss: 0.0186 - accuracy: 0.9941 - val_loss: 0.0828 - val_accuracy: 0.9831\n",
            "Epoch 20/20\n",
            "1212/1212 [==============================] - 39s 32ms/step - loss: 0.0133 - accuracy: 0.9954 - val_loss: 0.1225 - val_accuracy: 0.9800\n",
            "INFO:tensorflow:Assets written to: final_models/5anomaly-classifier3/assets\n",
            "Model 3 saved\n",
            "{0: 0, 1: 1, 2: 2, 3: 3, 6: 4, 7: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(39017,)\n",
            "{0: 0, 1: 1, 2: 2, 3: 3, 6: 4, 7: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9720,)\n",
            "Epoch 1/20\n",
            "1220/1220 [==============================] - 40s 32ms/step - loss: 4.6302 - accuracy: 0.8513 - val_loss: 0.5443 - val_accuracy: 0.9063\n",
            "Epoch 2/20\n",
            "1220/1220 [==============================] - 39s 32ms/step - loss: 0.1395 - accuracy: 0.9752 - val_loss: 0.0801 - val_accuracy: 0.9787\n",
            "Epoch 3/20\n",
            "1220/1220 [==============================] - 39s 32ms/step - loss: 0.0622 - accuracy: 0.9829 - val_loss: 0.1073 - val_accuracy: 0.9729\n",
            "Epoch 4/20\n",
            "1220/1220 [==============================] - 39s 32ms/step - loss: 0.0576 - accuracy: 0.9834 - val_loss: 0.0826 - val_accuracy: 0.9802\n",
            "Epoch 5/20\n",
            "1220/1220 [==============================] - 39s 32ms/step - loss: 0.0557 - accuracy: 0.9839 - val_loss: 0.0857 - val_accuracy: 0.9756\n",
            "Epoch 6/20\n",
            "1220/1220 [==============================] - 39s 32ms/step - loss: 0.0500 - accuracy: 0.9842 - val_loss: 0.2165 - val_accuracy: 0.9577\n",
            "Epoch 7/20\n",
            "1220/1220 [==============================] - 39s 32ms/step - loss: 0.0442 - accuracy: 0.9856 - val_loss: 0.1234 - val_accuracy: 0.9733\n",
            "Epoch 8/20\n",
            "1220/1220 [==============================] - 39s 32ms/step - loss: 0.0416 - accuracy: 0.9878 - val_loss: 0.1510 - val_accuracy: 0.9674\n",
            "Epoch 9/20\n",
            "1220/1220 [==============================] - 39s 32ms/step - loss: 0.0446 - accuracy: 0.9872 - val_loss: 0.3003 - val_accuracy: 0.9578\n",
            "Epoch 10/20\n",
            "1220/1220 [==============================] - 39s 32ms/step - loss: 0.0316 - accuracy: 0.9904 - val_loss: 0.0559 - val_accuracy: 0.9870\n",
            "Epoch 11/20\n",
            "1220/1220 [==============================] - 39s 32ms/step - loss: 0.0305 - accuracy: 0.9912 - val_loss: 0.0617 - val_accuracy: 0.9845\n",
            "Epoch 12/20\n",
            "1220/1220 [==============================] - 39s 32ms/step - loss: 0.0257 - accuracy: 0.9919 - val_loss: 0.0840 - val_accuracy: 0.9791\n",
            "Epoch 13/20\n",
            "1220/1220 [==============================] - 39s 32ms/step - loss: 0.0194 - accuracy: 0.9939 - val_loss: 0.1757 - val_accuracy: 0.9618\n",
            "Epoch 14/20\n",
            "1220/1220 [==============================] - 39s 32ms/step - loss: 0.0207 - accuracy: 0.9932 - val_loss: 0.1724 - val_accuracy: 0.9682\n",
            "Epoch 15/20\n",
            "1220/1220 [==============================] - 39s 32ms/step - loss: 0.0240 - accuracy: 0.9921 - val_loss: 0.0823 - val_accuracy: 0.9833\n",
            "Epoch 16/20\n",
            "1220/1220 [==============================] - 39s 32ms/step - loss: 0.0152 - accuracy: 0.9949 - val_loss: 0.0683 - val_accuracy: 0.9846\n",
            "Epoch 17/20\n",
            "1220/1220 [==============================] - 39s 32ms/step - loss: 0.0172 - accuracy: 0.9949 - val_loss: 0.0729 - val_accuracy: 0.9842\n",
            "Epoch 18/20\n",
            "1220/1220 [==============================] - 39s 32ms/step - loss: 0.0172 - accuracy: 0.9950 - val_loss: 0.1156 - val_accuracy: 0.9809\n",
            "Epoch 19/20\n",
            "1220/1220 [==============================] - 39s 32ms/step - loss: 0.0162 - accuracy: 0.9951 - val_loss: 0.1090 - val_accuracy: 0.9782\n",
            "Epoch 20/20\n",
            "1220/1220 [==============================] - 39s 32ms/step - loss: 0.0127 - accuracy: 0.9963 - val_loss: 0.0656 - val_accuracy: 0.9872\n",
            "INFO:tensorflow:Assets written to: final_models/5anomaly-classifier4/assets\n",
            "Model 4 saved\n",
            "{0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 7: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(38942,)\n",
            "{0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 7: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9719,)\n",
            "Epoch 1/20\n",
            "1217/1217 [==============================] - 40s 32ms/step - loss: 5.5482 - accuracy: 0.8421 - val_loss: 0.2882 - val_accuracy: 0.9538\n",
            "Epoch 2/20\n",
            "1217/1217 [==============================] - 39s 32ms/step - loss: 0.1276 - accuracy: 0.9749 - val_loss: 0.2432 - val_accuracy: 0.9505\n",
            "Epoch 3/20\n",
            "1217/1217 [==============================] - 39s 32ms/step - loss: 0.0633 - accuracy: 0.9810 - val_loss: 0.2326 - val_accuracy: 0.9476\n",
            "Epoch 4/20\n",
            "1217/1217 [==============================] - 39s 32ms/step - loss: 0.0697 - accuracy: 0.9807 - val_loss: 0.1480 - val_accuracy: 0.9600\n",
            "Epoch 5/20\n",
            "1217/1217 [==============================] - 39s 32ms/step - loss: 0.0658 - accuracy: 0.9802 - val_loss: 0.2182 - val_accuracy: 0.9474\n",
            "Epoch 6/20\n",
            "1217/1217 [==============================] - 39s 32ms/step - loss: 0.0560 - accuracy: 0.9835 - val_loss: 0.0938 - val_accuracy: 0.9738\n",
            "Epoch 7/20\n",
            "1217/1217 [==============================] - 39s 32ms/step - loss: 0.0515 - accuracy: 0.9840 - val_loss: 0.0880 - val_accuracy: 0.9781\n",
            "Epoch 8/20\n",
            "1217/1217 [==============================] - 39s 32ms/step - loss: 0.0462 - accuracy: 0.9858 - val_loss: 0.0994 - val_accuracy: 0.9723\n",
            "Epoch 9/20\n",
            "1217/1217 [==============================] - 39s 32ms/step - loss: 0.0440 - accuracy: 0.9859 - val_loss: 0.1091 - val_accuracy: 0.9744\n",
            "Epoch 10/20\n",
            "1217/1217 [==============================] - 39s 32ms/step - loss: 0.0402 - accuracy: 0.9878 - val_loss: 0.1173 - val_accuracy: 0.9687\n",
            "Epoch 11/20\n",
            "1217/1217 [==============================] - 39s 32ms/step - loss: 0.0321 - accuracy: 0.9901 - val_loss: 0.0895 - val_accuracy: 0.9825\n",
            "Epoch 12/20\n",
            "1217/1217 [==============================] - 39s 32ms/step - loss: 0.0296 - accuracy: 0.9911 - val_loss: 0.0667 - val_accuracy: 0.9833\n",
            "Epoch 13/20\n",
            "1217/1217 [==============================] - 39s 32ms/step - loss: 0.0295 - accuracy: 0.9910 - val_loss: 0.0621 - val_accuracy: 0.9838\n",
            "Epoch 14/20\n",
            "1217/1217 [==============================] - 39s 32ms/step - loss: 0.0230 - accuracy: 0.9927 - val_loss: 0.1180 - val_accuracy: 0.9767\n",
            "Epoch 15/20\n",
            "1217/1217 [==============================] - 39s 32ms/step - loss: 0.0274 - accuracy: 0.9918 - val_loss: 0.0930 - val_accuracy: 0.9796\n",
            "Epoch 16/20\n",
            "1217/1217 [==============================] - 39s 32ms/step - loss: 0.0188 - accuracy: 0.9941 - val_loss: 0.0659 - val_accuracy: 0.9857\n",
            "Epoch 17/20\n",
            "1217/1217 [==============================] - 39s 32ms/step - loss: 0.0167 - accuracy: 0.9953 - val_loss: 0.0641 - val_accuracy: 0.9860\n",
            "Epoch 18/20\n",
            "1217/1217 [==============================] - 39s 32ms/step - loss: 0.0220 - accuracy: 0.9938 - val_loss: 0.0675 - val_accuracy: 0.9862\n",
            "Epoch 19/20\n",
            "1217/1217 [==============================] - 39s 32ms/step - loss: 0.0159 - accuracy: 0.9956 - val_loss: 0.0687 - val_accuracy: 0.9851\n",
            "Epoch 20/20\n",
            "1217/1217 [==============================] - 39s 32ms/step - loss: 0.0169 - accuracy: 0.9948 - val_loss: 0.0894 - val_accuracy: 0.9824\n",
            "INFO:tensorflow:Assets written to: final_models/5anomaly-classifier5/assets\n",
            "Model 5 saved\n",
            "{0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 6: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(38717,)\n",
            "{0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 6: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9597,)\n",
            "Epoch 1/20\n",
            "1210/1210 [==============================] - 40s 32ms/step - loss: 4.9014 - accuracy: 0.8238 - val_loss: 0.2076 - val_accuracy: 0.9653\n",
            "Epoch 2/20\n",
            "1210/1210 [==============================] - 39s 32ms/step - loss: 0.1318 - accuracy: 0.9753 - val_loss: 0.0958 - val_accuracy: 0.9772\n",
            "Epoch 3/20\n",
            "1210/1210 [==============================] - 39s 32ms/step - loss: 0.0683 - accuracy: 0.9835 - val_loss: 0.1672 - val_accuracy: 0.9658\n",
            "Epoch 4/20\n",
            "1210/1210 [==============================] - 39s 32ms/step - loss: 0.0559 - accuracy: 0.9839 - val_loss: 0.2199 - val_accuracy: 0.9551\n",
            "Epoch 5/20\n",
            "1210/1210 [==============================] - 39s 32ms/step - loss: 0.0587 - accuracy: 0.9834 - val_loss: 0.0783 - val_accuracy: 0.9799\n",
            "Epoch 6/20\n",
            "1210/1210 [==============================] - 39s 32ms/step - loss: 0.0516 - accuracy: 0.9844 - val_loss: 0.1162 - val_accuracy: 0.9773\n",
            "Epoch 7/20\n",
            "1210/1210 [==============================] - 39s 32ms/step - loss: 0.0491 - accuracy: 0.9860 - val_loss: 0.0596 - val_accuracy: 0.9851\n",
            "Epoch 8/20\n",
            "1210/1210 [==============================] - 39s 32ms/step - loss: 0.0436 - accuracy: 0.9870 - val_loss: 0.1919 - val_accuracy: 0.9617\n",
            "Epoch 9/20\n",
            "1210/1210 [==============================] - 39s 32ms/step - loss: 0.0339 - accuracy: 0.9891 - val_loss: 0.1960 - val_accuracy: 0.9627\n",
            "Epoch 10/20\n",
            "1210/1210 [==============================] - 39s 32ms/step - loss: 0.0346 - accuracy: 0.9896 - val_loss: 0.1091 - val_accuracy: 0.9786\n",
            "Epoch 11/20\n",
            "1210/1210 [==============================] - 39s 32ms/step - loss: 0.0285 - accuracy: 0.9918 - val_loss: 0.1463 - val_accuracy: 0.9709\n",
            "Epoch 12/20\n",
            "1210/1210 [==============================] - 39s 32ms/step - loss: 0.0296 - accuracy: 0.9909 - val_loss: 0.0445 - val_accuracy: 0.9897\n",
            "Epoch 13/20\n",
            "1210/1210 [==============================] - 39s 32ms/step - loss: 0.0223 - accuracy: 0.9931 - val_loss: 0.0755 - val_accuracy: 0.9815\n",
            "Epoch 14/20\n",
            "1210/1210 [==============================] - 39s 32ms/step - loss: 0.0247 - accuracy: 0.9927 - val_loss: 0.0741 - val_accuracy: 0.9842\n",
            "Epoch 15/20\n",
            "1210/1210 [==============================] - 39s 32ms/step - loss: 0.0188 - accuracy: 0.9937 - val_loss: 0.1241 - val_accuracy: 0.9751\n",
            "Epoch 16/20\n",
            "1210/1210 [==============================] - 39s 32ms/step - loss: 0.0190 - accuracy: 0.9940 - val_loss: 0.1373 - val_accuracy: 0.9737\n",
            "Epoch 17/20\n",
            "1210/1210 [==============================] - 39s 32ms/step - loss: 0.0175 - accuracy: 0.9954 - val_loss: 0.1079 - val_accuracy: 0.9762\n",
            "Epoch 18/20\n",
            "1210/1210 [==============================] - 39s 32ms/step - loss: 0.0171 - accuracy: 0.9939 - val_loss: 0.0684 - val_accuracy: 0.9868\n",
            "Epoch 19/20\n",
            "1210/1210 [==============================] - 39s 32ms/step - loss: 0.0151 - accuracy: 0.9951 - val_loss: 0.0802 - val_accuracy: 0.9836\n",
            "Epoch 20/20\n",
            "1210/1210 [==============================] - 39s 32ms/step - loss: 0.0151 - accuracy: 0.9952 - val_loss: 0.2396 - val_accuracy: 0.9623\n",
            "INFO:tensorflow:Assets written to: final_models/5anomaly-classifier6/assets\n",
            "Model 6 saved\n",
            "{0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 6: 5, 7: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(38992,)\n",
            "{0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 6: 5, 7: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9736,)\n",
            "Epoch 1/20\n",
            "1219/1219 [==============================] - 40s 32ms/step - loss: 4.4336 - accuracy: 0.8559 - val_loss: 0.3565 - val_accuracy: 0.9256\n",
            "Epoch 2/20\n",
            "1219/1219 [==============================] - 39s 32ms/step - loss: 0.1336 - accuracy: 0.9723 - val_loss: 0.2708 - val_accuracy: 0.9633\n",
            "Epoch 3/20\n",
            "1219/1219 [==============================] - 39s 32ms/step - loss: 0.0872 - accuracy: 0.9762 - val_loss: 0.1733 - val_accuracy: 0.9618\n",
            "Epoch 4/20\n",
            "1219/1219 [==============================] - 39s 32ms/step - loss: 0.0663 - accuracy: 0.9818 - val_loss: 0.0971 - val_accuracy: 0.9774\n",
            "Epoch 5/20\n",
            "1219/1219 [==============================] - 39s 32ms/step - loss: 0.0645 - accuracy: 0.9820 - val_loss: 0.1245 - val_accuracy: 0.9721\n",
            "Epoch 6/20\n",
            "1219/1219 [==============================] - 39s 32ms/step - loss: 0.0601 - accuracy: 0.9831 - val_loss: 0.0442 - val_accuracy: 0.9871\n",
            "Epoch 7/20\n",
            "1219/1219 [==============================] - 39s 32ms/step - loss: 0.0466 - accuracy: 0.9865 - val_loss: 0.0686 - val_accuracy: 0.9803\n",
            "Epoch 8/20\n",
            "1219/1219 [==============================] - 39s 32ms/step - loss: 0.0450 - accuracy: 0.9875 - val_loss: 0.0698 - val_accuracy: 0.9799\n",
            "Epoch 9/20\n",
            "1219/1219 [==============================] - 39s 32ms/step - loss: 0.0401 - accuracy: 0.9876 - val_loss: 0.0587 - val_accuracy: 0.9844\n",
            "Epoch 10/20\n",
            "1219/1219 [==============================] - 39s 32ms/step - loss: 0.0399 - accuracy: 0.9882 - val_loss: 0.0881 - val_accuracy: 0.9798\n",
            "Epoch 11/20\n",
            "1219/1219 [==============================] - 39s 32ms/step - loss: 0.0323 - accuracy: 0.9901 - val_loss: 0.0588 - val_accuracy: 0.9863\n",
            "Epoch 12/20\n",
            "1219/1219 [==============================] - 39s 32ms/step - loss: 0.0303 - accuracy: 0.9911 - val_loss: 0.0800 - val_accuracy: 0.9803\n",
            "Epoch 13/20\n",
            "1219/1219 [==============================] - 39s 32ms/step - loss: 0.0255 - accuracy: 0.9914 - val_loss: 0.0845 - val_accuracy: 0.9829\n",
            "Epoch 14/20\n",
            "1219/1219 [==============================] - 39s 32ms/step - loss: 0.0232 - accuracy: 0.9932 - val_loss: 0.0640 - val_accuracy: 0.9864\n",
            "Epoch 15/20\n",
            "1219/1219 [==============================] - 39s 32ms/step - loss: 0.0175 - accuracy: 0.9947 - val_loss: 0.0596 - val_accuracy: 0.9877\n",
            "Epoch 16/20\n",
            "1219/1219 [==============================] - 39s 32ms/step - loss: 0.0213 - accuracy: 0.9933 - val_loss: 0.0782 - val_accuracy: 0.9839\n",
            "Epoch 17/20\n",
            "1219/1219 [==============================] - 39s 32ms/step - loss: 0.0158 - accuracy: 0.9951 - val_loss: 0.0687 - val_accuracy: 0.9841\n",
            "Epoch 18/20\n",
            "1219/1219 [==============================] - 39s 32ms/step - loss: 0.0184 - accuracy: 0.9942 - val_loss: 0.0473 - val_accuracy: 0.9886\n",
            "Epoch 19/20\n",
            "1219/1219 [==============================] - 39s 32ms/step - loss: 0.0154 - accuracy: 0.9951 - val_loss: 0.0838 - val_accuracy: 0.9871\n",
            "Epoch 20/20\n",
            "1219/1219 [==============================] - 39s 32ms/step - loss: 0.0155 - accuracy: 0.9951 - val_loss: 0.0656 - val_accuracy: 0.9876\n",
            "INFO:tensorflow:Assets written to: final_models/5anomaly-classifier7/assets\n",
            "Model 7 saved\n",
            "{0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 6: 5, 7: 6, 8: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(38928,)\n",
            "{0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 6: 5, 7: 6, 8: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9702,)\n",
            "Epoch 1/20\n",
            "1217/1217 [==============================] - 40s 32ms/step - loss: 4.0699 - accuracy: 0.8612 - val_loss: 0.1930 - val_accuracy: 0.9641\n",
            "Epoch 2/20\n",
            "1217/1217 [==============================] - 39s 32ms/step - loss: 0.1340 - accuracy: 0.9746 - val_loss: 0.1358 - val_accuracy: 0.9661\n",
            "Epoch 3/20\n",
            "1217/1217 [==============================] - 39s 32ms/step - loss: 0.0584 - accuracy: 0.9827 - val_loss: 0.0829 - val_accuracy: 0.9792\n",
            "Epoch 4/20\n",
            "1217/1217 [==============================] - 39s 32ms/step - loss: 0.0520 - accuracy: 0.9847 - val_loss: 0.2246 - val_accuracy: 0.9555\n",
            "Epoch 5/20\n",
            "1217/1217 [==============================] - 39s 32ms/step - loss: 0.0436 - accuracy: 0.9871 - val_loss: 0.1378 - val_accuracy: 0.9718\n",
            "Epoch 6/20\n",
            "1217/1217 [==============================] - 39s 32ms/step - loss: 0.0484 - accuracy: 0.9860 - val_loss: 0.0638 - val_accuracy: 0.9866\n",
            "Epoch 7/20\n",
            "1217/1217 [==============================] - 39s 32ms/step - loss: 0.0436 - accuracy: 0.9878 - val_loss: 0.1779 - val_accuracy: 0.9643\n",
            "Epoch 8/20\n",
            "1217/1217 [==============================] - 39s 32ms/step - loss: 0.0379 - accuracy: 0.9885 - val_loss: 0.0771 - val_accuracy: 0.9835\n",
            "Epoch 9/20\n",
            " 659/1217 [===============>..............] - ETA: 16s - loss: 0.0337 - accuracy: 0.9901"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F33Z6_Uz_zQM",
        "outputId": "8ec90940-8e73-4cb6-b278-f8bdbd872f5a"
      },
      "source": [
        "#train_data8 = get_train_data(8, new_train_images)\n",
        "train_imgs8, train_lbls8 = get_train_data(9, new_train_images, new_train_labels)\n",
        "val_imgs8, val_lbls8 = get_train_data(9, new_val_images, new_val_labels)\n",
        "class_8 = model8.build()\n",
        "#model8.train(train_data8)\n",
        "model8.train2(train_imgs8, train_lbls8, val_imgs8, val_lbls8)\n",
        "model8.save_model(\"final_models/5anomaly-classifier8\")\n",
        "print('Model 8 saved')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 6: 5, 7: 6, 8: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(38928,)\n",
            "{0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 6: 5, 7: 6, 8: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9702,)\n",
            "Epoch 1/20\n",
            "1217/1217 [==============================] - 45s 31ms/step - loss: 5.0705 - accuracy: 0.8361 - val_loss: 0.2271 - val_accuracy: 0.9683\n",
            "Epoch 2/20\n",
            "1217/1217 [==============================] - 37s 31ms/step - loss: 0.1265 - accuracy: 0.9743 - val_loss: 0.1462 - val_accuracy: 0.9758\n",
            "Epoch 3/20\n",
            "1217/1217 [==============================] - 38s 31ms/step - loss: 0.1039 - accuracy: 0.9764 - val_loss: 0.1703 - val_accuracy: 0.9723\n",
            "Epoch 4/20\n",
            "1217/1217 [==============================] - 38s 31ms/step - loss: 0.0832 - accuracy: 0.9792 - val_loss: 0.1113 - val_accuracy: 0.9743\n",
            "Epoch 5/20\n",
            "1217/1217 [==============================] - 39s 32ms/step - loss: 0.0536 - accuracy: 0.9845 - val_loss: 0.0985 - val_accuracy: 0.9741\n",
            "Epoch 6/20\n",
            "1217/1217 [==============================] - 39s 32ms/step - loss: 0.0568 - accuracy: 0.9835 - val_loss: 0.0822 - val_accuracy: 0.9784\n",
            "Epoch 7/20\n",
            "1217/1217 [==============================] - 39s 32ms/step - loss: 0.0450 - accuracy: 0.9868 - val_loss: 0.0589 - val_accuracy: 0.9850\n",
            "Epoch 8/20\n",
            "1217/1217 [==============================] - 39s 32ms/step - loss: 0.0381 - accuracy: 0.9885 - val_loss: 0.2734 - val_accuracy: 0.9483\n",
            "Epoch 9/20\n",
            "1217/1217 [==============================] - 39s 32ms/step - loss: 0.0361 - accuracy: 0.9887 - val_loss: 0.0737 - val_accuracy: 0.9833\n",
            "Epoch 10/20\n",
            "1217/1217 [==============================] - 39s 32ms/step - loss: 0.0315 - accuracy: 0.9900 - val_loss: 0.1215 - val_accuracy: 0.9730\n",
            "Epoch 11/20\n",
            "1217/1217 [==============================] - 39s 32ms/step - loss: 0.0253 - accuracy: 0.9921 - val_loss: 0.2535 - val_accuracy: 0.9521\n",
            "Epoch 12/20\n",
            "1217/1217 [==============================] - 39s 32ms/step - loss: 0.0283 - accuracy: 0.9909 - val_loss: 0.0495 - val_accuracy: 0.9891\n",
            "Epoch 13/20\n",
            "1217/1217 [==============================] - 39s 32ms/step - loss: 0.0232 - accuracy: 0.9929 - val_loss: 0.0450 - val_accuracy: 0.9878\n",
            "Epoch 14/20\n",
            "1217/1217 [==============================] - 39s 32ms/step - loss: 0.0259 - accuracy: 0.9915 - val_loss: 0.0547 - val_accuracy: 0.9885\n",
            "Epoch 15/20\n",
            "1217/1217 [==============================] - 39s 32ms/step - loss: 0.0194 - accuracy: 0.9942 - val_loss: 0.0485 - val_accuracy: 0.9880\n",
            "Epoch 16/20\n",
            "1217/1217 [==============================] - 39s 32ms/step - loss: 0.0163 - accuracy: 0.9951 - val_loss: 0.0772 - val_accuracy: 0.9856\n",
            "Epoch 17/20\n",
            "1217/1217 [==============================] - 39s 32ms/step - loss: 0.0149 - accuracy: 0.9956 - val_loss: 0.1375 - val_accuracy: 0.9790\n",
            "Epoch 18/20\n",
            "1217/1217 [==============================] - 39s 32ms/step - loss: 0.0171 - accuracy: 0.9947 - val_loss: 0.0652 - val_accuracy: 0.9868\n",
            "Epoch 19/20\n",
            "1217/1217 [==============================] - 39s 32ms/step - loss: 0.0151 - accuracy: 0.9954 - val_loss: 0.0625 - val_accuracy: 0.9856\n",
            "Epoch 20/20\n",
            "1217/1217 [==============================] - 39s 32ms/step - loss: 0.0108 - accuracy: 0.9965 - val_loss: 0.0954 - val_accuracy: 0.9833\n",
            "INFO:tensorflow:Assets written to: final_models/5anomaly-classifier8/assets\n",
            "Model 8 saved\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kaG0ZKCNSKaW"
      },
      "source": [
        "class_0 = model0.load_model(\"final_models/5anomaly-classifier0\")\n",
        "class_1 = model1.load_model(\"final_models/5anomaly-classifier1\")\n",
        "class_2 = model2.load_model(\"final_models/5anomaly-classifier2\")\n",
        "class_3 = model3.load_model(\"final_models/5anomaly-classifier3\")\n",
        "class_4 = model4.load_model(\"final_models/5anomaly-classifier4\")\n",
        "class_5 = model5.load_model(\"final_models/5anomaly-classifier5\")\n",
        "class_6 = model6.load_model(\"final_models/5anomaly-classifier6\")\n",
        "class_7 = model7.load_model(\"final_models/5anomaly-classifier7\")\n",
        "class_8 = model8.load_model(\"final_models/5anomaly-classifier8\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sQbcMQLKSKaX",
        "outputId": "424c4866-1803-4ada-c85d-ae7183823950"
      },
      "source": [
        "layer_name_list = []\n",
        "\n",
        "layer_name_list.append(class_0.layers[-2:][0].name)\n",
        "layer_name_list.append(class_1.layers[-2:][0].name)\n",
        "layer_name_list.append(class_2.layers[-2:][0].name)\n",
        "layer_name_list.append(class_3.layers[-2:][0].name)\n",
        "layer_name_list.append(class_4.layers[-2:][0].name)\n",
        "layer_name_list.append(class_5.layers[-2:][0].name)\n",
        "layer_name_list.append(class_6.layers[-2:][0].name)\n",
        "layer_name_list.append(class_7.layers[-2:][0].name)\n",
        "layer_name_list.append(class_8.layers[-2:][0].name)\n",
        "\n",
        "print(layer_name_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['dense_93', 'dense_95', 'dense_97', 'dense_99', 'dense_101', 'dense_103', 'dense_105', 'dense_107', 'dense_19']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PiT1-eHJSKaX"
      },
      "source": [
        "from keras import Model\n",
        "model_dict = {}\n",
        "model_output0 = class_0.get_layer(layer_name_list[0]).output\n",
        "m0 = Model(inputs=class_0.input, outputs=model_output0)\n",
        "model_dict[0] = m0\n",
        "\n",
        "model_output1 = class_1.get_layer(layer_name_list[1]).output\n",
        "m1 = Model(inputs=class_1.input, outputs=model_output1)\n",
        "model_dict[1] = m1\n",
        "\n",
        "model_output2 = class_2.get_layer(layer_name_list[2]).output\n",
        "m2 = Model(inputs=class_2.input, outputs=model_output2)\n",
        "model_dict[2] = m2\n",
        "\n",
        "model_output3 = class_3.get_layer(layer_name_list[3]).output\n",
        "m3 = Model(inputs=class_3.input, outputs=model_output3)\n",
        "model_dict[3] = m3\n",
        "\n",
        "model_output4 = class_4.get_layer(layer_name_list[4]).output\n",
        "m4 = Model(inputs=class_4.input, outputs=model_output4)\n",
        "model_dict[4] = m4\n",
        "\n",
        "model_output5 = class_5.get_layer(layer_name_list[5]).output\n",
        "m5 = Model(inputs=class_5.input, outputs=model_output5)\n",
        "model_dict[5] = m5\n",
        "\n",
        "model_output6 = class_6.get_layer(layer_name_list[6]).output\n",
        "m6 = Model(inputs=class_6.input, outputs=model_output6)\n",
        "model_dict[6] = m6\n",
        "\n",
        "model_output7 = class_7.get_layer(layer_name_list[7]).output\n",
        "m7 = Model(inputs=class_7.input, outputs=model_output7)\n",
        "model_dict[7] = m7\n",
        "\n",
        "model_output8 = class_8.get_layer(layer_name_list[8]).output\n",
        "m8 = Model(inputs=class_8.input, outputs=model_output8)\n",
        "model_dict[8] = m8\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QWB_6gu8SKaY",
        "outputId": "f3755e80-0d17-4f05-b820-780c38990409"
      },
      "source": [
        "set(new_val_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0, 1, 2, 3, 4, 6, 7, 8, 9}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mVgVaAu8SKaY",
        "outputId": "1131211c-12ad-4439-ddec-53f829966514"
      },
      "source": [
        "temp_val = []\n",
        "y_pred = []\n",
        "labels = set(new_val_labels)\n",
        "for i, lo in zip(range(9), labels):\n",
        "  m = model_dict[i]\n",
        "  val_imgs_, val_lbls_ = get_train_data(lo, new_val_images, new_val_labels)\n",
        "  y_p = m.predict(val_imgs_)\n",
        "  y_pred.append(y_p)\n",
        "  temp = temp_cal(y_p, val_lbls_)\n",
        "  temp_val.append(temp)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{1: 0, 2: 1, 3: 2, 4: 3, 6: 4, 7: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9721,)\n",
            "Temperature Initial value: 1.0\n",
            "Temperature Final value: 2.056544065475464\n",
            "{0: 0, 2: 1, 3: 2, 4: 3, 6: 4, 7: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9574,)\n",
            "Temperature Initial value: 1.0\n",
            "Temperature Final value: 2.1163601875305176\n",
            "{0: 0, 1: 1, 3: 2, 4: 3, 6: 4, 7: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9722,)\n",
            "Temperature Initial value: 1.0\n",
            "Temperature Final value: 2.3622562885284424\n",
            "{0: 0, 1: 1, 2: 2, 4: 3, 6: 4, 7: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9677,)\n",
            "Temperature Initial value: 1.0\n",
            "Temperature Final value: 2.390667676925659\n",
            "{0: 0, 1: 1, 2: 2, 3: 3, 6: 4, 7: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9720,)\n",
            "Temperature Initial value: 1.0\n",
            "Temperature Final value: 2.2536275386810303\n",
            "{0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 7: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9719,)\n",
            "Temperature Initial value: 1.0\n",
            "Temperature Final value: 2.30367112159729\n",
            "{0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 6: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9597,)\n",
            "Temperature Initial value: 1.0\n",
            "Temperature Final value: 2.5086586475372314\n",
            "{0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 6: 5, 7: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9736,)\n",
            "Temperature Initial value: 1.0\n",
            "Temperature Final value: 2.2106051445007324\n",
            "{0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 6: 5, 7: 6, 8: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9702,)\n",
            "Temperature Initial value: 1.0\n",
            "Temperature Final value: 2.2668819427490234\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dWzRyTCiSKaZ",
        "outputId": "616068fd-d962-4008-a12e-e08c9be19296"
      },
      "source": [
        "temp_val"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=2.056544>,\n",
              " <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=2.1163602>,\n",
              " <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=2.3622563>,\n",
              " <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=2.3906677>,\n",
              " <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=2.2536275>,\n",
              " <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=2.3036711>,\n",
              " <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=2.5086586>,\n",
              " <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=2.2106051>,\n",
              " <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=2.266882>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WvqZZODgSKaZ",
        "outputId": "dff5479b-a168-413a-fd6f-205c097d854e"
      },
      "source": [
        "from tqdm import tqdm\n",
        "avg = [0,0,0,0,0,0,0,0,0]\n",
        "count = [0,0,0,0,0,0,0,0,0]\n",
        "entropy_list = [0,0,0,0,0,0,0,0,0]\n",
        "for img, lbl in tqdm(zip(new_val_images,new_val_labels)):\n",
        "  img = img.reshape([-1, 28, 28, 1])\n",
        "  if not lbl == 0:\n",
        "    logits = model_dict[0](img)\n",
        "    logits = tf.math.divide(logits, temp_val[0])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e0 = entropy(pred[0])\n",
        "    entropy_list[0] = entropy_list[0] + e0\n",
        "    max_val0 = np.max(pred)\n",
        "    avg[0] = avg[0] + max_val0\n",
        "    count[0] = count[0] + 1\n",
        "  if not lbl == 1:\n",
        "    logits = model_dict[1](img)\n",
        "    logits = tf.math.divide(logits, temp_val[1])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e1 = entropy(pred[0])\n",
        "    entropy_list[1] = entropy_list[1] + e1\n",
        "    max_val1 = np.max(pred)\n",
        "    avg[1] = avg[1] + max_val1\n",
        "    count[1] = count[1] + 1\n",
        "  if not lbl == 2:\n",
        "    logits = model_dict[2](img)\n",
        "    logits = tf.math.divide(logits, temp_val[2])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e2 = entropy(pred[0])\n",
        "    entropy_list[2] = entropy_list[2] + e2\n",
        "    max_val2 = np.max(pred)\n",
        "    avg[2] = avg[2] + max_val2\n",
        "    count[2] = count[2] + 1\n",
        "  if not lbl == 3:\n",
        "    logits = model_dict[3](img)\n",
        "    logits = tf.math.divide(logits, temp_val[3])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e3 = entropy(pred[0])\n",
        "    entropy_list[3] = entropy_list[3] + e3\n",
        "    max_val3 = np.max(pred)  \n",
        "    avg[3] = avg[3] + max_val3\n",
        "    count[3] = count[3] + 1\n",
        "  if not lbl == 4:\n",
        "    logits = model_dict[4](img)\n",
        "    logits = tf.math.divide(logits, temp_val[4])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e4 = entropy(pred[0])\n",
        "    entropy_list[4] = entropy_list[4] + e4\n",
        "    max_val4 = np.max(pred)\n",
        "    avg[4] = avg[4] + max_val4\n",
        "    count[4] = count[4] + 1\n",
        "  if not lbl == 6:\n",
        "    logits = model_dict[5](img)\n",
        "    logits = tf.math.divide(logits, temp_val[5])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e5 = entropy(pred[0])\n",
        "    entropy_list[5] = entropy_list[5] + e5\n",
        "    max_val5 = np.max(pred)\n",
        "    avg[5] = avg[5] + max_val5\n",
        "    count[5] = count[5] + 1\n",
        "  if not lbl == 7:\n",
        "    logits = model_dict[6](img)\n",
        "    logits = tf.math.divide(logits, temp_val[6])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e6 = entropy(pred[0])\n",
        "    entropy_list[6] = entropy_list[6] + e6\n",
        "    max_val6 = np.max(pred)\n",
        "    avg[6] = avg[6] + max_val6\n",
        "    count[6] = count[6] + 1\n",
        "  if not lbl == 8:\n",
        "    logits = model_dict[7](img)\n",
        "    logits = tf.math.divide(logits, temp_val[7])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e7 = entropy(pred[0])\n",
        "    entropy_list[7] = entropy_list[7] + e7\n",
        "    max_val7 = np.max(pred)\n",
        "    avg[7] = avg[7] + max_val7\n",
        "    count[7] = count[7] + 1\n",
        "  if not lbl == 9:\n",
        "    logits = model_dict[8](img)\n",
        "    logits = tf.math.divide(logits, temp_val[8])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e8 = entropy(pred[0])\n",
        "    entropy_list[8] = entropy_list[8] + e8\n",
        "    max_val8 = np.max(pred)\n",
        "    avg[8] = avg[8] + max_val8\n",
        "    count[8] = count[8] + 1\n",
        "\n",
        "print(avg)\n",
        "print(count)\n",
        "print(entropy_list)\n",
        "\n",
        "entropy_avg_t = [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]\n",
        "for i in range(9):\n",
        "  entropy_avg_t[i] = entropy_list[i]/count[i]\n",
        "\n",
        "entropy_value_t = 0.0\n",
        "for i in range(9):\n",
        "  entropy_value_t = entropy_value_t + entropy_avg_t[i]\n",
        "\n",
        "entropy_t = entropy_value_t/len(entropy_avg_t)\n",
        "\n",
        "print('Entropy:', entropy_t)\n",
        "\n",
        "classifier_avg_t = [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]\n",
        "for i in range(9):\n",
        "  classifier_avg_t[i] = avg[i]/count[i]\n",
        "\n",
        "print('Each Classifier Average: ',classifier_avg_t)\n",
        "\n",
        "treshold_value = 0.0\n",
        "for i in range(9):\n",
        "  treshold_value = treshold_value + classifier_avg_t[i]\n",
        "\n",
        "treshold_t = treshold_value/len(classifier_avg_t)\n",
        "\n",
        "print('Threshold:', treshold_t)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10896it [12:50, 14.14it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[9603.444884419441, 9458.451500624418, 9540.7890779078, 9502.559653133154, 9601.45196017623, 9567.101613849401, 9315.152011096478, 9607.079118192196, 9541.850670456886]\n",
            "[9721, 9574, 9722, 9677, 9720, 9719, 9597, 9736, 9702]\n",
            "[372.91374230632096, 363.7050214233947, 551.1446032763299, 553.0551536597962, 369.17797936960636, 473.1718330646984, 815.7394185809904, 390.944743651228, 520.7509795909762]\n",
            "Entropy: 0.050631949011271875\n",
            "Each Classifier Average:  [0.9879070964324083, 0.9879310111368726, 0.981360736258774, 0.9819737163514678, 0.987803699606608, 0.9843709860941868, 0.970631656881992, 0.9867583317781631, 0.9834931633123981]\n",
            "Threshold: 0.9835811553169856\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WhfgnCeISKaa",
        "outputId": "41024e36-90b5-4c53-d551-970f5e037d76"
      },
      "source": [
        "ref_vect_in_5an = []\n",
        "ref_vect_in_5an.append(classifier_avg_t)\n",
        "\n",
        "threshold_in_5an = []\n",
        "threshold_in_5an.append(treshold_t)\n",
        "\n",
        "entropy_in_5an = []\n",
        "entropy_in_5an.append(entropy_t)\n",
        "\n",
        "print(entropy_in_5an)\n",
        "print(ref_vect_in_5an)\n",
        "print(threshold_in_5an)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.050631949011271875]\n",
            "[[0.9879070964324083, 0.9879310111368726, 0.981360736258774, 0.9819737163514678, 0.987803699606608, 0.9843709860941868, 0.970631656881992, 0.9867583317781631, 0.9834931633123981]]\n",
            "[0.9835811553169856]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmP3VuWkHFfM"
      },
      "source": [
        "entropy_in_5an = [0.050631949011271875]\n",
        "ref_vect_in_5an = [[0.9879070964324083, 0.9879310111368726, 0.981360736258774, 0.9819737163514678, 0.987803699606608, 0.9843709860941868, 0.970631656881992, 0.9867583317781631, 0.9834931633123981]]\n",
        "threshold_in_5an = [0.9835811553169856]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8qiGRV4iSKaa",
        "outputId": "44ee24a9-8764-417d-837d-fab24b5e5a5b"
      },
      "source": [
        "from tqdm import tqdm\n",
        "avg = [0,0,0,0,0,0,0,0,0]\n",
        "count = [0,0,0,0,0,0,0,0,0]\n",
        "entropy_list = [0,0,0,0,0,0,0,0,0]\n",
        "\n",
        "for img, lbl in tqdm(zip(new_val_images,new_val_labels)):\n",
        "  img = img.reshape([-1, 28, 28, 1])\n",
        "  if lbl == 0:\n",
        "    logits = model_dict[0](img)\n",
        "    logits = tf.math.divide(logits, temp_val[0])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e0 = entropy(pred[0])\n",
        "    entropy_list[0] = entropy_list[0] + e0\n",
        "    max_val0 = np.max(pred)\n",
        "    avg[0] = avg[0] + max_val0\n",
        "    count[0] = count[0] + 1\n",
        "  if lbl == 1:\n",
        "    logits = model_dict[1](img)\n",
        "    logits = tf.math.divide(logits, temp_val[1])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e1 = entropy(pred[0])\n",
        "    entropy_list[1] = entropy_list[1] + e1\n",
        "    max_val1 = np.max(pred)\n",
        "    avg[1] = avg[1] + max_val1\n",
        "    count[1] = count[1] + 1\n",
        "  if lbl == 2:\n",
        "    logits = model_dict[2](img)\n",
        "    logits = tf.math.divide(logits, temp_val[2])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e2 = entropy(pred[0])\n",
        "    entropy_list[2] = entropy_list[2] + e2\n",
        "    max_val2 = np.max(pred)\n",
        "    avg[2] = avg[2] + max_val2\n",
        "    count[2] = count[2] + 1\n",
        "  if lbl == 3:\n",
        "    logits = model_dict[3](img)\n",
        "    logits = tf.math.divide(logits, temp_val[3])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e3 = entropy(pred[0])\n",
        "    entropy_list[3] = entropy_list[3] + e3\n",
        "    max_val3 = np.max(pred)  \n",
        "    avg[3] = avg[3] + max_val3\n",
        "    count[3] = count[3] + 1\n",
        "  if lbl == 4:\n",
        "    logits = model_dict[4](img)\n",
        "    logits = tf.math.divide(logits, temp_val[4])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e4 = entropy(pred[0])\n",
        "    entropy_list[4] = entropy_list[4] + e4\n",
        "    max_val4 = np.max(pred)\n",
        "    avg[4] = avg[4] + max_val4\n",
        "    count[4] = count[4] + 1\n",
        "  if lbl == 6:\n",
        "    logits = model_dict[5](img)\n",
        "    logits = tf.math.divide(logits, temp_val[5])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e5 = entropy(pred[0])\n",
        "    entropy_list[5] = entropy_list[5] + e5\n",
        "    max_val5 = np.max(pred)\n",
        "    avg[5] = avg[5] + max_val5\n",
        "    count[5] = count[5] + 1\n",
        "  if lbl == 7:\n",
        "    logits = model_dict[6](img)\n",
        "    logits = tf.math.divide(logits, temp_val[6])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e6 = entropy(pred[0])\n",
        "    entropy_list[6] = entropy_list[6] + e6\n",
        "    max_val6 = np.max(pred)\n",
        "    avg[6] = avg[6] + max_val6\n",
        "    count[6] = count[6] + 1\n",
        "  if lbl == 8:\n",
        "    logits = model_dict[7](img)\n",
        "    logits = tf.math.divide(logits, temp_val[7])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e7 = entropy(pred[0])\n",
        "    entropy_list[7] = entropy_list[7] + e7\n",
        "    max_val7 = np.max(pred)\n",
        "    avg[7] = avg[7] + max_val7\n",
        "    count[7] = count[7] + 1\n",
        "  if lbl == 9:\n",
        "    logits = model_dict[8](img)\n",
        "    logits = tf.math.divide(logits, temp_val[8])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e8 = entropy(pred[0])\n",
        "    entropy_list[8] = entropy_list[8] + e8\n",
        "    max_val8 = np.max(pred)\n",
        "    avg[8] = avg[8] + max_val8\n",
        "    count[8] = count[8] + 1\n",
        "\n",
        "print(avg)\n",
        "print(count)\n",
        "print(entropy_list)\n",
        "\n",
        "entropy_avg_t = [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]\n",
        "for i in range(9):\n",
        "  entropy_avg_t[i] = entropy_list[i]/count[i]\n",
        "\n",
        "entropy_value_t = 0.0\n",
        "for i in range(9):\n",
        "  entropy_value_t = entropy_value_t + entropy_avg_t[i]\n",
        "\n",
        "entropy_t = entropy_value_t/len(entropy_avg_t)\n",
        "\n",
        "print('Entropy:', entropy_t)\n",
        "\n",
        "classifier_avg_t = [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]\n",
        "for i in range(9):\n",
        "  classifier_avg_t[i] = avg[i]/count[i]\n",
        "\n",
        "print('Each Classifier Average: ',classifier_avg_t)\n",
        "\n",
        "treshold_value = 0.0\n",
        "for i in range(9):\n",
        "  treshold_value = treshold_value + classifier_avg_t[i]\n",
        "\n",
        "treshold_t = treshold_value/len(classifier_avg_t)\n",
        "\n",
        "print('Threshold:', treshold_t)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10896it [01:37, 111.86it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[924.3241517841816, 731.6788532584906, 946.221238464117, 1028.1971726715565, 1016.7988847345114, 983.6910042464733, 949.471155077219, 902.6606788635254, 936.6449221968651]\n",
            "[1175, 1322, 1174, 1219, 1176, 1177, 1299, 1160, 1194]\n",
            "[669.8063464202714, 1523.4804593534209, 594.4251946387958, 508.0769529964525, 438.64450425197083, 511.1045718697294, 898.2843052904627, 683.4913887701114, 597.5700110852486]\n",
            "Entropy: 0.5815590091425396\n",
            "Each Classifier Average:  [0.7866588525822822, 0.553463580377073, 0.8059806119796568, 0.8434759414861005, 0.8646249019851288, 0.8357612610420334, 0.7309246767338099, 0.7781557576409701, 0.7844597338332203]\n",
            "Threshold: 0.7759450352955861\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U8g05oyoSKab",
        "outputId": "6a7cfad0-271b-4828-ee0a-74357ac68cb5"
      },
      "source": [
        "ref_vect_out_5an = []\n",
        "ref_vect_out_5an.append(classifier_avg_t)\n",
        "\n",
        "threshold_out_5an = []\n",
        "threshold_out_5an.append(treshold_t)\n",
        "\n",
        "entropy_out_5an = []\n",
        "entropy_out_5an.append(entropy_t)\n",
        "\n",
        "print(entropy_out_5an)\n",
        "print(ref_vect_out_5an)\n",
        "print(threshold_out_5an)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.5815590091425396]\n",
            "[[0.7866588525822822, 0.553463580377073, 0.8059806119796568, 0.8434759414861005, 0.8646249019851288, 0.8357612610420334, 0.7309246767338099, 0.7781557576409701, 0.7844597338332203]]\n",
            "[0.7759450352955861]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30OTVxvJHQhV"
      },
      "source": [
        "entropy_out_5an = [0.5815590091425396]\n",
        "ref_vect_out_5an = [[0.7866588525822822, 0.553463580377073, 0.8059806119796568, 0.8434759414861005, 0.8646249019851288, 0.8357612610420334, 0.7309246767338099, 0.7781557576409701, 0.7844597338332203]]\n",
        "threshold_out_5an = [0.7759450352955861]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRId6ouySKab"
      },
      "source": [
        "def get_max_pred_value(model, img, temp):\n",
        "  logits = model(img)\n",
        "  logits = tf.math.divide(logits, temp)\n",
        "  pred = tf.nn.softmax(logits)\n",
        "  e = entropy(pred[0])\n",
        "\n",
        "  return np.max(pred), tf.argmax(pred[0]).numpy(), e"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMReGsOnSKab"
      },
      "source": [
        "def get_mapping(leave_out_class, anomaly_class):\n",
        "  mapping = {}\n",
        "\n",
        "  labels = set(train_labels)\n",
        "  labels.remove(anomaly_class)\n",
        "  labels.remove(leave_out_class)\n",
        "  labels = sorted(labels)\n",
        "\n",
        "  for i,j in enumerate(labels):\n",
        "    mapping[i] = j\n",
        "\n",
        "  return mapping\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_HD3NEISKab"
      },
      "source": [
        "ood = 0\n",
        "ind = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJmCwtW3SKac",
        "outputId": "a88464f5-b2aa-4b02-cc01-a905b1254bdc"
      },
      "source": [
        "max_sm_all_wt_5an = []\n",
        "for data, label in tqdm(zip(test_imgs, test_lbls)):\n",
        "  img = data.reshape([-1, 28, 28, 1])\n",
        "  ref_value = []\n",
        "  \n",
        "  if label == 5:\n",
        "    lbl = ood\n",
        "  else:\n",
        "    lbl = ind\n",
        "\n",
        "\n",
        "  max0, pred_0, e0 = get_max_pred_value(model_dict[0], img, temp=temp_val[0])\n",
        "  map0 = get_mapping(0, 5)\n",
        "  pred_0 = map0[pred_0]\n",
        "\n",
        "  max1, pred_1, e1 = get_max_pred_value(model_dict[1], img, temp=temp_val[1])\n",
        "  map1 = get_mapping(1, 5)\n",
        "  pred_1 = map1[pred_1]\n",
        "\n",
        "  max2, pred_2, e2 = get_max_pred_value(model_dict[2], img, temp=temp_val[2])\n",
        "  map2 = get_mapping(2, 5)\n",
        "  pred_2 = map2[pred_2]\n",
        "\n",
        "  max3, pred_3, e3 = get_max_pred_value(model_dict[3], img, temp=temp_val[3])\n",
        "  map3 = get_mapping(3, 5)\n",
        "  pred_3 = map3[pred_3]\n",
        "\n",
        "  max4, pred_4, e4 = get_max_pred_value(model_dict[4], img, temp=temp_val[4])\n",
        "  map4 = get_mapping(4, 5)\n",
        "  pred_4 = map4[pred_4]\n",
        "\n",
        "  max5, pred_5, e5 = get_max_pred_value(model_dict[5], img, temp=temp_val[5])\n",
        "  map5 = get_mapping(6, 5)\n",
        "  pred_5 = map5[pred_5]\n",
        "\n",
        "  max6, pred_6, e6 = get_max_pred_value(model_dict[6], img, temp=temp_val[6])\n",
        "  map6 = get_mapping(7, 5)\n",
        "  pred_6 = map6[pred_6]\n",
        "\n",
        "  max7, pred_7, e7 = get_max_pred_value(model_dict[7], img, temp=temp_val[7])\n",
        "  map7 = get_mapping(8, 5)\n",
        "  pred_7 = map7[pred_7]\n",
        "\n",
        "  max8, pred_8, e8 = get_max_pred_value(model_dict[8], img, temp=temp_val[8])\n",
        "  map8 = get_mapping(9, 5)\n",
        "  pred_8 = map8[pred_8]\n",
        "\n",
        "  ref_value =[max0, max1, max2, max3, max4, max5, max6, max7, max8]\n",
        "  pred_value = [pred_0, pred_1, pred_2, pred_3, pred_4, pred_5, pred_6, pred_7, pred_8]\n",
        "  e_value = [e0, e1, e2, e3, e4, e5, e6, e7, e8]\n",
        "  e_ = 0.0\n",
        "  for  e in e_value:\n",
        "    e_ = e_ + e\n",
        "  e_ = e_/len(e_value)\n",
        "  max_sm_all_wt_5an.append([ref_value, lbl, pred_value, label, e_])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000it [20:53,  7.98it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oi83NaZ1SKac"
      },
      "source": [
        "pickle_out = open(\"sm_all_wt_5an.pickle\",\"wb\")\n",
        "pickle.dump(max_sm_all_wt_5an, pickle_out)\n",
        "pickle_out.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxPb6pleSKac"
      },
      "source": [
        "pickle_in = open(\"sm_all_wt_5an.pickle\",\"rb\")\n",
        "max_sm_all_wt_5an = pickle.load(pickle_in)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AF4LIWTXSKac",
        "outputId": "70fdf534-e4a2-470a-b023-9706c5af76c8"
      },
      "source": [
        "for data, lbl, p, a_l, e_ in max_sm_all_wt_5an:\n",
        "  print(p, lbl, a_l)\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[7, 7, 7, 7, 7, 7, 9, 7, 7] 1 7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wamxsIoDSKad",
        "outputId": "590ad577-2418-474a-f258-39b658ea6554"
      },
      "source": [
        "accuracy = 0.0\n",
        "count_in = 0\n",
        "count_ood = 0\n",
        "acc_in = 0.0\n",
        "acc_ood = 0.0\n",
        "tp = 0.0\n",
        "tn = 0.0\n",
        "fp = 0.0\n",
        "fn = 0.0\n",
        "y_true = []\n",
        "y_pred = []\n",
        "sim_score = []\n",
        "sim_score_ = []\n",
        "\n",
        "for data, lbl, p, a_l, e_ in max_sm_all_wt_5an:\n",
        "\n",
        "  score = 0.0\n",
        "  for d in data:\n",
        "    score = score + d\n",
        "  score = score / len(data)\n",
        "  sim_score.append(score)\n",
        "\n",
        "  dist_ood = np.linalg.norm(np.array(data) - np.array(ref_vect_out_5an[0])) \n",
        "  dist_in = np.linalg.norm(np.array(data) - np.array(ref_vect_in_5an[0]))\n",
        "\n",
        "  dist_ood2 = np.linalg.norm(np.array(e_) - np.array(entropy_out_5an[0])) \n",
        "  dist_in2 = np.linalg.norm(np.array(e_) - np.array(entropy_in_5an[0]))\n",
        "\n",
        "  dist_in = dist_in / (dist_in + dist_ood)\n",
        "  dist_ood = dist_ood / (dist_in + dist_ood)\n",
        "\n",
        "  dist_in2 = dist_in2 / (dist_in2 + dist_ood2)\n",
        "  dist_ood2 = dist_ood2 / (dist_in2 + dist_ood2)\n",
        "\n",
        "  sim_in = 1 / (1 + dist_in)\n",
        "  sim_ood = 1 / (1 + dist_ood)\n",
        "\n",
        "  sim_in2 = 1 / (1 + dist_in2)\n",
        "  sim_ood2 = 1 / (1 + dist_ood2)\n",
        "\n",
        "  sim_in = sim_in + sim_in2\n",
        "  sim_ood = sim_ood + sim_ood2\n",
        "\n",
        "  sim_score_.append(sim_ood2)\n",
        "\n",
        "  values, counts = np.unique(p, return_counts=True)\n",
        "#  print(values, counts)\n",
        "  #print(sim_in, sim_ood, lbl, e_)\n",
        "\n",
        "\n",
        "  if sim_in >= sim_ood:\n",
        "    y_ = ind    \n",
        "    if np.max(counts) >= 8:\n",
        "      y_ = ind\n",
        "    else:\n",
        "      y_ = ood\n",
        "  else:\n",
        "    y_ = ood\n",
        "\n",
        "\n",
        "  y_pred.append(y_)\n",
        "  if lbl == 1:\n",
        "    y_true.append(0)\n",
        "  else:\n",
        "    y_true.append(1)\n",
        "#  y_true.append(lbl)\n",
        "\n",
        "\n",
        "  if lbl == ind:\n",
        "    count_in = count_in + 1\n",
        "  else:\n",
        "    count_ood = count_ood + 1\n",
        "\n",
        "  if y_ == lbl:\n",
        "    #sim_score_.append(1)\n",
        "    accuracy = accuracy + 1\n",
        "    if y_ == ind:\n",
        "      acc_in = acc_in + 1\n",
        "      tp = tp + 1\n",
        "    else:\n",
        "      acc_ood = acc_ood + 1\n",
        "      tn = tn + 1\n",
        "  else:\n",
        "    #sim_score_.append(0)\n",
        "    if y_ == ind:\n",
        "      fp = fp + 1\n",
        "    else:\n",
        "      fn = fn + 1\n",
        "\n",
        "\n",
        "print(\"Total Accuracy: \", accuracy/len(max_sm_all_wt_5an)) \n",
        "print(\"Accuracy of determining ID data: \", acc_in/count_in)\n",
        "print(\"Accuracy of determining OOD data: \", acc_ood/count_ood)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Accuracy:  0.9271\n",
            "Accuracy of determining ID data:  0.9236934563021519\n",
            "Accuracy of determining OOD data:  0.9618834080717489\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20NPeUDTSKad",
        "outputId": "ed622687-d5f2-4641-b7dd-6b59a01c5c62"
      },
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "roc_auc_score(y_true, sim_score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9603154030064734"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H7FEeTKnSKae",
        "outputId": "12019d2a-5911-4ae9-8ae5-22e5c807e784"
      },
      "source": [
        "roc_auc_score(y_true, y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9427884321869504"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 235
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vj55gFlMSKae",
        "outputId": "1ba52fd5-78d9-464a-ae91-50c7463ea7e4"
      },
      "source": [
        "roc_auc_score(y_true, sim_score_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9628085298293915"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 243
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DRyANtH_UfpQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZPMvF-nV7F8"
      },
      "source": [
        "# 6 as anomaly"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8LZLSUjV81o"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ebCP7wGWWDR"
      },
      "source": [
        "new_train_images, new_train_labels, new_val_images, new_val_labels = separate_class(6, train_images, train_labels, val_images, val_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "roB6QHeOWWDd"
      },
      "source": [
        "model0 = Model(name='6anomaly:classifier0')\n",
        "model1 = Model(name='6anomaly:classifier1')\n",
        "model2 = Model(name='6anomaly:classifier2')\n",
        "model3 = Model(name='6anomaly:classifier3')\n",
        "model4 = Model(name='6anomaly:classifier4')\n",
        "model5 = Model(name='6anomaly:classifier5')\n",
        "model6 = Model(name='6anomaly:classifier6')\n",
        "model7 = Model(name='6anomaly:classifier7')\n",
        "model8 = Model(name='6anomaly:classifier8')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCnl-bsNWWDf"
      },
      "source": [
        "class_0 = model0.build()\n",
        "class_1 = model1.build()\n",
        "class_2 = model2.build()\n",
        "class_3 = model3.build()\n",
        "class_4 = model4.build()\n",
        "class_5 = model5.build()\n",
        "class_6 = model6.build()\n",
        "class_7 = model7.build()\n",
        "class_8 = model8.build()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HPalohNSWWDg",
        "outputId": "8f2e3d75-a613-4c7c-9756-38e637724965"
      },
      "source": [
        "train_imgs0, train_lbls0 = get_train_data(0, new_train_images, new_train_labels)\n",
        "val_imgs0, val_lbls0 = get_train_data(0, new_val_images, new_val_labels)\n",
        "class_0 = model0.build()\n",
        "model0.train2(train_imgs0, train_lbls0, val_imgs0, val_lbls0)\n",
        "#model0.train(train_data0)\n",
        "model0.save_model(\"final_models/6anomaly-classifier0\")\n",
        "print('Model 0 saved')\n",
        "\n",
        "train_imgs1, train_lbls1 = get_train_data(1, new_train_images, new_train_labels)\n",
        "val_imgs1, val_lbls1 = get_train_data(1, new_val_images, new_val_labels)\n",
        "class_1 = model1.build()\n",
        "model1.train2(train_imgs1, train_lbls1, val_imgs1, val_lbls1)\n",
        "#model1.train(train_data1)\n",
        "model1.save_model(\"final_models/6anomaly-classifier1\")\n",
        "print('Model 1 saved')\n",
        "\n",
        "#train_data2 = get_train_data(2, new_train_images)\n",
        "train_imgs2, train_lbls2 = get_train_data(2, new_train_images, new_train_labels)\n",
        "val_imgs2, val_lbls2 = get_train_data(2, new_val_images, new_val_labels)\n",
        "class_2 = model2.build()\n",
        "model2.train2(train_imgs2, train_lbls2, val_imgs2, val_lbls2)\n",
        "#model2.train(train_data2)\n",
        "model2.save_model(\"final_models/6anomaly-classifier2\")\n",
        "print('Model 2 saved')\n",
        "\n",
        "#train_data3 = get_train_data(3, new_train_images)\n",
        "train_imgs3, train_lbls3 = get_train_data(3, new_train_images, new_train_labels)\n",
        "val_imgs3, val_lbls3 = get_train_data(3, new_val_images, new_val_labels)\n",
        "class_3 = model3.build()\n",
        "model3.train2(train_imgs3, train_lbls3, val_imgs3, val_lbls3)\n",
        "#model3.train(train_data3)\n",
        "model3.save_model(\"final_models/6anomaly-classifier3\")\n",
        "print('Model 3 saved')\n",
        "\n",
        "#train_data4 = get_train_data(4, new_train_images)\n",
        "train_imgs4, train_lbls4 = get_train_data(4, new_train_images, new_train_labels)\n",
        "val_imgs4, val_lbls4 = get_train_data(4, new_val_images, new_val_labels)\n",
        "class_4 = model4.build()\n",
        "model4.train2(train_imgs4, train_lbls4, val_imgs4, val_lbls4)\n",
        "#model4.train(train_data4)\n",
        "model4.save_model(\"final_models/6anomaly-classifier4\")\n",
        "print('Model 4 saved')\n",
        "\n",
        "#train_data5 = get_train_data(5, new_train_images)\n",
        "train_imgs5, train_lbls5 = get_train_data(5, new_train_images, new_train_labels)\n",
        "val_imgs5, val_lbls5 = get_train_data(5, new_val_images, new_val_labels)\n",
        "class_5 = model5.build()\n",
        "model5.train2(train_imgs5, train_lbls5, val_imgs5, val_lbls5)\n",
        "#model5.train(train_data5)\n",
        "model5.save_model(\"final_models/6anomaly-classifier5\")\n",
        "print('Model 5 saved')\n",
        "\n",
        "#train_data6 = get_train_data(6, new_train_images)\n",
        "train_imgs6, train_lbls6 = get_train_data(7, new_train_images, new_train_labels)\n",
        "val_imgs6, val_lbls6 = get_train_data(7, new_val_images, new_val_labels)\n",
        "class_6 = model6.build()\n",
        "model6.train2(train_imgs6, train_lbls6, val_imgs6, val_lbls6)\n",
        "#model6.train(train_data6)\n",
        "model6.save_model(\"final_models/6anomaly-classifier6\")\n",
        "print('Model 6 saved')\n",
        "\n",
        "#train_data7 = get_train_data(7, new_train_images)\n",
        "train_imgs7, train_lbls7 = get_train_data(8, new_train_images, new_train_labels)\n",
        "val_imgs7, val_lbls7 = get_train_data(8, new_val_images, new_val_labels)\n",
        "class_7 = model7.build()\n",
        "#model7.train(train_data7)\n",
        "model7.train2(train_imgs7, train_lbls7, val_imgs7, val_lbls7)\n",
        "model7.save_model(\"final_models/6anomaly-classifier7\")\n",
        "print('Model 7 saved')\n",
        "\n",
        "#train_data8 = get_train_data(8, new_train_images)\n",
        "train_imgs8, train_lbls8 = get_train_data(9, new_train_images, new_train_labels)\n",
        "val_imgs8, val_lbls8 = get_train_data(9, new_val_images, new_val_labels)\n",
        "class_8 = model8.build()\n",
        "#model8.train(train_data8)\n",
        "model8.train2(train_imgs8, train_lbls8, val_imgs8, val_lbls8)\n",
        "model8.save_model(\"final_models/6anomaly-classifier8\")\n",
        "print('Model 8 saved')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{1: 0, 2: 1, 3: 2, 4: 3, 5: 4, 7: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(38511,)\n",
            "{1: 0, 2: 1, 3: 2, 4: 3, 5: 4, 7: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9648,)\n",
            "Epoch 1/20\n",
            "1204/1204 [==============================] - 40s 32ms/step - loss: 4.6164 - accuracy: 0.8365 - val_loss: 1.4840 - val_accuracy: 0.8826\n",
            "Epoch 2/20\n",
            "1204/1204 [==============================] - 38s 32ms/step - loss: 0.1812 - accuracy: 0.9652 - val_loss: 0.2462 - val_accuracy: 0.9438\n",
            "Epoch 3/20\n",
            "1204/1204 [==============================] - 38s 32ms/step - loss: 0.0727 - accuracy: 0.9772 - val_loss: 0.1626 - val_accuracy: 0.9554\n",
            "Epoch 4/20\n",
            "1204/1204 [==============================] - 38s 32ms/step - loss: 0.0634 - accuracy: 0.9813 - val_loss: 0.1164 - val_accuracy: 0.9655\n",
            "Epoch 5/20\n",
            "1204/1204 [==============================] - 38s 32ms/step - loss: 0.0561 - accuracy: 0.9836 - val_loss: 0.1070 - val_accuracy: 0.9663\n",
            "Epoch 6/20\n",
            "1204/1204 [==============================] - 38s 32ms/step - loss: 0.0515 - accuracy: 0.9840 - val_loss: 0.0785 - val_accuracy: 0.9784\n",
            "Epoch 7/20\n",
            "1204/1204 [==============================] - 38s 32ms/step - loss: 0.0468 - accuracy: 0.9853 - val_loss: 0.1098 - val_accuracy: 0.9729\n",
            "Epoch 8/20\n",
            "1204/1204 [==============================] - 38s 32ms/step - loss: 0.0486 - accuracy: 0.9853 - val_loss: 0.0615 - val_accuracy: 0.9856\n",
            "Epoch 9/20\n",
            "1204/1204 [==============================] - 38s 32ms/step - loss: 0.0381 - accuracy: 0.9878 - val_loss: 0.1193 - val_accuracy: 0.9722\n",
            "Epoch 10/20\n",
            "1204/1204 [==============================] - 38s 32ms/step - loss: 0.0367 - accuracy: 0.9884 - val_loss: 0.1537 - val_accuracy: 0.9632\n",
            "Epoch 11/20\n",
            "1204/1204 [==============================] - 38s 32ms/step - loss: 0.0354 - accuracy: 0.9893 - val_loss: 0.0580 - val_accuracy: 0.9854\n",
            "Epoch 12/20\n",
            "1204/1204 [==============================] - 38s 32ms/step - loss: 0.0328 - accuracy: 0.9897 - val_loss: 0.2278 - val_accuracy: 0.9557\n",
            "Epoch 13/20\n",
            "1204/1204 [==============================] - 38s 32ms/step - loss: 0.0277 - accuracy: 0.9911 - val_loss: 0.1209 - val_accuracy: 0.9733\n",
            "Epoch 14/20\n",
            "1204/1204 [==============================] - 38s 32ms/step - loss: 0.0269 - accuracy: 0.9919 - val_loss: 0.0649 - val_accuracy: 0.9830\n",
            "Epoch 15/20\n",
            "1204/1204 [==============================] - 38s 32ms/step - loss: 0.0270 - accuracy: 0.9908 - val_loss: 0.0658 - val_accuracy: 0.9840\n",
            "Epoch 16/20\n",
            "1204/1204 [==============================] - 38s 32ms/step - loss: 0.0200 - accuracy: 0.9939 - val_loss: 0.0898 - val_accuracy: 0.9798\n",
            "Epoch 17/20\n",
            "1204/1204 [==============================] - 38s 32ms/step - loss: 0.0208 - accuracy: 0.9934 - val_loss: 0.1331 - val_accuracy: 0.9751\n",
            "Epoch 18/20\n",
            "1204/1204 [==============================] - 38s 32ms/step - loss: 0.0233 - accuracy: 0.9932 - val_loss: 0.0582 - val_accuracy: 0.9875\n",
            "Epoch 19/20\n",
            "1204/1204 [==============================] - 38s 32ms/step - loss: 0.0166 - accuracy: 0.9950 - val_loss: 0.0838 - val_accuracy: 0.9812\n",
            "Epoch 20/20\n",
            "1204/1204 [==============================] - 38s 32ms/step - loss: 0.0180 - accuracy: 0.9944 - val_loss: 0.1418 - val_accuracy: 0.9752\n",
            "INFO:tensorflow:Assets written to: final_models/6anomaly-classifier0/assets\n",
            "Model 0 saved\n",
            "{0: 0, 2: 1, 3: 2, 4: 3, 5: 4, 7: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(37839,)\n",
            "{0: 0, 2: 1, 3: 2, 4: 3, 5: 4, 7: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9501,)\n",
            "Epoch 1/20\n",
            "1183/1183 [==============================] - 39s 32ms/step - loss: 6.0325 - accuracy: 0.7865 - val_loss: 0.4169 - val_accuracy: 0.9291\n",
            "Epoch 2/20\n",
            "1183/1183 [==============================] - 38s 32ms/step - loss: 0.1445 - accuracy: 0.9726 - val_loss: 0.1305 - val_accuracy: 0.9621\n",
            "Epoch 3/20\n",
            "1183/1183 [==============================] - 38s 32ms/step - loss: 0.0716 - accuracy: 0.9801 - val_loss: 0.3076 - val_accuracy: 0.9178\n",
            "Epoch 4/20\n",
            "1183/1183 [==============================] - 38s 32ms/step - loss: 0.0577 - accuracy: 0.9818 - val_loss: 0.1043 - val_accuracy: 0.9715\n",
            "Epoch 5/20\n",
            "1183/1183 [==============================] - 37s 32ms/step - loss: 0.0657 - accuracy: 0.9799 - val_loss: 0.1708 - val_accuracy: 0.9533\n",
            "Epoch 6/20\n",
            "1183/1183 [==============================] - 37s 32ms/step - loss: 0.0540 - accuracy: 0.9839 - val_loss: 0.1713 - val_accuracy: 0.9602\n",
            "Epoch 7/20\n",
            "1183/1183 [==============================] - 38s 32ms/step - loss: 0.0504 - accuracy: 0.9846 - val_loss: 0.0702 - val_accuracy: 0.9811\n",
            "Epoch 8/20\n",
            "1183/1183 [==============================] - 38s 32ms/step - loss: 0.0429 - accuracy: 0.9867 - val_loss: 0.1400 - val_accuracy: 0.9665\n",
            "Epoch 9/20\n",
            "1183/1183 [==============================] - 38s 32ms/step - loss: 0.0441 - accuracy: 0.9872 - val_loss: 0.1307 - val_accuracy: 0.9686\n",
            "Epoch 10/20\n",
            "1183/1183 [==============================] - 37s 32ms/step - loss: 0.0369 - accuracy: 0.9890 - val_loss: 0.2468 - val_accuracy: 0.9436\n",
            "Epoch 11/20\n",
            "1183/1183 [==============================] - 38s 32ms/step - loss: 0.0319 - accuracy: 0.9898 - val_loss: 0.0936 - val_accuracy: 0.9777\n",
            "Epoch 12/20\n",
            "1183/1183 [==============================] - 38s 32ms/step - loss: 0.0326 - accuracy: 0.9903 - val_loss: 0.1242 - val_accuracy: 0.9728\n",
            "Epoch 13/20\n",
            "1183/1183 [==============================] - 38s 32ms/step - loss: 0.0301 - accuracy: 0.9907 - val_loss: 0.0974 - val_accuracy: 0.9765\n",
            "Epoch 14/20\n",
            "1183/1183 [==============================] - 38s 32ms/step - loss: 0.0305 - accuracy: 0.9902 - val_loss: 0.0728 - val_accuracy: 0.9834\n",
            "Epoch 15/20\n",
            "1183/1183 [==============================] - 38s 32ms/step - loss: 0.0217 - accuracy: 0.9940 - val_loss: 0.0881 - val_accuracy: 0.9817\n",
            "Epoch 16/20\n",
            "1183/1183 [==============================] - 38s 32ms/step - loss: 0.0287 - accuracy: 0.9915 - val_loss: 0.0858 - val_accuracy: 0.9788\n",
            "Epoch 17/20\n",
            "1183/1183 [==============================] - 38s 32ms/step - loss: 0.0214 - accuracy: 0.9926 - val_loss: 0.2258 - val_accuracy: 0.9581\n",
            "Epoch 18/20\n",
            "1183/1183 [==============================] - 38s 32ms/step - loss: 0.0204 - accuracy: 0.9934 - val_loss: 0.2198 - val_accuracy: 0.9628\n",
            "Epoch 19/20\n",
            "1183/1183 [==============================] - 38s 32ms/step - loss: 0.0191 - accuracy: 0.9947 - val_loss: 0.0922 - val_accuracy: 0.9817\n",
            "Epoch 20/20\n",
            "1183/1183 [==============================] - 38s 32ms/step - loss: 0.0179 - accuracy: 0.9954 - val_loss: 0.1473 - val_accuracy: 0.9734\n",
            "INFO:tensorflow:Assets written to: final_models/6anomaly-classifier1/assets\n",
            "Model 1 saved\n",
            "{0: 0, 1: 1, 3: 2, 4: 3, 5: 4, 7: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(38475,)\n",
            "{0: 0, 1: 1, 3: 2, 4: 3, 5: 4, 7: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9649,)\n",
            "Epoch 1/20\n",
            "1203/1203 [==============================] - 39s 32ms/step - loss: 5.1402 - accuracy: 0.8507 - val_loss: 0.2461 - val_accuracy: 0.9684\n",
            "Epoch 2/20\n",
            "1203/1203 [==============================] - 38s 32ms/step - loss: 0.1469 - accuracy: 0.9718 - val_loss: 0.2150 - val_accuracy: 0.9498\n",
            "Epoch 3/20\n",
            "1203/1203 [==============================] - 38s 32ms/step - loss: 0.0617 - accuracy: 0.9833 - val_loss: 0.1101 - val_accuracy: 0.9714\n",
            "Epoch 4/20\n",
            "1203/1203 [==============================] - 38s 32ms/step - loss: 0.0523 - accuracy: 0.9851 - val_loss: 0.1068 - val_accuracy: 0.9746\n",
            "Epoch 5/20\n",
            "1203/1203 [==============================] - 38s 32ms/step - loss: 0.0573 - accuracy: 0.9842 - val_loss: 0.1180 - val_accuracy: 0.9665\n",
            "Epoch 6/20\n",
            "1203/1203 [==============================] - 38s 32ms/step - loss: 0.0487 - accuracy: 0.9866 - val_loss: 0.0713 - val_accuracy: 0.9827\n",
            "Epoch 7/20\n",
            "1203/1203 [==============================] - 38s 32ms/step - loss: 0.0448 - accuracy: 0.9865 - val_loss: 0.0908 - val_accuracy: 0.9748\n",
            "Epoch 8/20\n",
            "1203/1203 [==============================] - 38s 32ms/step - loss: 0.0388 - accuracy: 0.9883 - val_loss: 0.1002 - val_accuracy: 0.9792\n",
            "Epoch 9/20\n",
            "1203/1203 [==============================] - 38s 32ms/step - loss: 0.0418 - accuracy: 0.9869 - val_loss: 0.0704 - val_accuracy: 0.9784\n",
            "Epoch 10/20\n",
            "1203/1203 [==============================] - 39s 32ms/step - loss: 0.0315 - accuracy: 0.9902 - val_loss: 0.1126 - val_accuracy: 0.9712\n",
            "Epoch 11/20\n",
            "1203/1203 [==============================] - 39s 32ms/step - loss: 0.0297 - accuracy: 0.9908 - val_loss: 0.0918 - val_accuracy: 0.9780\n",
            "Epoch 12/20\n",
            "1203/1203 [==============================] - 38s 32ms/step - loss: 0.0282 - accuracy: 0.9912 - val_loss: 0.0572 - val_accuracy: 0.9830\n",
            "Epoch 13/20\n",
            "1203/1203 [==============================] - 38s 32ms/step - loss: 0.0274 - accuracy: 0.9922 - val_loss: 0.0531 - val_accuracy: 0.9875\n",
            "Epoch 14/20\n",
            "1203/1203 [==============================] - 38s 32ms/step - loss: 0.0224 - accuracy: 0.9933 - val_loss: 0.0788 - val_accuracy: 0.9811\n",
            "Epoch 15/20\n",
            "1203/1203 [==============================] - 38s 32ms/step - loss: 0.0270 - accuracy: 0.9912 - val_loss: 0.0956 - val_accuracy: 0.9808\n",
            "Epoch 16/20\n",
            "1203/1203 [==============================] - 38s 32ms/step - loss: 0.0199 - accuracy: 0.9931 - val_loss: 0.0604 - val_accuracy: 0.9850\n",
            "Epoch 17/20\n",
            "1203/1203 [==============================] - 38s 32ms/step - loss: 0.0190 - accuracy: 0.9940 - val_loss: 0.1088 - val_accuracy: 0.9771\n",
            "Epoch 18/20\n",
            "1203/1203 [==============================] - 38s 32ms/step - loss: 0.0168 - accuracy: 0.9945 - val_loss: 0.0630 - val_accuracy: 0.9834\n",
            "Epoch 19/20\n",
            "1203/1203 [==============================] - 38s 32ms/step - loss: 0.0179 - accuracy: 0.9946 - val_loss: 0.0445 - val_accuracy: 0.9889\n",
            "Epoch 20/20\n",
            "1203/1203 [==============================] - 38s 32ms/step - loss: 0.0134 - accuracy: 0.9953 - val_loss: 0.0759 - val_accuracy: 0.9867\n",
            "INFO:tensorflow:Assets written to: final_models/6anomaly-classifier2/assets\n",
            "Model 2 saved\n",
            "{0: 0, 1: 1, 2: 2, 4: 3, 5: 4, 7: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(38347,)\n",
            "{0: 0, 1: 1, 2: 2, 4: 3, 5: 4, 7: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9604,)\n",
            "Epoch 1/20\n",
            "1199/1199 [==============================] - 39s 32ms/step - loss: 4.3013 - accuracy: 0.7822 - val_loss: 0.1879 - val_accuracy: 0.9644\n",
            "Epoch 2/20\n",
            "1199/1199 [==============================] - 38s 32ms/step - loss: 0.1056 - accuracy: 0.9730 - val_loss: 0.1005 - val_accuracy: 0.9739\n",
            "Epoch 3/20\n",
            "1199/1199 [==============================] - 38s 32ms/step - loss: 0.0690 - accuracy: 0.9790 - val_loss: 0.2105 - val_accuracy: 0.9541\n",
            "Epoch 4/20\n",
            "1199/1199 [==============================] - 38s 32ms/step - loss: 0.0629 - accuracy: 0.9811 - val_loss: 0.1092 - val_accuracy: 0.9732\n",
            "Epoch 5/20\n",
            "1199/1199 [==============================] - 38s 32ms/step - loss: 0.0582 - accuracy: 0.9824 - val_loss: 0.1908 - val_accuracy: 0.9603\n",
            "Epoch 6/20\n",
            "1199/1199 [==============================] - 38s 32ms/step - loss: 0.0725 - accuracy: 0.9796 - val_loss: 0.0751 - val_accuracy: 0.9783\n",
            "Epoch 7/20\n",
            "1199/1199 [==============================] - 38s 32ms/step - loss: 0.0452 - accuracy: 0.9865 - val_loss: 0.1051 - val_accuracy: 0.9737\n",
            "Epoch 8/20\n",
            "1199/1199 [==============================] - 38s 32ms/step - loss: 0.0445 - accuracy: 0.9864 - val_loss: 0.1916 - val_accuracy: 0.9601\n",
            "Epoch 9/20\n",
            "1199/1199 [==============================] - 38s 32ms/step - loss: 0.0430 - accuracy: 0.9869 - val_loss: 0.1249 - val_accuracy: 0.9702\n",
            "Epoch 10/20\n",
            "1199/1199 [==============================] - 38s 32ms/step - loss: 0.0371 - accuracy: 0.9887 - val_loss: 0.0850 - val_accuracy: 0.9818\n",
            "Epoch 11/20\n",
            "1199/1199 [==============================] - 38s 32ms/step - loss: 0.0342 - accuracy: 0.9899 - val_loss: 0.0714 - val_accuracy: 0.9825\n",
            "Epoch 12/20\n",
            "1199/1199 [==============================] - 38s 32ms/step - loss: 0.0261 - accuracy: 0.9920 - val_loss: 0.1274 - val_accuracy: 0.9699\n",
            "Epoch 13/20\n",
            "1199/1199 [==============================] - 38s 32ms/step - loss: 0.0232 - accuracy: 0.9930 - val_loss: 0.0701 - val_accuracy: 0.9821\n",
            "Epoch 14/20\n",
            "1199/1199 [==============================] - 38s 32ms/step - loss: 0.0292 - accuracy: 0.9914 - val_loss: 0.0942 - val_accuracy: 0.9771\n",
            "Epoch 15/20\n",
            "1199/1199 [==============================] - 38s 32ms/step - loss: 0.0274 - accuracy: 0.9921 - val_loss: 0.0847 - val_accuracy: 0.9813\n",
            "Epoch 16/20\n",
            "1199/1199 [==============================] - 38s 32ms/step - loss: 0.0188 - accuracy: 0.9939 - val_loss: 0.1037 - val_accuracy: 0.9781\n",
            "Epoch 17/20\n",
            "1199/1199 [==============================] - 38s 32ms/step - loss: 0.0193 - accuracy: 0.9942 - val_loss: 0.0780 - val_accuracy: 0.9830\n",
            "Epoch 18/20\n",
            "1199/1199 [==============================] - 38s 32ms/step - loss: 0.0233 - accuracy: 0.9926 - val_loss: 0.0814 - val_accuracy: 0.9842\n",
            "Epoch 19/20\n",
            "1199/1199 [==============================] - 38s 32ms/step - loss: 0.0186 - accuracy: 0.9940 - val_loss: 0.0994 - val_accuracy: 0.9835\n",
            "Epoch 20/20\n",
            "1199/1199 [==============================] - 38s 32ms/step - loss: 0.0179 - accuracy: 0.9944 - val_loss: 0.0712 - val_accuracy: 0.9875\n",
            "INFO:tensorflow:Assets written to: final_models/6anomaly-classifier3/assets\n",
            "Model 3 saved\n",
            "{0: 0, 1: 1, 2: 2, 3: 3, 5: 4, 7: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(38593,)\n",
            "{0: 0, 1: 1, 2: 2, 3: 3, 5: 4, 7: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9647,)\n",
            "Epoch 1/20\n",
            "1207/1207 [==============================] - 40s 32ms/step - loss: 5.3111 - accuracy: 0.8326 - val_loss: 0.9403 - val_accuracy: 0.8036\n",
            "Epoch 2/20\n",
            "1207/1207 [==============================] - 38s 32ms/step - loss: 0.4254 - accuracy: 0.9428 - val_loss: 0.1248 - val_accuracy: 0.9660\n",
            "Epoch 3/20\n",
            "1207/1207 [==============================] - 38s 32ms/step - loss: 0.0704 - accuracy: 0.9793 - val_loss: 0.0813 - val_accuracy: 0.9747\n",
            "Epoch 4/20\n",
            "1207/1207 [==============================] - 38s 32ms/step - loss: 0.0587 - accuracy: 0.9835 - val_loss: 0.2198 - val_accuracy: 0.9468\n",
            "Epoch 5/20\n",
            "1207/1207 [==============================] - 38s 32ms/step - loss: 0.0602 - accuracy: 0.9819 - val_loss: 0.1441 - val_accuracy: 0.9712\n",
            "Epoch 6/20\n",
            "1207/1207 [==============================] - 38s 32ms/step - loss: 0.0551 - accuracy: 0.9838 - val_loss: 0.2052 - val_accuracy: 0.9553\n",
            "Epoch 7/20\n",
            "1207/1207 [==============================] - 38s 32ms/step - loss: 0.0503 - accuracy: 0.9853 - val_loss: 0.1193 - val_accuracy: 0.9701\n",
            "Epoch 8/20\n",
            "1207/1207 [==============================] - 38s 32ms/step - loss: 0.0452 - accuracy: 0.9866 - val_loss: 0.2050 - val_accuracy: 0.9582\n",
            "Epoch 9/20\n",
            "1207/1207 [==============================] - 38s 32ms/step - loss: 0.0390 - accuracy: 0.9884 - val_loss: 0.3566 - val_accuracy: 0.9348\n",
            "Epoch 10/20\n",
            "1207/1207 [==============================] - 38s 32ms/step - loss: 0.0376 - accuracy: 0.9889 - val_loss: 0.1569 - val_accuracy: 0.9695\n",
            "Epoch 11/20\n",
            "1207/1207 [==============================] - 38s 32ms/step - loss: 0.0312 - accuracy: 0.9903 - val_loss: 0.0856 - val_accuracy: 0.9807\n",
            "Epoch 12/20\n",
            "1207/1207 [==============================] - 38s 32ms/step - loss: 0.0268 - accuracy: 0.9919 - val_loss: 0.1138 - val_accuracy: 0.9742\n",
            "Epoch 13/20\n",
            "1207/1207 [==============================] - 38s 32ms/step - loss: 0.0243 - accuracy: 0.9923 - val_loss: 0.1274 - val_accuracy: 0.9704\n",
            "Epoch 14/20\n",
            "1207/1207 [==============================] - 38s 32ms/step - loss: 0.0195 - accuracy: 0.9937 - val_loss: 0.0985 - val_accuracy: 0.9791\n",
            "Epoch 15/20\n",
            "1207/1207 [==============================] - 38s 32ms/step - loss: 0.0213 - accuracy: 0.9928 - val_loss: 0.1103 - val_accuracy: 0.9769\n",
            "Epoch 16/20\n",
            "1207/1207 [==============================] - 38s 32ms/step - loss: 0.0167 - accuracy: 0.9948 - val_loss: 0.1325 - val_accuracy: 0.9761\n",
            "Epoch 17/20\n",
            "1207/1207 [==============================] - 38s 32ms/step - loss: 0.0177 - accuracy: 0.9944 - val_loss: 0.1797 - val_accuracy: 0.9659\n",
            "Epoch 18/20\n",
            "1207/1207 [==============================] - 38s 32ms/step - loss: 0.0143 - accuracy: 0.9951 - val_loss: 0.0946 - val_accuracy: 0.9806\n",
            "Epoch 19/20\n",
            "1207/1207 [==============================] - 38s 32ms/step - loss: 0.0141 - accuracy: 0.9956 - val_loss: 0.1487 - val_accuracy: 0.9749\n",
            "Epoch 20/20\n",
            "1207/1207 [==============================] - 38s 32ms/step - loss: 0.0153 - accuracy: 0.9950 - val_loss: 0.1947 - val_accuracy: 0.9683\n",
            "INFO:tensorflow:Assets written to: final_models/6anomaly-classifier4/assets\n",
            "Model 4 saved\n",
            "{0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 7: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(38942,)\n",
            "{0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 7: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9719,)\n",
            "Epoch 1/20\n",
            "1217/1217 [==============================] - 40s 32ms/step - loss: 4.8757 - accuracy: 0.8226 - val_loss: 0.2274 - val_accuracy: 0.9600\n",
            "Epoch 2/20\n",
            "1217/1217 [==============================] - 39s 32ms/step - loss: 0.1418 - accuracy: 0.9711 - val_loss: 0.1693 - val_accuracy: 0.9553\n",
            "Epoch 3/20\n",
            "1217/1217 [==============================] - 39s 32ms/step - loss: 0.0864 - accuracy: 0.9762 - val_loss: 0.4218 - val_accuracy: 0.9029\n",
            "Epoch 4/20\n",
            "1217/1217 [==============================] - 39s 32ms/step - loss: 0.0629 - accuracy: 0.9806 - val_loss: 0.1080 - val_accuracy: 0.9718\n",
            "Epoch 5/20\n",
            "1217/1217 [==============================] - 39s 32ms/step - loss: 0.0603 - accuracy: 0.9822 - val_loss: 0.2562 - val_accuracy: 0.9479\n",
            "Epoch 6/20\n",
            "1217/1217 [==============================] - 39s 32ms/step - loss: 0.0505 - accuracy: 0.9854 - val_loss: 0.2268 - val_accuracy: 0.9546\n",
            "Epoch 7/20\n",
            "1217/1217 [==============================] - 39s 32ms/step - loss: 0.0527 - accuracy: 0.9840 - val_loss: 0.0818 - val_accuracy: 0.9795\n",
            "Epoch 8/20\n",
            "1217/1217 [==============================] - 39s 32ms/step - loss: 0.0456 - accuracy: 0.9865 - val_loss: 0.0756 - val_accuracy: 0.9798\n",
            "Epoch 9/20\n",
            "1217/1217 [==============================] - 39s 32ms/step - loss: 0.0420 - accuracy: 0.9871 - val_loss: 0.1113 - val_accuracy: 0.9752\n",
            "Epoch 10/20\n",
            "1217/1217 [==============================] - 39s 32ms/step - loss: 0.0338 - accuracy: 0.9898 - val_loss: 0.0868 - val_accuracy: 0.9785\n",
            "Epoch 11/20\n",
            "1217/1217 [==============================] - 39s 32ms/step - loss: 0.0315 - accuracy: 0.9914 - val_loss: 0.0896 - val_accuracy: 0.9776\n",
            "Epoch 12/20\n",
            "1217/1217 [==============================] - 39s 32ms/step - loss: 0.0364 - accuracy: 0.9887 - val_loss: 0.0858 - val_accuracy: 0.9806\n",
            "Epoch 13/20\n",
            "1217/1217 [==============================] - 39s 32ms/step - loss: 0.0274 - accuracy: 0.9912 - val_loss: 0.1232 - val_accuracy: 0.9724\n",
            "Epoch 14/20\n",
            "1217/1217 [==============================] - 39s 32ms/step - loss: 0.0245 - accuracy: 0.9921 - val_loss: 0.1110 - val_accuracy: 0.9754\n",
            "Epoch 15/20\n",
            "1217/1217 [==============================] - 39s 32ms/step - loss: 0.0217 - accuracy: 0.9931 - val_loss: 0.0633 - val_accuracy: 0.9841\n",
            "Epoch 16/20\n",
            "1217/1217 [==============================] - 39s 32ms/step - loss: 0.0219 - accuracy: 0.9941 - val_loss: 0.0677 - val_accuracy: 0.9846\n",
            "Epoch 17/20\n",
            "1217/1217 [==============================] - 39s 32ms/step - loss: 0.0191 - accuracy: 0.9942 - val_loss: 0.0690 - val_accuracy: 0.9847\n",
            "Epoch 18/20\n",
            "1217/1217 [==============================] - 39s 32ms/step - loss: 0.0158 - accuracy: 0.9949 - val_loss: 0.0623 - val_accuracy: 0.9866\n",
            "Epoch 19/20\n",
            "1217/1217 [==============================] - 39s 32ms/step - loss: 0.0151 - accuracy: 0.9951 - val_loss: 0.0859 - val_accuracy: 0.9820\n",
            "Epoch 20/20\n",
            "1217/1217 [==============================] - 39s 32ms/step - loss: 0.0173 - accuracy: 0.9951 - val_loss: 0.0551 - val_accuracy: 0.9880\n",
            "INFO:tensorflow:Assets written to: final_models/6anomaly-classifier5/assets\n",
            "Model 5 saved\n",
            "{0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(38293,)\n",
            "{0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9524,)\n",
            "Epoch 1/20\n",
            "1197/1197 [==============================] - 39s 32ms/step - loss: 5.3645 - accuracy: 0.7576 - val_loss: 0.6802 - val_accuracy: 0.9315\n",
            "Epoch 2/20\n",
            "1197/1197 [==============================] - 38s 32ms/step - loss: 0.2485 - accuracy: 0.9559 - val_loss: 0.4067 - val_accuracy: 0.9314\n",
            "Epoch 3/20\n",
            "1197/1197 [==============================] - 38s 32ms/step - loss: 0.1005 - accuracy: 0.9748 - val_loss: 0.3353 - val_accuracy: 0.9306\n",
            "Epoch 4/20\n",
            "1197/1197 [==============================] - 38s 32ms/step - loss: 0.0688 - accuracy: 0.9792 - val_loss: 0.1216 - val_accuracy: 0.9665\n",
            "Epoch 5/20\n",
            "1197/1197 [==============================] - 38s 32ms/step - loss: 0.0625 - accuracy: 0.9816 - val_loss: 0.1979 - val_accuracy: 0.9584\n",
            "Epoch 6/20\n",
            "1197/1197 [==============================] - 38s 32ms/step - loss: 0.0570 - accuracy: 0.9822 - val_loss: 0.0757 - val_accuracy: 0.9805\n",
            "Epoch 7/20\n",
            "1197/1197 [==============================] - 38s 32ms/step - loss: 0.0509 - accuracy: 0.9840 - val_loss: 0.1366 - val_accuracy: 0.9697\n",
            "Epoch 8/20\n",
            "1197/1197 [==============================] - 38s 32ms/step - loss: 0.0425 - accuracy: 0.9870 - val_loss: 0.0946 - val_accuracy: 0.9738\n",
            "Epoch 9/20\n",
            "1197/1197 [==============================] - 38s 32ms/step - loss: 0.0424 - accuracy: 0.9870 - val_loss: 0.1016 - val_accuracy: 0.9721\n",
            "Epoch 10/20\n",
            "1197/1197 [==============================] - 38s 32ms/step - loss: 0.0354 - accuracy: 0.9895 - val_loss: 0.0696 - val_accuracy: 0.9814\n",
            "Epoch 11/20\n",
            "1197/1197 [==============================] - 38s 32ms/step - loss: 0.0388 - accuracy: 0.9879 - val_loss: 0.0515 - val_accuracy: 0.9866\n",
            "Epoch 12/20\n",
            "1197/1197 [==============================] - 38s 32ms/step - loss: 0.0327 - accuracy: 0.9903 - val_loss: 0.0990 - val_accuracy: 0.9745\n",
            "Epoch 13/20\n",
            "1197/1197 [==============================] - 38s 32ms/step - loss: 0.0279 - accuracy: 0.9915 - val_loss: 0.0768 - val_accuracy: 0.9830\n",
            "Epoch 14/20\n",
            "1197/1197 [==============================] - 38s 32ms/step - loss: 0.0255 - accuracy: 0.9930 - val_loss: 0.1247 - val_accuracy: 0.9736\n",
            "Epoch 15/20\n",
            "1197/1197 [==============================] - 38s 32ms/step - loss: 0.0245 - accuracy: 0.9927 - val_loss: 0.0816 - val_accuracy: 0.9810\n",
            "Epoch 16/20\n",
            "1197/1197 [==============================] - 38s 32ms/step - loss: 0.0189 - accuracy: 0.9936 - val_loss: 0.1380 - val_accuracy: 0.9681\n",
            "Epoch 17/20\n",
            "1197/1197 [==============================] - 38s 32ms/step - loss: 0.0188 - accuracy: 0.9941 - val_loss: 0.0606 - val_accuracy: 0.9853\n",
            "Epoch 18/20\n",
            "1197/1197 [==============================] - 38s 32ms/step - loss: 0.0162 - accuracy: 0.9951 - val_loss: 0.0689 - val_accuracy: 0.9853\n",
            "Epoch 19/20\n",
            "1197/1197 [==============================] - 38s 32ms/step - loss: 0.0182 - accuracy: 0.9944 - val_loss: 0.0978 - val_accuracy: 0.9807\n",
            "Epoch 20/20\n",
            "1197/1197 [==============================] - 38s 32ms/step - loss: 0.0206 - accuracy: 0.9929 - val_loss: 0.0692 - val_accuracy: 0.9855\n",
            "INFO:tensorflow:Assets written to: final_models/6anomaly-classifier6/assets\n",
            "Model 6 saved\n",
            "{0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 7: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(38568,)\n",
            "{0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 7: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9663,)\n",
            "Epoch 1/20\n",
            "1206/1206 [==============================] - 40s 32ms/step - loss: 5.0819 - accuracy: 0.8501 - val_loss: 0.2622 - val_accuracy: 0.9699\n",
            "Epoch 2/20\n",
            "1206/1206 [==============================] - 38s 32ms/step - loss: 0.1579 - accuracy: 0.9740 - val_loss: 0.1028 - val_accuracy: 0.9740\n",
            "Epoch 3/20\n",
            "1206/1206 [==============================] - 38s 32ms/step - loss: 0.0646 - accuracy: 0.9830 - val_loss: 0.0809 - val_accuracy: 0.9761\n",
            "Epoch 4/20\n",
            "1206/1206 [==============================] - 38s 32ms/step - loss: 0.0559 - accuracy: 0.9835 - val_loss: 0.2616 - val_accuracy: 0.9396\n",
            "Epoch 5/20\n",
            "1206/1206 [==============================] - 38s 32ms/step - loss: 0.0557 - accuracy: 0.9828 - val_loss: 0.1351 - val_accuracy: 0.9608\n",
            "Epoch 6/20\n",
            "1206/1206 [==============================] - 38s 32ms/step - loss: 0.0532 - accuracy: 0.9840 - val_loss: 0.0779 - val_accuracy: 0.9750\n",
            "Epoch 7/20\n",
            "1206/1206 [==============================] - 38s 32ms/step - loss: 0.0429 - accuracy: 0.9880 - val_loss: 0.1684 - val_accuracy: 0.9608\n",
            "Epoch 8/20\n",
            "1206/1206 [==============================] - 38s 32ms/step - loss: 0.0392 - accuracy: 0.9881 - val_loss: 0.0604 - val_accuracy: 0.9853\n",
            "Epoch 9/20\n",
            "1206/1206 [==============================] - 38s 32ms/step - loss: 0.0358 - accuracy: 0.9889 - val_loss: 0.1234 - val_accuracy: 0.9669\n",
            "Epoch 10/20\n",
            "1206/1206 [==============================] - 38s 32ms/step - loss: 0.0365 - accuracy: 0.9888 - val_loss: 0.0460 - val_accuracy: 0.9881\n",
            "Epoch 11/20\n",
            "1206/1206 [==============================] - 38s 32ms/step - loss: 0.0262 - accuracy: 0.9922 - val_loss: 0.1091 - val_accuracy: 0.9724\n",
            "Epoch 12/20\n",
            "1206/1206 [==============================] - 38s 32ms/step - loss: 0.0290 - accuracy: 0.9906 - val_loss: 0.1090 - val_accuracy: 0.9751\n",
            "Epoch 13/20\n",
            "1206/1206 [==============================] - 38s 32ms/step - loss: 0.0254 - accuracy: 0.9922 - val_loss: 0.0759 - val_accuracy: 0.9828\n",
            "Epoch 14/20\n",
            "1206/1206 [==============================] - 38s 32ms/step - loss: 0.0222 - accuracy: 0.9930 - val_loss: 0.0612 - val_accuracy: 0.9861\n",
            "Epoch 15/20\n",
            "1206/1206 [==============================] - 38s 32ms/step - loss: 0.0217 - accuracy: 0.9933 - val_loss: 0.0862 - val_accuracy: 0.9798\n",
            "Epoch 16/20\n",
            "1206/1206 [==============================] - 38s 32ms/step - loss: 0.0175 - accuracy: 0.9942 - val_loss: 0.0745 - val_accuracy: 0.9838\n",
            "Epoch 17/20\n",
            "1206/1206 [==============================] - 38s 32ms/step - loss: 0.0187 - accuracy: 0.9943 - val_loss: 0.0609 - val_accuracy: 0.9869\n",
            "Epoch 18/20\n",
            "1206/1206 [==============================] - 38s 32ms/step - loss: 0.0157 - accuracy: 0.9951 - val_loss: 0.0526 - val_accuracy: 0.9885\n",
            "Epoch 19/20\n",
            "1206/1206 [==============================] - 38s 32ms/step - loss: 0.0154 - accuracy: 0.9953 - val_loss: 0.0736 - val_accuracy: 0.9840\n",
            "Epoch 20/20\n",
            "1206/1206 [==============================] - 38s 32ms/step - loss: 0.0151 - accuracy: 0.9953 - val_loss: 0.1081 - val_accuracy: 0.9816\n",
            "INFO:tensorflow:Assets written to: final_models/6anomaly-classifier7/assets\n",
            "Model 7 saved\n",
            "{0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 7: 6, 8: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(38504,)\n",
            "{0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 7: 6, 8: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9629,)\n",
            "Epoch 1/20\n",
            "1204/1204 [==============================] - 39s 32ms/step - loss: 5.5718 - accuracy: 0.8140 - val_loss: 0.3402 - val_accuracy: 0.9553\n",
            "Epoch 2/20\n",
            "1204/1204 [==============================] - 38s 32ms/step - loss: 0.1662 - accuracy: 0.9737 - val_loss: 0.0677 - val_accuracy: 0.9810\n",
            "Epoch 3/20\n",
            "1204/1204 [==============================] - 38s 32ms/step - loss: 0.0617 - accuracy: 0.9836 - val_loss: 0.0639 - val_accuracy: 0.9812\n",
            "Epoch 4/20\n",
            "1204/1204 [==============================] - 38s 32ms/step - loss: 0.0547 - accuracy: 0.9835 - val_loss: 0.1803 - val_accuracy: 0.9542\n",
            "Epoch 5/20\n",
            "1204/1204 [==============================] - 38s 32ms/step - loss: 0.0511 - accuracy: 0.9848 - val_loss: 0.1281 - val_accuracy: 0.9728\n",
            "Epoch 6/20\n",
            "1204/1204 [==============================] - 38s 32ms/step - loss: 0.0461 - accuracy: 0.9864 - val_loss: 0.1457 - val_accuracy: 0.9627\n",
            "Epoch 7/20\n",
            "1204/1204 [==============================] - 38s 32ms/step - loss: 0.0455 - accuracy: 0.9859 - val_loss: 0.1286 - val_accuracy: 0.9728\n",
            "Epoch 8/20\n",
            "1204/1204 [==============================] - 38s 32ms/step - loss: 0.0379 - accuracy: 0.9879 - val_loss: 0.0686 - val_accuracy: 0.9821\n",
            "Epoch 9/20\n",
            "1204/1204 [==============================] - 38s 32ms/step - loss: 0.0353 - accuracy: 0.9885 - val_loss: 0.1357 - val_accuracy: 0.9705\n",
            "Epoch 10/20\n",
            "1204/1204 [==============================] - 38s 32ms/step - loss: 0.0345 - accuracy: 0.9891 - val_loss: 0.0962 - val_accuracy: 0.9765\n",
            "Epoch 11/20\n",
            "1204/1204 [==============================] - 38s 32ms/step - loss: 0.0294 - accuracy: 0.9914 - val_loss: 0.0751 - val_accuracy: 0.9831\n",
            "Epoch 12/20\n",
            "1204/1204 [==============================] - 38s 32ms/step - loss: 0.0279 - accuracy: 0.9912 - val_loss: 0.0890 - val_accuracy: 0.9810\n",
            "Epoch 13/20\n",
            "1204/1204 [==============================] - 38s 32ms/step - loss: 0.0203 - accuracy: 0.9932 - val_loss: 0.0835 - val_accuracy: 0.9824\n",
            "Epoch 14/20\n",
            "1204/1204 [==============================] - 38s 32ms/step - loss: 0.0203 - accuracy: 0.9937 - val_loss: 0.0613 - val_accuracy: 0.9860\n",
            "Epoch 15/20\n",
            "1204/1204 [==============================] - 38s 32ms/step - loss: 0.0178 - accuracy: 0.9946 - val_loss: 0.1035 - val_accuracy: 0.9816\n",
            "Epoch 16/20\n",
            "1204/1204 [==============================] - 38s 32ms/step - loss: 0.0182 - accuracy: 0.9938 - val_loss: 0.0676 - val_accuracy: 0.9864\n",
            "Epoch 17/20\n",
            "1204/1204 [==============================] - 38s 32ms/step - loss: 0.0146 - accuracy: 0.9957 - val_loss: 0.1139 - val_accuracy: 0.9828\n",
            "Epoch 18/20\n",
            "1204/1204 [==============================] - 38s 32ms/step - loss: 0.0168 - accuracy: 0.9944 - val_loss: 0.0626 - val_accuracy: 0.9884\n",
            "Epoch 19/20\n",
            "1204/1204 [==============================] - 38s 32ms/step - loss: 0.0142 - accuracy: 0.9954 - val_loss: 0.1046 - val_accuracy: 0.9805\n",
            "Epoch 20/20\n",
            "1204/1204 [==============================] - 38s 32ms/step - loss: 0.0159 - accuracy: 0.9957 - val_loss: 0.2939 - val_accuracy: 0.9537\n",
            "INFO:tensorflow:Assets written to: final_models/6anomaly-classifier8/assets\n",
            "Model 8 saved\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1A283osWWDj"
      },
      "source": [
        "class_0 = model0.load_model(\"final_models/6anomaly-classifier0\")\n",
        "class_1 = model1.load_model(\"final_models/6anomaly-classifier1\")\n",
        "class_2 = model2.load_model(\"final_models/6anomaly-classifier2\")\n",
        "class_3 = model3.load_model(\"final_models/6anomaly-classifier3\")\n",
        "class_4 = model4.load_model(\"final_models/6anomaly-classifier4\")\n",
        "class_5 = model5.load_model(\"final_models/6anomaly-classifier5\")\n",
        "class_6 = model6.load_model(\"final_models/6anomaly-classifier6\")\n",
        "class_7 = model7.load_model(\"final_models/6anomaly-classifier7\")\n",
        "class_8 = model8.load_model(\"final_models/6anomaly-classifier8\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8XdjFNQZWWDk",
        "outputId": "22aed80f-7448-4ae2-c916-140bb84bef34"
      },
      "source": [
        "layer_name_list = []\n",
        "\n",
        "layer_name_list.append(class_0.layers[-2:][0].name)\n",
        "layer_name_list.append(class_1.layers[-2:][0].name)\n",
        "layer_name_list.append(class_2.layers[-2:][0].name)\n",
        "layer_name_list.append(class_3.layers[-2:][0].name)\n",
        "layer_name_list.append(class_4.layers[-2:][0].name)\n",
        "layer_name_list.append(class_5.layers[-2:][0].name)\n",
        "layer_name_list.append(class_6.layers[-2:][0].name)\n",
        "layer_name_list.append(class_7.layers[-2:][0].name)\n",
        "layer_name_list.append(class_8.layers[-2:][0].name)\n",
        "\n",
        "print(layer_name_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['dense_39', 'dense_41', 'dense_43', 'dense_45', 'dense_47', 'dense_49', 'dense_51', 'dense_53', 'dense_55']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMTomPJ2WWDl"
      },
      "source": [
        "from keras import Model\n",
        "model_dict = {}\n",
        "model_output0 = class_0.get_layer(layer_name_list[0]).output\n",
        "m0 = Model(inputs=class_0.input, outputs=model_output0)\n",
        "model_dict[0] = m0\n",
        "\n",
        "model_output1 = class_1.get_layer(layer_name_list[1]).output\n",
        "m1 = Model(inputs=class_1.input, outputs=model_output1)\n",
        "model_dict[1] = m1\n",
        "\n",
        "model_output2 = class_2.get_layer(layer_name_list[2]).output\n",
        "m2 = Model(inputs=class_2.input, outputs=model_output2)\n",
        "model_dict[2] = m2\n",
        "\n",
        "model_output3 = class_3.get_layer(layer_name_list[3]).output\n",
        "m3 = Model(inputs=class_3.input, outputs=model_output3)\n",
        "model_dict[3] = m3\n",
        "\n",
        "model_output4 = class_4.get_layer(layer_name_list[4]).output\n",
        "m4 = Model(inputs=class_4.input, outputs=model_output4)\n",
        "model_dict[4] = m4\n",
        "\n",
        "model_output5 = class_5.get_layer(layer_name_list[5]).output\n",
        "m5 = Model(inputs=class_5.input, outputs=model_output5)\n",
        "model_dict[5] = m5\n",
        "\n",
        "model_output6 = class_6.get_layer(layer_name_list[6]).output\n",
        "m6 = Model(inputs=class_6.input, outputs=model_output6)\n",
        "model_dict[6] = m6\n",
        "\n",
        "model_output7 = class_7.get_layer(layer_name_list[7]).output\n",
        "m7 = Model(inputs=class_7.input, outputs=model_output7)\n",
        "model_dict[7] = m7\n",
        "\n",
        "model_output8 = class_8.get_layer(layer_name_list[8]).output\n",
        "m8 = Model(inputs=class_8.input, outputs=model_output8)\n",
        "model_dict[8] = m8\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UE8f4ehwWWDm",
        "outputId": "52bfa0b2-7578-44ad-bc4d-8e60bf962259"
      },
      "source": [
        "temp_val = []\n",
        "y_pred = []\n",
        "labels = set(new_val_labels)\n",
        "for i, lo in zip(range(9), labels):\n",
        "  m = model_dict[i]\n",
        "  val_imgs_, val_lbls_ = get_train_data(lo, new_val_images, new_val_labels)\n",
        "  y_p = m.predict(val_imgs_)\n",
        "  y_pred.append(y_p)\n",
        "  temp = temp_cal(y_p, val_lbls_)\n",
        "  temp_val.append(temp)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{1: 0, 2: 1, 3: 2, 4: 3, 5: 4, 7: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9648,)\n",
            "Temperature Initial value: 1.0\n",
            "Temperature Final value: 2.3399412631988525\n",
            "{0: 0, 2: 1, 3: 2, 4: 3, 5: 4, 7: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9501,)\n",
            "Temperature Initial value: 1.0\n",
            "Temperature Final value: 2.3231940269470215\n",
            "{0: 0, 1: 1, 3: 2, 4: 3, 5: 4, 7: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9649,)\n",
            "Temperature Initial value: 1.0\n",
            "Temperature Final value: 2.2757489681243896\n",
            "{0: 0, 1: 1, 2: 2, 4: 3, 5: 4, 7: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9604,)\n",
            "Temperature Initial value: 1.0\n",
            "Temperature Final value: 2.1671793460845947\n",
            "{0: 0, 1: 1, 2: 2, 3: 3, 5: 4, 7: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9647,)\n",
            "Temperature Initial value: 1.0\n",
            "Temperature Final value: 2.4774105548858643\n",
            "{0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 7: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9719,)\n",
            "Temperature Initial value: 1.0\n",
            "Temperature Final value: 2.0073540210723877\n",
            "{0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9524,)\n",
            "Temperature Initial value: 1.0\n",
            "Temperature Final value: 2.0190629959106445\n",
            "{0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 7: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9663,)\n",
            "Temperature Initial value: 1.0\n",
            "Temperature Final value: 2.4026806354522705\n",
            "{0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 7: 6, 8: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9629,)\n",
            "Temperature Initial value: 1.0\n",
            "Temperature Final value: 2.480726718902588\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xnT-9j1IWWDo",
        "outputId": "ad2dfa63-662d-4b6a-ab22-fbd9d5902ed7"
      },
      "source": [
        "temp_val"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=2.3399413>,\n",
              " <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=2.323194>,\n",
              " <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=2.275749>,\n",
              " <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=2.1671793>,\n",
              " <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=2.4774106>,\n",
              " <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=2.007354>,\n",
              " <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=2.019063>,\n",
              " <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=2.4026806>,\n",
              " <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=2.4807267>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0dzJdCqKWWDp",
        "outputId": "d7ae05eb-f103-441c-fd7d-93821d4d46fb"
      },
      "source": [
        "from tqdm import tqdm\n",
        "avg = [0,0,0,0,0,0,0,0,0]\n",
        "count = [0,0,0,0,0,0,0,0,0]\n",
        "entropy_list = [0,0,0,0,0,0,0,0,0]\n",
        "for img, lbl in tqdm(zip(new_val_images,new_val_labels)):\n",
        "  img = img.reshape([-1, 28, 28, 1])\n",
        "  if not lbl == 0:\n",
        "    logits = model_dict[0](img)\n",
        "    logits = tf.math.divide(logits, temp_val[0])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e0 = entropy(pred[0])\n",
        "    entropy_list[0] = entropy_list[0] + e0\n",
        "    max_val0 = np.max(pred)\n",
        "    avg[0] = avg[0] + max_val0\n",
        "    count[0] = count[0] + 1\n",
        "  if not lbl == 1:\n",
        "    logits = model_dict[1](img)\n",
        "    logits = tf.math.divide(logits, temp_val[1])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e1 = entropy(pred[0])\n",
        "    entropy_list[1] = entropy_list[1] + e1\n",
        "    max_val1 = np.max(pred)\n",
        "    avg[1] = avg[1] + max_val1\n",
        "    count[1] = count[1] + 1\n",
        "  if not lbl == 2:\n",
        "    logits = model_dict[2](img)\n",
        "    logits = tf.math.divide(logits, temp_val[2])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e2 = entropy(pred[0])\n",
        "    entropy_list[2] = entropy_list[2] + e2\n",
        "    max_val2 = np.max(pred)\n",
        "    avg[2] = avg[2] + max_val2\n",
        "    count[2] = count[2] + 1\n",
        "  if not lbl == 3:\n",
        "    logits = model_dict[3](img)\n",
        "    logits = tf.math.divide(logits, temp_val[3])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e3 = entropy(pred[0])\n",
        "    entropy_list[3] = entropy_list[3] + e3\n",
        "    max_val3 = np.max(pred)  \n",
        "    avg[3] = avg[3] + max_val3\n",
        "    count[3] = count[3] + 1\n",
        "  if not lbl == 4:\n",
        "    logits = model_dict[4](img)\n",
        "    logits = tf.math.divide(logits, temp_val[4])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e4 = entropy(pred[0])\n",
        "    entropy_list[4] = entropy_list[4] + e4\n",
        "    max_val4 = np.max(pred)\n",
        "    avg[4] = avg[4] + max_val4\n",
        "    count[4] = count[4] + 1\n",
        "  if not lbl == 5:\n",
        "    logits = model_dict[5](img)\n",
        "    logits = tf.math.divide(logits, temp_val[5])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e5 = entropy(pred[0])\n",
        "    entropy_list[5] = entropy_list[5] + e5\n",
        "    max_val5 = np.max(pred)\n",
        "    avg[5] = avg[5] + max_val5\n",
        "    count[5] = count[5] + 1\n",
        "  if not lbl == 7:\n",
        "    logits = model_dict[6](img)\n",
        "    logits = tf.math.divide(logits, temp_val[6])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e6 = entropy(pred[0])\n",
        "    entropy_list[6] = entropy_list[6] + e6\n",
        "    max_val6 = np.max(pred)\n",
        "    avg[6] = avg[6] + max_val6\n",
        "    count[6] = count[6] + 1\n",
        "  if not lbl == 8:\n",
        "    logits = model_dict[7](img)\n",
        "    logits = tf.math.divide(logits, temp_val[7])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e7 = entropy(pred[0])\n",
        "    entropy_list[7] = entropy_list[7] + e7\n",
        "    max_val7 = np.max(pred)\n",
        "    avg[7] = avg[7] + max_val7\n",
        "    count[7] = count[7] + 1\n",
        "  if not lbl == 9:\n",
        "    logits = model_dict[8](img)\n",
        "    logits = tf.math.divide(logits, temp_val[8])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e8 = entropy(pred[0])\n",
        "    entropy_list[8] = entropy_list[8] + e8\n",
        "    max_val8 = np.max(pred)\n",
        "    avg[8] = avg[8] + max_val8\n",
        "    count[8] = count[8] + 1\n",
        "\n",
        "print(avg)\n",
        "print(count)\n",
        "print(entropy_list)\n",
        "\n",
        "entropy_avg_t = [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]\n",
        "for i in range(9):\n",
        "  entropy_avg_t[i] = entropy_list[i]/count[i]\n",
        "\n",
        "entropy_value_t = 0.0\n",
        "for i in range(9):\n",
        "  entropy_value_t = entropy_value_t + entropy_avg_t[i]\n",
        "\n",
        "entropy_t = entropy_value_t/len(entropy_avg_t)\n",
        "\n",
        "print('Entropy:', entropy_t)\n",
        "\n",
        "classifier_avg_t = [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]\n",
        "for i in range(9):\n",
        "  classifier_avg_t[i] = avg[i]/count[i]\n",
        "\n",
        "print('Each Classifier Average: ',classifier_avg_t)\n",
        "\n",
        "treshold_value = 0.0\n",
        "for i in range(9):\n",
        "  treshold_value = treshold_value + classifier_avg_t[i]\n",
        "\n",
        "treshold_t = treshold_value/len(classifier_avg_t)\n",
        "\n",
        "print('Threshold:', treshold_t)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10823it [12:28, 14.46it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[9420.375517904758, 9262.270715504885, 9523.519088238478, 9475.3318811059, 9399.644717305899, 9602.747386485338, 9385.62716987729, 9502.379462838173, 9273.205349057913]\n",
            "[9648, 9501, 9649, 9604, 9647, 9719, 9524, 9663, 9629]\n",
            "[703.5884800964678, 738.8165594201257, 407.5849095720339, 424.0141194273701, 738.1703139624831, 374.3955660142659, 455.14935245186825, 482.94503568533435, 1072.3461702701527]\n",
            "Entropy: 0.0623615202184385\n",
            "Each Classifier Average:  [0.9764070810431964, 0.9748732465535086, 0.9869954490867943, 0.9866026531763744, 0.9743593570338861, 0.9880386239824404, 0.9854711434142472, 0.9833777773815764, 0.9630496779580343]\n",
            "Threshold: 0.9799083344033398\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_fbu5JFWWDq",
        "outputId": "7d91b369-7c7d-41ee-bd38-62503aadc79d"
      },
      "source": [
        "ref_vect_in_6an = []\n",
        "ref_vect_in_6an.append(classifier_avg_t)\n",
        "\n",
        "threshold_in_6an = []\n",
        "threshold_in_6an.append(treshold_t)\n",
        "\n",
        "entropy_in_6an = []\n",
        "entropy_in_6an.append(entropy_t)\n",
        "\n",
        "print(entropy_in_6an)\n",
        "print(ref_vect_in_6an)\n",
        "print(threshold_in_6an)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.0623615202184385]\n",
            "[[0.9764070810431964, 0.9748732465535086, 0.9869954490867943, 0.9866026531763744, 0.9743593570338861, 0.9880386239824404, 0.9854711434142472, 0.9833777773815764, 0.9630496779580343]]\n",
            "[0.9799083344033398]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2PZec5-JHIx"
      },
      "source": [
        "entropy_in_6an = [0.0623615202184385]\n",
        "ref_vect_in_6an = [[0.9764070810431964, 0.9748732465535086, 0.9869954490867943, 0.9866026531763744, 0.9743593570338861, 0.9880386239824404, 0.9854711434142472, 0.9833777773815764, 0.9630496779580343]]\n",
        "threshold_in_6an = [0.9799083344033398]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pnkVbP1LWWDq",
        "outputId": "53435a50-dd08-4e3d-db31-20ec7a761911"
      },
      "source": [
        "from tqdm import tqdm\n",
        "avg = [0,0,0,0,0,0,0,0,0]\n",
        "count = [0,0,0,0,0,0,0,0,0]\n",
        "entropy_list = [0,0,0,0,0,0,0,0,0]\n",
        "\n",
        "for img, lbl in tqdm(zip(new_val_images,new_val_labels)):\n",
        "  img = img.reshape([-1, 28, 28, 1])\n",
        "  if lbl == 0:\n",
        "    logits = model_dict[0](img)\n",
        "    logits = tf.math.divide(logits, temp_val[0])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e0 = entropy(pred[0])\n",
        "    entropy_list[0] = entropy_list[0] + e0\n",
        "    max_val0 = np.max(pred)\n",
        "    avg[0] = avg[0] + max_val0\n",
        "    count[0] = count[0] + 1\n",
        "  if lbl == 1:\n",
        "    logits = model_dict[1](img)\n",
        "    logits = tf.math.divide(logits, temp_val[1])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e1 = entropy(pred[0])\n",
        "    entropy_list[1] = entropy_list[1] + e1\n",
        "    max_val1 = np.max(pred)\n",
        "    avg[1] = avg[1] + max_val1\n",
        "    count[1] = count[1] + 1\n",
        "  if lbl == 2:\n",
        "    logits = model_dict[2](img)\n",
        "    logits = tf.math.divide(logits, temp_val[2])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e2 = entropy(pred[0])\n",
        "    entropy_list[2] = entropy_list[2] + e2\n",
        "    max_val2 = np.max(pred)\n",
        "    avg[2] = avg[2] + max_val2\n",
        "    count[2] = count[2] + 1\n",
        "  if lbl == 3:\n",
        "    logits = model_dict[3](img)\n",
        "    logits = tf.math.divide(logits, temp_val[3])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e3 = entropy(pred[0])\n",
        "    entropy_list[3] = entropy_list[3] + e3\n",
        "    max_val3 = np.max(pred)  \n",
        "    avg[3] = avg[3] + max_val3\n",
        "    count[3] = count[3] + 1\n",
        "  if lbl == 4:\n",
        "    logits = model_dict[4](img)\n",
        "    logits = tf.math.divide(logits, temp_val[4])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e4 = entropy(pred[0])\n",
        "    entropy_list[4] = entropy_list[4] + e4\n",
        "    max_val4 = np.max(pred)\n",
        "    avg[4] = avg[4] + max_val4\n",
        "    count[4] = count[4] + 1\n",
        "  if lbl == 5:\n",
        "    logits = model_dict[5](img)\n",
        "    logits = tf.math.divide(logits, temp_val[5])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e5 = entropy(pred[0])\n",
        "    entropy_list[5] = entropy_list[5] + e5\n",
        "    max_val5 = np.max(pred)\n",
        "    avg[5] = avg[5] + max_val5\n",
        "    count[5] = count[5] + 1\n",
        "  if lbl == 7:\n",
        "    logits = model_dict[6](img)\n",
        "    logits = tf.math.divide(logits, temp_val[6])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e6 = entropy(pred[0])\n",
        "    entropy_list[6] = entropy_list[6] + e6\n",
        "    max_val6 = np.max(pred)\n",
        "    avg[6] = avg[6] + max_val6\n",
        "    count[6] = count[6] + 1\n",
        "  if lbl == 8:\n",
        "    logits = model_dict[7](img)\n",
        "    logits = tf.math.divide(logits, temp_val[7])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e7 = entropy(pred[0])\n",
        "    entropy_list[7] = entropy_list[7] + e7\n",
        "    max_val7 = np.max(pred)\n",
        "    avg[7] = avg[7] + max_val7\n",
        "    count[7] = count[7] + 1\n",
        "  if lbl == 9:\n",
        "    logits = model_dict[8](img)\n",
        "    logits = tf.math.divide(logits, temp_val[8])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e8 = entropy(pred[0])\n",
        "    entropy_list[8] = entropy_list[8] + e8\n",
        "    max_val8 = np.max(pred)\n",
        "    avg[8] = avg[8] + max_val8\n",
        "    count[8] = count[8] + 1\n",
        "\n",
        "print(avg)\n",
        "print(count)\n",
        "print(entropy_list)\n",
        "\n",
        "entropy_avg_t = [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]\n",
        "for i in range(9):\n",
        "  entropy_avg_t[i] = entropy_list[i]/count[i]\n",
        "\n",
        "entropy_value_t = 0.0\n",
        "for i in range(9):\n",
        "  entropy_value_t = entropy_value_t + entropy_avg_t[i]\n",
        "\n",
        "entropy_t = entropy_value_t/len(entropy_avg_t)\n",
        "\n",
        "print('Entropy:', entropy_t)\n",
        "\n",
        "classifier_avg_t = [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]\n",
        "for i in range(9):\n",
        "  classifier_avg_t[i] = avg[i]/count[i]\n",
        "\n",
        "print('Each Classifier Average: ',classifier_avg_t)\n",
        "\n",
        "treshold_value = 0.0\n",
        "for i in range(9):\n",
        "  treshold_value = treshold_value + classifier_avg_t[i]\n",
        "\n",
        "treshold_t = treshold_value/len(classifier_avg_t)\n",
        "\n",
        "print('Threshold:', treshold_t)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10823it [01:34, 114.24it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[810.8496254086494, 771.8726341128349, 922.2594998776913, 1027.8617151379585, 915.4727564007044, 899.0839091837406, 900.8293139487505, 910.9361905455589, 1010.5103847384453]\n",
            "[1175, 1322, 1174, 1219, 1176, 1104, 1299, 1160, 1194]\n",
            "[959.1896780845709, 1370.0300924649928, 652.1723656872637, 519.1910479807548, 676.2272188120842, 524.7716135883747, 1020.1400757234369, 667.1080591225764, 439.6067816337766]\n",
            "Entropy: 0.6236724091756243\n",
            "Each Classifier Average:  [0.6900847875818293, 0.5838673480429917, 0.7855702724682209, 0.8432007507284319, 0.7784632282318915, 0.8143875988983158, 0.6934790715540804, 0.7852898194358267, 0.8463236053085806]\n",
            "Threshold: 0.7578518313611299\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8OfVFDl9WWDr",
        "outputId": "43fe95cf-b40d-4736-c70a-5965ac532fa1"
      },
      "source": [
        "ref_vect_out_6an = []\n",
        "ref_vect_out_6an.append(classifier_avg_t)\n",
        "\n",
        "threshold_out_6an = []\n",
        "threshold_out_6an.append(treshold_t)\n",
        "\n",
        "entropy_out_6an = []\n",
        "entropy_out_6an.append(entropy_t)\n",
        "\n",
        "print(entropy_out_6an)\n",
        "print(ref_vect_out_6an)\n",
        "print(threshold_out_6an)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.6236724091756243]\n",
            "[[0.6900847875818293, 0.5838673480429917, 0.7855702724682209, 0.8432007507284319, 0.7784632282318915, 0.8143875988983158, 0.6934790715540804, 0.7852898194358267, 0.8463236053085806]]\n",
            "[0.7578518313611299]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZAIdxx1VJTsW"
      },
      "source": [
        "entropy_out_6an = [0.6236724091756243]\n",
        "ref_vect_out_6an = [[0.6900847875818293, 0.5838673480429917, 0.7855702724682209, 0.8432007507284319, 0.7784632282318915, 0.8143875988983158, 0.6934790715540804, 0.7852898194358267, 0.8463236053085806]]\n",
        "threshold_out_6an = [0.7578518313611299]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESA8dYIsWWDs"
      },
      "source": [
        "def get_max_pred_value(model, img, temp):\n",
        "  logits = model(img)\n",
        "  logits = tf.math.divide(logits, temp)\n",
        "  pred = tf.nn.softmax(logits)\n",
        "  e = entropy(pred[0])\n",
        "\n",
        "  return np.max(pred), tf.argmax(pred[0]).numpy(), e"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PABmJ8ooWWDs"
      },
      "source": [
        "def get_mapping(leave_out_class, anomaly_class):\n",
        "  mapping = {}\n",
        "\n",
        "  labels = set(train_labels)\n",
        "  labels.remove(anomaly_class)\n",
        "  labels.remove(leave_out_class)\n",
        "  labels = sorted(labels)\n",
        "\n",
        "  for i,j in enumerate(labels):\n",
        "    mapping[i] = j\n",
        "\n",
        "  return mapping\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PkLSwyT_WWDt"
      },
      "source": [
        "ood = 0\n",
        "ind = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q6L7XGtxWWDt",
        "outputId": "e31f7a52-3841-48d1-d7df-17578affe310"
      },
      "source": [
        "max_sm_all_wt_6an = []\n",
        "for data, label in tqdm(zip(test_imgs, test_lbls)):\n",
        "  img = data.reshape([-1, 28, 28, 1])\n",
        "  ref_value = []\n",
        "  \n",
        "  if label == 6:\n",
        "    lbl = ood\n",
        "  else:\n",
        "    lbl = ind\n",
        "\n",
        "\n",
        "  max0, pred_0, e0 = get_max_pred_value(model_dict[0], img, temp=temp_val[0])\n",
        "  map0 = get_mapping(0, 6)\n",
        "  pred_0 = map0[pred_0]\n",
        "\n",
        "  max1, pred_1, e1 = get_max_pred_value(model_dict[1], img, temp=temp_val[1])\n",
        "  map1 = get_mapping(1, 6)\n",
        "  pred_1 = map1[pred_1]\n",
        "\n",
        "  max2, pred_2, e2 = get_max_pred_value(model_dict[2], img, temp=temp_val[2])\n",
        "  map2 = get_mapping(2, 6)\n",
        "  pred_2 = map2[pred_2]\n",
        "\n",
        "  max3, pred_3, e3 = get_max_pred_value(model_dict[3], img, temp=temp_val[3])\n",
        "  map3 = get_mapping(3, 6)\n",
        "  pred_3 = map3[pred_3]\n",
        "\n",
        "  max4, pred_4, e4 = get_max_pred_value(model_dict[4], img, temp=temp_val[4])\n",
        "  map4 = get_mapping(4, 6)\n",
        "  pred_4 = map4[pred_4]\n",
        "\n",
        "  max5, pred_5, e5 = get_max_pred_value(model_dict[5], img, temp=temp_val[5])\n",
        "  map5 = get_mapping(5, 6)\n",
        "  pred_5 = map5[pred_5]\n",
        "\n",
        "  max6, pred_6, e6 = get_max_pred_value(model_dict[6], img, temp=temp_val[6])\n",
        "  map6 = get_mapping(7, 6)\n",
        "  pred_6 = map6[pred_6]\n",
        "\n",
        "  max7, pred_7, e7 = get_max_pred_value(model_dict[7], img, temp=temp_val[7])\n",
        "  map7 = get_mapping(8, 6)\n",
        "  pred_7 = map7[pred_7]\n",
        "\n",
        "  max8, pred_8, e8 = get_max_pred_value(model_dict[8], img, temp=temp_val[8])\n",
        "  map8 = get_mapping(9, 6)\n",
        "  pred_8 = map8[pred_8]\n",
        "\n",
        "  ref_value =[max0, max1, max2, max3, max4, max5, max6, max7, max8]\n",
        "  pred_value = [pred_0, pred_1, pred_2, pred_3, pred_4, pred_5, pred_6, pred_7, pred_8]\n",
        "  e_value = [e0, e1, e2, e3, e4, e5, e6, e7, e8]\n",
        "  e_ = 0.0\n",
        "  for  e in e_value:\n",
        "    e_ = e_ + e\n",
        "  e_ = e_/len(e_value)\n",
        "  max_sm_all_wt_6an.append([ref_value, lbl, pred_value, label, e_])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000it [20:39,  8.07it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L42prs6nWWDu"
      },
      "source": [
        "pickle_out = open(\"sm_all_wt_6an.pickle\",\"wb\")\n",
        "pickle.dump(max_sm_all_wt_6an, pickle_out)\n",
        "pickle_out.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubzQ3HiMWWDu"
      },
      "source": [
        "pickle_in = open(\"sm_all_wt_6an.pickle\",\"rb\")\n",
        "max_sm_all_wt_6an = pickle.load(pickle_in)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YyIR15XEWWDv",
        "outputId": "aa20bab6-31dc-4e86-f0bd-463ec982ed55"
      },
      "source": [
        "for data, lbl, p, a_l, e_ in max_sm_all_wt_6an:\n",
        "  print(p, lbl, a_l)\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[7, 7, 7, 7, 7, 7, 2, 7, 7] 1 7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DiOxI1jWWWDw",
        "outputId": "fae3947b-2448-4074-fa18-e832075ef92e"
      },
      "source": [
        "accuracy = 0.0\n",
        "count_in = 0\n",
        "count_ood = 0\n",
        "acc_in = 0.0\n",
        "acc_ood = 0.0\n",
        "tp = 0.0\n",
        "tn = 0.0\n",
        "fp = 0.0\n",
        "fn = 0.0\n",
        "y_true = []\n",
        "y_pred = []\n",
        "sim_score = []\n",
        "sim_score_ = []\n",
        "\n",
        "for data, lbl, p, a_l, e_ in max_sm_all_wt_6an:\n",
        "\n",
        "  score = 0.0\n",
        "  for d in data:\n",
        "    score = score + d\n",
        "  score = score / len(data)\n",
        "  sim_score.append(score)\n",
        "\n",
        "  dist_ood = np.linalg.norm(np.array(data) - np.array(ref_vect_out_6an[0])) \n",
        "  dist_in = np.linalg.norm(np.array(data) - np.array(ref_vect_in_6an[0]))\n",
        "\n",
        "  dist_ood2 = np.linalg.norm(np.array(e_) - np.array(entropy_out_6an[0])) \n",
        "  dist_in2 = np.linalg.norm(np.array(e_) - np.array(entropy_in_6an[0]))\n",
        "\n",
        "  dist_in = dist_in / (dist_in + dist_ood)\n",
        "  dist_ood = dist_ood / (dist_in + dist_ood)\n",
        "\n",
        "  dist_in2 = dist_in2 / (dist_in2 + dist_ood2)\n",
        "  dist_ood2 = dist_ood2 / (dist_in2 + dist_ood2)\n",
        "\n",
        "  sim_in = 1 / (1 + dist_in)\n",
        "  sim_ood = 1 / (1 + dist_ood)\n",
        "\n",
        "  sim_in2 = 1 / (1 + dist_in2)\n",
        "  sim_ood2 = 1 / (1 + dist_ood2)\n",
        "\n",
        "  sim_in = sim_in + sim_in2\n",
        "  sim_ood = sim_ood + sim_ood2\n",
        "\n",
        "  sim_score_.append(sim_ood2)\n",
        "\n",
        "  values, counts = np.unique(p, return_counts=True)\n",
        "#  print(values, counts)\n",
        "  #print(sim_in, sim_ood, lbl, e_)\n",
        "\n",
        "\n",
        "  if sim_in > sim_ood:\n",
        "    y_ = ind\n",
        "    if np.max(counts) >= 8:\n",
        "      y_ = ind\n",
        "    else:\n",
        "      y_ = ood\n",
        "  else:\n",
        "    y_ = ood\n",
        "\n",
        "\n",
        "  y_pred.append(y_)\n",
        "#  if lbl == 1:\n",
        "#    y_true.append(0)\n",
        "#  else:\n",
        "#    y_true.append(1)\n",
        "  y_true.append(lbl)\n",
        "\n",
        "\n",
        "  if lbl == ind:\n",
        "    count_in = count_in + 1\n",
        "  else:\n",
        "    count_ood = count_ood + 1\n",
        "\n",
        "  if y_ == lbl:\n",
        "    #sim_score_.append(1)\n",
        "    accuracy = accuracy + 1\n",
        "    if y_ == ind:\n",
        "      acc_in = acc_in + 1\n",
        "      tp = tp + 1\n",
        "    else:\n",
        "      acc_ood = acc_ood + 1\n",
        "      tn = tn + 1\n",
        "  else:\n",
        "    #sim_score_.append(0)\n",
        "    if y_ == ind:\n",
        "      fp = fp + 1\n",
        "    else:\n",
        "      fn = fn + 1\n",
        "\n",
        "\n",
        "print(\"Total Accuracy: \", accuracy/len(max_sm_all_wt_6an)) \n",
        "print(\"Accuracy of determining ID data: \", acc_in/count_in)\n",
        "print(\"Accuracy of determining OOD data: \", acc_ood/count_ood)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Accuracy:  0.8977\n",
            "Accuracy of determining ID data:  0.8969254589692546\n",
            "Accuracy of determining OOD data:  0.9050104384133612\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rMxwTbACWWDw",
        "outputId": "1ae9bcbb-ddbc-45a4-e3c1-6a2de8ae16e4"
      },
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "roc_auc_score(y_true, sim_score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9164895761325367"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TbjqKaBbWWDx",
        "outputId": "2aca2b8a-33c0-4bc1-aa0c-c98505645f1b"
      },
      "source": [
        "roc_auc_score(y_true, y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8888992403347127"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3kp_9yBZTCIO"
      },
      "source": [
        "sim_score_ = sim_score_ / max(sim_score_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5N1stRZzWWDx",
        "outputId": "4f069b36-bd82-4d61-fe6b-fc711fc58426"
      },
      "source": [
        "roc_auc_score(y_true, sim_score_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7098903793431627"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wE7XE4yU0aWH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d9ba3e9-2620-453e-8da9-88388ef9c123"
      },
      "source": [
        "sim_score_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.96736581, 0.98604915, 0.94387278, ..., 0.97899977, 0.97265618,\n",
              "       0.9870728 ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0D-J_-cD1t7W"
      },
      "source": [
        "# 7 as anomaly"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1m0Sxi31vQb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0L6NElzH1wFC"
      },
      "source": [
        "new_train_images, new_train_labels, new_val_images, new_val_labels = separate_class(7, train_images, train_labels, val_images, val_labels)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fk3qri501wFE"
      },
      "source": [
        "model0 = Model(name='7anomaly:classifier0')\n",
        "model1 = Model(name='7anomaly:classifier1')\n",
        "model2 = Model(name='7anomaly:classifier2')\n",
        "model3 = Model(name='7anomaly:classifier3')\n",
        "model4 = Model(name='7anomaly:classifier4')\n",
        "model5 = Model(name='7anomaly:classifier5')\n",
        "model6 = Model(name='7anomaly:classifier6')\n",
        "model7 = Model(name='7anomaly:classifier7')\n",
        "model8 = Model(name='7anomaly:classifier8')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1ihSnPb1wFF"
      },
      "source": [
        "class_0 = model0.build()\n",
        "class_1 = model1.build()\n",
        "class_2 = model2.build()\n",
        "class_3 = model3.build()\n",
        "class_4 = model4.build()\n",
        "class_5 = model5.build()\n",
        "class_6 = model6.build()\n",
        "class_7 = model7.build()\n",
        "class_8 = model8.build()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FYxihKlk1wFG",
        "outputId": "39481686-246a-4314-f0a1-f8d749c15140"
      },
      "source": [
        "train_imgs0, train_lbls0 = get_train_data(0, new_train_images, new_train_labels)\n",
        "val_imgs0, val_lbls0 = get_train_data(0, new_val_images, new_val_labels)\n",
        "class_0 = model0.build()\n",
        "model0.train2(train_imgs0, train_lbls0, val_imgs0, val_lbls0)\n",
        "#model0.train(train_data0)\n",
        "model0.save_model(\"final_models/7anomaly-classifier0\")\n",
        "print('Model 0 saved')\n",
        "\n",
        "train_imgs1, train_lbls1 = get_train_data(1, new_train_images, new_train_labels)\n",
        "val_imgs1, val_lbls1 = get_train_data(1, new_val_images, new_val_labels)\n",
        "class_1 = model1.build()\n",
        "model1.train2(train_imgs1, train_lbls1, val_imgs1, val_lbls1)\n",
        "#model1.train(train_data1)\n",
        "model1.save_model(\"final_models/7anomaly-classifier1\")\n",
        "print('Model 1 saved')\n",
        "\n",
        "#train_data2 = get_train_data(2, new_train_images)\n",
        "train_imgs2, train_lbls2 = get_train_data(2, new_train_images, new_train_labels)\n",
        "val_imgs2, val_lbls2 = get_train_data(2, new_val_images, new_val_labels)\n",
        "class_2 = model2.build()\n",
        "model2.train2(train_imgs2, train_lbls2, val_imgs2, val_lbls2)\n",
        "#model2.train(train_data2)\n",
        "model2.save_model(\"final_models/7anomaly-classifier2\")\n",
        "print('Model 2 saved')\n",
        "\n",
        "#train_data3 = get_train_data(3, new_train_images)\n",
        "train_imgs3, train_lbls3 = get_train_data(3, new_train_images, new_train_labels)\n",
        "val_imgs3, val_lbls3 = get_train_data(3, new_val_images, new_val_labels)\n",
        "class_3 = model3.build()\n",
        "model3.train2(train_imgs3, train_lbls3, val_imgs3, val_lbls3)\n",
        "#model3.train(train_data3)\n",
        "model3.save_model(\"final_models/7anomaly-classifier3\")\n",
        "print('Model 3 saved')\n",
        "\n",
        "#train_data4 = get_train_data(4, new_train_images)\n",
        "train_imgs4, train_lbls4 = get_train_data(4, new_train_images, new_train_labels)\n",
        "val_imgs4, val_lbls4 = get_train_data(4, new_val_images, new_val_labels)\n",
        "class_4 = model4.build()\n",
        "model4.train2(train_imgs4, train_lbls4, val_imgs4, val_lbls4)\n",
        "#model4.train(train_data4)\n",
        "model4.save_model(\"final_models/7anomaly-classifier4\")\n",
        "print('Model 4 saved')\n",
        "\n",
        "#train_data5 = get_train_data(5, new_train_images)\n",
        "train_imgs5, train_lbls5 = get_train_data(5, new_train_images, new_train_labels)\n",
        "val_imgs5, val_lbls5 = get_train_data(5, new_val_images, new_val_labels)\n",
        "class_5 = model5.build()\n",
        "model5.train2(train_imgs5, train_lbls5, val_imgs5, val_lbls5)\n",
        "#model5.train(train_data5)\n",
        "model5.save_model(\"final_models/7anomaly-classifier5\")\n",
        "print('Model 5 saved')\n",
        "\n",
        "#train_data6 = get_train_data(6, new_train_images)\n",
        "train_imgs6, train_lbls6 = get_train_data(6, new_train_images, new_train_labels)\n",
        "val_imgs6, val_lbls6 = get_train_data(6, new_val_images, new_val_labels)\n",
        "class_6 = model6.build()\n",
        "model6.train2(train_imgs6, train_lbls6, val_imgs6, val_lbls6)\n",
        "#model6.train(train_data6)\n",
        "model6.save_model(\"final_models/7anomaly-classifier6\")\n",
        "print('Model 6 saved')\n",
        "\n",
        "#train_data7 = get_train_data(7, new_train_images)\n",
        "train_imgs7, train_lbls7 = get_train_data(8, new_train_images, new_train_labels)\n",
        "val_imgs7, val_lbls7 = get_train_data(8, new_val_images, new_val_labels)\n",
        "class_7 = model7.build()\n",
        "#model7.train(train_data7)\n",
        "model7.train2(train_imgs7, train_lbls7, val_imgs7, val_lbls7)\n",
        "model7.save_model(\"final_models/7anomaly-classifier7\")\n",
        "print('Model 7 saved')\n",
        "\n",
        "#train_data8 = get_train_data(8, new_train_images)\n",
        "train_imgs8, train_lbls8 = get_train_data(9, new_train_images, new_train_labels)\n",
        "val_imgs8, val_lbls8 = get_train_data(9, new_val_images, new_val_labels)\n",
        "class_8 = model8.build()\n",
        "#model8.train(train_data8)\n",
        "model8.train2(train_imgs8, train_lbls8, val_imgs8, val_lbls8)\n",
        "model8.save_model(\"final_models/7anomaly-classifier8\")\n",
        "print('Model 8 saved')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{1: 0, 2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(38286,)\n",
            "{1: 0, 2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9526,)\n",
            "Epoch 1/20\n",
            "1197/1197 [==============================] - 40s 32ms/step - loss: 5.7006 - accuracy: 0.7752 - val_loss: 0.1483 - val_accuracy: 0.9666\n",
            "Epoch 2/20\n",
            "1197/1197 [==============================] - 38s 32ms/step - loss: 0.1602 - accuracy: 0.9661 - val_loss: 0.2425 - val_accuracy: 0.9596\n",
            "Epoch 3/20\n",
            "1197/1197 [==============================] - 38s 32ms/step - loss: 0.0924 - accuracy: 0.9749 - val_loss: 0.0798 - val_accuracy: 0.9790\n",
            "Epoch 4/20\n",
            "1197/1197 [==============================] - 38s 32ms/step - loss: 0.0782 - accuracy: 0.9778 - val_loss: 0.0852 - val_accuracy: 0.9785\n",
            "Epoch 5/20\n",
            "1197/1197 [==============================] - 38s 32ms/step - loss: 0.0626 - accuracy: 0.9821 - val_loss: 0.1244 - val_accuracy: 0.9710\n",
            "Epoch 6/20\n",
            "1197/1197 [==============================] - 38s 32ms/step - loss: 0.0508 - accuracy: 0.9842 - val_loss: 0.1577 - val_accuracy: 0.9600\n",
            "Epoch 7/20\n",
            "1197/1197 [==============================] - 38s 32ms/step - loss: 0.0525 - accuracy: 0.9838 - val_loss: 0.1220 - val_accuracy: 0.9684\n",
            "Epoch 8/20\n",
            "1197/1197 [==============================] - 38s 32ms/step - loss: 0.0491 - accuracy: 0.9850 - val_loss: 0.0464 - val_accuracy: 0.9872\n",
            "Epoch 9/20\n",
            "1197/1197 [==============================] - 38s 32ms/step - loss: 0.0440 - accuracy: 0.9861 - val_loss: 0.0911 - val_accuracy: 0.9762\n",
            "Epoch 10/20\n",
            "1197/1197 [==============================] - 38s 31ms/step - loss: 0.0354 - accuracy: 0.9893 - val_loss: 0.0637 - val_accuracy: 0.9831\n",
            "Epoch 11/20\n",
            "1197/1197 [==============================] - 38s 31ms/step - loss: 0.0341 - accuracy: 0.9894 - val_loss: 0.0409 - val_accuracy: 0.9877\n",
            "Epoch 12/20\n",
            "1197/1197 [==============================] - 38s 31ms/step - loss: 0.0281 - accuracy: 0.9911 - val_loss: 0.0553 - val_accuracy: 0.9856\n",
            "Epoch 13/20\n",
            "1197/1197 [==============================] - 38s 31ms/step - loss: 0.0286 - accuracy: 0.9912 - val_loss: 0.0782 - val_accuracy: 0.9820\n",
            "Epoch 14/20\n",
            "1197/1197 [==============================] - 38s 31ms/step - loss: 0.0203 - accuracy: 0.9933 - val_loss: 0.0628 - val_accuracy: 0.9841\n",
            "Epoch 15/20\n",
            "1197/1197 [==============================] - 38s 31ms/step - loss: 0.0251 - accuracy: 0.9922 - val_loss: 0.0839 - val_accuracy: 0.9806\n",
            "Epoch 16/20\n",
            "1197/1197 [==============================] - 38s 32ms/step - loss: 0.0196 - accuracy: 0.9933 - val_loss: 0.1065 - val_accuracy: 0.9746\n",
            "Epoch 17/20\n",
            "1197/1197 [==============================] - 38s 32ms/step - loss: 0.0204 - accuracy: 0.9938 - val_loss: 0.1032 - val_accuracy: 0.9758\n",
            "Epoch 18/20\n",
            "1197/1197 [==============================] - 38s 32ms/step - loss: 0.0183 - accuracy: 0.9941 - val_loss: 0.0909 - val_accuracy: 0.9791\n",
            "Epoch 19/20\n",
            "1197/1197 [==============================] - 38s 32ms/step - loss: 0.0168 - accuracy: 0.9942 - val_loss: 0.0741 - val_accuracy: 0.9836\n",
            "Epoch 20/20\n",
            "1197/1197 [==============================] - 38s 31ms/step - loss: 0.0160 - accuracy: 0.9949 - val_loss: 0.0496 - val_accuracy: 0.9894\n",
            "INFO:tensorflow:Assets written to: final_models/7anomaly-classifier0/assets\n",
            "Model 0 saved\n",
            "{0: 0, 2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(37614,)\n",
            "{0: 0, 2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9379,)\n",
            "Epoch 1/20\n",
            "1176/1176 [==============================] - 38s 32ms/step - loss: 5.4802 - accuracy: 0.8261 - val_loss: 0.2339 - val_accuracy: 0.9601\n",
            "Epoch 2/20\n",
            "1176/1176 [==============================] - 37s 32ms/step - loss: 0.1492 - accuracy: 0.9720 - val_loss: 0.1225 - val_accuracy: 0.9646\n",
            "Epoch 3/20\n",
            "1176/1176 [==============================] - 37s 32ms/step - loss: 0.0689 - accuracy: 0.9807 - val_loss: 0.1289 - val_accuracy: 0.9633\n",
            "Epoch 4/20\n",
            "1176/1176 [==============================] - 37s 32ms/step - loss: 0.0583 - accuracy: 0.9826 - val_loss: 0.0851 - val_accuracy: 0.9749\n",
            "Epoch 5/20\n",
            "1176/1176 [==============================] - 37s 32ms/step - loss: 0.0547 - accuracy: 0.9842 - val_loss: 0.1583 - val_accuracy: 0.9655\n",
            "Epoch 6/20\n",
            "1176/1176 [==============================] - 37s 32ms/step - loss: 0.0517 - accuracy: 0.9843 - val_loss: 0.1097 - val_accuracy: 0.9716\n",
            "Epoch 7/20\n",
            "1176/1176 [==============================] - 37s 32ms/step - loss: 0.0537 - accuracy: 0.9841 - val_loss: 0.1078 - val_accuracy: 0.9739\n",
            "Epoch 8/20\n",
            "1176/1176 [==============================] - 37s 32ms/step - loss: 0.0494 - accuracy: 0.9857 - val_loss: 0.0646 - val_accuracy: 0.9836\n",
            "Epoch 9/20\n",
            "1176/1176 [==============================] - 37s 32ms/step - loss: 0.0389 - accuracy: 0.9881 - val_loss: 0.1163 - val_accuracy: 0.9719\n",
            "Epoch 10/20\n",
            "1176/1176 [==============================] - 37s 32ms/step - loss: 0.0341 - accuracy: 0.9891 - val_loss: 0.0793 - val_accuracy: 0.9818\n",
            "Epoch 11/20\n",
            "1176/1176 [==============================] - 37s 32ms/step - loss: 0.0286 - accuracy: 0.9918 - val_loss: 0.0967 - val_accuracy: 0.9779\n",
            "Epoch 12/20\n",
            "1176/1176 [==============================] - 37s 32ms/step - loss: 0.0277 - accuracy: 0.9910 - val_loss: 0.0940 - val_accuracy: 0.9786\n",
            "Epoch 13/20\n",
            "1176/1176 [==============================] - 37s 32ms/step - loss: 0.0251 - accuracy: 0.9926 - val_loss: 0.0803 - val_accuracy: 0.9803\n",
            "Epoch 14/20\n",
            "1176/1176 [==============================] - 37s 32ms/step - loss: 0.0234 - accuracy: 0.9932 - val_loss: 0.2214 - val_accuracy: 0.9555\n",
            "Epoch 15/20\n",
            "1176/1176 [==============================] - 37s 32ms/step - loss: 0.0204 - accuracy: 0.9937 - val_loss: 0.0952 - val_accuracy: 0.9811\n",
            "Epoch 16/20\n",
            "1176/1176 [==============================] - 37s 32ms/step - loss: 0.0232 - accuracy: 0.9925 - val_loss: 0.1139 - val_accuracy: 0.9762\n",
            "Epoch 17/20\n",
            "1176/1176 [==============================] - 37s 32ms/step - loss: 0.0217 - accuracy: 0.9932 - val_loss: 0.0722 - val_accuracy: 0.9857\n",
            "Epoch 18/20\n",
            "1176/1176 [==============================] - 37s 32ms/step - loss: 0.0158 - accuracy: 0.9952 - val_loss: 0.0979 - val_accuracy: 0.9810\n",
            "Epoch 19/20\n",
            "1176/1176 [==============================] - 37s 32ms/step - loss: 0.0133 - accuracy: 0.9955 - val_loss: 0.0916 - val_accuracy: 0.9830\n",
            "Epoch 20/20\n",
            "1176/1176 [==============================] - 37s 32ms/step - loss: 0.0135 - accuracy: 0.9955 - val_loss: 0.1022 - val_accuracy: 0.9809\n",
            "INFO:tensorflow:Assets written to: final_models/7anomaly-classifier1/assets\n",
            "Model 1 saved\n",
            "{0: 0, 1: 1, 3: 2, 4: 3, 5: 4, 6: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(38250,)\n",
            "{0: 0, 1: 1, 3: 2, 4: 3, 5: 4, 6: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9527,)\n",
            "Epoch 1/20\n",
            "1196/1196 [==============================] - 40s 32ms/step - loss: 5.6544 - accuracy: 0.8032 - val_loss: 0.4171 - val_accuracy: 0.9409\n",
            "Epoch 2/20\n",
            "1196/1196 [==============================] - 38s 31ms/step - loss: 0.1443 - accuracy: 0.9664 - val_loss: 0.1190 - val_accuracy: 0.9733\n",
            "Epoch 3/20\n",
            "1196/1196 [==============================] - 38s 32ms/step - loss: 0.1074 - accuracy: 0.9739 - val_loss: 0.1195 - val_accuracy: 0.9713\n",
            "Epoch 4/20\n",
            "1196/1196 [==============================] - 38s 32ms/step - loss: 0.0632 - accuracy: 0.9822 - val_loss: 0.0819 - val_accuracy: 0.9796\n",
            "Epoch 5/20\n",
            "1196/1196 [==============================] - 38s 31ms/step - loss: 0.0668 - accuracy: 0.9802 - val_loss: 0.0498 - val_accuracy: 0.9857\n",
            "Epoch 6/20\n",
            "1196/1196 [==============================] - 38s 32ms/step - loss: 0.0567 - accuracy: 0.9824 - val_loss: 0.0942 - val_accuracy: 0.9748\n",
            "Epoch 7/20\n",
            "1196/1196 [==============================] - 38s 32ms/step - loss: 0.0428 - accuracy: 0.9866 - val_loss: 0.0530 - val_accuracy: 0.9859\n",
            "Epoch 8/20\n",
            "1196/1196 [==============================] - 38s 32ms/step - loss: 0.0371 - accuracy: 0.9886 - val_loss: 0.0887 - val_accuracy: 0.9791\n",
            "Epoch 9/20\n",
            "1196/1196 [==============================] - 38s 32ms/step - loss: 0.0419 - accuracy: 0.9874 - val_loss: 0.0554 - val_accuracy: 0.9856\n",
            "Epoch 10/20\n",
            "1196/1196 [==============================] - 38s 32ms/step - loss: 0.0319 - accuracy: 0.9902 - val_loss: 0.0815 - val_accuracy: 0.9801\n",
            "Epoch 11/20\n",
            "1196/1196 [==============================] - 38s 32ms/step - loss: 0.0288 - accuracy: 0.9912 - val_loss: 0.0733 - val_accuracy: 0.9831\n",
            "Epoch 12/20\n",
            "1196/1196 [==============================] - 38s 32ms/step - loss: 0.0292 - accuracy: 0.9912 - val_loss: 0.0659 - val_accuracy: 0.9860\n",
            "Epoch 13/20\n",
            "1196/1196 [==============================] - 38s 32ms/step - loss: 0.0244 - accuracy: 0.9924 - val_loss: 0.0492 - val_accuracy: 0.9888\n",
            "Epoch 14/20\n",
            "1196/1196 [==============================] - 38s 32ms/step - loss: 0.0250 - accuracy: 0.9925 - val_loss: 0.0804 - val_accuracy: 0.9813\n",
            "Epoch 15/20\n",
            "1196/1196 [==============================] - 38s 32ms/step - loss: 0.0236 - accuracy: 0.9923 - val_loss: 0.0584 - val_accuracy: 0.9873\n",
            "Epoch 16/20\n",
            "1196/1196 [==============================] - 38s 32ms/step - loss: 0.0182 - accuracy: 0.9934 - val_loss: 0.0612 - val_accuracy: 0.9862\n",
            "Epoch 17/20\n",
            "1196/1196 [==============================] - 38s 32ms/step - loss: 0.0163 - accuracy: 0.9950 - val_loss: 0.0772 - val_accuracy: 0.9855\n",
            "Epoch 18/20\n",
            "1196/1196 [==============================] - 38s 32ms/step - loss: 0.0200 - accuracy: 0.9938 - val_loss: 0.0449 - val_accuracy: 0.9904\n",
            "Epoch 19/20\n",
            "1196/1196 [==============================] - 38s 32ms/step - loss: 0.0136 - accuracy: 0.9957 - val_loss: 0.0704 - val_accuracy: 0.9860\n",
            "Epoch 20/20\n",
            "1196/1196 [==============================] - 38s 32ms/step - loss: 0.0146 - accuracy: 0.9960 - val_loss: 0.0426 - val_accuracy: 0.9904\n",
            "INFO:tensorflow:Assets written to: final_models/7anomaly-classifier2/assets\n",
            "Model 2 saved\n",
            "{0: 0, 1: 1, 2: 2, 4: 3, 5: 4, 6: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(38122,)\n",
            "{0: 0, 1: 1, 2: 2, 4: 3, 5: 4, 6: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9482,)\n",
            "Epoch 1/20\n",
            "1192/1192 [==============================] - 39s 32ms/step - loss: 6.0369 - accuracy: 0.8336 - val_loss: 0.1665 - val_accuracy: 0.9630\n",
            "Epoch 2/20\n",
            "1192/1192 [==============================] - 38s 32ms/step - loss: 0.0986 - accuracy: 0.9770 - val_loss: 0.1684 - val_accuracy: 0.9558\n",
            "Epoch 3/20\n",
            "1192/1192 [==============================] - 38s 32ms/step - loss: 0.0652 - accuracy: 0.9819 - val_loss: 0.0752 - val_accuracy: 0.9801\n",
            "Epoch 4/20\n",
            "1192/1192 [==============================] - 38s 31ms/step - loss: 0.0638 - accuracy: 0.9817 - val_loss: 0.2046 - val_accuracy: 0.9539\n",
            "Epoch 5/20\n",
            "1192/1192 [==============================] - 38s 31ms/step - loss: 0.0651 - accuracy: 0.9810 - val_loss: 0.0721 - val_accuracy: 0.9818\n",
            "Epoch 6/20\n",
            "1192/1192 [==============================] - 38s 32ms/step - loss: 0.0576 - accuracy: 0.9825 - val_loss: 0.0666 - val_accuracy: 0.9831\n",
            "Epoch 7/20\n",
            "1192/1192 [==============================] - 38s 32ms/step - loss: 0.0462 - accuracy: 0.9861 - val_loss: 0.2308 - val_accuracy: 0.9511\n",
            "Epoch 8/20\n",
            "1192/1192 [==============================] - 38s 32ms/step - loss: 0.0470 - accuracy: 0.9860 - val_loss: 0.0926 - val_accuracy: 0.9789\n",
            "Epoch 9/20\n",
            "1192/1192 [==============================] - 38s 32ms/step - loss: 0.0368 - accuracy: 0.9882 - val_loss: 0.0730 - val_accuracy: 0.9833\n",
            "Epoch 10/20\n",
            "1192/1192 [==============================] - 38s 32ms/step - loss: 0.0355 - accuracy: 0.9885 - val_loss: 0.2112 - val_accuracy: 0.9646\n",
            "Epoch 11/20\n",
            "1192/1192 [==============================] - 38s 32ms/step - loss: 0.0325 - accuracy: 0.9894 - val_loss: 0.0701 - val_accuracy: 0.9835\n",
            "Epoch 12/20\n",
            "1192/1192 [==============================] - 38s 32ms/step - loss: 0.0289 - accuracy: 0.9912 - val_loss: 0.1014 - val_accuracy: 0.9769\n",
            "Epoch 13/20\n",
            "1192/1192 [==============================] - 38s 32ms/step - loss: 0.0282 - accuracy: 0.9908 - val_loss: 0.0697 - val_accuracy: 0.9846\n",
            "Epoch 14/20\n",
            "1192/1192 [==============================] - 38s 32ms/step - loss: 0.0226 - accuracy: 0.9927 - val_loss: 0.0665 - val_accuracy: 0.9841\n",
            "Epoch 15/20\n",
            "1192/1192 [==============================] - 38s 32ms/step - loss: 0.0237 - accuracy: 0.9919 - val_loss: 0.1016 - val_accuracy: 0.9809\n",
            "Epoch 16/20\n",
            "1192/1192 [==============================] - 38s 32ms/step - loss: 0.0198 - accuracy: 0.9932 - val_loss: 0.0873 - val_accuracy: 0.9837\n",
            "Epoch 17/20\n",
            "1192/1192 [==============================] - 38s 32ms/step - loss: 0.0177 - accuracy: 0.9939 - val_loss: 0.0697 - val_accuracy: 0.9857\n",
            "Epoch 18/20\n",
            "1192/1192 [==============================] - 38s 32ms/step - loss: 0.0182 - accuracy: 0.9944 - val_loss: 0.0668 - val_accuracy: 0.9870\n",
            "Epoch 19/20\n",
            "1192/1192 [==============================] - 38s 32ms/step - loss: 0.0148 - accuracy: 0.9955 - val_loss: 0.0704 - val_accuracy: 0.9866\n",
            "Epoch 20/20\n",
            "1192/1192 [==============================] - 38s 32ms/step - loss: 0.0140 - accuracy: 0.9956 - val_loss: 0.0757 - val_accuracy: 0.9844\n",
            "INFO:tensorflow:Assets written to: final_models/7anomaly-classifier3/assets\n",
            "Model 3 saved\n",
            "{0: 0, 1: 1, 2: 2, 3: 3, 5: 4, 6: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(38368,)\n",
            "{0: 0, 1: 1, 2: 2, 3: 3, 5: 4, 6: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9525,)\n",
            "Epoch 1/20\n",
            "1199/1199 [==============================] - 40s 32ms/step - loss: 6.1254 - accuracy: 0.7790 - val_loss: 0.2615 - val_accuracy: 0.9675\n",
            "Epoch 2/20\n",
            "1199/1199 [==============================] - 38s 32ms/step - loss: 0.1601 - accuracy: 0.9734 - val_loss: 0.0811 - val_accuracy: 0.9770\n",
            "Epoch 3/20\n",
            "1199/1199 [==============================] - 38s 32ms/step - loss: 0.0745 - accuracy: 0.9814 - val_loss: 0.1965 - val_accuracy: 0.9495\n",
            "Epoch 4/20\n",
            "1199/1199 [==============================] - 38s 32ms/step - loss: 0.0550 - accuracy: 0.9839 - val_loss: 0.1023 - val_accuracy: 0.9729\n",
            "Epoch 5/20\n",
            "1199/1199 [==============================] - 38s 32ms/step - loss: 0.0491 - accuracy: 0.9853 - val_loss: 0.3016 - val_accuracy: 0.9351\n",
            "Epoch 6/20\n",
            "1199/1199 [==============================] - 39s 32ms/step - loss: 0.0496 - accuracy: 0.9848 - val_loss: 0.1068 - val_accuracy: 0.9668\n",
            "Epoch 7/20\n",
            "1199/1199 [==============================] - 39s 32ms/step - loss: 0.0481 - accuracy: 0.9854 - val_loss: 0.1614 - val_accuracy: 0.9592\n",
            "Epoch 8/20\n",
            "1199/1199 [==============================] - 38s 32ms/step - loss: 0.0450 - accuracy: 0.9856 - val_loss: 0.2252 - val_accuracy: 0.9552\n",
            "Epoch 9/20\n",
            "1199/1199 [==============================] - 38s 32ms/step - loss: 0.0372 - accuracy: 0.9886 - val_loss: 0.0866 - val_accuracy: 0.9793\n",
            "Epoch 10/20\n",
            "1199/1199 [==============================] - 38s 32ms/step - loss: 0.0319 - accuracy: 0.9903 - val_loss: 0.2281 - val_accuracy: 0.9487\n",
            "Epoch 11/20\n",
            "1199/1199 [==============================] - 38s 32ms/step - loss: 0.0337 - accuracy: 0.9900 - val_loss: 0.0918 - val_accuracy: 0.9769\n",
            "Epoch 12/20\n",
            "1199/1199 [==============================] - 38s 32ms/step - loss: 0.0243 - accuracy: 0.9919 - val_loss: 0.1450 - val_accuracy: 0.9692\n",
            "Epoch 13/20\n",
            "1199/1199 [==============================] - 38s 32ms/step - loss: 0.0240 - accuracy: 0.9925 - val_loss: 0.0830 - val_accuracy: 0.9796\n",
            "Epoch 14/20\n",
            "1199/1199 [==============================] - 38s 32ms/step - loss: 0.0198 - accuracy: 0.9939 - val_loss: 0.1428 - val_accuracy: 0.9730\n",
            "Epoch 15/20\n",
            "1199/1199 [==============================] - 38s 32ms/step - loss: 0.0208 - accuracy: 0.9933 - val_loss: 0.1445 - val_accuracy: 0.9710\n",
            "Epoch 16/20\n",
            "1199/1199 [==============================] - 38s 32ms/step - loss: 0.0160 - accuracy: 0.9947 - val_loss: 0.1748 - val_accuracy: 0.9685\n",
            "Epoch 17/20\n",
            "1199/1199 [==============================] - 38s 32ms/step - loss: 0.0175 - accuracy: 0.9938 - val_loss: 0.0982 - val_accuracy: 0.9815\n",
            "Epoch 18/20\n",
            "1199/1199 [==============================] - 38s 32ms/step - loss: 0.0187 - accuracy: 0.9944 - val_loss: 0.0799 - val_accuracy: 0.9847\n",
            "Epoch 19/20\n",
            "1199/1199 [==============================] - 38s 32ms/step - loss: 0.0202 - accuracy: 0.9937 - val_loss: 0.0770 - val_accuracy: 0.9854\n",
            "Epoch 20/20\n",
            "1199/1199 [==============================] - 38s 32ms/step - loss: 0.0154 - accuracy: 0.9950 - val_loss: 0.0884 - val_accuracy: 0.9831\n",
            "INFO:tensorflow:Assets written to: final_models/7anomaly-classifier4/assets\n",
            "Model 4 saved\n",
            "{0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 6: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(38717,)\n",
            "{0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 6: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9597,)\n",
            "Epoch 1/20\n",
            "1210/1210 [==============================] - 39s 32ms/step - loss: 5.3556 - accuracy: 0.8233 - val_loss: 0.5034 - val_accuracy: 0.9514\n",
            "Epoch 2/20\n",
            "1210/1210 [==============================] - 38s 31ms/step - loss: 0.2080 - accuracy: 0.9720 - val_loss: 0.0763 - val_accuracy: 0.9797\n",
            "Epoch 3/20\n",
            "1210/1210 [==============================] - 38s 32ms/step - loss: 0.0562 - accuracy: 0.9859 - val_loss: 0.1772 - val_accuracy: 0.9552\n",
            "Epoch 4/20\n",
            "1210/1210 [==============================] - 38s 32ms/step - loss: 0.0494 - accuracy: 0.9860 - val_loss: 0.0843 - val_accuracy: 0.9742\n",
            "Epoch 5/20\n",
            "1210/1210 [==============================] - 38s 32ms/step - loss: 0.0477 - accuracy: 0.9854 - val_loss: 0.1180 - val_accuracy: 0.9649\n",
            "Epoch 6/20\n",
            "1210/1210 [==============================] - 38s 32ms/step - loss: 0.0491 - accuracy: 0.9848 - val_loss: 0.1226 - val_accuracy: 0.9651\n",
            "Epoch 7/20\n",
            "1210/1210 [==============================] - 38s 31ms/step - loss: 0.0480 - accuracy: 0.9857 - val_loss: 0.0843 - val_accuracy: 0.9802\n",
            "Epoch 8/20\n",
            "1210/1210 [==============================] - 38s 31ms/step - loss: 0.0394 - accuracy: 0.9871 - val_loss: 0.0901 - val_accuracy: 0.9777\n",
            "Epoch 9/20\n",
            "1210/1210 [==============================] - 38s 31ms/step - loss: 0.0382 - accuracy: 0.9890 - val_loss: 0.0888 - val_accuracy: 0.9777\n",
            "Epoch 10/20\n",
            "1210/1210 [==============================] - 38s 32ms/step - loss: 0.0357 - accuracy: 0.9891 - val_loss: 0.1381 - val_accuracy: 0.9672\n",
            "Epoch 11/20\n",
            "1210/1210 [==============================] - 38s 31ms/step - loss: 0.0308 - accuracy: 0.9907 - val_loss: 0.1196 - val_accuracy: 0.9755\n",
            "Epoch 12/20\n",
            "1210/1210 [==============================] - 38s 32ms/step - loss: 0.0269 - accuracy: 0.9919 - val_loss: 0.0729 - val_accuracy: 0.9832\n",
            "Epoch 13/20\n",
            "1210/1210 [==============================] - 38s 32ms/step - loss: 0.0256 - accuracy: 0.9932 - val_loss: 0.0853 - val_accuracy: 0.9791\n",
            "Epoch 14/20\n",
            "1210/1210 [==============================] - 38s 31ms/step - loss: 0.0218 - accuracy: 0.9930 - val_loss: 0.0563 - val_accuracy: 0.9856\n",
            "Epoch 15/20\n",
            "1210/1210 [==============================] - 38s 31ms/step - loss: 0.0214 - accuracy: 0.9933 - val_loss: 0.0626 - val_accuracy: 0.9856\n",
            "Epoch 16/20\n",
            "1210/1210 [==============================] - 38s 31ms/step - loss: 0.0213 - accuracy: 0.9939 - val_loss: 0.0738 - val_accuracy: 0.9836\n",
            "Epoch 17/20\n",
            "1210/1210 [==============================] - 38s 32ms/step - loss: 0.0158 - accuracy: 0.9949 - val_loss: 0.0670 - val_accuracy: 0.9837\n",
            "Epoch 18/20\n",
            "1210/1210 [==============================] - 38s 31ms/step - loss: 0.0167 - accuracy: 0.9951 - val_loss: 0.0865 - val_accuracy: 0.9828\n",
            "Epoch 19/20\n",
            "1210/1210 [==============================] - 38s 31ms/step - loss: 0.0224 - accuracy: 0.9933 - val_loss: 0.0907 - val_accuracy: 0.9809\n",
            "Epoch 20/20\n",
            "1210/1210 [==============================] - 38s 31ms/step - loss: 0.0152 - accuracy: 0.9949 - val_loss: 0.0908 - val_accuracy: 0.9833\n",
            "INFO:tensorflow:Assets written to: final_models/7anomaly-classifier5/assets\n",
            "Model 5 saved\n",
            "{0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(38293,)\n",
            "{0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9524,)\n",
            "Epoch 1/20\n",
            "1197/1197 [==============================] - 39s 32ms/step - loss: 5.3087 - accuracy: 0.8382 - val_loss: 0.2299 - val_accuracy: 0.9581\n",
            "Epoch 2/20\n",
            "1197/1197 [==============================] - 38s 31ms/step - loss: 0.1146 - accuracy: 0.9752 - val_loss: 0.1095 - val_accuracy: 0.9687\n",
            "Epoch 3/20\n",
            "1197/1197 [==============================] - 38s 32ms/step - loss: 0.0616 - accuracy: 0.9827 - val_loss: 0.1312 - val_accuracy: 0.9648\n",
            "Epoch 4/20\n",
            "1197/1197 [==============================] - 38s 32ms/step - loss: 0.0627 - accuracy: 0.9822 - val_loss: 0.8276 - val_accuracy: 0.8620\n",
            "Epoch 5/20\n",
            "1197/1197 [==============================] - 38s 32ms/step - loss: 0.0566 - accuracy: 0.9837 - val_loss: 0.1732 - val_accuracy: 0.9537\n",
            "Epoch 6/20\n",
            "1197/1197 [==============================] - 38s 32ms/step - loss: 0.0509 - accuracy: 0.9843 - val_loss: 0.2738 - val_accuracy: 0.9405\n",
            "Epoch 7/20\n",
            "1197/1197 [==============================] - 38s 32ms/step - loss: 0.0493 - accuracy: 0.9857 - val_loss: 0.2911 - val_accuracy: 0.9444\n",
            "Epoch 8/20\n",
            "1197/1197 [==============================] - 38s 32ms/step - loss: 0.0413 - accuracy: 0.9874 - val_loss: 0.0981 - val_accuracy: 0.9773\n",
            "Epoch 9/20\n",
            "1197/1197 [==============================] - 38s 32ms/step - loss: 0.0411 - accuracy: 0.9880 - val_loss: 0.1174 - val_accuracy: 0.9726\n",
            "Epoch 10/20\n",
            "1197/1197 [==============================] - 38s 32ms/step - loss: 0.0361 - accuracy: 0.9890 - val_loss: 0.1460 - val_accuracy: 0.9688\n",
            "Epoch 11/20\n",
            "1197/1197 [==============================] - 38s 31ms/step - loss: 0.0314 - accuracy: 0.9901 - val_loss: 0.1093 - val_accuracy: 0.9767\n",
            "Epoch 12/20\n",
            "1197/1197 [==============================] - 38s 32ms/step - loss: 0.0296 - accuracy: 0.9905 - val_loss: 0.0837 - val_accuracy: 0.9827\n",
            "Epoch 13/20\n",
            "1197/1197 [==============================] - 38s 32ms/step - loss: 0.0258 - accuracy: 0.9916 - val_loss: 0.0634 - val_accuracy: 0.9841\n",
            "Epoch 14/20\n",
            "1197/1197 [==============================] - 38s 32ms/step - loss: 0.0255 - accuracy: 0.9924 - val_loss: 0.0750 - val_accuracy: 0.9829\n",
            "Epoch 15/20\n",
            "1197/1197 [==============================] - 38s 31ms/step - loss: 0.0206 - accuracy: 0.9935 - val_loss: 0.0888 - val_accuracy: 0.9808\n",
            "Epoch 16/20\n",
            "1197/1197 [==============================] - 38s 31ms/step - loss: 0.0193 - accuracy: 0.9938 - val_loss: 0.0949 - val_accuracy: 0.9808\n",
            "Epoch 17/20\n",
            "1197/1197 [==============================] - 38s 32ms/step - loss: 0.0168 - accuracy: 0.9946 - val_loss: 0.1184 - val_accuracy: 0.9757\n",
            "Epoch 18/20\n",
            "1197/1197 [==============================] - 38s 32ms/step - loss: 0.0177 - accuracy: 0.9939 - val_loss: 0.1079 - val_accuracy: 0.9777\n",
            "Epoch 19/20\n",
            "1197/1197 [==============================] - 38s 32ms/step - loss: 0.0168 - accuracy: 0.9946 - val_loss: 0.0872 - val_accuracy: 0.9832\n",
            "Epoch 20/20\n",
            "1197/1197 [==============================] - 38s 32ms/step - loss: 0.0152 - accuracy: 0.9946 - val_loss: 0.1172 - val_accuracy: 0.9791\n",
            "INFO:tensorflow:Assets written to: final_models/7anomaly-classifier6/assets\n",
            "Model 6 saved\n",
            "{0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(38343,)\n",
            "{0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9541,)\n",
            "Epoch 1/20\n",
            "1199/1199 [==============================] - 39s 32ms/step - loss: 5.3870 - accuracy: 0.8419 - val_loss: 0.1520 - val_accuracy: 0.9721\n",
            "Epoch 2/20\n",
            "1199/1199 [==============================] - 38s 31ms/step - loss: 0.1039 - accuracy: 0.9792 - val_loss: 0.1862 - val_accuracy: 0.9622\n",
            "Epoch 3/20\n",
            "1199/1199 [==============================] - 38s 32ms/step - loss: 0.0580 - accuracy: 0.9837 - val_loss: 0.1567 - val_accuracy: 0.9635\n",
            "Epoch 4/20\n",
            "1199/1199 [==============================] - 38s 32ms/step - loss: 0.0504 - accuracy: 0.9857 - val_loss: 0.3502 - val_accuracy: 0.9360\n",
            "Epoch 5/20\n",
            "1199/1199 [==============================] - 38s 32ms/step - loss: 0.0481 - accuracy: 0.9849 - val_loss: 0.2598 - val_accuracy: 0.9451\n",
            "Epoch 6/20\n",
            "1199/1199 [==============================] - 38s 32ms/step - loss: 0.0464 - accuracy: 0.9858 - val_loss: 0.2212 - val_accuracy: 0.9594\n",
            "Epoch 7/20\n",
            "1199/1199 [==============================] - 38s 32ms/step - loss: 0.0444 - accuracy: 0.9872 - val_loss: 0.1343 - val_accuracy: 0.9712\n",
            "Epoch 8/20\n",
            "1199/1199 [==============================] - 38s 32ms/step - loss: 0.0392 - accuracy: 0.9875 - val_loss: 0.0605 - val_accuracy: 0.9842\n",
            "Epoch 9/20\n",
            "1199/1199 [==============================] - 38s 32ms/step - loss: 0.0347 - accuracy: 0.9892 - val_loss: 0.0822 - val_accuracy: 0.9808\n",
            "Epoch 10/20\n",
            "1199/1199 [==============================] - 38s 32ms/step - loss: 0.0320 - accuracy: 0.9902 - val_loss: 0.0852 - val_accuracy: 0.9814\n",
            "Epoch 11/20\n",
            "1199/1199 [==============================] - 38s 32ms/step - loss: 0.0267 - accuracy: 0.9915 - val_loss: 0.0577 - val_accuracy: 0.9856\n",
            "Epoch 12/20\n",
            "1199/1199 [==============================] - 38s 32ms/step - loss: 0.0278 - accuracy: 0.9917 - val_loss: 0.0688 - val_accuracy: 0.9847\n",
            "Epoch 13/20\n",
            "1199/1199 [==============================] - 38s 32ms/step - loss: 0.0239 - accuracy: 0.9925 - val_loss: 0.1006 - val_accuracy: 0.9797\n",
            "Epoch 14/20\n",
            "1199/1199 [==============================] - 38s 32ms/step - loss: 0.0197 - accuracy: 0.9942 - val_loss: 0.0537 - val_accuracy: 0.9904\n",
            "Epoch 15/20\n",
            "1199/1199 [==============================] - 38s 32ms/step - loss: 0.0209 - accuracy: 0.9932 - val_loss: 0.0861 - val_accuracy: 0.9849\n",
            "Epoch 16/20\n",
            "1199/1199 [==============================] - 38s 32ms/step - loss: 0.0153 - accuracy: 0.9956 - val_loss: 0.0648 - val_accuracy: 0.9857\n",
            "Epoch 17/20\n",
            "1199/1199 [==============================] - 38s 32ms/step - loss: 0.0210 - accuracy: 0.9947 - val_loss: 0.1005 - val_accuracy: 0.9834\n",
            "Epoch 18/20\n",
            "1199/1199 [==============================] - 38s 31ms/step - loss: 0.0191 - accuracy: 0.9938 - val_loss: 0.0618 - val_accuracy: 0.9873\n",
            "Epoch 19/20\n",
            "1199/1199 [==============================] - 38s 32ms/step - loss: 0.0128 - accuracy: 0.9965 - val_loss: 0.0565 - val_accuracy: 0.9892\n",
            "Epoch 20/20\n",
            "1199/1199 [==============================] - 38s 31ms/step - loss: 0.0155 - accuracy: 0.9954 - val_loss: 0.0905 - val_accuracy: 0.9848\n",
            "INFO:tensorflow:Assets written to: final_models/7anomaly-classifier7/assets\n",
            "Model 7 saved\n",
            "{0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 8: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(38279,)\n",
            "{0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 8: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9507,)\n",
            "Epoch 1/20\n",
            "1197/1197 [==============================] - 39s 32ms/step - loss: 4.2597 - accuracy: 0.8677 - val_loss: 0.1835 - val_accuracy: 0.9637\n",
            "Epoch 2/20\n",
            "1197/1197 [==============================] - 38s 32ms/step - loss: 0.1118 - accuracy: 0.9739 - val_loss: 0.0757 - val_accuracy: 0.9815\n",
            "Epoch 3/20\n",
            "1197/1197 [==============================] - 38s 32ms/step - loss: 0.0662 - accuracy: 0.9813 - val_loss: 0.1093 - val_accuracy: 0.9710\n",
            "Epoch 4/20\n",
            "1197/1197 [==============================] - 38s 31ms/step - loss: 0.0531 - accuracy: 0.9834 - val_loss: 0.0936 - val_accuracy: 0.9797\n",
            "Epoch 5/20\n",
            "1197/1197 [==============================] - 38s 32ms/step - loss: 0.0505 - accuracy: 0.9844 - val_loss: 0.0698 - val_accuracy: 0.9805\n",
            "Epoch 6/20\n",
            "1197/1197 [==============================] - 38s 32ms/step - loss: 0.0473 - accuracy: 0.9859 - val_loss: 0.5180 - val_accuracy: 0.8903\n",
            "Epoch 7/20\n",
            "1197/1197 [==============================] - 38s 31ms/step - loss: 0.0433 - accuracy: 0.9874 - val_loss: 0.0597 - val_accuracy: 0.9835\n",
            "Epoch 8/20\n",
            "1197/1197 [==============================] - 38s 31ms/step - loss: 0.0366 - accuracy: 0.9883 - val_loss: 0.0438 - val_accuracy: 0.9877\n",
            "Epoch 9/20\n",
            "1197/1197 [==============================] - 38s 32ms/step - loss: 0.0308 - accuracy: 0.9907 - val_loss: 0.0453 - val_accuracy: 0.9884\n",
            "Epoch 10/20\n",
            "1197/1197 [==============================] - 38s 31ms/step - loss: 0.0271 - accuracy: 0.9917 - val_loss: 0.0877 - val_accuracy: 0.9782\n",
            "Epoch 11/20\n",
            "1197/1197 [==============================] - 38s 32ms/step - loss: 0.0268 - accuracy: 0.9913 - val_loss: 0.0819 - val_accuracy: 0.9803\n",
            "Epoch 12/20\n",
            "1197/1197 [==============================] - 38s 32ms/step - loss: 0.0286 - accuracy: 0.9922 - val_loss: 0.0663 - val_accuracy: 0.9846\n",
            "Epoch 13/20\n",
            "1197/1197 [==============================] - 38s 32ms/step - loss: 0.0216 - accuracy: 0.9939 - val_loss: 0.0481 - val_accuracy: 0.9875\n",
            "Epoch 14/20\n",
            "1197/1197 [==============================] - 38s 31ms/step - loss: 0.0271 - accuracy: 0.9914 - val_loss: 0.1087 - val_accuracy: 0.9784\n",
            "Epoch 15/20\n",
            "1197/1197 [==============================] - 38s 32ms/step - loss: 0.0174 - accuracy: 0.9947 - val_loss: 0.1082 - val_accuracy: 0.9789\n",
            "Epoch 16/20\n",
            "1197/1197 [==============================] - 38s 32ms/step - loss: 0.0165 - accuracy: 0.9943 - val_loss: 0.0995 - val_accuracy: 0.9789\n",
            "Epoch 17/20\n",
            "1197/1197 [==============================] - 38s 32ms/step - loss: 0.0163 - accuracy: 0.9952 - val_loss: 0.0537 - val_accuracy: 0.9881\n",
            "Epoch 18/20\n",
            "1197/1197 [==============================] - 38s 32ms/step - loss: 0.0134 - accuracy: 0.9958 - val_loss: 0.0784 - val_accuracy: 0.9852\n",
            "Epoch 19/20\n",
            "1197/1197 [==============================] - 38s 32ms/step - loss: 0.0109 - accuracy: 0.9964 - val_loss: 0.0514 - val_accuracy: 0.9881\n",
            "Epoch 20/20\n",
            "1197/1197 [==============================] - 38s 32ms/step - loss: 0.0122 - accuracy: 0.9961 - val_loss: 0.0768 - val_accuracy: 0.9856\n",
            "INFO:tensorflow:Assets written to: final_models/7anomaly-classifier8/assets\n",
            "Model 8 saved\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFySoxdH1wFJ"
      },
      "source": [
        "class_0 = model0.load_model(\"final_models/7anomaly-classifier0\")\n",
        "class_1 = model1.load_model(\"final_models/7anomaly-classifier1\")\n",
        "class_2 = model2.load_model(\"final_models/7anomaly-classifier2\")\n",
        "class_3 = model3.load_model(\"final_models/7anomaly-classifier3\")\n",
        "class_4 = model4.load_model(\"final_models/7anomaly-classifier4\")\n",
        "class_5 = model5.load_model(\"final_models/7anomaly-classifier5\")\n",
        "class_6 = model6.load_model(\"final_models/7anomaly-classifier6\")\n",
        "class_7 = model7.load_model(\"final_models/7anomaly-classifier7\")\n",
        "class_8 = model8.load_model(\"final_models/7anomaly-classifier8\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dy4QzKfn1wFK",
        "outputId": "956f84e2-b5fe-4cc6-f5a6-f32d557ce471"
      },
      "source": [
        "layer_name_list = []\n",
        "\n",
        "layer_name_list.append(class_0.layers[-2:][0].name)\n",
        "layer_name_list.append(class_1.layers[-2:][0].name)\n",
        "layer_name_list.append(class_2.layers[-2:][0].name)\n",
        "layer_name_list.append(class_3.layers[-2:][0].name)\n",
        "layer_name_list.append(class_4.layers[-2:][0].name)\n",
        "layer_name_list.append(class_5.layers[-2:][0].name)\n",
        "layer_name_list.append(class_6.layers[-2:][0].name)\n",
        "layer_name_list.append(class_7.layers[-2:][0].name)\n",
        "layer_name_list.append(class_8.layers[-2:][0].name)\n",
        "\n",
        "print(layer_name_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['dense_37', 'dense_39', 'dense_41', 'dense_43', 'dense_45', 'dense_47', 'dense_49', 'dense_51', 'dense_53']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EqB2JlgZ1wFM"
      },
      "source": [
        "from keras import Model\n",
        "model_dict = {}\n",
        "model_output0 = class_0.get_layer(layer_name_list[0]).output\n",
        "m0 = Model(inputs=class_0.input, outputs=model_output0)\n",
        "model_dict[0] = m0\n",
        "\n",
        "model_output1 = class_1.get_layer(layer_name_list[1]).output\n",
        "m1 = Model(inputs=class_1.input, outputs=model_output1)\n",
        "model_dict[1] = m1\n",
        "\n",
        "model_output2 = class_2.get_layer(layer_name_list[2]).output\n",
        "m2 = Model(inputs=class_2.input, outputs=model_output2)\n",
        "model_dict[2] = m2\n",
        "\n",
        "model_output3 = class_3.get_layer(layer_name_list[3]).output\n",
        "m3 = Model(inputs=class_3.input, outputs=model_output3)\n",
        "model_dict[3] = m3\n",
        "\n",
        "model_output4 = class_4.get_layer(layer_name_list[4]).output\n",
        "m4 = Model(inputs=class_4.input, outputs=model_output4)\n",
        "model_dict[4] = m4\n",
        "\n",
        "model_output5 = class_5.get_layer(layer_name_list[5]).output\n",
        "m5 = Model(inputs=class_5.input, outputs=model_output5)\n",
        "model_dict[5] = m5\n",
        "\n",
        "model_output6 = class_6.get_layer(layer_name_list[6]).output\n",
        "m6 = Model(inputs=class_6.input, outputs=model_output6)\n",
        "model_dict[6] = m6\n",
        "\n",
        "model_output7 = class_7.get_layer(layer_name_list[7]).output\n",
        "m7 = Model(inputs=class_7.input, outputs=model_output7)\n",
        "model_dict[7] = m7\n",
        "\n",
        "model_output8 = class_8.get_layer(layer_name_list[8]).output\n",
        "m8 = Model(inputs=class_8.input, outputs=model_output8)\n",
        "model_dict[8] = m8\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5zYTSSuC1wFN",
        "outputId": "1fd6cbb9-e764-4974-fc0d-9ff028a41d16"
      },
      "source": [
        "temp_val = []\n",
        "y_pred = []\n",
        "labels = set(new_val_labels)\n",
        "for i, lo in zip(range(9), labels):\n",
        "  m = model_dict[i]\n",
        "  val_imgs_, val_lbls_ = get_train_data(lo, new_val_images, new_val_labels)\n",
        "  y_p = m.predict(val_imgs_)\n",
        "  y_pred.append(y_p)\n",
        "  temp = temp_cal(y_p, val_lbls_)\n",
        "  temp_val.append(temp)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{1: 0, 2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9526,)\n",
            "Temperature Initial value: 1.0\n",
            "Temperature Final value: 2.184089422225952\n",
            "{0: 0, 2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9379,)\n",
            "Temperature Initial value: 1.0\n",
            "Temperature Final value: 2.3121402263641357\n",
            "{0: 0, 1: 1, 3: 2, 4: 3, 5: 4, 6: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9527,)\n",
            "Temperature Initial value: 1.0\n",
            "Temperature Final value: 1.8578717708587646\n",
            "{0: 0, 1: 1, 2: 2, 4: 3, 5: 4, 6: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9482,)\n",
            "Temperature Initial value: 1.0\n",
            "Temperature Final value: 2.017979383468628\n",
            "{0: 0, 1: 1, 2: 2, 3: 3, 5: 4, 6: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9525,)\n",
            "Temperature Initial value: 1.0\n",
            "Temperature Final value: 2.3343472480773926\n",
            "{0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 6: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9597,)\n",
            "Temperature Initial value: 1.0\n",
            "Temperature Final value: 2.3091700077056885\n",
            "{0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 8: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9524,)\n",
            "Temperature Initial value: 1.0\n",
            "Temperature Final value: 2.2927048206329346\n",
            "{0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9541,)\n",
            "Temperature Initial value: 1.0\n",
            "Temperature Final value: 2.3133301734924316\n",
            "{0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 8: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9507,)\n",
            "Temperature Initial value: 1.0\n",
            "Temperature Final value: 2.140700340270996\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YF0ybswC1wFO",
        "outputId": "1d1155e6-931a-419b-ef28-b43dbb3a9c7b"
      },
      "source": [
        "temp_val"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=2.1840894>,\n",
              " <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=2.3121402>,\n",
              " <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=1.8578718>,\n",
              " <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=2.0179794>,\n",
              " <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=2.3343472>,\n",
              " <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=2.30917>,\n",
              " <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=2.2927048>,\n",
              " <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=2.3133302>,\n",
              " <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=2.1407003>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwsmkPQE1wFP",
        "outputId": "cd59454e-df5e-460b-b401-ad14d4ee469e"
      },
      "source": [
        "from tqdm import tqdm\n",
        "avg = [0,0,0,0,0,0,0,0,0]\n",
        "count = [0,0,0,0,0,0,0,0,0]\n",
        "entropy_list = [0,0,0,0,0,0,0,0,0]\n",
        "for img, lbl in tqdm(zip(new_val_images,new_val_labels)):\n",
        "  img = img.reshape([-1, 28, 28, 1])\n",
        "  if not lbl == 0:\n",
        "    logits = model_dict[0](img)\n",
        "    logits = tf.math.divide(logits, temp_val[0])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e0 = entropy(pred[0])\n",
        "    entropy_list[0] = entropy_list[0] + e0\n",
        "    max_val0 = np.max(pred)\n",
        "    avg[0] = avg[0] + max_val0\n",
        "    count[0] = count[0] + 1\n",
        "  if not lbl == 1:\n",
        "    logits = model_dict[1](img)\n",
        "    logits = tf.math.divide(logits, temp_val[1])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e1 = entropy(pred[0])\n",
        "    entropy_list[1] = entropy_list[1] + e1\n",
        "    max_val1 = np.max(pred)\n",
        "    avg[1] = avg[1] + max_val1\n",
        "    count[1] = count[1] + 1\n",
        "  if not lbl == 2:\n",
        "    logits = model_dict[2](img)\n",
        "    logits = tf.math.divide(logits, temp_val[2])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e2 = entropy(pred[0])\n",
        "    entropy_list[2] = entropy_list[2] + e2\n",
        "    max_val2 = np.max(pred)\n",
        "    avg[2] = avg[2] + max_val2\n",
        "    count[2] = count[2] + 1\n",
        "  if not lbl == 3:\n",
        "    logits = model_dict[3](img)\n",
        "    logits = tf.math.divide(logits, temp_val[3])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e3 = entropy(pred[0])\n",
        "    entropy_list[3] = entropy_list[3] + e3\n",
        "    max_val3 = np.max(pred)  \n",
        "    avg[3] = avg[3] + max_val3\n",
        "    count[3] = count[3] + 1\n",
        "  if not lbl == 4:\n",
        "    logits = model_dict[4](img)\n",
        "    logits = tf.math.divide(logits, temp_val[4])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e4 = entropy(pred[0])\n",
        "    entropy_list[4] = entropy_list[4] + e4\n",
        "    max_val4 = np.max(pred)\n",
        "    avg[4] = avg[4] + max_val4\n",
        "    count[4] = count[4] + 1\n",
        "  if not lbl == 5:\n",
        "    logits = model_dict[5](img)\n",
        "    logits = tf.math.divide(logits, temp_val[5])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e5 = entropy(pred[0])\n",
        "    entropy_list[5] = entropy_list[5] + e5\n",
        "    max_val5 = np.max(pred)\n",
        "    avg[5] = avg[5] + max_val5\n",
        "    count[5] = count[5] + 1\n",
        "  if not lbl == 6:\n",
        "    logits = model_dict[6](img)\n",
        "    logits = tf.math.divide(logits, temp_val[6])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e6 = entropy(pred[0])\n",
        "    entropy_list[6] = entropy_list[6] + e6\n",
        "    max_val6 = np.max(pred)\n",
        "    avg[6] = avg[6] + max_val6\n",
        "    count[6] = count[6] + 1\n",
        "  if not lbl == 8:\n",
        "    logits = model_dict[7](img)\n",
        "    logits = tf.math.divide(logits, temp_val[7])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e7 = entropy(pred[0])\n",
        "    entropy_list[7] = entropy_list[7] + e7\n",
        "    max_val7 = np.max(pred)\n",
        "    avg[7] = avg[7] + max_val7\n",
        "    count[7] = count[7] + 1\n",
        "  if not lbl == 9:\n",
        "    logits = model_dict[8](img)\n",
        "    logits = tf.math.divide(logits, temp_val[8])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e8 = entropy(pred[0])\n",
        "    entropy_list[8] = entropy_list[8] + e8\n",
        "    max_val8 = np.max(pred)\n",
        "    avg[8] = avg[8] + max_val8\n",
        "    count[8] = count[8] + 1\n",
        "\n",
        "print(avg)\n",
        "print(count)\n",
        "print(entropy_list)\n",
        "\n",
        "entropy_avg_t = [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]\n",
        "for i in range(9):\n",
        "  entropy_avg_t[i] = entropy_list[i]/count[i]\n",
        "\n",
        "entropy_value_t = 0.0\n",
        "for i in range(9):\n",
        "  entropy_value_t = entropy_value_t + entropy_avg_t[i]\n",
        "\n",
        "entropy_t = entropy_value_t/len(entropy_avg_t)\n",
        "\n",
        "print('Entropy:', entropy_t)\n",
        "\n",
        "classifier_avg_t = [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]\n",
        "for i in range(9):\n",
        "  classifier_avg_t[i] = avg[i]/count[i]\n",
        "\n",
        "print('Each Classifier Average: ',classifier_avg_t)\n",
        "\n",
        "treshold_value = 0.0\n",
        "for i in range(9):\n",
        "  treshold_value = treshold_value + classifier_avg_t[i]\n",
        "\n",
        "treshold_t = treshold_value/len(classifier_avg_t)\n",
        "\n",
        "print('Threshold:', treshold_t)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10701it [12:20, 14.45it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[9429.74279871583, 9203.4357637465, 9428.05303543806, 9331.52282872796, 9374.472832918167, 9452.06161659956, 9320.431676834822, 9396.391365140676, 9365.88415876031]\n",
            "[9526, 9379, 9527, 9482, 9525, 9597, 9524, 9541, 9507]\n",
            "[295.5887232365815, 523.7630844539426, 308.2188068750683, 495.9309783718782, 446.70406029953773, 463.49675650828357, 622.1243507756442, 458.75812259034694, 462.52658726557945]\n",
            "Entropy: 0.04764202276565664\n",
            "Each Classifier Average:  [0.9898953179420354, 0.9812811348487579, 0.9896140480149114, 0.9841302287205189, 0.9841966228785477, 0.9848975322079357, 0.9786257535525852, 0.9848434509108769, 0.9851566381361427]\n",
            "Threshold: 0.9847378585791459\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vlBwkGt61wFR",
        "outputId": "30a7893a-8390-45e5-e5ae-fc1e2a917a8f"
      },
      "source": [
        "ref_vect_in_7an = []\n",
        "ref_vect_in_7an.append(classifier_avg_t)\n",
        "\n",
        "threshold_in_7an = []\n",
        "threshold_in_7an.append(treshold_t)\n",
        "\n",
        "entropy_in_7an = []\n",
        "entropy_in_7an.append(entropy_t)\n",
        "\n",
        "print(entropy_in_7an)\n",
        "print(ref_vect_in_7an)\n",
        "print(threshold_in_7an)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.04764202276565664]\n",
            "[[0.9898953179420354, 0.9812811348487579, 0.9896140480149114, 0.9841302287205189, 0.9841966228785477, 0.9848975322079357, 0.9786257535525852, 0.9848434509108769, 0.9851566381361427]]\n",
            "[0.9847378585791459]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9W1k-OhVKTQ"
      },
      "source": [
        "entropy_in_7an = [0.04764202276565664]\n",
        "ref_vect_in_7an = [[0.9898953179420354, 0.9812811348487579, 0.9896140480149114, 0.9841302287205189, 0.9841966228785477, 0.9848975322079357, 0.9786257535525852, 0.9848434509108769, 0.9851566381361427]]\n",
        "threshold_in_7an = [0.9847378585791459]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LlR3rmZg1wFS",
        "outputId": "5d54d28a-0c29-4853-83e5-7856ab6dd180"
      },
      "source": [
        "from tqdm import tqdm\n",
        "avg = [0,0,0,0,0,0,0,0,0]\n",
        "count = [0,0,0,0,0,0,0,0,0]\n",
        "entropy_list = [0,0,0,0,0,0,0,0,0]\n",
        "\n",
        "for img, lbl in tqdm(zip(new_val_images,new_val_labels)):\n",
        "  img = img.reshape([-1, 28, 28, 1])\n",
        "  if lbl == 0:\n",
        "    logits = model_dict[0](img)\n",
        "    logits = tf.math.divide(logits, temp_val[0])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e0 = entropy(pred[0])\n",
        "    entropy_list[0] = entropy_list[0] + e0\n",
        "    max_val0 = np.max(pred)\n",
        "    avg[0] = avg[0] + max_val0\n",
        "    count[0] = count[0] + 1\n",
        "  if lbl == 1:\n",
        "    logits = model_dict[1](img)\n",
        "    logits = tf.math.divide(logits, temp_val[1])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e1 = entropy(pred[0])\n",
        "    entropy_list[1] = entropy_list[1] + e1\n",
        "    max_val1 = np.max(pred)\n",
        "    avg[1] = avg[1] + max_val1\n",
        "    count[1] = count[1] + 1\n",
        "  if lbl == 2:\n",
        "    logits = model_dict[2](img)\n",
        "    logits = tf.math.divide(logits, temp_val[2])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e2 = entropy(pred[0])\n",
        "    entropy_list[2] = entropy_list[2] + e2\n",
        "    max_val2 = np.max(pred)\n",
        "    avg[2] = avg[2] + max_val2\n",
        "    count[2] = count[2] + 1\n",
        "  if lbl == 3:\n",
        "    logits = model_dict[3](img)\n",
        "    logits = tf.math.divide(logits, temp_val[3])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e3 = entropy(pred[0])\n",
        "    entropy_list[3] = entropy_list[3] + e3\n",
        "    max_val3 = np.max(pred)  \n",
        "    avg[3] = avg[3] + max_val3\n",
        "    count[3] = count[3] + 1\n",
        "  if lbl == 4:\n",
        "    logits = model_dict[4](img)\n",
        "    logits = tf.math.divide(logits, temp_val[4])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e4 = entropy(pred[0])\n",
        "    entropy_list[4] = entropy_list[4] + e4\n",
        "    max_val4 = np.max(pred)\n",
        "    avg[4] = avg[4] + max_val4\n",
        "    count[4] = count[4] + 1\n",
        "  if lbl == 5:\n",
        "    logits = model_dict[5](img)\n",
        "    logits = tf.math.divide(logits, temp_val[5])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e5 = entropy(pred[0])\n",
        "    entropy_list[5] = entropy_list[5] + e5\n",
        "    max_val5 = np.max(pred)\n",
        "    avg[5] = avg[5] + max_val5\n",
        "    count[5] = count[5] + 1\n",
        "  if lbl == 6:\n",
        "    logits = model_dict[6](img)\n",
        "    logits = tf.math.divide(logits, temp_val[6])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e6 = entropy(pred[0])\n",
        "    entropy_list[6] = entropy_list[6] + e6\n",
        "    max_val6 = np.max(pred)\n",
        "    avg[6] = avg[6] + max_val6\n",
        "    count[6] = count[6] + 1\n",
        "  if lbl == 8:\n",
        "    logits = model_dict[7](img)\n",
        "    logits = tf.math.divide(logits, temp_val[7])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e7 = entropy(pred[0])\n",
        "    entropy_list[7] = entropy_list[7] + e7\n",
        "    max_val7 = np.max(pred)\n",
        "    avg[7] = avg[7] + max_val7\n",
        "    count[7] = count[7] + 1\n",
        "  if lbl == 9:\n",
        "    logits = model_dict[8](img)\n",
        "    logits = tf.math.divide(logits, temp_val[8])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e8 = entropy(pred[0])\n",
        "    entropy_list[8] = entropy_list[8] + e8\n",
        "    max_val8 = np.max(pred)\n",
        "    avg[8] = avg[8] + max_val8\n",
        "    count[8] = count[8] + 1\n",
        "\n",
        "print(avg)\n",
        "print(count)\n",
        "print(entropy_list)\n",
        "\n",
        "entropy_avg_t = [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]\n",
        "for i in range(9):\n",
        "  entropy_avg_t[i] = entropy_list[i]/count[i]\n",
        "\n",
        "entropy_value_t = 0.0\n",
        "for i in range(9):\n",
        "  entropy_value_t = entropy_value_t + entropy_avg_t[i]\n",
        "\n",
        "entropy_t = entropy_value_t/len(entropy_avg_t)\n",
        "\n",
        "print('Entropy:', entropy_t)\n",
        "\n",
        "classifier_avg_t = [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]\n",
        "for i in range(9):\n",
        "  classifier_avg_t[i] = avg[i]/count[i]\n",
        "\n",
        "print('Each Classifier Average: ',classifier_avg_t)\n",
        "\n",
        "treshold_value = 0.0\n",
        "for i in range(9):\n",
        "  treshold_value = treshold_value + classifier_avg_t[i]\n",
        "\n",
        "treshold_t = treshold_value/len(classifier_avg_t)\n",
        "\n",
        "print('Threshold:', treshold_t)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10701it [01:33, 115.03it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[901.7580592930317, 767.9853129386902, 964.5302682518959, 995.1774223446846, 1032.1835075318813, 830.8286636769772, 959.181392878294, 874.544561907649, 999.2052688896656]\n",
            "[1175, 1322, 1174, 1219, 1176, 1104, 1177, 1160, 1194]\n",
            "[712.4436416855642, 1541.9443767247722, 532.1211717518565, 601.0975149059086, 390.73232021798367, 716.8298604735173, 601.9435984068477, 752.3643363680603, 512.3374292557655]\n",
            "Entropy: 0.5877480370363201\n",
            "Each Classifier Average:  [0.7674536674834312, 0.5809268630398564, 0.8215760376932674, 0.8163883694378052, 0.8777070642277902, 0.7525621953595808, 0.8149374620886101, 0.7539177257824561, 0.8368553340784469]\n",
            "Threshold: 0.7802583021323605\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zp5IUZz01wFT",
        "outputId": "3662802a-329e-4177-9c06-d838c0df008d"
      },
      "source": [
        "ref_vect_out_7an = []\n",
        "ref_vect_out_7an.append(classifier_avg_t)\n",
        "\n",
        "threshold_out_7an = []\n",
        "threshold_out_7an.append(treshold_t)\n",
        "\n",
        "entropy_out_7an = []\n",
        "entropy_out_7an.append(entropy_t)\n",
        "\n",
        "print(entropy_out_7an)\n",
        "print(ref_vect_out_7an)\n",
        "print(threshold_out_7an)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.5877480370363201]\n",
            "[[0.7674536674834312, 0.5809268630398564, 0.8215760376932674, 0.8163883694378052, 0.8777070642277902, 0.7525621953595808, 0.8149374620886101, 0.7539177257824561, 0.8368553340784469]]\n",
            "[0.7802583021323605]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3i_5_W2BVWt9"
      },
      "source": [
        "entropy_out_7an = [0.5877480370363201]\n",
        "ref_vect_out_7an = [[0.7674536674834312, 0.5809268630398564, 0.8215760376932674, 0.8163883694378052, 0.8777070642277902, 0.7525621953595808, 0.8149374620886101, 0.7539177257824561, 0.8368553340784469]]\n",
        "threshold_out_7an = [0.7802583021323605]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDcKyWKc1wFU"
      },
      "source": [
        "def get_max_pred_value(model, img, temp):\n",
        "  logits = model(img)\n",
        "  logits = tf.math.divide(logits, temp)\n",
        "  pred = tf.nn.softmax(logits)\n",
        "  e = entropy(pred[0])\n",
        "\n",
        "  return np.max(pred), tf.argmax(pred[0]).numpy(), e"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1SNIAr-w1wFV"
      },
      "source": [
        "def get_mapping(leave_out_class, anomaly_class):\n",
        "  mapping = {}\n",
        "\n",
        "  labels = set(train_labels)\n",
        "  labels.remove(anomaly_class)\n",
        "  labels.remove(leave_out_class)\n",
        "  labels = sorted(labels)\n",
        "\n",
        "  for i,j in enumerate(labels):\n",
        "    mapping[i] = j\n",
        "\n",
        "  return mapping\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzP_SoiJ1wFV"
      },
      "source": [
        "ood = 0\n",
        "ind = 1"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9mE0XWpQ1wFW",
        "outputId": "a1f99063-b7e3-48da-b469-f319701b37ef"
      },
      "source": [
        "max_sm_all_wt_7an = []\n",
        "for data, label in tqdm(zip(test_imgs, test_lbls)):\n",
        "  img = data.reshape([-1, 28, 28, 1])\n",
        "  ref_value = []\n",
        "  \n",
        "  if label == 7:\n",
        "    lbl = ood\n",
        "  else:\n",
        "    lbl = ind\n",
        "\n",
        "\n",
        "  max0, pred_0, e0 = get_max_pred_value(model_dict[0], img, temp=temp_val[0])\n",
        "  map0 = get_mapping(0, 7)\n",
        "  pred_0 = map0[pred_0]\n",
        "\n",
        "  max1, pred_1, e1 = get_max_pred_value(model_dict[1], img, temp=temp_val[1])\n",
        "  map1 = get_mapping(1, 7)\n",
        "  pred_1 = map1[pred_1]\n",
        "\n",
        "  max2, pred_2, e2 = get_max_pred_value(model_dict[2], img, temp=temp_val[2])\n",
        "  map2 = get_mapping(2, 7)\n",
        "  pred_2 = map2[pred_2]\n",
        "\n",
        "  max3, pred_3, e3 = get_max_pred_value(model_dict[3], img, temp=temp_val[3])\n",
        "  map3 = get_mapping(3, 7)\n",
        "  pred_3 = map3[pred_3]\n",
        "\n",
        "  max4, pred_4, e4 = get_max_pred_value(model_dict[4], img, temp=temp_val[4])\n",
        "  map4 = get_mapping(4, 7)\n",
        "  pred_4 = map4[pred_4]\n",
        "\n",
        "  max5, pred_5, e5 = get_max_pred_value(model_dict[5], img, temp=temp_val[5])\n",
        "  map5 = get_mapping(5, 7)\n",
        "  pred_5 = map5[pred_5]\n",
        "\n",
        "  max6, pred_6, e6 = get_max_pred_value(model_dict[6], img, temp=temp_val[6])\n",
        "  map6 = get_mapping(6, 7)\n",
        "  pred_6 = map6[pred_6]\n",
        "\n",
        "  max7, pred_7, e7 = get_max_pred_value(model_dict[7], img, temp=temp_val[7])\n",
        "  map7 = get_mapping(8, 7)\n",
        "  pred_7 = map7[pred_7]\n",
        "\n",
        "  max8, pred_8, e8 = get_max_pred_value(model_dict[8], img, temp=temp_val[8])\n",
        "  map8 = get_mapping(9, 7)\n",
        "  pred_8 = map8[pred_8]\n",
        "\n",
        "  ref_value =[max0, max1, max2, max3, max4, max5, max6, max7, max8]\n",
        "  pred_value = [pred_0, pred_1, pred_2, pred_3, pred_4, pred_5, pred_6, pred_7, pred_8]\n",
        "  e_value = [e0, e1, e2, e3, e4, e5, e6, e7, e8]\n",
        "  e_ = 0.0\n",
        "  for  e in e_value:\n",
        "    e_ = e_ + e\n",
        "  e_ = e_/len(e_value)\n",
        "  max_sm_all_wt_7an.append([ref_value, lbl, pred_value, label, e_])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000it [20:25,  8.16it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqfBgy3t1wFX"
      },
      "source": [
        "pickle_out = open(\"sm_all_wt_7an.pickle\",\"wb\")\n",
        "pickle.dump(max_sm_all_wt_7an, pickle_out)\n",
        "pickle_out.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U20XSPkj1wFY"
      },
      "source": [
        "pickle_in = open(\"sm_all_wt_7an.pickle\",\"rb\")\n",
        "max_sm_all_wt_7an = pickle.load(pickle_in)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6yR6-zZ1wFY",
        "outputId": "7554e8f2-0508-4196-b2eb-3d432a05c1bc"
      },
      "source": [
        "for data, lbl, p, a_l, e_ in max_sm_all_wt_7an:\n",
        "  print(p, lbl, a_l)\n",
        "  break"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[9, 9, 3, 9, 1, 2, 9, 9, 1] 0 7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ifEwRgXD1wFa",
        "outputId": "09b49172-a21a-4d5f-f848-63c6e6a6cea7"
      },
      "source": [
        "accuracy = 0.0\n",
        "count_in = 0\n",
        "count_ood = 0\n",
        "acc_in = 0.0\n",
        "acc_ood = 0.0\n",
        "tp = 0.0\n",
        "tn = 0.0\n",
        "fp = 0.0\n",
        "fn = 0.0\n",
        "y_true = []\n",
        "y_pred = []\n",
        "sim_score = []\n",
        "sim_score_ = []\n",
        "\n",
        "for data, lbl, p, a_l, e_ in max_sm_all_wt_7an:\n",
        "\n",
        "  score = 0.0\n",
        "  for d in data:\n",
        "    score = score + d\n",
        "  score = score / len(data)\n",
        "  sim_score.append(score)\n",
        "\n",
        "  dist_ood = np.linalg.norm(np.array(data) - np.array(ref_vect_out_7an[0])) \n",
        "  dist_in = np.linalg.norm(np.array(data) - np.array(ref_vect_in_7an[0]))\n",
        "\n",
        "  dist_ood2 = np.linalg.norm(np.array(e_) - np.array(entropy_out_7an[0])) \n",
        "  dist_in2 = np.linalg.norm(np.array(e_) - np.array(entropy_in_7an[0]))\n",
        "\n",
        "  dist_in = dist_in / (dist_in + dist_ood)\n",
        "  dist_ood = dist_ood / (dist_in + dist_ood)\n",
        "\n",
        "  dist_in2 = dist_in2 / (dist_in2 + dist_ood2)\n",
        "  dist_ood2 = dist_ood2 / (dist_in2 + dist_ood2)\n",
        "\n",
        "  sim_in = 1 / (1 + dist_in)\n",
        "  sim_ood = 1 / (1 + dist_ood)\n",
        "\n",
        "  sim_in2 = 1 / (1 + dist_in2)\n",
        "  sim_ood2 = 1 / (1 + dist_ood2)\n",
        "\n",
        "  sim_in = sim_in + sim_in2\n",
        "#  sim_ood = sim_ood + sim_ood2\n",
        "\n",
        "  sim_score_.append(sim_ood2)\n",
        "\n",
        "  values, counts = np.unique(p, return_counts=True)\n",
        "#  print(values, counts)\n",
        "  #print(sim_in, sim_ood, lbl, e_)\n",
        "\n",
        "  if sim_in >= sim_ood:\n",
        "    y_ = ind\n",
        "    if np.max(counts) >= 8:\n",
        "      y_ = ind\n",
        "    else:\n",
        "      y_ = ood\n",
        "  else:\n",
        "    y_ = ood\n",
        "\n",
        "\n",
        "  y_pred.append(y_)\n",
        "  if lbl == 1:\n",
        "    y_true.append(0)\n",
        "  else:\n",
        "    y_true.append(1)\n",
        "#  y_true.append(lbl)\n",
        "\n",
        "\n",
        "  if lbl == ind:\n",
        "    count_in = count_in + 1\n",
        "  else:\n",
        "    count_ood = count_ood + 1\n",
        "\n",
        "  if y_ == lbl:\n",
        "    #sim_score_.append(1)\n",
        "    accuracy = accuracy + 1\n",
        "    if y_ == ind:\n",
        "      acc_in = acc_in + 1\n",
        "      tp = tp + 1\n",
        "    else:\n",
        "      acc_ood = acc_ood + 1\n",
        "      tn = tn + 1\n",
        "  else:\n",
        "    #sim_score_.append(0)\n",
        "    if y_ == ind:\n",
        "      fp = fp + 1\n",
        "    else:\n",
        "      fn = fn + 1\n",
        "\n",
        "\n",
        "print(\"Total Accuracy: \", accuracy/len(max_sm_all_wt_7an)) \n",
        "print(\"Accuracy of determining ID data: \", acc_in/count_in)\n",
        "print(\"Accuracy of determining OOD data: \", acc_ood/count_ood)\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Accuracy:  0.9351\n",
            "Accuracy of determining ID data:  0.9410387873383861\n",
            "Accuracy of determining OOD data:  0.8832684824902723\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GIwO4ZRc1wFb",
        "outputId": "64df686f-bc24-49ab-9740-494eb0d8bc35"
      },
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "roc_auc_score(y_true, sim_score)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.024163480503980393"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ErfypO0f1wFc",
        "outputId": "843689c4-5176-47f1-a5c8-f3c99e1222a4"
      },
      "source": [
        "roc_auc_score(y_true, y_pred)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0654066867782344"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XUs5L4Hf1wFc",
        "outputId": "2c237a29-1559-4acf-d05a-048b4c3a84de"
      },
      "source": [
        "roc_auc_score(y_true, sim_score_)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9756027615530201"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRS1n8PH2vXj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RAJzlpiX5DE8"
      },
      "source": [
        "# 8 as anomaly"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCKwaU1x5EiE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yo8oxH995SwG"
      },
      "source": [
        "new_train_images, new_train_labels, new_val_images, new_val_labels = separate_class(8, train_images, train_labels, val_images, val_labels)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9bqgltS5SwI"
      },
      "source": [
        "model0 = Model(name='8anomaly:classifier0')\n",
        "model1 = Model(name='8anomaly:classifier1')\n",
        "model2 = Model(name='8anomaly:classifier2')\n",
        "model3 = Model(name='8anomaly:classifier3')\n",
        "model4 = Model(name='8anomaly:classifier4')\n",
        "model5 = Model(name='8anomaly:classifier5')\n",
        "model6 = Model(name='8anomaly:classifier6')\n",
        "model7 = Model(name='8anomaly:classifier7')\n",
        "model8 = Model(name='8anomaly:classifier8')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8cyJgP3E5SwJ"
      },
      "source": [
        "class_0 = model0.build()\n",
        "class_1 = model1.build()\n",
        "class_2 = model2.build()\n",
        "class_3 = model3.build()\n",
        "class_4 = model4.build()\n",
        "class_5 = model5.build()\n",
        "class_6 = model6.build()\n",
        "class_7 = model7.build()\n",
        "class_8 = model8.build()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6A4ZZIN5SwK",
        "outputId": "698b796f-4510-416c-b074-1fc15f34164c"
      },
      "source": [
        "train_imgs0, train_lbls0 = get_train_data(0, new_train_images, new_train_labels)\n",
        "val_imgs0, val_lbls0 = get_train_data(0, new_val_images, new_val_labels)\n",
        "class_0 = model0.build()\n",
        "model0.train2(train_imgs0, train_lbls0, val_imgs0, val_lbls0)\n",
        "#model0.train(train_data0)\n",
        "model0.save_model(\"final_models/8anomaly-classifier0\")\n",
        "print('Model 0 saved')\n",
        "\n",
        "train_imgs1, train_lbls1 = get_train_data(1, new_train_images, new_train_labels)\n",
        "val_imgs1, val_lbls1 = get_train_data(1, new_val_images, new_val_labels)\n",
        "class_1 = model1.build()\n",
        "model1.train2(train_imgs1, train_lbls1, val_imgs1, val_lbls1)\n",
        "#model1.train(train_data1)\n",
        "model1.save_model(\"final_models/8anomaly-classifier1\")\n",
        "print('Model 1 saved')\n",
        "\n",
        "#train_data2 = get_train_data(2, new_train_images)\n",
        "train_imgs2, train_lbls2 = get_train_data(2, new_train_images, new_train_labels)\n",
        "val_imgs2, val_lbls2 = get_train_data(2, new_val_images, new_val_labels)\n",
        "class_2 = model2.build()\n",
        "model2.train2(train_imgs2, train_lbls2, val_imgs2, val_lbls2)\n",
        "#model2.train(train_data2)\n",
        "model2.save_model(\"final_models/8anomaly-classifier2\")\n",
        "print('Model 2 saved')\n",
        "\n",
        "#train_data3 = get_train_data(3, new_train_images)\n",
        "train_imgs3, train_lbls3 = get_train_data(3, new_train_images, new_train_labels)\n",
        "val_imgs3, val_lbls3 = get_train_data(3, new_val_images, new_val_labels)\n",
        "class_3 = model3.build()\n",
        "model3.train2(train_imgs3, train_lbls3, val_imgs3, val_lbls3)\n",
        "#model3.train(train_data3)\n",
        "model3.save_model(\"final_models/8anomaly-classifier3\")\n",
        "print('Model 3 saved')\n",
        "\n",
        "#train_data4 = get_train_data(4, new_train_images)\n",
        "train_imgs4, train_lbls4 = get_train_data(4, new_train_images, new_train_labels)\n",
        "val_imgs4, val_lbls4 = get_train_data(4, new_val_images, new_val_labels)\n",
        "class_4 = model4.build()\n",
        "model4.train2(train_imgs4, train_lbls4, val_imgs4, val_lbls4)\n",
        "#model4.train(train_data4)\n",
        "model4.save_model(\"final_models/8anomaly-classifier4\")\n",
        "print('Model 4 saved')\n",
        "\n",
        "#train_data5 = get_train_data(5, new_train_images)\n",
        "train_imgs5, train_lbls5 = get_train_data(5, new_train_images, new_train_labels)\n",
        "val_imgs5, val_lbls5 = get_train_data(5, new_val_images, new_val_labels)\n",
        "class_5 = model5.build()\n",
        "model5.train2(train_imgs5, train_lbls5, val_imgs5, val_lbls5)\n",
        "#model5.train(train_data5)\n",
        "model5.save_model(\"final_models/8anomaly-classifier5\")\n",
        "print('Model 5 saved')\n",
        "\n",
        "#train_data6 = get_train_data(6, new_train_images)\n",
        "train_imgs6, train_lbls6 = get_train_data(6, new_train_images, new_train_labels)\n",
        "val_imgs6, val_lbls6 = get_train_data(6, new_val_images, new_val_labels)\n",
        "class_6 = model6.build()\n",
        "model6.train2(train_imgs6, train_lbls6, val_imgs6, val_lbls6)\n",
        "#model6.train(train_data6)\n",
        "model6.save_model(\"final_models/8anomaly-classifier6\")\n",
        "print('Model 6 saved')\n",
        "\n",
        "#train_data7 = get_train_data(7, new_train_images)\n",
        "train_imgs7, train_lbls7 = get_train_data(7, new_train_images, new_train_labels)\n",
        "val_imgs7, val_lbls7 = get_train_data(7, new_val_images, new_val_labels)\n",
        "class_7 = model7.build()\n",
        "#model7.train(train_data7)\n",
        "model7.train2(train_imgs7, train_lbls7, val_imgs7, val_lbls7)\n",
        "model7.save_model(\"final_models/8anomaly-classifier7\")\n",
        "print('Model 7 saved')\n",
        "\n",
        "#train_data8 = get_train_data(8, new_train_images)\n",
        "train_imgs8, train_lbls8 = get_train_data(9, new_train_images, new_train_labels)\n",
        "val_imgs8, val_lbls8 = get_train_data(9, new_val_images, new_val_labels)\n",
        "class_8 = model8.build()\n",
        "#model8.train(train_data8)\n",
        "model8.train2(train_imgs8, train_lbls8, val_imgs8, val_lbls8)\n",
        "model8.save_model(\"final_models/8anomaly-classifier8\")\n",
        "print('Model 8 saved')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{1: 0, 2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(38561,)\n",
            "{1: 0, 2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9665,)\n",
            "Epoch 1/20\n",
            "1206/1206 [==============================] - 38s 31ms/step - loss: 5.0723 - accuracy: 0.8471 - val_loss: 1.0640 - val_accuracy: 0.8619\n",
            "Epoch 2/20\n",
            "1206/1206 [==============================] - 38s 31ms/step - loss: 0.3995 - accuracy: 0.9545 - val_loss: 0.1423 - val_accuracy: 0.9617\n",
            "Epoch 3/20\n",
            "1206/1206 [==============================] - 39s 32ms/step - loss: 0.0625 - accuracy: 0.9815 - val_loss: 0.1176 - val_accuracy: 0.9681\n",
            "Epoch 4/20\n",
            "1206/1206 [==============================] - 38s 32ms/step - loss: 0.0557 - accuracy: 0.9824 - val_loss: 0.1520 - val_accuracy: 0.9596\n",
            "Epoch 5/20\n",
            "1206/1206 [==============================] - 38s 32ms/step - loss: 0.0527 - accuracy: 0.9839 - val_loss: 0.1089 - val_accuracy: 0.9728\n",
            "Epoch 6/20\n",
            "1206/1206 [==============================] - 39s 32ms/step - loss: 0.0550 - accuracy: 0.9835 - val_loss: 0.2119 - val_accuracy: 0.9542\n",
            "Epoch 7/20\n",
            "1206/1206 [==============================] - 39s 32ms/step - loss: 0.0470 - accuracy: 0.9855 - val_loss: 0.1532 - val_accuracy: 0.9612\n",
            "Epoch 8/20\n",
            "1206/1206 [==============================] - 38s 32ms/step - loss: 0.0474 - accuracy: 0.9857 - val_loss: 0.4280 - val_accuracy: 0.9294\n",
            "Epoch 9/20\n",
            "1206/1206 [==============================] - 38s 32ms/step - loss: 0.0398 - accuracy: 0.9873 - val_loss: 0.1081 - val_accuracy: 0.9702\n",
            "Epoch 10/20\n",
            "1206/1206 [==============================] - 38s 32ms/step - loss: 0.0339 - accuracy: 0.9894 - val_loss: 0.0841 - val_accuracy: 0.9780\n",
            "Epoch 11/20\n",
            "1206/1206 [==============================] - 38s 32ms/step - loss: 0.0323 - accuracy: 0.9900 - val_loss: 0.1153 - val_accuracy: 0.9715\n",
            "Epoch 12/20\n",
            "1206/1206 [==============================] - 39s 32ms/step - loss: 0.0277 - accuracy: 0.9914 - val_loss: 0.0510 - val_accuracy: 0.9870\n",
            "Epoch 13/20\n",
            "1206/1206 [==============================] - 38s 32ms/step - loss: 0.0254 - accuracy: 0.9921 - val_loss: 0.0982 - val_accuracy: 0.9793\n",
            "Epoch 14/20\n",
            "1206/1206 [==============================] - 39s 32ms/step - loss: 0.0246 - accuracy: 0.9921 - val_loss: 0.0780 - val_accuracy: 0.9822\n",
            "Epoch 15/20\n",
            "1206/1206 [==============================] - 39s 32ms/step - loss: 0.0258 - accuracy: 0.9914 - val_loss: 0.0598 - val_accuracy: 0.9863\n",
            "Epoch 16/20\n",
            "1206/1206 [==============================] - 39s 32ms/step - loss: 0.0198 - accuracy: 0.9943 - val_loss: 0.0740 - val_accuracy: 0.9813\n",
            "Epoch 17/20\n",
            "1206/1206 [==============================] - 39s 32ms/step - loss: 0.0205 - accuracy: 0.9937 - val_loss: 0.1387 - val_accuracy: 0.9705\n",
            "Epoch 18/20\n",
            "1206/1206 [==============================] - 38s 32ms/step - loss: 0.0173 - accuracy: 0.9945 - val_loss: 0.0774 - val_accuracy: 0.9840\n",
            "Epoch 19/20\n",
            "1206/1206 [==============================] - 39s 32ms/step - loss: 0.0219 - accuracy: 0.9932 - val_loss: 0.0641 - val_accuracy: 0.9859\n",
            "Epoch 20/20\n",
            "1206/1206 [==============================] - 39s 32ms/step - loss: 0.0144 - accuracy: 0.9954 - val_loss: 0.0902 - val_accuracy: 0.9831\n",
            "INFO:tensorflow:Assets written to: final_models/8anomaly-classifier0/assets\n",
            "Model 0 saved\n",
            "{0: 0, 2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(37889,)\n",
            "{0: 0, 2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9518,)\n",
            "Epoch 1/20\n",
            "1185/1185 [==============================] - 39s 32ms/step - loss: 5.8591 - accuracy: 0.8063 - val_loss: 0.3565 - val_accuracy: 0.9541\n",
            "Epoch 2/20\n",
            "1185/1185 [==============================] - 38s 32ms/step - loss: 0.1734 - accuracy: 0.9714 - val_loss: 0.1104 - val_accuracy: 0.9694\n",
            "Epoch 3/20\n",
            "1185/1185 [==============================] - 38s 32ms/step - loss: 0.0675 - accuracy: 0.9806 - val_loss: 0.0836 - val_accuracy: 0.9753\n",
            "Epoch 4/20\n",
            "1185/1185 [==============================] - 38s 32ms/step - loss: 0.0566 - accuracy: 0.9824 - val_loss: 0.0614 - val_accuracy: 0.9819\n",
            "Epoch 5/20\n",
            "1185/1185 [==============================] - 38s 32ms/step - loss: 0.0598 - accuracy: 0.9819 - val_loss: 0.1714 - val_accuracy: 0.9547\n",
            "Epoch 6/20\n",
            "1185/1185 [==============================] - 38s 32ms/step - loss: 0.1011 - accuracy: 0.9745 - val_loss: 0.2106 - val_accuracy: 0.9560\n",
            "Epoch 7/20\n",
            "1185/1185 [==============================] - 38s 32ms/step - loss: 0.0515 - accuracy: 0.9849 - val_loss: 0.1817 - val_accuracy: 0.9604\n",
            "Epoch 8/20\n",
            "1185/1185 [==============================] - 38s 32ms/step - loss: 0.0475 - accuracy: 0.9855 - val_loss: 0.0905 - val_accuracy: 0.9815\n",
            "Epoch 9/20\n",
            "1185/1185 [==============================] - 38s 32ms/step - loss: 0.0460 - accuracy: 0.9863 - val_loss: 0.2010 - val_accuracy: 0.9636\n",
            "Epoch 10/20\n",
            "1185/1185 [==============================] - 38s 32ms/step - loss: 0.0425 - accuracy: 0.9877 - val_loss: 0.0720 - val_accuracy: 0.9831\n",
            "Epoch 11/20\n",
            "1185/1185 [==============================] - 38s 32ms/step - loss: 0.0318 - accuracy: 0.9901 - val_loss: 0.0955 - val_accuracy: 0.9771\n",
            "Epoch 12/20\n",
            "1185/1185 [==============================] - 38s 32ms/step - loss: 0.0307 - accuracy: 0.9903 - val_loss: 0.0520 - val_accuracy: 0.9888\n",
            "Epoch 13/20\n",
            "1185/1185 [==============================] - 38s 32ms/step - loss: 0.0291 - accuracy: 0.9915 - val_loss: 0.1859 - val_accuracy: 0.9647\n",
            "Epoch 14/20\n",
            "1185/1185 [==============================] - 38s 32ms/step - loss: 0.0263 - accuracy: 0.9916 - val_loss: 0.1489 - val_accuracy: 0.9692\n",
            "Epoch 15/20\n",
            "1185/1185 [==============================] - 38s 32ms/step - loss: 0.0222 - accuracy: 0.9929 - val_loss: 0.0884 - val_accuracy: 0.9822\n",
            "Epoch 16/20\n",
            "1185/1185 [==============================] - 38s 32ms/step - loss: 0.0220 - accuracy: 0.9924 - val_loss: 0.1175 - val_accuracy: 0.9749\n",
            "Epoch 17/20\n",
            "1185/1185 [==============================] - 38s 32ms/step - loss: 0.0224 - accuracy: 0.9929 - val_loss: 0.0942 - val_accuracy: 0.9825\n",
            "Epoch 18/20\n",
            "1185/1185 [==============================] - 38s 32ms/step - loss: 0.0178 - accuracy: 0.9942 - val_loss: 0.0871 - val_accuracy: 0.9806\n",
            "Epoch 19/20\n",
            "1185/1185 [==============================] - 38s 32ms/step - loss: 0.0185 - accuracy: 0.9946 - val_loss: 0.1037 - val_accuracy: 0.9799\n",
            "Epoch 20/20\n",
            "1185/1185 [==============================] - 38s 32ms/step - loss: 0.0154 - accuracy: 0.9954 - val_loss: 0.0657 - val_accuracy: 0.9869\n",
            "INFO:tensorflow:Assets written to: final_models/8anomaly-classifier1/assets\n",
            "Model 1 saved\n",
            "{0: 0, 1: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(38525,)\n",
            "{0: 0, 1: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9666,)\n",
            "Epoch 1/20\n",
            "1204/1204 [==============================] - 40s 32ms/step - loss: 5.3880 - accuracy: 0.8519 - val_loss: 0.1555 - val_accuracy: 0.9756\n",
            "Epoch 2/20\n",
            "1204/1204 [==============================] - 39s 32ms/step - loss: 0.1574 - accuracy: 0.9708 - val_loss: 0.1006 - val_accuracy: 0.9747\n",
            "Epoch 3/20\n",
            "1204/1204 [==============================] - 39s 32ms/step - loss: 0.0556 - accuracy: 0.9836 - val_loss: 0.1117 - val_accuracy: 0.9721\n",
            "Epoch 4/20\n",
            "1204/1204 [==============================] - 39s 32ms/step - loss: 0.0534 - accuracy: 0.9840 - val_loss: 0.0991 - val_accuracy: 0.9753\n",
            "Epoch 5/20\n",
            "1204/1204 [==============================] - 38s 32ms/step - loss: 0.0533 - accuracy: 0.9847 - val_loss: 0.1837 - val_accuracy: 0.9583\n",
            "Epoch 6/20\n",
            "1204/1204 [==============================] - 39s 32ms/step - loss: 0.0476 - accuracy: 0.9855 - val_loss: 0.1197 - val_accuracy: 0.9728\n",
            "Epoch 7/20\n",
            "1204/1204 [==============================] - 39s 32ms/step - loss: 0.0455 - accuracy: 0.9863 - val_loss: 0.0776 - val_accuracy: 0.9813\n",
            "Epoch 8/20\n",
            "1204/1204 [==============================] - 38s 32ms/step - loss: 0.0412 - accuracy: 0.9881 - val_loss: 0.0528 - val_accuracy: 0.9840\n",
            "Epoch 9/20\n",
            "1204/1204 [==============================] - 39s 32ms/step - loss: 0.0376 - accuracy: 0.9889 - val_loss: 0.1816 - val_accuracy: 0.9651\n",
            "Epoch 10/20\n",
            "1204/1204 [==============================] - 38s 32ms/step - loss: 0.0394 - accuracy: 0.9886 - val_loss: 0.2070 - val_accuracy: 0.9600\n",
            "Epoch 11/20\n",
            "1204/1204 [==============================] - 39s 32ms/step - loss: 0.0300 - accuracy: 0.9908 - val_loss: 0.1150 - val_accuracy: 0.9754\n",
            "Epoch 12/20\n",
            "1204/1204 [==============================] - 39s 32ms/step - loss: 0.0287 - accuracy: 0.9907 - val_loss: 0.0828 - val_accuracy: 0.9823\n",
            "Epoch 13/20\n",
            "1204/1204 [==============================] - 39s 32ms/step - loss: 0.0313 - accuracy: 0.9906 - val_loss: 0.1145 - val_accuracy: 0.9771\n",
            "Epoch 14/20\n",
            "1204/1204 [==============================] - 39s 32ms/step - loss: 0.0246 - accuracy: 0.9917 - val_loss: 0.0820 - val_accuracy: 0.9827\n",
            "Epoch 15/20\n",
            "1204/1204 [==============================] - 39s 32ms/step - loss: 0.0164 - accuracy: 0.9953 - val_loss: 0.0674 - val_accuracy: 0.9862\n",
            "Epoch 16/20\n",
            "1204/1204 [==============================] - 39s 32ms/step - loss: 0.0254 - accuracy: 0.9921 - val_loss: 0.0529 - val_accuracy: 0.9888\n",
            "Epoch 17/20\n",
            "1204/1204 [==============================] - 38s 32ms/step - loss: 0.0195 - accuracy: 0.9941 - val_loss: 0.0425 - val_accuracy: 0.9905\n",
            "Epoch 18/20\n",
            "1204/1204 [==============================] - 39s 32ms/step - loss: 0.0135 - accuracy: 0.9958 - val_loss: 0.0589 - val_accuracy: 0.9879\n",
            "Epoch 19/20\n",
            "1204/1204 [==============================] - 39s 32ms/step - loss: 0.0168 - accuracy: 0.9948 - val_loss: 0.1091 - val_accuracy: 0.9796\n",
            "Epoch 20/20\n",
            "1204/1204 [==============================] - 39s 32ms/step - loss: 0.0154 - accuracy: 0.9944 - val_loss: 0.0678 - val_accuracy: 0.9843\n",
            "INFO:tensorflow:Assets written to: final_models/8anomaly-classifier2/assets\n",
            "Model 2 saved\n",
            "{0: 0, 1: 1, 2: 2, 4: 3, 5: 4, 6: 5, 7: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(38397,)\n",
            "{0: 0, 1: 1, 2: 2, 4: 3, 5: 4, 6: 5, 7: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9621,)\n",
            "Epoch 1/20\n",
            "1200/1200 [==============================] - 40s 32ms/step - loss: 4.2715 - accuracy: 0.8465 - val_loss: 0.5021 - val_accuracy: 0.9418\n",
            "Epoch 2/20\n",
            "1200/1200 [==============================] - 38s 32ms/step - loss: 0.1162 - accuracy: 0.9734 - val_loss: 0.1290 - val_accuracy: 0.9691\n",
            "Epoch 3/20\n",
            "1200/1200 [==============================] - 38s 32ms/step - loss: 0.0764 - accuracy: 0.9783 - val_loss: 0.0998 - val_accuracy: 0.9787\n",
            "Epoch 4/20\n",
            "1200/1200 [==============================] - 38s 32ms/step - loss: 0.0667 - accuracy: 0.9806 - val_loss: 0.1116 - val_accuracy: 0.9777\n",
            "Epoch 5/20\n",
            "1200/1200 [==============================] - 38s 32ms/step - loss: 0.0605 - accuracy: 0.9826 - val_loss: 0.0796 - val_accuracy: 0.9804\n",
            "Epoch 6/20\n",
            "1200/1200 [==============================] - 38s 32ms/step - loss: 0.0490 - accuracy: 0.9855 - val_loss: 0.4395 - val_accuracy: 0.9347\n",
            "Epoch 7/20\n",
            "1200/1200 [==============================] - 38s 32ms/step - loss: 0.0475 - accuracy: 0.9857 - val_loss: 0.1568 - val_accuracy: 0.9683\n",
            "Epoch 8/20\n",
            "1200/1200 [==============================] - 38s 32ms/step - loss: 0.0416 - accuracy: 0.9869 - val_loss: 0.0692 - val_accuracy: 0.9837\n",
            "Epoch 9/20\n",
            "1200/1200 [==============================] - 38s 32ms/step - loss: 0.0387 - accuracy: 0.9887 - val_loss: 0.0504 - val_accuracy: 0.9851\n",
            "Epoch 10/20\n",
            "1200/1200 [==============================] - 38s 32ms/step - loss: 0.0324 - accuracy: 0.9906 - val_loss: 0.1111 - val_accuracy: 0.9736\n",
            "Epoch 11/20\n",
            "1200/1200 [==============================] - 38s 32ms/step - loss: 0.0357 - accuracy: 0.9891 - val_loss: 0.0529 - val_accuracy: 0.9865\n",
            "Epoch 12/20\n",
            "1200/1200 [==============================] - 38s 32ms/step - loss: 0.0272 - accuracy: 0.9910 - val_loss: 0.0815 - val_accuracy: 0.9790\n",
            "Epoch 13/20\n",
            "1200/1200 [==============================] - 38s 32ms/step - loss: 0.0271 - accuracy: 0.9923 - val_loss: 0.1157 - val_accuracy: 0.9796\n",
            "Epoch 14/20\n",
            "1200/1200 [==============================] - 38s 32ms/step - loss: 0.0231 - accuracy: 0.9929 - val_loss: 0.0706 - val_accuracy: 0.9854\n",
            "Epoch 15/20\n",
            "1200/1200 [==============================] - 38s 32ms/step - loss: 0.0235 - accuracy: 0.9925 - val_loss: 0.0687 - val_accuracy: 0.9833\n",
            "Epoch 16/20\n",
            "1200/1200 [==============================] - 38s 32ms/step - loss: 0.0248 - accuracy: 0.9923 - val_loss: 0.1463 - val_accuracy: 0.9673\n",
            "Epoch 17/20\n",
            "1200/1200 [==============================] - 38s 32ms/step - loss: 0.0138 - accuracy: 0.9951 - val_loss: 0.0922 - val_accuracy: 0.9825\n",
            "Epoch 18/20\n",
            "1200/1200 [==============================] - 38s 32ms/step - loss: 0.0190 - accuracy: 0.9939 - val_loss: 0.0581 - val_accuracy: 0.9885\n",
            "Epoch 19/20\n",
            "1200/1200 [==============================] - 38s 32ms/step - loss: 0.0162 - accuracy: 0.9949 - val_loss: 0.0717 - val_accuracy: 0.9837\n",
            "Epoch 20/20\n",
            "1200/1200 [==============================] - 38s 32ms/step - loss: 0.0143 - accuracy: 0.9956 - val_loss: 0.0908 - val_accuracy: 0.9794\n",
            "INFO:tensorflow:Assets written to: final_models/8anomaly-classifier3/assets\n",
            "Model 3 saved\n",
            "{0: 0, 1: 1, 2: 2, 3: 3, 5: 4, 6: 5, 7: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(38643,)\n",
            "{0: 0, 1: 1, 2: 2, 3: 3, 5: 4, 6: 5, 7: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9664,)\n",
            "Epoch 1/20\n",
            "1208/1208 [==============================] - 40s 32ms/step - loss: 4.7284 - accuracy: 0.8657 - val_loss: 0.1282 - val_accuracy: 0.9748\n",
            "Epoch 2/20\n",
            "1208/1208 [==============================] - 38s 32ms/step - loss: 0.1164 - accuracy: 0.9770 - val_loss: 0.0929 - val_accuracy: 0.9802\n",
            "Epoch 3/20\n",
            "1208/1208 [==============================] - 39s 32ms/step - loss: 0.0537 - accuracy: 0.9846 - val_loss: 0.2064 - val_accuracy: 0.9513\n",
            "Epoch 4/20\n",
            "1208/1208 [==============================] - 39s 32ms/step - loss: 0.0545 - accuracy: 0.9840 - val_loss: 0.2126 - val_accuracy: 0.9561\n",
            "Epoch 5/20\n",
            "1208/1208 [==============================] - 39s 32ms/step - loss: 0.0498 - accuracy: 0.9849 - val_loss: 0.1687 - val_accuracy: 0.9647\n",
            "Epoch 6/20\n",
            "1208/1208 [==============================] - 39s 32ms/step - loss: 0.0487 - accuracy: 0.9864 - val_loss: 0.0721 - val_accuracy: 0.9821\n",
            "Epoch 7/20\n",
            "1208/1208 [==============================] - 38s 32ms/step - loss: 0.0380 - accuracy: 0.9882 - val_loss: 0.0852 - val_accuracy: 0.9816\n",
            "Epoch 8/20\n",
            "1208/1208 [==============================] - 39s 32ms/step - loss: 0.0368 - accuracy: 0.9885 - val_loss: 0.0635 - val_accuracy: 0.9856\n",
            "Epoch 9/20\n",
            "1208/1208 [==============================] - 38s 32ms/step - loss: 0.0303 - accuracy: 0.9902 - val_loss: 0.1362 - val_accuracy: 0.9682\n",
            "Epoch 10/20\n",
            "1208/1208 [==============================] - 38s 32ms/step - loss: 0.0367 - accuracy: 0.9894 - val_loss: 0.1841 - val_accuracy: 0.9647\n",
            "Epoch 11/20\n",
            "1208/1208 [==============================] - 38s 32ms/step - loss: 0.0264 - accuracy: 0.9916 - val_loss: 0.0532 - val_accuracy: 0.9873\n",
            "Epoch 12/20\n",
            "1208/1208 [==============================] - 39s 32ms/step - loss: 0.0247 - accuracy: 0.9921 - val_loss: 0.0868 - val_accuracy: 0.9826\n",
            "Epoch 13/20\n",
            "1208/1208 [==============================] - 38s 32ms/step - loss: 0.0237 - accuracy: 0.9922 - val_loss: 0.0716 - val_accuracy: 0.9834\n",
            "Epoch 14/20\n",
            "1208/1208 [==============================] - 38s 32ms/step - loss: 0.0164 - accuracy: 0.9948 - val_loss: 0.0903 - val_accuracy: 0.9786\n",
            "Epoch 15/20\n",
            "1208/1208 [==============================] - 39s 32ms/step - loss: 0.0234 - accuracy: 0.9924 - val_loss: 0.0658 - val_accuracy: 0.9860\n",
            "Epoch 16/20\n",
            "1208/1208 [==============================] - 39s 32ms/step - loss: 0.0165 - accuracy: 0.9949 - val_loss: 0.1552 - val_accuracy: 0.9716\n",
            "Epoch 17/20\n",
            "1208/1208 [==============================] - 39s 32ms/step - loss: 0.0146 - accuracy: 0.9951 - val_loss: 0.1372 - val_accuracy: 0.9734\n",
            "Epoch 18/20\n",
            "1208/1208 [==============================] - 39s 32ms/step - loss: 0.0177 - accuracy: 0.9935 - val_loss: 0.1155 - val_accuracy: 0.9785\n",
            "Epoch 19/20\n",
            "1208/1208 [==============================] - 39s 32ms/step - loss: 0.0141 - accuracy: 0.9960 - val_loss: 0.1215 - val_accuracy: 0.9764\n",
            "Epoch 20/20\n",
            "1208/1208 [==============================] - 39s 32ms/step - loss: 0.0099 - accuracy: 0.9969 - val_loss: 0.1324 - val_accuracy: 0.9769\n",
            "INFO:tensorflow:Assets written to: final_models/8anomaly-classifier4/assets\n",
            "Model 4 saved\n",
            "{0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 6: 5, 7: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(38992,)\n",
            "{0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 6: 5, 7: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9736,)\n",
            "Epoch 1/20\n",
            "1219/1219 [==============================] - 41s 33ms/step - loss: 3.8389 - accuracy: 0.8569 - val_loss: 0.0975 - val_accuracy: 0.9752\n",
            "Epoch 2/20\n",
            "1219/1219 [==============================] - 39s 32ms/step - loss: 0.0876 - accuracy: 0.9804 - val_loss: 0.1463 - val_accuracy: 0.9595\n",
            "Epoch 3/20\n",
            "1219/1219 [==============================] - 39s 32ms/step - loss: 0.0628 - accuracy: 0.9829 - val_loss: 0.1859 - val_accuracy: 0.9537\n",
            "Epoch 4/20\n",
            "1219/1219 [==============================] - 39s 32ms/step - loss: 0.0544 - accuracy: 0.9848 - val_loss: 0.1541 - val_accuracy: 0.9598\n",
            "Epoch 5/20\n",
            "1219/1219 [==============================] - 39s 32ms/step - loss: 0.0534 - accuracy: 0.9842 - val_loss: 0.0967 - val_accuracy: 0.9773\n",
            "Epoch 6/20\n",
            "1219/1219 [==============================] - 39s 32ms/step - loss: 0.0490 - accuracy: 0.9862 - val_loss: 0.1829 - val_accuracy: 0.9598\n",
            "Epoch 7/20\n",
            "1219/1219 [==============================] - 39s 32ms/step - loss: 0.0456 - accuracy: 0.9860 - val_loss: 0.1532 - val_accuracy: 0.9665\n",
            "Epoch 8/20\n",
            "1219/1219 [==============================] - 39s 32ms/step - loss: 0.0388 - accuracy: 0.9876 - val_loss: 0.0858 - val_accuracy: 0.9784\n",
            "Epoch 9/20\n",
            "1219/1219 [==============================] - 39s 32ms/step - loss: 0.0351 - accuracy: 0.9886 - val_loss: 0.0861 - val_accuracy: 0.9771\n",
            "Epoch 10/20\n",
            "1219/1219 [==============================] - 39s 32ms/step - loss: 0.0338 - accuracy: 0.9897 - val_loss: 0.0633 - val_accuracy: 0.9852\n",
            "Epoch 11/20\n",
            "1219/1219 [==============================] - 39s 32ms/step - loss: 0.0301 - accuracy: 0.9900 - val_loss: 0.0800 - val_accuracy: 0.9810\n",
            "Epoch 12/20\n",
            "1219/1219 [==============================] - 39s 32ms/step - loss: 0.0319 - accuracy: 0.9901 - val_loss: 0.0865 - val_accuracy: 0.9802\n",
            "Epoch 13/20\n",
            "1219/1219 [==============================] - 39s 32ms/step - loss: 0.0232 - accuracy: 0.9925 - val_loss: 0.1066 - val_accuracy: 0.9778\n",
            "Epoch 14/20\n",
            "1219/1219 [==============================] - 39s 32ms/step - loss: 0.0254 - accuracy: 0.9924 - val_loss: 0.0891 - val_accuracy: 0.9817\n",
            "Epoch 15/20\n",
            "1219/1219 [==============================] - 39s 32ms/step - loss: 0.0194 - accuracy: 0.9941 - val_loss: 0.0627 - val_accuracy: 0.9859\n",
            "Epoch 16/20\n",
            "1219/1219 [==============================] - 39s 32ms/step - loss: 0.0171 - accuracy: 0.9950 - val_loss: 0.0781 - val_accuracy: 0.9812\n",
            "Epoch 17/20\n",
            "1219/1219 [==============================] - 39s 32ms/step - loss: 0.0195 - accuracy: 0.9939 - val_loss: 0.0746 - val_accuracy: 0.9848\n",
            "Epoch 18/20\n",
            "1219/1219 [==============================] - 39s 32ms/step - loss: 0.0134 - accuracy: 0.9957 - val_loss: 0.0647 - val_accuracy: 0.9854\n",
            "Epoch 19/20\n",
            "1219/1219 [==============================] - 39s 32ms/step - loss: 0.0176 - accuracy: 0.9950 - val_loss: 0.0855 - val_accuracy: 0.9815\n",
            "Epoch 20/20\n",
            "1219/1219 [==============================] - 39s 32ms/step - loss: 0.0174 - accuracy: 0.9947 - val_loss: 0.0564 - val_accuracy: 0.9879\n",
            "INFO:tensorflow:Assets written to: final_models/8anomaly-classifier5/assets\n",
            "Model 5 saved\n",
            "{0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 7: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(38568,)\n",
            "{0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 7: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9663,)\n",
            "Epoch 1/20\n",
            "1206/1206 [==============================] - 40s 32ms/step - loss: 4.5419 - accuracy: 0.8157 - val_loss: 0.2909 - val_accuracy: 0.9517\n",
            "Epoch 2/20\n",
            "1206/1206 [==============================] - 38s 32ms/step - loss: 0.1463 - accuracy: 0.9672 - val_loss: 0.0737 - val_accuracy: 0.9801\n",
            "Epoch 3/20\n",
            "1206/1206 [==============================] - 39s 32ms/step - loss: 0.0649 - accuracy: 0.9800 - val_loss: 0.2822 - val_accuracy: 0.9436\n",
            "Epoch 4/20\n",
            "1206/1206 [==============================] - 39s 32ms/step - loss: 0.0600 - accuracy: 0.9829 - val_loss: 0.0707 - val_accuracy: 0.9808\n",
            "Epoch 5/20\n",
            "1206/1206 [==============================] - 39s 32ms/step - loss: 0.0586 - accuracy: 0.9826 - val_loss: 0.1072 - val_accuracy: 0.9754\n",
            "Epoch 6/20\n",
            "1206/1206 [==============================] - 38s 32ms/step - loss: 0.0473 - accuracy: 0.9852 - val_loss: 0.1135 - val_accuracy: 0.9737\n",
            "Epoch 7/20\n",
            "1206/1206 [==============================] - 39s 32ms/step - loss: 0.0473 - accuracy: 0.9858 - val_loss: 0.2246 - val_accuracy: 0.9532\n",
            "Epoch 8/20\n",
            "1206/1206 [==============================] - 39s 32ms/step - loss: 0.0430 - accuracy: 0.9870 - val_loss: 0.0681 - val_accuracy: 0.9827\n",
            "Epoch 9/20\n",
            "1206/1206 [==============================] - 39s 32ms/step - loss: 0.0376 - accuracy: 0.9890 - val_loss: 0.0788 - val_accuracy: 0.9814\n",
            "Epoch 10/20\n",
            "1206/1206 [==============================] - 38s 32ms/step - loss: 0.0389 - accuracy: 0.9887 - val_loss: 0.0662 - val_accuracy: 0.9845\n",
            "Epoch 11/20\n",
            "1206/1206 [==============================] - 39s 32ms/step - loss: 0.0285 - accuracy: 0.9920 - val_loss: 0.0862 - val_accuracy: 0.9791\n",
            "Epoch 12/20\n",
            "1206/1206 [==============================] - 39s 32ms/step - loss: 0.0294 - accuracy: 0.9909 - val_loss: 0.0858 - val_accuracy: 0.9781\n",
            "Epoch 13/20\n",
            "1206/1206 [==============================] - 38s 32ms/step - loss: 0.0209 - accuracy: 0.9932 - val_loss: 0.0755 - val_accuracy: 0.9829\n",
            "Epoch 14/20\n",
            "1206/1206 [==============================] - 39s 32ms/step - loss: 0.0225 - accuracy: 0.9928 - val_loss: 0.0768 - val_accuracy: 0.9833\n",
            "Epoch 15/20\n",
            "1206/1206 [==============================] - 38s 32ms/step - loss: 0.0234 - accuracy: 0.9930 - val_loss: 0.1330 - val_accuracy: 0.9747\n",
            "Epoch 16/20\n",
            "1206/1206 [==============================] - 38s 32ms/step - loss: 0.0198 - accuracy: 0.9936 - val_loss: 0.0516 - val_accuracy: 0.9888\n",
            "Epoch 17/20\n",
            "1206/1206 [==============================] - 39s 32ms/step - loss: 0.0161 - accuracy: 0.9950 - val_loss: 0.0838 - val_accuracy: 0.9844\n",
            "Epoch 18/20\n",
            "1206/1206 [==============================] - 39s 32ms/step - loss: 0.0206 - accuracy: 0.9941 - val_loss: 0.0639 - val_accuracy: 0.9872\n",
            "Epoch 19/20\n",
            "1206/1206 [==============================] - 38s 32ms/step - loss: 0.0161 - accuracy: 0.9952 - val_loss: 0.1392 - val_accuracy: 0.9730\n",
            "Epoch 20/20\n",
            "1206/1206 [==============================] - 39s 32ms/step - loss: 0.0142 - accuracy: 0.9959 - val_loss: 0.0861 - val_accuracy: 0.9854\n",
            "INFO:tensorflow:Assets written to: final_models/8anomaly-classifier6/assets\n",
            "Model 6 saved\n",
            "{0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(38343,)\n",
            "{0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9541,)\n",
            "Epoch 1/20\n",
            "1199/1199 [==============================] - 40s 32ms/step - loss: 6.4077 - accuracy: 0.8048 - val_loss: 0.6678 - val_accuracy: 0.9508\n",
            "Epoch 2/20\n",
            "1199/1199 [==============================] - 38s 32ms/step - loss: 0.3814 - accuracy: 0.9658 - val_loss: 0.1794 - val_accuracy: 0.9655\n",
            "Epoch 3/20\n",
            "1199/1199 [==============================] - 38s 32ms/step - loss: 0.0749 - accuracy: 0.9824 - val_loss: 0.0929 - val_accuracy: 0.9767\n",
            "Epoch 4/20\n",
            "1199/1199 [==============================] - 38s 32ms/step - loss: 0.0479 - accuracy: 0.9866 - val_loss: 0.1768 - val_accuracy: 0.9609\n",
            "Epoch 5/20\n",
            "1199/1199 [==============================] - 38s 32ms/step - loss: 0.0457 - accuracy: 0.9860 - val_loss: 0.1567 - val_accuracy: 0.9630\n",
            "Epoch 6/20\n",
            "1199/1199 [==============================] - 38s 32ms/step - loss: 0.0476 - accuracy: 0.9855 - val_loss: 0.0899 - val_accuracy: 0.9755\n",
            "Epoch 7/20\n",
            "1199/1199 [==============================] - 38s 32ms/step - loss: 0.0519 - accuracy: 0.9844 - val_loss: 0.2917 - val_accuracy: 0.9469\n",
            "Epoch 8/20\n",
            "1199/1199 [==============================] - 38s 32ms/step - loss: 0.0390 - accuracy: 0.9881 - val_loss: 0.1669 - val_accuracy: 0.9654\n",
            "Epoch 9/20\n",
            "1199/1199 [==============================] - 38s 32ms/step - loss: 0.0390 - accuracy: 0.9882 - val_loss: 0.0927 - val_accuracy: 0.9775\n",
            "Epoch 10/20\n",
            "1199/1199 [==============================] - 38s 32ms/step - loss: 0.0324 - accuracy: 0.9898 - val_loss: 0.1450 - val_accuracy: 0.9704\n",
            "Epoch 11/20\n",
            "1199/1199 [==============================] - 38s 32ms/step - loss: 0.0320 - accuracy: 0.9893 - val_loss: 0.1337 - val_accuracy: 0.9745\n",
            "Epoch 12/20\n",
            "1199/1199 [==============================] - 38s 32ms/step - loss: 0.0318 - accuracy: 0.9905 - val_loss: 0.1495 - val_accuracy: 0.9719\n",
            "Epoch 13/20\n",
            "1199/1199 [==============================] - 38s 32ms/step - loss: 0.0270 - accuracy: 0.9912 - val_loss: 0.0878 - val_accuracy: 0.9827\n",
            "Epoch 14/20\n",
            "1199/1199 [==============================] - 38s 32ms/step - loss: 0.0247 - accuracy: 0.9919 - val_loss: 0.0902 - val_accuracy: 0.9829\n",
            "Epoch 15/20\n",
            "1199/1199 [==============================] - 38s 32ms/step - loss: 0.0210 - accuracy: 0.9933 - val_loss: 0.1244 - val_accuracy: 0.9746\n",
            "Epoch 16/20\n",
            "1199/1199 [==============================] - 38s 32ms/step - loss: 0.0216 - accuracy: 0.9934 - val_loss: 0.1280 - val_accuracy: 0.9778\n",
            "Epoch 17/20\n",
            "1199/1199 [==============================] - 38s 32ms/step - loss: 0.0192 - accuracy: 0.9940 - val_loss: 0.0716 - val_accuracy: 0.9825\n",
            "Epoch 18/20\n",
            "1199/1199 [==============================] - 38s 32ms/step - loss: 0.0183 - accuracy: 0.9940 - val_loss: 0.1432 - val_accuracy: 0.9758\n",
            "Epoch 19/20\n",
            "1199/1199 [==============================] - 38s 32ms/step - loss: 0.0183 - accuracy: 0.9946 - val_loss: 0.1409 - val_accuracy: 0.9773\n",
            "Epoch 20/20\n",
            "1199/1199 [==============================] - 38s 32ms/step - loss: 0.0167 - accuracy: 0.9946 - val_loss: 0.0749 - val_accuracy: 0.9832\n",
            "INFO:tensorflow:Assets written to: final_models/8anomaly-classifier7/assets\n",
            "Model 7 saved\n",
            "{0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(38554,)\n",
            "{0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9646,)\n",
            "Epoch 1/20\n",
            "1205/1205 [==============================] - 40s 32ms/step - loss: 3.6549 - accuracy: 0.8577 - val_loss: 0.2007 - val_accuracy: 0.9659\n",
            "Epoch 2/20\n",
            "1205/1205 [==============================] - 39s 32ms/step - loss: 0.1130 - accuracy: 0.9742 - val_loss: 0.1894 - val_accuracy: 0.9722\n",
            "Epoch 3/20\n",
            "1205/1205 [==============================] - 39s 32ms/step - loss: 0.0664 - accuracy: 0.9840 - val_loss: 0.3650 - val_accuracy: 0.9628\n",
            "Epoch 4/20\n",
            "1205/1205 [==============================] - 39s 32ms/step - loss: 0.0597 - accuracy: 0.9843 - val_loss: 0.0784 - val_accuracy: 0.9782\n",
            "Epoch 5/20\n",
            "1205/1205 [==============================] - 39s 32ms/step - loss: 0.0506 - accuracy: 0.9853 - val_loss: 0.0889 - val_accuracy: 0.9765\n",
            "Epoch 6/20\n",
            "1205/1205 [==============================] - 39s 32ms/step - loss: 0.0441 - accuracy: 0.9872 - val_loss: 0.2392 - val_accuracy: 0.9517\n",
            "Epoch 7/20\n",
            "1205/1205 [==============================] - 39s 32ms/step - loss: 0.0435 - accuracy: 0.9868 - val_loss: 0.1255 - val_accuracy: 0.9712\n",
            "Epoch 8/20\n",
            "1205/1205 [==============================] - 39s 32ms/step - loss: 0.0375 - accuracy: 0.9890 - val_loss: 0.0785 - val_accuracy: 0.9798\n",
            "Epoch 9/20\n",
            "1205/1205 [==============================] - 39s 32ms/step - loss: 0.0401 - accuracy: 0.9873 - val_loss: 0.0534 - val_accuracy: 0.9877\n",
            "Epoch 10/20\n",
            "1205/1205 [==============================] - 39s 32ms/step - loss: 0.0261 - accuracy: 0.9913 - val_loss: 0.0540 - val_accuracy: 0.9864\n",
            "Epoch 11/20\n",
            "1205/1205 [==============================] - 39s 32ms/step - loss: 0.0317 - accuracy: 0.9907 - val_loss: 0.0732 - val_accuracy: 0.9841\n",
            "Epoch 12/20\n",
            "1205/1205 [==============================] - 39s 32ms/step - loss: 0.0249 - accuracy: 0.9924 - val_loss: 0.0467 - val_accuracy: 0.9883\n",
            "Epoch 13/20\n",
            "1205/1205 [==============================] - 39s 32ms/step - loss: 0.0255 - accuracy: 0.9917 - val_loss: 0.0723 - val_accuracy: 0.9837\n",
            "Epoch 14/20\n",
            "1205/1205 [==============================] - 39s 32ms/step - loss: 0.0205 - accuracy: 0.9934 - val_loss: 0.0578 - val_accuracy: 0.9874\n",
            "Epoch 15/20\n",
            "1205/1205 [==============================] - 39s 32ms/step - loss: 0.0203 - accuracy: 0.9933 - val_loss: 0.1052 - val_accuracy: 0.9775\n",
            "Epoch 16/20\n",
            "1205/1205 [==============================] - 39s 32ms/step - loss: 0.0159 - accuracy: 0.9947 - val_loss: 0.1184 - val_accuracy: 0.9781\n",
            "Epoch 17/20\n",
            "1205/1205 [==============================] - 39s 32ms/step - loss: 0.0176 - accuracy: 0.9945 - val_loss: 0.0634 - val_accuracy: 0.9877\n",
            "Epoch 18/20\n",
            "1205/1205 [==============================] - 39s 32ms/step - loss: 0.0175 - accuracy: 0.9944 - val_loss: 0.0577 - val_accuracy: 0.9859\n",
            "Epoch 19/20\n",
            "1205/1205 [==============================] - 39s 32ms/step - loss: 0.0173 - accuracy: 0.9954 - val_loss: 0.1331 - val_accuracy: 0.9765\n",
            "Epoch 20/20\n",
            "1205/1205 [==============================] - 39s 32ms/step - loss: 0.0120 - accuracy: 0.9959 - val_loss: 0.1024 - val_accuracy: 0.9804\n",
            "INFO:tensorflow:Assets written to: final_models/8anomaly-classifier8/assets\n",
            "Model 8 saved\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iviAIdx05SwO"
      },
      "source": [
        "class_0 = model0.load_model(\"final_models/8anomaly-classifier0\")\n",
        "class_1 = model1.load_model(\"final_models/8anomaly-classifier1\")\n",
        "class_2 = model2.load_model(\"final_models/8anomaly-classifier2\")\n",
        "class_3 = model3.load_model(\"final_models/8anomaly-classifier3\")\n",
        "class_4 = model4.load_model(\"final_models/8anomaly-classifier4\")\n",
        "class_5 = model5.load_model(\"final_models/8anomaly-classifier5\")\n",
        "class_6 = model6.load_model(\"final_models/8anomaly-classifier6\")\n",
        "class_7 = model7.load_model(\"final_models/8anomaly-classifier7\")\n",
        "class_8 = model8.load_model(\"final_models/8anomaly-classifier8\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lK_VCO0V5SwP",
        "outputId": "0333f65c-2067-4cbf-e9dd-ba1735f42988"
      },
      "source": [
        "layer_name_list = []\n",
        "\n",
        "layer_name_list.append(class_0.layers[-2:][0].name)\n",
        "layer_name_list.append(class_1.layers[-2:][0].name)\n",
        "layer_name_list.append(class_2.layers[-2:][0].name)\n",
        "layer_name_list.append(class_3.layers[-2:][0].name)\n",
        "layer_name_list.append(class_4.layers[-2:][0].name)\n",
        "layer_name_list.append(class_5.layers[-2:][0].name)\n",
        "layer_name_list.append(class_6.layers[-2:][0].name)\n",
        "layer_name_list.append(class_7.layers[-2:][0].name)\n",
        "layer_name_list.append(class_8.layers[-2:][0].name)\n",
        "\n",
        "print(layer_name_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['dense_19', 'dense_21', 'dense_23', 'dense_25', 'dense_27', 'dense_29', 'dense_31', 'dense_33', 'dense_35']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4w0vmrZN5SwQ"
      },
      "source": [
        "from keras import Model\n",
        "model_dict = {}\n",
        "model_output0 = class_0.get_layer(layer_name_list[0]).output\n",
        "m0 = Model(inputs=class_0.input, outputs=model_output0)\n",
        "model_dict[0] = m0\n",
        "\n",
        "model_output1 = class_1.get_layer(layer_name_list[1]).output\n",
        "m1 = Model(inputs=class_1.input, outputs=model_output1)\n",
        "model_dict[1] = m1\n",
        "\n",
        "model_output2 = class_2.get_layer(layer_name_list[2]).output\n",
        "m2 = Model(inputs=class_2.input, outputs=model_output2)\n",
        "model_dict[2] = m2\n",
        "\n",
        "model_output3 = class_3.get_layer(layer_name_list[3]).output\n",
        "m3 = Model(inputs=class_3.input, outputs=model_output3)\n",
        "model_dict[3] = m3\n",
        "\n",
        "model_output4 = class_4.get_layer(layer_name_list[4]).output\n",
        "m4 = Model(inputs=class_4.input, outputs=model_output4)\n",
        "model_dict[4] = m4\n",
        "\n",
        "model_output5 = class_5.get_layer(layer_name_list[5]).output\n",
        "m5 = Model(inputs=class_5.input, outputs=model_output5)\n",
        "model_dict[5] = m5\n",
        "\n",
        "model_output6 = class_6.get_layer(layer_name_list[6]).output\n",
        "m6 = Model(inputs=class_6.input, outputs=model_output6)\n",
        "model_dict[6] = m6\n",
        "\n",
        "model_output7 = class_7.get_layer(layer_name_list[7]).output\n",
        "m7 = Model(inputs=class_7.input, outputs=model_output7)\n",
        "model_dict[7] = m7\n",
        "\n",
        "model_output8 = class_8.get_layer(layer_name_list[8]).output\n",
        "m8 = Model(inputs=class_8.input, outputs=model_output8)\n",
        "model_dict[8] = m8\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sC-3KpW85SwR",
        "outputId": "bde4da56-41db-485a-beae-ee0717500ecf"
      },
      "source": [
        "temp_val = []\n",
        "y_pred = []\n",
        "labels = set(new_val_labels)\n",
        "for i, lo in zip(range(9), labels):\n",
        "  m = model_dict[i]\n",
        "  val_imgs_, val_lbls_ = get_train_data(lo, new_val_images, new_val_labels)\n",
        "  y_p = m.predict(val_imgs_)\n",
        "  y_pred.append(y_p)\n",
        "  temp = temp_cal(y_p, val_lbls_)\n",
        "  temp_val.append(temp)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{1: 0, 2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9665,)\n",
            "Temperature Initial value: 1.0\n",
            "Temperature Final value: 2.289517879486084\n",
            "{0: 0, 2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9518,)\n",
            "Temperature Initial value: 1.0\n",
            "Temperature Final value: 2.1803793907165527\n",
            "{0: 0, 1: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9666,)\n",
            "Temperature Initial value: 1.0\n",
            "Temperature Final value: 1.9876495599746704\n",
            "{0: 0, 1: 1, 2: 2, 4: 3, 5: 4, 6: 5, 7: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9621,)\n",
            "Temperature Initial value: 1.0\n",
            "Temperature Final value: 1.944435954093933\n",
            "{0: 0, 1: 1, 2: 2, 3: 3, 5: 4, 6: 5, 7: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9664,)\n",
            "Temperature Initial value: 1.0\n",
            "Temperature Final value: 2.4403905868530273\n",
            "{0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 6: 5, 7: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9736,)\n",
            "Temperature Initial value: 1.0\n",
            "Temperature Final value: 1.9343997240066528\n",
            "{0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 7: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9663,)\n",
            "Temperature Initial value: 1.0\n",
            "Temperature Final value: 2.242398262023926\n",
            "{0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 9: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9541,)\n",
            "Temperature Initial value: 1.0\n",
            "Temperature Final value: 2.22208833694458\n",
            "{0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9646,)\n",
            "Temperature Initial value: 1.0\n",
            "Temperature Final value: 2.220364570617676\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oCXFSt1w5SwS",
        "outputId": "e6ca4ebb-6ab8-4250-cfd9-dfef73d24a58"
      },
      "source": [
        "temp_val"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=2.2895179>,\n",
              " <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=2.1803794>,\n",
              " <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=1.9876496>,\n",
              " <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=1.944436>,\n",
              " <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=2.4403906>,\n",
              " <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=1.9343997>,\n",
              " <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=2.2423983>,\n",
              " <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=2.2220883>,\n",
              " <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=2.2203646>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-Zkv-kM5SwU",
        "outputId": "8269f96c-7c04-4488-f976-1020dec78b60"
      },
      "source": [
        "from tqdm import tqdm\n",
        "avg = [0,0,0,0,0,0,0,0,0]\n",
        "count = [0,0,0,0,0,0,0,0,0]\n",
        "entropy_list = [0,0,0,0,0,0,0,0,0]\n",
        "for img, lbl in tqdm(zip(new_val_images,new_val_labels)):\n",
        "  img = img.reshape([-1, 28, 28, 1])\n",
        "  if not lbl == 0:\n",
        "    logits = model_dict[0](img)\n",
        "    logits = tf.math.divide(logits, temp_val[0])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e0 = entropy(pred[0])\n",
        "    entropy_list[0] = entropy_list[0] + e0\n",
        "    max_val0 = np.max(pred)\n",
        "    avg[0] = avg[0] + max_val0\n",
        "    count[0] = count[0] + 1\n",
        "  if not lbl == 1:\n",
        "    logits = model_dict[1](img)\n",
        "    logits = tf.math.divide(logits, temp_val[1])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e1 = entropy(pred[0])\n",
        "    entropy_list[1] = entropy_list[1] + e1\n",
        "    max_val1 = np.max(pred)\n",
        "    avg[1] = avg[1] + max_val1\n",
        "    count[1] = count[1] + 1\n",
        "  if not lbl == 2:\n",
        "    logits = model_dict[2](img)\n",
        "    logits = tf.math.divide(logits, temp_val[2])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e2 = entropy(pred[0])\n",
        "    entropy_list[2] = entropy_list[2] + e2\n",
        "    max_val2 = np.max(pred)\n",
        "    avg[2] = avg[2] + max_val2\n",
        "    count[2] = count[2] + 1\n",
        "  if not lbl == 3:\n",
        "    logits = model_dict[3](img)\n",
        "    logits = tf.math.divide(logits, temp_val[3])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e3 = entropy(pred[0])\n",
        "    entropy_list[3] = entropy_list[3] + e3\n",
        "    max_val3 = np.max(pred)  \n",
        "    avg[3] = avg[3] + max_val3\n",
        "    count[3] = count[3] + 1\n",
        "  if not lbl == 4:\n",
        "    logits = model_dict[4](img)\n",
        "    logits = tf.math.divide(logits, temp_val[4])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e4 = entropy(pred[0])\n",
        "    entropy_list[4] = entropy_list[4] + e4\n",
        "    max_val4 = np.max(pred)\n",
        "    avg[4] = avg[4] + max_val4\n",
        "    count[4] = count[4] + 1\n",
        "  if not lbl == 5:\n",
        "    logits = model_dict[5](img)\n",
        "    logits = tf.math.divide(logits, temp_val[5])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e5 = entropy(pred[0])\n",
        "    entropy_list[5] = entropy_list[5] + e5\n",
        "    max_val5 = np.max(pred)\n",
        "    avg[5] = avg[5] + max_val5\n",
        "    count[5] = count[5] + 1\n",
        "  if not lbl == 6:\n",
        "    logits = model_dict[6](img)\n",
        "    logits = tf.math.divide(logits, temp_val[6])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e6 = entropy(pred[0])\n",
        "    entropy_list[6] = entropy_list[6] + e6\n",
        "    max_val6 = np.max(pred)\n",
        "    avg[6] = avg[6] + max_val6\n",
        "    count[6] = count[6] + 1\n",
        "  if not lbl == 7:\n",
        "    logits = model_dict[7](img)\n",
        "    logits = tf.math.divide(logits, temp_val[7])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e7 = entropy(pred[0])\n",
        "    entropy_list[7] = entropy_list[7] + e7\n",
        "    max_val7 = np.max(pred)\n",
        "    avg[7] = avg[7] + max_val7\n",
        "    count[7] = count[7] + 1\n",
        "  if not lbl == 9:\n",
        "    logits = model_dict[8](img)\n",
        "    logits = tf.math.divide(logits, temp_val[8])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e8 = entropy(pred[0])\n",
        "    entropy_list[8] = entropy_list[8] + e8\n",
        "    max_val8 = np.max(pred)\n",
        "    avg[8] = avg[8] + max_val8\n",
        "    count[8] = count[8] + 1\n",
        "\n",
        "print(avg)\n",
        "print(count)\n",
        "print(entropy_list)\n",
        "\n",
        "entropy_avg_t = [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]\n",
        "for i in range(9):\n",
        "  entropy_avg_t[i] = entropy_list[i]/count[i]\n",
        "\n",
        "entropy_value_t = 0.0\n",
        "for i in range(9):\n",
        "  entropy_value_t = entropy_value_t + entropy_avg_t[i]\n",
        "\n",
        "entropy_t = entropy_value_t/len(entropy_avg_t)\n",
        "\n",
        "print('Entropy:', entropy_t)\n",
        "\n",
        "classifier_avg_t = [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]\n",
        "for i in range(9):\n",
        "  classifier_avg_t[i] = avg[i]/count[i]\n",
        "\n",
        "print('Each Classifier Average: ',classifier_avg_t)\n",
        "\n",
        "treshold_value = 0.0\n",
        "for i in range(9):\n",
        "  treshold_value = treshold_value + classifier_avg_t[i]\n",
        "\n",
        "treshold_t = treshold_value/len(classifier_avg_t)\n",
        "\n",
        "print('Threshold:', treshold_t)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10840it [12:30, 14.45it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[9510.209820628166, 9385.876577079296, 9520.956473916769, 9422.133226245642, 9467.75987970829, 9608.657942205667, 9525.557143509388, 9388.458064109087, 9450.711543440819]\n",
            "[9665, 9518, 9666, 9621, 9664, 9736, 9663, 9541, 9646]\n",
            "[481.30395679948793, 394.72724081672425, 464.1030757331269, 630.9795363556774, 564.8434673613069, 400.83978233250735, 470.2301088136472, 439.5882373143666, 597.977337849038]\n",
            "Entropy: 0.051246196019809176\n",
            "Each Classifier Average:  [0.9839844615238661, 0.986118572922809, 0.9849944624370752, 0.979329926852265, 0.9796936961618677, 0.9869204952963915, 0.9857763782996366, 0.984011955152404, 0.9797544623098506]\n",
            "Threshold: 0.9833982678840185\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4JEmYgEK5SwV",
        "outputId": "b2deed60-9a8e-432a-ec5f-a2f1f36bba11"
      },
      "source": [
        "ref_vect_in_8an = []\n",
        "ref_vect_in_8an.append(classifier_avg_t)\n",
        "\n",
        "threshold_in_8an = []\n",
        "threshold_in_8an.append(treshold_t)\n",
        "\n",
        "entropy_in_8an = []\n",
        "entropy_in_8an.append(entropy_t)\n",
        "\n",
        "print(entropy_in_8an)\n",
        "print(ref_vect_in_8an)\n",
        "print(threshold_in_8an)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.051246196019809176]\n",
            "[[0.9839844615238661, 0.986118572922809, 0.9849944624370752, 0.979329926852265, 0.9796936961618677, 0.9869204952963915, 0.9857763782996366, 0.984011955152404, 0.9797544623098506]]\n",
            "[0.9833982678840185]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWw8M8UrWs_j"
      },
      "source": [
        "entropy_in_8an = [0.051246196019809176]\n",
        "ref_vect_in_8an = [[0.9839844615238661, 0.986118572922809, 0.9849944624370752, 0.979329926852265, 0.9796936961618677, 0.9869204952963915, 0.9857763782996366, 0.984011955152404, 0.9797544623098506]]\n",
        "threshold_in_8an = [0.9833982678840185]"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ZqKhe155SwW",
        "outputId": "02e8d05e-179b-4ca4-cc36-8de6b04f3071"
      },
      "source": [
        "from tqdm import tqdm\n",
        "avg = [0,0,0,0,0,0,0,0,0]\n",
        "count = [0,0,0,0,0,0,0,0,0]\n",
        "entropy_list = [0,0,0,0,0,0,0,0,0]\n",
        "\n",
        "for img, lbl in tqdm(zip(new_val_images,new_val_labels)):\n",
        "  img = img.reshape([-1, 28, 28, 1])\n",
        "  if lbl == 0:\n",
        "    logits = model_dict[0](img)\n",
        "    logits = tf.math.divide(logits, temp_val[0])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e0 = entropy(pred[0])\n",
        "    entropy_list[0] = entropy_list[0] + e0\n",
        "    max_val0 = np.max(pred)\n",
        "    avg[0] = avg[0] + max_val0\n",
        "    count[0] = count[0] + 1\n",
        "  if lbl == 1:\n",
        "    logits = model_dict[1](img)\n",
        "    logits = tf.math.divide(logits, temp_val[1])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e1 = entropy(pred[0])\n",
        "    entropy_list[1] = entropy_list[1] + e1\n",
        "    max_val1 = np.max(pred)\n",
        "    avg[1] = avg[1] + max_val1\n",
        "    count[1] = count[1] + 1\n",
        "  if lbl == 2:\n",
        "    logits = model_dict[2](img)\n",
        "    logits = tf.math.divide(logits, temp_val[2])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e2 = entropy(pred[0])\n",
        "    entropy_list[2] = entropy_list[2] + e2\n",
        "    max_val2 = np.max(pred)\n",
        "    avg[2] = avg[2] + max_val2\n",
        "    count[2] = count[2] + 1\n",
        "  if lbl == 3:\n",
        "    logits = model_dict[3](img)\n",
        "    logits = tf.math.divide(logits, temp_val[3])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e3 = entropy(pred[0])\n",
        "    entropy_list[3] = entropy_list[3] + e3\n",
        "    max_val3 = np.max(pred)  \n",
        "    avg[3] = avg[3] + max_val3\n",
        "    count[3] = count[3] + 1\n",
        "  if lbl == 4:\n",
        "    logits = model_dict[4](img)\n",
        "    logits = tf.math.divide(logits, temp_val[4])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e4 = entropy(pred[0])\n",
        "    entropy_list[4] = entropy_list[4] + e4\n",
        "    max_val4 = np.max(pred)\n",
        "    avg[4] = avg[4] + max_val4\n",
        "    count[4] = count[4] + 1\n",
        "  if lbl == 5:\n",
        "    logits = model_dict[5](img)\n",
        "    logits = tf.math.divide(logits, temp_val[5])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e5 = entropy(pred[0])\n",
        "    entropy_list[5] = entropy_list[5] + e5\n",
        "    max_val5 = np.max(pred)\n",
        "    avg[5] = avg[5] + max_val5\n",
        "    count[5] = count[5] + 1\n",
        "  if lbl == 6:\n",
        "    logits = model_dict[6](img)\n",
        "    logits = tf.math.divide(logits, temp_val[6])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e6 = entropy(pred[0])\n",
        "    entropy_list[6] = entropy_list[6] + e6\n",
        "    max_val6 = np.max(pred)\n",
        "    avg[6] = avg[6] + max_val6\n",
        "    count[6] = count[6] + 1\n",
        "  if lbl == 7:\n",
        "    logits = model_dict[7](img)\n",
        "    logits = tf.math.divide(logits, temp_val[7])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e7 = entropy(pred[0])\n",
        "    entropy_list[7] = entropy_list[7] + e7\n",
        "    max_val7 = np.max(pred)\n",
        "    avg[7] = avg[7] + max_val7\n",
        "    count[7] = count[7] + 1\n",
        "  if lbl == 9:\n",
        "    logits = model_dict[8](img)\n",
        "    logits = tf.math.divide(logits, temp_val[8])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e8 = entropy(pred[0])\n",
        "    entropy_list[8] = entropy_list[8] + e8\n",
        "    max_val8 = np.max(pred)\n",
        "    avg[8] = avg[8] + max_val8\n",
        "    count[8] = count[8] + 1\n",
        "\n",
        "print(avg)\n",
        "print(count)\n",
        "print(entropy_list)\n",
        "\n",
        "entropy_avg_t = [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]\n",
        "for i in range(9):\n",
        "  entropy_avg_t[i] = entropy_list[i]/count[i]\n",
        "\n",
        "entropy_value_t = 0.0\n",
        "for i in range(9):\n",
        "  entropy_value_t = entropy_value_t + entropy_avg_t[i]\n",
        "\n",
        "entropy_t = entropy_value_t/len(entropy_avg_t)\n",
        "\n",
        "print('Entropy:', entropy_t)\n",
        "\n",
        "classifier_avg_t = [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]\n",
        "for i in range(9):\n",
        "  classifier_avg_t[i] = avg[i]/count[i]\n",
        "\n",
        "print('Each Classifier Average: ',classifier_avg_t)\n",
        "\n",
        "treshold_value = 0.0\n",
        "for i in range(9):\n",
        "  treshold_value = treshold_value + classifier_avg_t[i]\n",
        "\n",
        "treshold_t = treshold_value/len(classifier_avg_t)\n",
        "\n",
        "print('Threshold:', treshold_t)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10840it [01:33, 115.56it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[988.5373156964779, 1055.8952522277832, 925.3744595348835, 993.735117405653, 1043.13758456707, 892.3960430324078, 1017.8893555998802, 993.6414393186569, 1076.8205579817295]\n",
            "[1175, 1322, 1174, 1219, 1176, 1104, 1177, 1299, 1194]\n",
            "[483.3240665173653, 854.2080204254016, 652.735131484762, 613.2850650179328, 351.530580905099, 543.6085416395326, 407.89182854065996, 781.7942911342107, 296.23225119417293]\n",
            "Entropy: 0.45604455692879053\n",
            "Each Classifier Average:  [0.8413083537842365, 0.7987104782358421, 0.7882235600808207, 0.8152051824492641, 0.8870217555842432, 0.8083297491235577, 0.8648167847067801, 0.7649279748411524, 0.9018597638037935]\n",
            "Threshold: 0.83004484473441\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xhulKukw5SwX",
        "outputId": "68131d8f-ad9e-4d87-ae3a-70cbb14f500d"
      },
      "source": [
        "ref_vect_out_8an = []\n",
        "ref_vect_out_8an.append(classifier_avg_t)\n",
        "\n",
        "threshold_out_8an = []\n",
        "threshold_out_8an.append(treshold_t)\n",
        "\n",
        "entropy_out_8an = []\n",
        "entropy_out_8an.append(entropy_t)\n",
        "\n",
        "print(entropy_out_8an)\n",
        "print(ref_vect_out_8an)\n",
        "print(threshold_out_8an)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.45604455692879053]\n",
            "[[0.8413083537842365, 0.7987104782358421, 0.7882235600808207, 0.8152051824492641, 0.8870217555842432, 0.8083297491235577, 0.8648167847067801, 0.7649279748411524, 0.9018597638037935]]\n",
            "[0.83004484473441]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "huBHw_xIW4kz"
      },
      "source": [
        "entropy_out_8an = [0.45604455692879053]\n",
        "ref_vect_out_8an = [[0.8413083537842365, 0.7987104782358421, 0.7882235600808207, 0.8152051824492641, 0.8870217555842432, 0.8083297491235577, 0.8648167847067801, 0.7649279748411524, 0.9018597638037935]]\n",
        "threshold_out_8an = [0.83004484473441]"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-EYofu_5SwY"
      },
      "source": [
        "def get_max_pred_value(model, img, temp):\n",
        "  logits = model(img)\n",
        "  logits = tf.math.divide(logits, temp)\n",
        "  pred = tf.nn.softmax(logits)\n",
        "  e = entropy(pred[0])\n",
        "\n",
        "  return np.max(pred), tf.argmax(pred[0]).numpy(), e"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGNFDWW55SwZ"
      },
      "source": [
        "def get_mapping(leave_out_class, anomaly_class):\n",
        "  mapping = {}\n",
        "\n",
        "  labels = set(train_labels)\n",
        "  labels.remove(anomaly_class)\n",
        "  labels.remove(leave_out_class)\n",
        "  labels = sorted(labels)\n",
        "\n",
        "  for i,j in enumerate(labels):\n",
        "    mapping[i] = j\n",
        "\n",
        "  return mapping\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RnUAz0Iw5Swa"
      },
      "source": [
        "ood = 0\n",
        "ind = 1"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S4Rp8uIs5Swa",
        "outputId": "afc1a3c1-daca-4a22-ffb8-9ed0ada6b999"
      },
      "source": [
        "max_sm_all_wt_8an = []\n",
        "for data, label in tqdm(zip(test_imgs, test_lbls)):\n",
        "  img = data.reshape([-1, 28, 28, 1])\n",
        "  ref_value = []\n",
        "  \n",
        "  if label == 8:\n",
        "    lbl = ood\n",
        "  else:\n",
        "    lbl = ind\n",
        "\n",
        "\n",
        "  max0, pred_0, e0 = get_max_pred_value(model_dict[0], img, temp=temp_val[0])\n",
        "  map0 = get_mapping(0, 8)\n",
        "  pred_0 = map0[pred_0]\n",
        "\n",
        "  max1, pred_1, e1 = get_max_pred_value(model_dict[1], img, temp=temp_val[1])\n",
        "  map1 = get_mapping(1, 8)\n",
        "  pred_1 = map1[pred_1]\n",
        "\n",
        "  max2, pred_2, e2 = get_max_pred_value(model_dict[2], img, temp=temp_val[2])\n",
        "  map2 = get_mapping(2, 8)\n",
        "  pred_2 = map2[pred_2]\n",
        "\n",
        "  max3, pred_3, e3 = get_max_pred_value(model_dict[3], img, temp=temp_val[3])\n",
        "  map3 = get_mapping(3, 8)\n",
        "  pred_3 = map3[pred_3]\n",
        "\n",
        "  max4, pred_4, e4 = get_max_pred_value(model_dict[4], img, temp=temp_val[4])\n",
        "  map4 = get_mapping(4, 8)\n",
        "  pred_4 = map4[pred_4]\n",
        "\n",
        "  max5, pred_5, e5 = get_max_pred_value(model_dict[5], img, temp=temp_val[5])\n",
        "  map5 = get_mapping(5, 8)\n",
        "  pred_5 = map5[pred_5]\n",
        "\n",
        "  max6, pred_6, e6 = get_max_pred_value(model_dict[6], img, temp=temp_val[6])\n",
        "  map6 = get_mapping(6, 8)\n",
        "  pred_6 = map6[pred_6]\n",
        "\n",
        "  max7, pred_7, e7 = get_max_pred_value(model_dict[7], img, temp=temp_val[7])\n",
        "  map7 = get_mapping(7, 8)\n",
        "  pred_7 = map7[pred_7]\n",
        "\n",
        "  max8, pred_8, e8 = get_max_pred_value(model_dict[8], img, temp=temp_val[8])\n",
        "  map8 = get_mapping(9, 8)\n",
        "  pred_8 = map8[pred_8]\n",
        "\n",
        "  ref_value =[max0, max1, max2, max3, max4, max5, max6, max7, max8]\n",
        "  pred_value = [pred_0, pred_1, pred_2, pred_3, pred_4, pred_5, pred_6, pred_7, pred_8]\n",
        "  e_value = [e0, e1, e2, e3, e4, e5, e6, e7, e8]\n",
        "  e_ = 0.0\n",
        "  for  e in e_value:\n",
        "    e_ = e_ + e\n",
        "  e_ = e_/len(e_value)\n",
        "  max_sm_all_wt_8an.append([ref_value, lbl, pred_value, label, e_])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000it [20:34,  8.10it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4yTBMUF5Swb"
      },
      "source": [
        "pickle_out = open(\"sm_all_wt_8an.pickle\",\"wb\")\n",
        "pickle.dump(max_sm_all_wt_8an, pickle_out)\n",
        "pickle_out.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GrLomBo25Swc"
      },
      "source": [
        "pickle_in = open(\"sm_all_wt_8an.pickle\",\"rb\")\n",
        "max_sm_all_wt_8an = pickle.load(pickle_in)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eKqByBXO5Swd",
        "outputId": "71c47e7a-044d-492b-a966-1a4108e93f75"
      },
      "source": [
        "for data, lbl, p, a_l, e_ in max_sm_all_wt_8an:\n",
        "  print(p, lbl, a_l)\n",
        "  break"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[7, 7, 7, 7, 7, 7, 7, 9, 7] 1 7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJY-VVD05Swe",
        "outputId": "40e004ef-6609-4e51-cab4-b340701d5897"
      },
      "source": [
        "accuracy = 0.0\n",
        "count_in = 0\n",
        "count_ood = 0\n",
        "acc_in = 0.0\n",
        "acc_ood = 0.0\n",
        "tp = 0.0\n",
        "tn = 0.0\n",
        "fp = 0.0\n",
        "fn = 0.0\n",
        "y_true = []\n",
        "y_pred = []\n",
        "sim_score = []\n",
        "sim_score_ = []\n",
        "\n",
        "for data, lbl, p, a_l, e_ in max_sm_all_wt_8an:\n",
        "\n",
        "  score = 0.0\n",
        "  for d in data:\n",
        "    score = score + d\n",
        "  score = score / len(data)\n",
        "  sim_score.append(score)\n",
        "\n",
        "  dist_ood = np.linalg.norm(np.array(data) - np.array(ref_vect_out_8an[0])) \n",
        "  dist_in = np.linalg.norm(np.array(data) - np.array(ref_vect_in_8an[0]))\n",
        "\n",
        "  dist_ood2 = np.linalg.norm(np.array(e_) - np.array(entropy_out_8an[0])) \n",
        "  dist_in2 = np.linalg.norm(np.array(e_) - np.array(entropy_in_8an[0]))\n",
        "\n",
        "  dist_in = dist_in / (dist_in + dist_ood)\n",
        "  dist_ood = dist_ood / (dist_in + dist_ood)\n",
        "\n",
        "  dist_in2 = dist_in2 / (dist_in2 + dist_ood2)\n",
        "  dist_ood2 = dist_ood2 / (dist_in2 + dist_ood2)\n",
        "\n",
        "  sim_in = 1 / (1 + dist_in)\n",
        "  sim_ood = 1 / (1 + dist_ood)\n",
        "\n",
        "  sim_in2 = 1 / (1 + dist_in2)\n",
        "  sim_ood2 = 1 / (1 + dist_ood2)\n",
        "\n",
        "  sim_in = sim_in + sim_in2\n",
        "#  sim_ood = sim_ood + sim_ood2\n",
        "\n",
        "  sim_score_.append(sim_ood)\n",
        "\n",
        "  values, counts = np.unique(p, return_counts=True)\n",
        "#  print(values, counts)\n",
        "  #print(sim_in, sim_ood, lbl, e_)\n",
        "\n",
        "\n",
        "  if sim_in >= sim_ood:\n",
        "    y_ = ind\n",
        "    if np.max(counts) >= 8:\n",
        "      y_ = ind\n",
        "    else:\n",
        "      y_ = ood\n",
        "  else:\n",
        "    y_ = ood\n",
        "\n",
        "\n",
        "  y_pred.append(y_)\n",
        "  if lbl == 1:\n",
        "    y_true.append(0)\n",
        "  else:\n",
        "    y_true.append(1)\n",
        "#  y_true.append(lbl)\n",
        "\n",
        "\n",
        "  if lbl == ind:\n",
        "    count_in = count_in + 1\n",
        "  else:\n",
        "    count_ood = count_ood + 1\n",
        "\n",
        "  if y_ == lbl:\n",
        "    #sim_score_.append(1)\n",
        "    accuracy = accuracy + 1\n",
        "    if y_ == ind:\n",
        "      acc_in = acc_in + 1\n",
        "      tp = tp + 1\n",
        "    else:\n",
        "      acc_ood = acc_ood + 1\n",
        "      tn = tn + 1\n",
        "  else:\n",
        "    #sim_score_.append(0)\n",
        "    if y_ == ind:\n",
        "      fp = fp + 1\n",
        "    else:\n",
        "      fn = fn + 1\n",
        "\n",
        "\n",
        "print(\"Total Accuracy: \", accuracy/len(max_sm_all_wt_8an)) \n",
        "print(\"Accuracy of determining ID data: \", acc_in/count_in)\n",
        "print(\"Accuracy of determining OOD data: \", acc_ood/count_ood)\n"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Accuracy:  0.9338\n",
            "Accuracy of determining ID data:  0.934190117438511\n",
            "Accuracy of determining OOD data:  0.9301848049281314\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O292ritC5Swf",
        "outputId": "bcc30f36-a4b6-4517-9efc-91bbfd699b1a"
      },
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "roc_auc_score(y_true, sim_score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9692839212842115"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nfLz2VA95Swg",
        "outputId": "961ce629-33ef-48a2-d171-f1cf741198bb"
      },
      "source": [
        "roc_auc_score(y_true, y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9351349125569709"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qPARWxzR5Swh",
        "outputId": "0431bb69-2e93-4cac-815c-985ffd935c79"
      },
      "source": [
        "roc_auc_score(y_true, sim_score_)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9124137615676545"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AsS25B1s2fe9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d22XwKBi3qeM"
      },
      "source": [
        "# 9 as anomaly"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rL_uQvU3sGk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjcR1Qg_3sdx"
      },
      "source": [
        "new_train_images, new_train_labels, new_val_images, new_val_labels = separate_class(9, train_images, train_labels, val_images, val_labels)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJeJyg0i3sdy"
      },
      "source": [
        "model0 = Model(name='9anomaly:classifier0')\n",
        "model1 = Model(name='9anomaly:classifier1')\n",
        "model2 = Model(name='9anomaly:classifier2')\n",
        "model3 = Model(name='9anomaly:classifier3')\n",
        "model4 = Model(name='9anomaly:classifier4')\n",
        "model5 = Model(name='9anomaly:classifier5')\n",
        "model6 = Model(name='9anomaly:classifier6')\n",
        "model7 = Model(name='9anomaly:classifier7')\n",
        "model8 = Model(name='9anomaly:classifier8')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ipfhxmzO3sdy"
      },
      "source": [
        "class_0 = model0.build()\n",
        "class_1 = model1.build()\n",
        "class_2 = model2.build()\n",
        "class_3 = model3.build()\n",
        "class_4 = model4.build()\n",
        "class_5 = model5.build()\n",
        "class_6 = model6.build()\n",
        "class_7 = model7.build()\n",
        "class_8 = model8.build()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QWFrIxlQ3sdy",
        "outputId": "3f893eb7-8f0b-49c1-ce01-aa3aa549492e"
      },
      "source": [
        "train_imgs0, train_lbls0 = get_train_data(0, new_train_images, new_train_labels)\n",
        "val_imgs0, val_lbls0 = get_train_data(0, new_val_images, new_val_labels)\n",
        "class_0 = model0.build()\n",
        "model0.train2(train_imgs0, train_lbls0, val_imgs0, val_lbls0)\n",
        "#model0.train(train_data0)\n",
        "model0.save_model(\"final_models/9anomaly-classifier0\")\n",
        "print('Model 0 saved')\n",
        "\n",
        "train_imgs1, train_lbls1 = get_train_data(1, new_train_images, new_train_labels)\n",
        "val_imgs1, val_lbls1 = get_train_data(1, new_val_images, new_val_labels)\n",
        "class_1 = model1.build()\n",
        "model1.train2(train_imgs1, train_lbls1, val_imgs1, val_lbls1)\n",
        "#model1.train(train_data1)\n",
        "model1.save_model(\"final_models/9anomaly-classifier1\")\n",
        "print('Model 1 saved')\n",
        "\n",
        "#train_data2 = get_train_data(2, new_train_images)\n",
        "train_imgs2, train_lbls2 = get_train_data(2, new_train_images, new_train_labels)\n",
        "val_imgs2, val_lbls2 = get_train_data(2, new_val_images, new_val_labels)\n",
        "class_2 = model2.build()\n",
        "model2.train2(train_imgs2, train_lbls2, val_imgs2, val_lbls2)\n",
        "#model2.train(train_data2)\n",
        "model2.save_model(\"final_models/9anomaly-classifier2\")\n",
        "print('Model 2 saved')\n",
        "\n",
        "#train_data3 = get_train_data(3, new_train_images)\n",
        "train_imgs3, train_lbls3 = get_train_data(3, new_train_images, new_train_labels)\n",
        "val_imgs3, val_lbls3 = get_train_data(3, new_val_images, new_val_labels)\n",
        "class_3 = model3.build()\n",
        "model3.train2(train_imgs3, train_lbls3, val_imgs3, val_lbls3)\n",
        "#model3.train(train_data3)\n",
        "model3.save_model(\"final_models/9anomaly-classifier3\")\n",
        "print('Model 3 saved')\n",
        "\n",
        "#train_data4 = get_train_data(4, new_train_images)\n",
        "train_imgs4, train_lbls4 = get_train_data(4, new_train_images, new_train_labels)\n",
        "val_imgs4, val_lbls4 = get_train_data(4, new_val_images, new_val_labels)\n",
        "class_4 = model4.build()\n",
        "model4.train2(train_imgs4, train_lbls4, val_imgs4, val_lbls4)\n",
        "#model4.train(train_data4)\n",
        "model4.save_model(\"final_models/9anomaly-classifier4\")\n",
        "print('Model 4 saved')\n",
        "\n",
        "#train_data5 = get_train_data(5, new_train_images)\n",
        "train_imgs5, train_lbls5 = get_train_data(5, new_train_images, new_train_labels)\n",
        "val_imgs5, val_lbls5 = get_train_data(5, new_val_images, new_val_labels)\n",
        "class_5 = model5.build()\n",
        "model5.train2(train_imgs5, train_lbls5, val_imgs5, val_lbls5)\n",
        "#model5.train(train_data5)\n",
        "model5.save_model(\"final_models/9anomaly-classifier5\")\n",
        "print('Model 5 saved')\n",
        "\n",
        "#train_data6 = get_train_data(6, new_train_images)\n",
        "train_imgs6, train_lbls6 = get_train_data(6, new_train_images, new_train_labels)\n",
        "val_imgs6, val_lbls6 = get_train_data(6, new_val_images, new_val_labels)\n",
        "class_6 = model6.build()\n",
        "model6.train2(train_imgs6, train_lbls6, val_imgs6, val_lbls6)\n",
        "#model6.train(train_data6)\n",
        "model6.save_model(\"final_models/9anomaly-classifier6\")\n",
        "print('Model 6 saved')\n",
        "\n",
        "#train_data7 = get_train_data(7, new_train_images)\n",
        "train_imgs7, train_lbls7 = get_train_data(7, new_train_images, new_train_labels)\n",
        "val_imgs7, val_lbls7 = get_train_data(7, new_val_images, new_val_labels)\n",
        "class_7 = model7.build()\n",
        "#model7.train(train_data7)\n",
        "model7.train2(train_imgs7, train_lbls7, val_imgs7, val_lbls7)\n",
        "model7.save_model(\"final_models/9anomaly-classifier7\")\n",
        "print('Model 7 saved')\n",
        "\n",
        "#train_data8 = get_train_data(8, new_train_images)\n",
        "train_imgs8, train_lbls8 = get_train_data(8, new_train_images, new_train_labels)\n",
        "val_imgs8, val_lbls8 = get_train_data(8, new_val_images, new_val_labels)\n",
        "class_8 = model8.build()\n",
        "#model8.train(train_data8)\n",
        "model8.train2(train_imgs8, train_lbls8, val_imgs8, val_lbls8)\n",
        "model8.save_model(\"final_models/9anomaly-classifier8\")\n",
        "print('Model 8 saved')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{1: 0, 2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, 8: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(38497,)\n",
            "{1: 0, 2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, 8: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9631,)\n",
            "Epoch 1/20\n",
            "1204/1204 [==============================] - 40s 32ms/step - loss: 4.8472 - accuracy: 0.8528 - val_loss: 0.2174 - val_accuracy: 0.9646\n",
            "Epoch 2/20\n",
            "1204/1204 [==============================] - 39s 32ms/step - loss: 0.1497 - accuracy: 0.9721 - val_loss: 0.2839 - val_accuracy: 0.9133\n",
            "Epoch 3/20\n",
            "1204/1204 [==============================] - 38s 32ms/step - loss: 0.0644 - accuracy: 0.9818 - val_loss: 0.1244 - val_accuracy: 0.9639\n",
            "Epoch 4/20\n",
            "1204/1204 [==============================] - 39s 32ms/step - loss: 0.0487 - accuracy: 0.9864 - val_loss: 0.1694 - val_accuracy: 0.9537\n",
            "Epoch 5/20\n",
            "1204/1204 [==============================] - 38s 32ms/step - loss: 0.0549 - accuracy: 0.9837 - val_loss: 0.1745 - val_accuracy: 0.9572\n",
            "Epoch 6/20\n",
            "1204/1204 [==============================] - 39s 32ms/step - loss: 0.0489 - accuracy: 0.9853 - val_loss: 0.2178 - val_accuracy: 0.9482\n",
            "Epoch 7/20\n",
            "1204/1204 [==============================] - 39s 32ms/step - loss: 0.0727 - accuracy: 0.9786 - val_loss: 0.0963 - val_accuracy: 0.9747\n",
            "Epoch 8/20\n",
            "1204/1204 [==============================] - 39s 32ms/step - loss: 0.0377 - accuracy: 0.9889 - val_loss: 0.1701 - val_accuracy: 0.9518\n",
            "Epoch 9/20\n",
            "1204/1204 [==============================] - 39s 32ms/step - loss: 0.0694 - accuracy: 0.9825 - val_loss: 0.0607 - val_accuracy: 0.9829\n",
            "Epoch 10/20\n",
            "1204/1204 [==============================] - 39s 32ms/step - loss: 0.0272 - accuracy: 0.9912 - val_loss: 0.1210 - val_accuracy: 0.9711\n",
            "Epoch 11/20\n",
            "1204/1204 [==============================] - 39s 32ms/step - loss: 0.0326 - accuracy: 0.9897 - val_loss: 0.1473 - val_accuracy: 0.9697\n",
            "Epoch 12/20\n",
            "1204/1204 [==============================] - 39s 32ms/step - loss: 0.0246 - accuracy: 0.9920 - val_loss: 0.1305 - val_accuracy: 0.9696\n",
            "Epoch 13/20\n",
            "1204/1204 [==============================] - 39s 32ms/step - loss: 0.0276 - accuracy: 0.9923 - val_loss: 0.0801 - val_accuracy: 0.9823\n",
            "Epoch 14/20\n",
            "1204/1204 [==============================] - 39s 32ms/step - loss: 0.0243 - accuracy: 0.9922 - val_loss: 0.0612 - val_accuracy: 0.9854\n",
            "Epoch 15/20\n",
            "1204/1204 [==============================] - 38s 32ms/step - loss: 0.0171 - accuracy: 0.9943 - val_loss: 0.0852 - val_accuracy: 0.9833\n",
            "Epoch 16/20\n",
            "1204/1204 [==============================] - 38s 32ms/step - loss: 0.0190 - accuracy: 0.9943 - val_loss: 0.0767 - val_accuracy: 0.9836\n",
            "Epoch 17/20\n",
            "1204/1204 [==============================] - 39s 32ms/step - loss: 0.0161 - accuracy: 0.9952 - val_loss: 0.0796 - val_accuracy: 0.9843\n",
            "Epoch 18/20\n",
            "1204/1204 [==============================] - 39s 32ms/step - loss: 0.0127 - accuracy: 0.9957 - val_loss: 0.0627 - val_accuracy: 0.9868\n",
            "Epoch 19/20\n",
            "1204/1204 [==============================] - 39s 32ms/step - loss: 0.0146 - accuracy: 0.9953 - val_loss: 0.0734 - val_accuracy: 0.9858\n",
            "Epoch 20/20\n",
            "1204/1204 [==============================] - 38s 32ms/step - loss: 0.0181 - accuracy: 0.9942 - val_loss: 0.0917 - val_accuracy: 0.9841\n",
            "INFO:tensorflow:Assets written to: final_models/9anomaly-classifier0/assets\n",
            "Model 0 saved\n",
            "{0: 0, 2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, 8: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(37825,)\n",
            "{0: 0, 2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, 8: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9484,)\n",
            "Epoch 1/20\n",
            "1183/1183 [==============================] - 39s 32ms/step - loss: 4.4381 - accuracy: 0.8192 - val_loss: 0.9444 - val_accuracy: 0.8444\n",
            "Epoch 2/20\n",
            "1183/1183 [==============================] - 38s 32ms/step - loss: 0.4713 - accuracy: 0.9370 - val_loss: 0.1897 - val_accuracy: 0.9521\n",
            "Epoch 3/20\n",
            "1183/1183 [==============================] - 38s 32ms/step - loss: 0.0665 - accuracy: 0.9809 - val_loss: 0.1210 - val_accuracy: 0.9726\n",
            "Epoch 4/20\n",
            "1183/1183 [==============================] - 38s 32ms/step - loss: 0.0651 - accuracy: 0.9810 - val_loss: 0.0720 - val_accuracy: 0.9821\n",
            "Epoch 5/20\n",
            "1183/1183 [==============================] - 38s 32ms/step - loss: 0.0546 - accuracy: 0.9845 - val_loss: 0.0581 - val_accuracy: 0.9831\n",
            "Epoch 6/20\n",
            "1183/1183 [==============================] - 38s 32ms/step - loss: 0.0458 - accuracy: 0.9866 - val_loss: 0.2826 - val_accuracy: 0.9488\n",
            "Epoch 7/20\n",
            "1183/1183 [==============================] - 38s 32ms/step - loss: 0.0541 - accuracy: 0.9832 - val_loss: 0.0782 - val_accuracy: 0.9798\n",
            "Epoch 8/20\n",
            "1183/1183 [==============================] - 38s 32ms/step - loss: 0.0453 - accuracy: 0.9862 - val_loss: 0.1537 - val_accuracy: 0.9653\n",
            "Epoch 9/20\n",
            "1183/1183 [==============================] - 38s 32ms/step - loss: 0.0426 - accuracy: 0.9862 - val_loss: 0.2719 - val_accuracy: 0.9413\n",
            "Epoch 10/20\n",
            "1183/1183 [==============================] - 38s 32ms/step - loss: 0.0349 - accuracy: 0.9890 - val_loss: 0.0653 - val_accuracy: 0.9830\n",
            "Epoch 11/20\n",
            "1183/1183 [==============================] - 38s 32ms/step - loss: 0.0304 - accuracy: 0.9902 - val_loss: 0.1134 - val_accuracy: 0.9756\n",
            "Epoch 12/20\n",
            "1183/1183 [==============================] - 38s 32ms/step - loss: 0.0277 - accuracy: 0.9905 - val_loss: 0.0747 - val_accuracy: 0.9821\n",
            "Epoch 13/20\n",
            "1183/1183 [==============================] - 38s 32ms/step - loss: 0.0263 - accuracy: 0.9919 - val_loss: 0.1837 - val_accuracy: 0.9640\n",
            "Epoch 14/20\n",
            "1183/1183 [==============================] - 38s 32ms/step - loss: 0.0213 - accuracy: 0.9932 - val_loss: 0.0559 - val_accuracy: 0.9878\n",
            "Epoch 15/20\n",
            "1183/1183 [==============================] - 38s 32ms/step - loss: 0.0190 - accuracy: 0.9943 - val_loss: 0.1212 - val_accuracy: 0.9752\n",
            "Epoch 16/20\n",
            "1183/1183 [==============================] - 38s 32ms/step - loss: 0.0193 - accuracy: 0.9938 - val_loss: 0.0633 - val_accuracy: 0.9875\n",
            "Epoch 17/20\n",
            "1183/1183 [==============================] - 38s 32ms/step - loss: 0.0194 - accuracy: 0.9935 - val_loss: 0.1080 - val_accuracy: 0.9806\n",
            "Epoch 18/20\n",
            "1183/1183 [==============================] - 38s 32ms/step - loss: 0.0148 - accuracy: 0.9951 - val_loss: 0.0791 - val_accuracy: 0.9823\n",
            "Epoch 19/20\n",
            "1183/1183 [==============================] - 38s 32ms/step - loss: 0.0149 - accuracy: 0.9953 - val_loss: 0.0707 - val_accuracy: 0.9862\n",
            "Epoch 20/20\n",
            "1183/1183 [==============================] - 38s 32ms/step - loss: 0.0161 - accuracy: 0.9949 - val_loss: 0.0927 - val_accuracy: 0.9825\n",
            "INFO:tensorflow:Assets written to: final_models/9anomaly-classifier1/assets\n",
            "Model 1 saved\n",
            "{0: 0, 1: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, 8: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(38461,)\n",
            "{0: 0, 1: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, 8: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9632,)\n",
            "Epoch 1/20\n",
            "1202/1202 [==============================] - 40s 32ms/step - loss: 4.7921 - accuracy: 0.8528 - val_loss: 0.2447 - val_accuracy: 0.9553\n",
            "Epoch 2/20\n",
            "1202/1202 [==============================] - 39s 32ms/step - loss: 0.1412 - accuracy: 0.9742 - val_loss: 0.0992 - val_accuracy: 0.9750\n",
            "Epoch 3/20\n",
            "1202/1202 [==============================] - 39s 32ms/step - loss: 0.0556 - accuracy: 0.9831 - val_loss: 0.1341 - val_accuracy: 0.9680\n",
            "Epoch 4/20\n",
            "1202/1202 [==============================] - 39s 32ms/step - loss: 0.0510 - accuracy: 0.9849 - val_loss: 0.0925 - val_accuracy: 0.9737\n",
            "Epoch 5/20\n",
            "1202/1202 [==============================] - 39s 32ms/step - loss: 0.0513 - accuracy: 0.9841 - val_loss: 0.1116 - val_accuracy: 0.9728\n",
            "Epoch 6/20\n",
            "1202/1202 [==============================] - 39s 32ms/step - loss: 0.0475 - accuracy: 0.9866 - val_loss: 0.0978 - val_accuracy: 0.9753\n",
            "Epoch 7/20\n",
            "1202/1202 [==============================] - 39s 32ms/step - loss: 0.0472 - accuracy: 0.9857 - val_loss: 0.1007 - val_accuracy: 0.9775\n",
            "Epoch 8/20\n",
            "1202/1202 [==============================] - 39s 32ms/step - loss: 0.0352 - accuracy: 0.9898 - val_loss: 0.0814 - val_accuracy: 0.9819\n",
            "Epoch 9/20\n",
            "1202/1202 [==============================] - 39s 32ms/step - loss: 0.0326 - accuracy: 0.9903 - val_loss: 0.0601 - val_accuracy: 0.9842\n",
            "Epoch 10/20\n",
            "1202/1202 [==============================] - 39s 32ms/step - loss: 0.0260 - accuracy: 0.9913 - val_loss: 0.0904 - val_accuracy: 0.9818\n",
            "Epoch 11/20\n",
            "1202/1202 [==============================] - 39s 32ms/step - loss: 0.0267 - accuracy: 0.9910 - val_loss: 0.0573 - val_accuracy: 0.9846\n",
            "Epoch 12/20\n",
            "1202/1202 [==============================] - 39s 32ms/step - loss: 0.0246 - accuracy: 0.9927 - val_loss: 0.0575 - val_accuracy: 0.9871\n",
            "Epoch 13/20\n",
            "1202/1202 [==============================] - 38s 32ms/step - loss: 0.0208 - accuracy: 0.9936 - val_loss: 0.0527 - val_accuracy: 0.9871\n",
            "Epoch 14/20\n",
            "1202/1202 [==============================] - 39s 32ms/step - loss: 0.0174 - accuracy: 0.9941 - val_loss: 0.0447 - val_accuracy: 0.9899\n",
            "Epoch 15/20\n",
            "1202/1202 [==============================] - 39s 32ms/step - loss: 0.0174 - accuracy: 0.9944 - val_loss: 0.0629 - val_accuracy: 0.9868\n",
            "Epoch 16/20\n",
            "1202/1202 [==============================] - 39s 32ms/step - loss: 0.0197 - accuracy: 0.9933 - val_loss: 0.0719 - val_accuracy: 0.9875\n",
            "Epoch 17/20\n",
            "1202/1202 [==============================] - 38s 32ms/step - loss: 0.0156 - accuracy: 0.9949 - val_loss: 0.1325 - val_accuracy: 0.9767\n",
            "Epoch 18/20\n",
            "1202/1202 [==============================] - 39s 32ms/step - loss: 0.0173 - accuracy: 0.9953 - val_loss: 0.0567 - val_accuracy: 0.9894\n",
            "Epoch 19/20\n",
            "1202/1202 [==============================] - 39s 32ms/step - loss: 0.0118 - accuracy: 0.9962 - val_loss: 0.0551 - val_accuracy: 0.9908\n",
            "Epoch 20/20\n",
            "1202/1202 [==============================] - 39s 32ms/step - loss: 0.0144 - accuracy: 0.9954 - val_loss: 0.0876 - val_accuracy: 0.9832\n",
            "INFO:tensorflow:Assets written to: final_models/9anomaly-classifier2/assets\n",
            "Model 2 saved\n",
            "{0: 0, 1: 1, 2: 2, 4: 3, 5: 4, 6: 5, 7: 6, 8: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(38333,)\n",
            "{0: 0, 1: 1, 2: 2, 4: 3, 5: 4, 6: 5, 7: 6, 8: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9587,)\n",
            "Epoch 1/20\n",
            "1198/1198 [==============================] - 40s 32ms/step - loss: 4.7537 - accuracy: 0.8455 - val_loss: 0.1936 - val_accuracy: 0.9708\n",
            "Epoch 2/20\n",
            "1198/1198 [==============================] - 38s 32ms/step - loss: 0.1095 - accuracy: 0.9777 - val_loss: 0.1339 - val_accuracy: 0.9674\n",
            "Epoch 3/20\n",
            "1198/1198 [==============================] - 38s 32ms/step - loss: 0.0568 - accuracy: 0.9841 - val_loss: 0.1092 - val_accuracy: 0.9731\n",
            "Epoch 4/20\n",
            "1198/1198 [==============================] - 38s 32ms/step - loss: 0.0552 - accuracy: 0.9842 - val_loss: 0.0915 - val_accuracy: 0.9774\n",
            "Epoch 5/20\n",
            "1198/1198 [==============================] - 39s 32ms/step - loss: 0.0528 - accuracy: 0.9855 - val_loss: 0.1258 - val_accuracy: 0.9725\n",
            "Epoch 6/20\n",
            "1198/1198 [==============================] - 39s 32ms/step - loss: 0.0536 - accuracy: 0.9841 - val_loss: 0.0761 - val_accuracy: 0.9804\n",
            "Epoch 7/20\n",
            "1198/1198 [==============================] - 38s 32ms/step - loss: 0.0466 - accuracy: 0.9867 - val_loss: 0.1244 - val_accuracy: 0.9698\n",
            "Epoch 8/20\n",
            "1198/1198 [==============================] - 38s 32ms/step - loss: 0.0381 - accuracy: 0.9878 - val_loss: 0.0897 - val_accuracy: 0.9786\n",
            "Epoch 9/20\n",
            "1198/1198 [==============================] - 38s 32ms/step - loss: 0.0374 - accuracy: 0.9887 - val_loss: 0.0666 - val_accuracy: 0.9829\n",
            "Epoch 10/20\n",
            "1198/1198 [==============================] - 38s 32ms/step - loss: 0.0307 - accuracy: 0.9910 - val_loss: 0.0754 - val_accuracy: 0.9815\n",
            "Epoch 11/20\n",
            "1198/1198 [==============================] - 38s 32ms/step - loss: 0.0296 - accuracy: 0.9911 - val_loss: 0.0671 - val_accuracy: 0.9852\n",
            "Epoch 12/20\n",
            "1198/1198 [==============================] - 38s 32ms/step - loss: 0.0248 - accuracy: 0.9923 - val_loss: 0.0581 - val_accuracy: 0.9847\n",
            "Epoch 13/20\n",
            "1198/1198 [==============================] - 38s 32ms/step - loss: 0.0222 - accuracy: 0.9928 - val_loss: 0.0726 - val_accuracy: 0.9836\n",
            "Epoch 14/20\n",
            "1198/1198 [==============================] - 38s 32ms/step - loss: 0.0207 - accuracy: 0.9935 - val_loss: 0.0889 - val_accuracy: 0.9838\n",
            "Epoch 15/20\n",
            "1198/1198 [==============================] - 38s 32ms/step - loss: 0.0222 - accuracy: 0.9927 - val_loss: 0.0595 - val_accuracy: 0.9862\n",
            "Epoch 16/20\n",
            "1198/1198 [==============================] - 38s 32ms/step - loss: 0.0191 - accuracy: 0.9938 - val_loss: 0.0694 - val_accuracy: 0.9838\n",
            "Epoch 17/20\n",
            "1198/1198 [==============================] - 38s 32ms/step - loss: 0.0148 - accuracy: 0.9955 - val_loss: 0.0609 - val_accuracy: 0.9866\n",
            "Epoch 18/20\n",
            "1198/1198 [==============================] - 38s 32ms/step - loss: 0.0153 - accuracy: 0.9950 - val_loss: 0.0777 - val_accuracy: 0.9848\n",
            "Epoch 19/20\n",
            "1198/1198 [==============================] - 38s 32ms/step - loss: 0.0180 - accuracy: 0.9945 - val_loss: 0.0613 - val_accuracy: 0.9877\n",
            "Epoch 20/20\n",
            "1198/1198 [==============================] - 38s 32ms/step - loss: 0.0110 - accuracy: 0.9966 - val_loss: 0.0460 - val_accuracy: 0.9899\n",
            "INFO:tensorflow:Assets written to: final_models/9anomaly-classifier3/assets\n",
            "Model 3 saved\n",
            "{0: 0, 1: 1, 2: 2, 3: 3, 5: 4, 6: 5, 7: 6, 8: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(38579,)\n",
            "{0: 0, 1: 1, 2: 2, 3: 3, 5: 4, 6: 5, 7: 6, 8: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9630,)\n",
            "Epoch 1/20\n",
            "1206/1206 [==============================] - 40s 32ms/step - loss: 5.9507 - accuracy: 0.8054 - val_loss: 0.4207 - val_accuracy: 0.9586\n",
            "Epoch 2/20\n",
            "1206/1206 [==============================] - 39s 32ms/step - loss: 0.1681 - accuracy: 0.9745 - val_loss: 0.0878 - val_accuracy: 0.9755\n",
            "Epoch 3/20\n",
            "1206/1206 [==============================] - 39s 32ms/step - loss: 0.0586 - accuracy: 0.9842 - val_loss: 0.0831 - val_accuracy: 0.9765\n",
            "Epoch 4/20\n",
            "1206/1206 [==============================] - 39s 32ms/step - loss: 0.0549 - accuracy: 0.9835 - val_loss: 0.1300 - val_accuracy: 0.9694\n",
            "Epoch 5/20\n",
            "1206/1206 [==============================] - 39s 32ms/step - loss: 0.0508 - accuracy: 0.9855 - val_loss: 0.0964 - val_accuracy: 0.9764\n",
            "Epoch 6/20\n",
            "1206/1206 [==============================] - 39s 32ms/step - loss: 0.0526 - accuracy: 0.9839 - val_loss: 0.1416 - val_accuracy: 0.9685\n",
            "Epoch 7/20\n",
            "1206/1206 [==============================] - 39s 32ms/step - loss: 0.0416 - accuracy: 0.9878 - val_loss: 0.1109 - val_accuracy: 0.9747\n",
            "Epoch 8/20\n",
            "1206/1206 [==============================] - 39s 32ms/step - loss: 0.0473 - accuracy: 0.9850 - val_loss: 0.2656 - val_accuracy: 0.9472\n",
            "Epoch 9/20\n",
            "1206/1206 [==============================] - 39s 32ms/step - loss: 0.0412 - accuracy: 0.9874 - val_loss: 0.1472 - val_accuracy: 0.9677\n",
            "Epoch 10/20\n",
            "1206/1206 [==============================] - 39s 32ms/step - loss: 0.0356 - accuracy: 0.9884 - val_loss: 0.3370 - val_accuracy: 0.9364\n",
            "Epoch 11/20\n",
            "1206/1206 [==============================] - 39s 32ms/step - loss: 0.0258 - accuracy: 0.9919 - val_loss: 0.1152 - val_accuracy: 0.9752\n",
            "Epoch 12/20\n",
            "1206/1206 [==============================] - 39s 32ms/step - loss: 0.0291 - accuracy: 0.9908 - val_loss: 0.1016 - val_accuracy: 0.9788\n",
            "Epoch 13/20\n",
            "1206/1206 [==============================] - 39s 32ms/step - loss: 0.0263 - accuracy: 0.9916 - val_loss: 0.0708 - val_accuracy: 0.9814\n",
            "Epoch 14/20\n",
            "1206/1206 [==============================] - 39s 32ms/step - loss: 0.0249 - accuracy: 0.9927 - val_loss: 0.0843 - val_accuracy: 0.9801\n",
            "Epoch 15/20\n",
            "1206/1206 [==============================] - 39s 32ms/step - loss: 0.0195 - accuracy: 0.9932 - val_loss: 0.1375 - val_accuracy: 0.9735\n",
            "Epoch 16/20\n",
            "1206/1206 [==============================] - 39s 32ms/step - loss: 0.0182 - accuracy: 0.9943 - val_loss: 0.1607 - val_accuracy: 0.9673\n",
            "Epoch 17/20\n",
            "1206/1206 [==============================] - 39s 32ms/step - loss: 0.0183 - accuracy: 0.9944 - val_loss: 0.0971 - val_accuracy: 0.9793\n",
            "Epoch 18/20\n",
            "1206/1206 [==============================] - 39s 32ms/step - loss: 0.0190 - accuracy: 0.9942 - val_loss: 0.1080 - val_accuracy: 0.9729\n",
            "Epoch 19/20\n",
            "1206/1206 [==============================] - 39s 32ms/step - loss: 0.0189 - accuracy: 0.9940 - val_loss: 0.1700 - val_accuracy: 0.9736\n",
            "Epoch 20/20\n",
            "1206/1206 [==============================] - 39s 32ms/step - loss: 0.0165 - accuracy: 0.9951 - val_loss: 0.1002 - val_accuracy: 0.9794\n",
            "INFO:tensorflow:Assets written to: final_models/9anomaly-classifier4/assets\n",
            "Model 4 saved\n",
            "{0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 6: 5, 7: 6, 8: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(38928,)\n",
            "{0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 6: 5, 7: 6, 8: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9702,)\n",
            "Epoch 1/20\n",
            "1217/1217 [==============================] - 40s 32ms/step - loss: 4.7542 - accuracy: 0.8375 - val_loss: 0.2112 - val_accuracy: 0.9616\n",
            "Epoch 2/20\n",
            "1217/1217 [==============================] - 39s 32ms/step - loss: 0.1262 - accuracy: 0.9732 - val_loss: 0.1374 - val_accuracy: 0.9753\n",
            "Epoch 3/20\n",
            "1217/1217 [==============================] - 39s 32ms/step - loss: 0.0820 - accuracy: 0.9794 - val_loss: 0.1527 - val_accuracy: 0.9643\n",
            "Epoch 4/20\n",
            "1217/1217 [==============================] - 39s 32ms/step - loss: 0.0714 - accuracy: 0.9811 - val_loss: 0.1414 - val_accuracy: 0.9636\n",
            "Epoch 5/20\n",
            "1217/1217 [==============================] - 39s 32ms/step - loss: 0.0531 - accuracy: 0.9842 - val_loss: 0.0986 - val_accuracy: 0.9733\n",
            "Epoch 6/20\n",
            "1217/1217 [==============================] - 39s 32ms/step - loss: 0.0497 - accuracy: 0.9849 - val_loss: 0.1130 - val_accuracy: 0.9728\n",
            "Epoch 7/20\n",
            "1217/1217 [==============================] - 39s 32ms/step - loss: 0.0435 - accuracy: 0.9871 - val_loss: 0.1053 - val_accuracy: 0.9729\n",
            "Epoch 8/20\n",
            "1217/1217 [==============================] - 39s 32ms/step - loss: 0.0402 - accuracy: 0.9889 - val_loss: 0.0672 - val_accuracy: 0.9806\n",
            "Epoch 9/20\n",
            "1217/1217 [==============================] - 39s 32ms/step - loss: 0.0331 - accuracy: 0.9902 - val_loss: 0.0521 - val_accuracy: 0.9856\n",
            "Epoch 10/20\n",
            "1217/1217 [==============================] - 39s 32ms/step - loss: 0.0344 - accuracy: 0.9892 - val_loss: 0.0621 - val_accuracy: 0.9846\n",
            "Epoch 11/20\n",
            "1217/1217 [==============================] - 39s 32ms/step - loss: 0.0303 - accuracy: 0.9900 - val_loss: 0.2071 - val_accuracy: 0.9452\n",
            "Epoch 12/20\n",
            "1217/1217 [==============================] - 39s 32ms/step - loss: 0.0258 - accuracy: 0.9920 - val_loss: 0.0567 - val_accuracy: 0.9856\n",
            "Epoch 13/20\n",
            "1217/1217 [==============================] - 39s 32ms/step - loss: 0.0228 - accuracy: 0.9929 - val_loss: 0.0657 - val_accuracy: 0.9839\n",
            "Epoch 14/20\n",
            "1217/1217 [==============================] - 39s 32ms/step - loss: 0.0207 - accuracy: 0.9941 - val_loss: 0.0827 - val_accuracy: 0.9794\n",
            "Epoch 15/20\n",
            "1217/1217 [==============================] - 39s 32ms/step - loss: 0.0223 - accuracy: 0.9932 - val_loss: 0.0501 - val_accuracy: 0.9886\n",
            "Epoch 16/20\n",
            "1217/1217 [==============================] - 39s 32ms/step - loss: 0.0190 - accuracy: 0.9938 - val_loss: 0.0768 - val_accuracy: 0.9840\n",
            "Epoch 17/20\n",
            "1217/1217 [==============================] - 39s 32ms/step - loss: 0.0172 - accuracy: 0.9944 - val_loss: 0.0891 - val_accuracy: 0.9825\n",
            "Epoch 18/20\n",
            "1217/1217 [==============================] - 39s 32ms/step - loss: 0.0176 - accuracy: 0.9945 - val_loss: 0.0825 - val_accuracy: 0.9832\n",
            "Epoch 19/20\n",
            "1217/1217 [==============================] - 39s 32ms/step - loss: 0.0140 - accuracy: 0.9955 - val_loss: 0.1132 - val_accuracy: 0.9817\n",
            "Epoch 20/20\n",
            "1217/1217 [==============================] - 39s 32ms/step - loss: 0.0197 - accuracy: 0.9941 - val_loss: 0.0517 - val_accuracy: 0.9904\n",
            "INFO:tensorflow:Assets written to: final_models/9anomaly-classifier5/assets\n",
            "Model 5 saved\n",
            "{0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 7: 6, 8: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(38504,)\n",
            "{0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 7: 6, 8: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9629,)\n",
            "Epoch 1/20\n",
            "1204/1204 [==============================] - 40s 32ms/step - loss: 5.0530 - accuracy: 0.8358 - val_loss: 0.3719 - val_accuracy: 0.9567\n",
            "Epoch 2/20\n",
            "1204/1204 [==============================] - 39s 32ms/step - loss: 0.1394 - accuracy: 0.9755 - val_loss: 0.1260 - val_accuracy: 0.9710\n",
            "Epoch 3/20\n",
            "1204/1204 [==============================] - 39s 32ms/step - loss: 0.0602 - accuracy: 0.9835 - val_loss: 0.0915 - val_accuracy: 0.9751\n",
            "Epoch 4/20\n",
            "1204/1204 [==============================] - 39s 32ms/step - loss: 0.0525 - accuracy: 0.9837 - val_loss: 0.0549 - val_accuracy: 0.9850\n",
            "Epoch 5/20\n",
            "1204/1204 [==============================] - 39s 32ms/step - loss: 0.0519 - accuracy: 0.9851 - val_loss: 0.2129 - val_accuracy: 0.9487\n",
            "Epoch 6/20\n",
            "1204/1204 [==============================] - 39s 32ms/step - loss: 0.0503 - accuracy: 0.9851 - val_loss: 0.2321 - val_accuracy: 0.9575\n",
            "Epoch 7/20\n",
            "1204/1204 [==============================] - 39s 32ms/step - loss: 0.0447 - accuracy: 0.9867 - val_loss: 0.1410 - val_accuracy: 0.9675\n",
            "Epoch 8/20\n",
            "1204/1204 [==============================] - 39s 32ms/step - loss: 0.0386 - accuracy: 0.9877 - val_loss: 0.1077 - val_accuracy: 0.9768\n",
            "Epoch 9/20\n",
            "1204/1204 [==============================] - 39s 32ms/step - loss: 0.0333 - accuracy: 0.9898 - val_loss: 0.2031 - val_accuracy: 0.9581\n",
            "Epoch 10/20\n",
            "1204/1204 [==============================] - 39s 32ms/step - loss: 0.0289 - accuracy: 0.9914 - val_loss: 0.1102 - val_accuracy: 0.9739\n",
            "Epoch 11/20\n",
            "1204/1204 [==============================] - 39s 32ms/step - loss: 0.0277 - accuracy: 0.9921 - val_loss: 0.0764 - val_accuracy: 0.9838\n",
            "Epoch 12/20\n",
            "1204/1204 [==============================] - 39s 32ms/step - loss: 0.0211 - accuracy: 0.9938 - val_loss: 0.1050 - val_accuracy: 0.9790\n",
            "Epoch 13/20\n",
            "1204/1204 [==============================] - 39s 32ms/step - loss: 0.0278 - accuracy: 0.9915 - val_loss: 0.0551 - val_accuracy: 0.9884\n",
            "Epoch 14/20\n",
            "1204/1204 [==============================] - 39s 32ms/step - loss: 0.0266 - accuracy: 0.9917 - val_loss: 0.0854 - val_accuracy: 0.9793\n",
            "Epoch 15/20\n",
            "1204/1204 [==============================] - 39s 32ms/step - loss: 0.0245 - accuracy: 0.9932 - val_loss: 0.1346 - val_accuracy: 0.9747\n",
            "Epoch 16/20\n",
            "1204/1204 [==============================] - 39s 32ms/step - loss: 0.0166 - accuracy: 0.9948 - val_loss: 0.0859 - val_accuracy: 0.9838\n",
            "Epoch 17/20\n",
            "1204/1204 [==============================] - 39s 32ms/step - loss: 0.0172 - accuracy: 0.9949 - val_loss: 0.2428 - val_accuracy: 0.9468\n",
            "Epoch 18/20\n",
            "1204/1204 [==============================] - 39s 32ms/step - loss: 0.0133 - accuracy: 0.9954 - val_loss: 0.0747 - val_accuracy: 0.9870\n",
            "Epoch 19/20\n",
            "1204/1204 [==============================] - 39s 32ms/step - loss: 0.0157 - accuracy: 0.9952 - val_loss: 0.1339 - val_accuracy: 0.9778\n",
            "Epoch 20/20\n",
            "1204/1204 [==============================] - 39s 32ms/step - loss: 0.0150 - accuracy: 0.9950 - val_loss: 0.1111 - val_accuracy: 0.9797\n",
            "INFO:tensorflow:Assets written to: final_models/9anomaly-classifier6/assets\n",
            "Model 6 saved\n",
            "{0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 8: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(38279,)\n",
            "{0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 8: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9507,)\n",
            "Epoch 1/20\n",
            "1197/1197 [==============================] - 40s 32ms/step - loss: 5.1061 - accuracy: 0.8429 - val_loss: 0.2165 - val_accuracy: 0.9619\n",
            "Epoch 2/20\n",
            "1197/1197 [==============================] - 38s 32ms/step - loss: 0.1077 - accuracy: 0.9788 - val_loss: 0.0964 - val_accuracy: 0.9763\n",
            "Epoch 3/20\n",
            "1197/1197 [==============================] - 38s 32ms/step - loss: 0.0580 - accuracy: 0.9850 - val_loss: 0.2189 - val_accuracy: 0.9546\n",
            "Epoch 4/20\n",
            "1197/1197 [==============================] - 38s 32ms/step - loss: 0.0494 - accuracy: 0.9857 - val_loss: 0.0628 - val_accuracy: 0.9820\n",
            "Epoch 5/20\n",
            "1197/1197 [==============================] - 39s 32ms/step - loss: 0.0473 - accuracy: 0.9866 - val_loss: 0.1169 - val_accuracy: 0.9735\n",
            "Epoch 6/20\n",
            "1197/1197 [==============================] - 39s 32ms/step - loss: 0.0489 - accuracy: 0.9862 - val_loss: 0.1941 - val_accuracy: 0.9585\n",
            "Epoch 7/20\n",
            "1197/1197 [==============================] - 38s 32ms/step - loss: 0.0373 - accuracy: 0.9892 - val_loss: 0.1347 - val_accuracy: 0.9727\n",
            "Epoch 8/20\n",
            "1197/1197 [==============================] - 38s 32ms/step - loss: 0.0366 - accuracy: 0.9896 - val_loss: 0.0994 - val_accuracy: 0.9766\n",
            "Epoch 9/20\n",
            "1197/1197 [==============================] - 38s 32ms/step - loss: 0.0325 - accuracy: 0.9898 - val_loss: 0.1687 - val_accuracy: 0.9605\n",
            "Epoch 10/20\n",
            "1197/1197 [==============================] - 38s 32ms/step - loss: 0.0309 - accuracy: 0.9900 - val_loss: 0.0611 - val_accuracy: 0.9862\n",
            "Epoch 11/20\n",
            "1197/1197 [==============================] - 38s 32ms/step - loss: 0.0293 - accuracy: 0.9908 - val_loss: 0.0782 - val_accuracy: 0.9844\n",
            "Epoch 12/20\n",
            "1197/1197 [==============================] - 38s 32ms/step - loss: 0.0245 - accuracy: 0.9927 - val_loss: 0.1057 - val_accuracy: 0.9792\n",
            "Epoch 13/20\n",
            "1197/1197 [==============================] - 38s 32ms/step - loss: 0.0211 - accuracy: 0.9935 - val_loss: 0.0784 - val_accuracy: 0.9819\n",
            "Epoch 14/20\n",
            "1197/1197 [==============================] - 38s 32ms/step - loss: 0.0218 - accuracy: 0.9928 - val_loss: 0.0744 - val_accuracy: 0.9847\n",
            "Epoch 15/20\n",
            "1197/1197 [==============================] - 38s 32ms/step - loss: 0.0202 - accuracy: 0.9939 - val_loss: 0.0561 - val_accuracy: 0.9872\n",
            "Epoch 16/20\n",
            "1197/1197 [==============================] - 38s 32ms/step - loss: 0.0186 - accuracy: 0.9940 - val_loss: 0.0478 - val_accuracy: 0.9887\n",
            "Epoch 17/20\n",
            "1197/1197 [==============================] - 38s 32ms/step - loss: 0.0150 - accuracy: 0.9955 - val_loss: 0.0781 - val_accuracy: 0.9838\n",
            "Epoch 18/20\n",
            "1197/1197 [==============================] - 38s 32ms/step - loss: 0.0166 - accuracy: 0.9946 - val_loss: 0.0969 - val_accuracy: 0.9822\n",
            "Epoch 19/20\n",
            "1197/1197 [==============================] - 39s 32ms/step - loss: 0.0208 - accuracy: 0.9943 - val_loss: 0.0679 - val_accuracy: 0.9884\n",
            "Epoch 20/20\n",
            "1197/1197 [==============================] - 38s 32ms/step - loss: 0.0084 - accuracy: 0.9975 - val_loss: 0.0634 - val_accuracy: 0.9894\n",
            "INFO:tensorflow:Assets written to: final_models/9anomaly-classifier7/assets\n",
            "Model 7 saved\n",
            "{0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(38554,)\n",
            "{0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9646,)\n",
            "Epoch 1/20\n",
            "1205/1205 [==============================] - 40s 32ms/step - loss: 5.5605 - accuracy: 0.8353 - val_loss: 0.1323 - val_accuracy: 0.9697\n",
            "Epoch 2/20\n",
            "1205/1205 [==============================] - 39s 32ms/step - loss: 0.1445 - accuracy: 0.9728 - val_loss: 0.1887 - val_accuracy: 0.9693\n",
            "Epoch 3/20\n",
            "1205/1205 [==============================] - 39s 32ms/step - loss: 0.0970 - accuracy: 0.9779 - val_loss: 0.3017 - val_accuracy: 0.9563\n",
            "Epoch 4/20\n",
            "1205/1205 [==============================] - 39s 32ms/step - loss: 0.0757 - accuracy: 0.9817 - val_loss: 0.1154 - val_accuracy: 0.9769\n",
            "Epoch 5/20\n",
            "1205/1205 [==============================] - 39s 32ms/step - loss: 0.0576 - accuracy: 0.9837 - val_loss: 0.0843 - val_accuracy: 0.9795\n",
            "Epoch 6/20\n",
            "1205/1205 [==============================] - 39s 32ms/step - loss: 0.0543 - accuracy: 0.9847 - val_loss: 0.5559 - val_accuracy: 0.9322\n",
            "Epoch 7/20\n",
            "1205/1205 [==============================] - 39s 32ms/step - loss: 0.0390 - accuracy: 0.9875 - val_loss: 0.1144 - val_accuracy: 0.9751\n",
            "Epoch 8/20\n",
            "1205/1205 [==============================] - 39s 32ms/step - loss: 0.0414 - accuracy: 0.9872 - val_loss: 0.0570 - val_accuracy: 0.9844\n",
            "Epoch 9/20\n",
            "1205/1205 [==============================] - 39s 32ms/step - loss: 0.0344 - accuracy: 0.9891 - val_loss: 0.0640 - val_accuracy: 0.9856\n",
            "Epoch 10/20\n",
            "1205/1205 [==============================] - 39s 32ms/step - loss: 0.0327 - accuracy: 0.9895 - val_loss: 0.0727 - val_accuracy: 0.9841\n",
            "Epoch 11/20\n",
            "1205/1205 [==============================] - 39s 32ms/step - loss: 0.0347 - accuracy: 0.9892 - val_loss: 0.0509 - val_accuracy: 0.9872\n",
            "Epoch 12/20\n",
            "1205/1205 [==============================] - 39s 32ms/step - loss: 0.0243 - accuracy: 0.9929 - val_loss: 0.0784 - val_accuracy: 0.9824\n",
            "Epoch 13/20\n",
            "1205/1205 [==============================] - 39s 32ms/step - loss: 0.0261 - accuracy: 0.9918 - val_loss: 0.0448 - val_accuracy: 0.9887\n",
            "Epoch 14/20\n",
            "1205/1205 [==============================] - 39s 32ms/step - loss: 0.0206 - accuracy: 0.9939 - val_loss: 0.1471 - val_accuracy: 0.9724\n",
            "Epoch 15/20\n",
            "1205/1205 [==============================] - 39s 32ms/step - loss: 0.0217 - accuracy: 0.9937 - val_loss: 0.0451 - val_accuracy: 0.9889\n",
            "Epoch 16/20\n",
            "1205/1205 [==============================] - 39s 32ms/step - loss: 0.0176 - accuracy: 0.9943 - val_loss: 0.0665 - val_accuracy: 0.9839\n",
            "Epoch 17/20\n",
            "1205/1205 [==============================] - 39s 32ms/step - loss: 0.0152 - accuracy: 0.9950 - val_loss: 0.0760 - val_accuracy: 0.9860\n",
            "Epoch 18/20\n",
            "1205/1205 [==============================] - 39s 32ms/step - loss: 0.0138 - accuracy: 0.9956 - val_loss: 0.0581 - val_accuracy: 0.9879\n",
            "Epoch 19/20\n",
            "1205/1205 [==============================] - 39s 32ms/step - loss: 0.0140 - accuracy: 0.9955 - val_loss: 0.0795 - val_accuracy: 0.9852\n",
            "Epoch 20/20\n",
            "1205/1205 [==============================] - 39s 32ms/step - loss: 0.0176 - accuracy: 0.9948 - val_loss: 0.0556 - val_accuracy: 0.9879\n",
            "INFO:tensorflow:Assets written to: final_models/9anomaly-classifier8/assets\n",
            "Model 8 saved\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ZcjNVrj3sdz"
      },
      "source": [
        "class_0 = model0.load_model(\"final_models/9anomaly-classifier0\")\n",
        "class_1 = model1.load_model(\"final_models/9anomaly-classifier1\")\n",
        "class_2 = model2.load_model(\"final_models/9anomaly-classifier2\")\n",
        "class_3 = model3.load_model(\"final_models/9anomaly-classifier3\")\n",
        "class_4 = model4.load_model(\"final_models/9anomaly-classifier4\")\n",
        "class_5 = model5.load_model(\"final_models/9anomaly-classifier5\")\n",
        "class_6 = model6.load_model(\"final_models/9anomaly-classifier6\")\n",
        "class_7 = model7.load_model(\"final_models/9anomaly-classifier7\")\n",
        "class_8 = model8.load_model(\"final_models/9anomaly-classifier8\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CKprNfEo3sd0",
        "outputId": "623b903b-53e9-43b8-f686-9c080341654f"
      },
      "source": [
        "layer_name_list = []\n",
        "\n",
        "layer_name_list.append(class_0.layers[-2:][0].name)\n",
        "layer_name_list.append(class_1.layers[-2:][0].name)\n",
        "layer_name_list.append(class_2.layers[-2:][0].name)\n",
        "layer_name_list.append(class_3.layers[-2:][0].name)\n",
        "layer_name_list.append(class_4.layers[-2:][0].name)\n",
        "layer_name_list.append(class_5.layers[-2:][0].name)\n",
        "layer_name_list.append(class_6.layers[-2:][0].name)\n",
        "layer_name_list.append(class_7.layers[-2:][0].name)\n",
        "layer_name_list.append(class_8.layers[-2:][0].name)\n",
        "\n",
        "print(layer_name_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['dense_37', 'dense_39', 'dense_41', 'dense_43', 'dense_45', 'dense_47', 'dense_49', 'dense_51', 'dense_53']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjZO8LN_3sd0"
      },
      "source": [
        "from keras import Model\n",
        "model_dict = {}\n",
        "model_output0 = class_0.get_layer(layer_name_list[0]).output\n",
        "m0 = Model(inputs=class_0.input, outputs=model_output0)\n",
        "model_dict[0] = m0\n",
        "\n",
        "model_output1 = class_1.get_layer(layer_name_list[1]).output\n",
        "m1 = Model(inputs=class_1.input, outputs=model_output1)\n",
        "model_dict[1] = m1\n",
        "\n",
        "model_output2 = class_2.get_layer(layer_name_list[2]).output\n",
        "m2 = Model(inputs=class_2.input, outputs=model_output2)\n",
        "model_dict[2] = m2\n",
        "\n",
        "model_output3 = class_3.get_layer(layer_name_list[3]).output\n",
        "m3 = Model(inputs=class_3.input, outputs=model_output3)\n",
        "model_dict[3] = m3\n",
        "\n",
        "model_output4 = class_4.get_layer(layer_name_list[4]).output\n",
        "m4 = Model(inputs=class_4.input, outputs=model_output4)\n",
        "model_dict[4] = m4\n",
        "\n",
        "model_output5 = class_5.get_layer(layer_name_list[5]).output\n",
        "m5 = Model(inputs=class_5.input, outputs=model_output5)\n",
        "model_dict[5] = m5\n",
        "\n",
        "model_output6 = class_6.get_layer(layer_name_list[6]).output\n",
        "m6 = Model(inputs=class_6.input, outputs=model_output6)\n",
        "model_dict[6] = m6\n",
        "\n",
        "model_output7 = class_7.get_layer(layer_name_list[7]).output\n",
        "m7 = Model(inputs=class_7.input, outputs=model_output7)\n",
        "model_dict[7] = m7\n",
        "\n",
        "model_output8 = class_8.get_layer(layer_name_list[8]).output\n",
        "m8 = Model(inputs=class_8.input, outputs=model_output8)\n",
        "model_dict[8] = m8\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bAqFElQD3sd0",
        "outputId": "26ff344d-36c4-46ff-b4f4-17bf0eda3ff3"
      },
      "source": [
        "temp_val = []\n",
        "y_pred = []\n",
        "labels = set(new_val_labels)\n",
        "for i, lo in zip(range(9), labels):\n",
        "  m = model_dict[i]\n",
        "  val_imgs_, val_lbls_ = get_train_data(lo, new_val_images, new_val_labels)\n",
        "  y_p = m.predict(val_imgs_)\n",
        "  y_pred.append(y_p)\n",
        "  temp = temp_cal(y_p, val_lbls_)\n",
        "  temp_val.append(temp)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{1: 0, 2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, 8: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9631,)\n",
            "Temperature Initial value: 1.0\n",
            "Temperature Final value: 2.398526191711426\n",
            "{0: 0, 2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, 8: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9484,)\n",
            "Temperature Initial value: 1.0\n",
            "Temperature Final value: 2.31925106048584\n",
            "{0: 0, 1: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, 8: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9632,)\n",
            "Temperature Initial value: 1.0\n",
            "Temperature Final value: 2.21435546875\n",
            "{0: 0, 1: 1, 2: 2, 4: 3, 5: 4, 6: 5, 7: 6, 8: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9587,)\n",
            "Temperature Initial value: 1.0\n",
            "Temperature Final value: 1.9258661270141602\n",
            "{0: 0, 1: 1, 2: 2, 3: 3, 5: 4, 6: 5, 7: 6, 8: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9630,)\n",
            "Temperature Initial value: 1.0\n",
            "Temperature Final value: 2.2611944675445557\n",
            "{0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 6: 5, 7: 6, 8: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9702,)\n",
            "Temperature Initial value: 1.0\n",
            "Temperature Final value: 2.222395420074463\n",
            "{0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 7: 6, 8: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9629,)\n",
            "Temperature Initial value: 1.0\n",
            "Temperature Final value: 2.358395576477051\n",
            "{0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 8: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9507,)\n",
            "Temperature Initial value: 1.0\n",
            "Temperature Final value: 2.299323558807373\n",
            "{0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7}\n",
            "(9646,)\n",
            "Temperature Initial value: 1.0\n",
            "Temperature Final value: 2.07049822807312\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BvGLS0a53sd1",
        "outputId": "0e82529e-cb5b-4f77-be76-ff1ee8747b2f"
      },
      "source": [
        "temp_val"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=2.3985262>,\n",
              " <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=2.319251>,\n",
              " <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=2.2143555>,\n",
              " <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=1.9258661>,\n",
              " <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=2.2611945>,\n",
              " <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=2.2223954>,\n",
              " <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=2.3583956>,\n",
              " <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=2.2993236>,\n",
              " <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=2.0704982>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-CTHTPo3sd1",
        "outputId": "df9c6eb7-5c30-4f77-923a-e58e4ff73812"
      },
      "source": [
        "from tqdm import tqdm\n",
        "avg = [0,0,0,0,0,0,0,0,0]\n",
        "count = [0,0,0,0,0,0,0,0,0]\n",
        "entropy_list = [0,0,0,0,0,0,0,0,0]\n",
        "for img, lbl in tqdm(zip(new_val_images,new_val_labels)):\n",
        "  img = img.reshape([-1, 28, 28, 1])\n",
        "  if not lbl == 0:\n",
        "    logits = model_dict[0](img)\n",
        "    logits = tf.math.divide(logits, temp_val[0])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e0 = entropy(pred[0])\n",
        "    entropy_list[0] = entropy_list[0] + e0\n",
        "    max_val0 = np.max(pred)\n",
        "    avg[0] = avg[0] + max_val0\n",
        "    count[0] = count[0] + 1\n",
        "  if not lbl == 1:\n",
        "    logits = model_dict[1](img)\n",
        "    logits = tf.math.divide(logits, temp_val[1])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e1 = entropy(pred[0])\n",
        "    entropy_list[1] = entropy_list[1] + e1\n",
        "    max_val1 = np.max(pred)\n",
        "    avg[1] = avg[1] + max_val1\n",
        "    count[1] = count[1] + 1\n",
        "  if not lbl == 2:\n",
        "    logits = model_dict[2](img)\n",
        "    logits = tf.math.divide(logits, temp_val[2])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e2 = entropy(pred[0])\n",
        "    entropy_list[2] = entropy_list[2] + e2\n",
        "    max_val2 = np.max(pred)\n",
        "    avg[2] = avg[2] + max_val2\n",
        "    count[2] = count[2] + 1\n",
        "  if not lbl == 3:\n",
        "    logits = model_dict[3](img)\n",
        "    logits = tf.math.divide(logits, temp_val[3])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e3 = entropy(pred[0])\n",
        "    entropy_list[3] = entropy_list[3] + e3\n",
        "    max_val3 = np.max(pred)  \n",
        "    avg[3] = avg[3] + max_val3\n",
        "    count[3] = count[3] + 1\n",
        "  if not lbl == 4:\n",
        "    logits = model_dict[4](img)\n",
        "    logits = tf.math.divide(logits, temp_val[4])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e4 = entropy(pred[0])\n",
        "    entropy_list[4] = entropy_list[4] + e4\n",
        "    max_val4 = np.max(pred)\n",
        "    avg[4] = avg[4] + max_val4\n",
        "    count[4] = count[4] + 1\n",
        "  if not lbl == 5:\n",
        "    logits = model_dict[5](img)\n",
        "    logits = tf.math.divide(logits, temp_val[5])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e5 = entropy(pred[0])\n",
        "    entropy_list[5] = entropy_list[5] + e5\n",
        "    max_val5 = np.max(pred)\n",
        "    avg[5] = avg[5] + max_val5\n",
        "    count[5] = count[5] + 1\n",
        "  if not lbl == 6:\n",
        "    logits = model_dict[6](img)\n",
        "    logits = tf.math.divide(logits, temp_val[6])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e6 = entropy(pred[0])\n",
        "    entropy_list[6] = entropy_list[6] + e6\n",
        "    max_val6 = np.max(pred)\n",
        "    avg[6] = avg[6] + max_val6\n",
        "    count[6] = count[6] + 1\n",
        "  if not lbl == 7:\n",
        "    logits = model_dict[7](img)\n",
        "    logits = tf.math.divide(logits, temp_val[7])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e7 = entropy(pred[0])\n",
        "    entropy_list[7] = entropy_list[7] + e7\n",
        "    max_val7 = np.max(pred)\n",
        "    avg[7] = avg[7] + max_val7\n",
        "    count[7] = count[7] + 1\n",
        "  if not lbl == 8:\n",
        "    logits = model_dict[8](img)\n",
        "    logits = tf.math.divide(logits, temp_val[8])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e8 = entropy(pred[0])\n",
        "    entropy_list[8] = entropy_list[8] + e8\n",
        "    max_val8 = np.max(pred)\n",
        "    avg[8] = avg[8] + max_val8\n",
        "    count[8] = count[8] + 1\n",
        "\n",
        "print(avg)\n",
        "print(count)\n",
        "print(entropy_list)\n",
        "\n",
        "entropy_avg_t = [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]\n",
        "for i in range(9):\n",
        "  entropy_avg_t[i] = entropy_list[i]/count[i]\n",
        "\n",
        "entropy_value_t = 0.0\n",
        "for i in range(9):\n",
        "  entropy_value_t = entropy_value_t + entropy_avg_t[i]\n",
        "\n",
        "entropy_t = entropy_value_t/len(entropy_avg_t)\n",
        "\n",
        "print('Entropy:', entropy_t)\n",
        "\n",
        "classifier_avg_t = [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]\n",
        "for i in range(9):\n",
        "  classifier_avg_t[i] = avg[i]/count[i]\n",
        "\n",
        "print('Each Classifier Average: ',classifier_avg_t)\n",
        "\n",
        "treshold_value = 0.0\n",
        "for i in range(9):\n",
        "  treshold_value = treshold_value + classifier_avg_t[i]\n",
        "\n",
        "treshold_t = treshold_value/len(classifier_avg_t)\n",
        "\n",
        "print('Threshold:', treshold_t)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10806it [12:16, 14.67it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[9495.856197595596, 9330.759849369526, 9472.157935276628, 9489.994508206844, 9441.329641819, 9609.918594390154, 9452.439297020435, 9403.818867236376, 9527.683840841055]\n",
            "[9631, 9484, 9632, 9587, 9630, 9702, 9629, 9507, 9646]\n",
            "[414.3286874832835, 468.35928304922413, 509.49605015605584, 318.3835482986842, 564.8503037065246, 298.0027289714437, 540.6929349365489, 329.0205501542547, 365.18769117814077]\n",
            "Entropy: 0.04405569144510324\n",
            "Each Classifier Average:  [0.9859678327894918, 0.9838422447669259, 0.9834051012538026, 0.9898815592163184, 0.9804080624941849, 0.9905090284879565, 0.9816636511600826, 0.9891468252063086, 0.9877341738379696]\n",
            "Threshold: 0.9858398310236711\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nBaeuHx_3sd1",
        "outputId": "d4df3fcb-f371-40a1-b11e-8d9a1d9d875b"
      },
      "source": [
        "ref_vect_in_9an = []\n",
        "ref_vect_in_9an.append(classifier_avg_t)\n",
        "\n",
        "threshold_in_9an = []\n",
        "threshold_in_9an.append(treshold_t)\n",
        "\n",
        "entropy_in_9an = []\n",
        "entropy_in_9an.append(entropy_t)\n",
        "\n",
        "print(entropy_in_9an)\n",
        "print(ref_vect_in_9an)\n",
        "print(threshold_in_9an)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.04405569144510324]\n",
            "[[0.9859678327894918, 0.9838422447669259, 0.9834051012538026, 0.9898815592163184, 0.9804080624941849, 0.9905090284879565, 0.9816636511600826, 0.9891468252063086, 0.9877341738379696]]\n",
            "[0.9858398310236711]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9YLuDY6X5J9"
      },
      "source": [
        "entropy_in_9an = [0.04405569144510324]\n",
        "ref_vect_in_9an = [[0.9859678327894918, 0.9838422447669259, 0.9834051012538026, 0.9898815592163184, 0.9804080624941849, 0.9905090284879565, 0.9816636511600826, 0.9891468252063086, 0.9877341738379696]]\n",
        "threshold_in_9an = [0.9858398310236711]"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_jftPo6C3sd2",
        "outputId": "a31e88c1-7285-42a9-827b-a81bdb471af8"
      },
      "source": [
        "from tqdm import tqdm\n",
        "avg = [0,0,0,0,0,0,0,0,0]\n",
        "count = [0,0,0,0,0,0,0,0,0]\n",
        "entropy_list = [0,0,0,0,0,0,0,0,0]\n",
        "\n",
        "for img, lbl in tqdm(zip(new_val_images,new_val_labels)):\n",
        "  img = img.reshape([-1, 28, 28, 1])\n",
        "  if lbl == 0:\n",
        "    logits = model_dict[0](img)\n",
        "    logits = tf.math.divide(logits, temp_val[0])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e0 = entropy(pred[0])\n",
        "    entropy_list[0] = entropy_list[0] + e0\n",
        "    max_val0 = np.max(pred)\n",
        "    avg[0] = avg[0] + max_val0\n",
        "    count[0] = count[0] + 1\n",
        "  if lbl == 1:\n",
        "    logits = model_dict[1](img)\n",
        "    logits = tf.math.divide(logits, temp_val[1])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e1 = entropy(pred[0])\n",
        "    entropy_list[1] = entropy_list[1] + e1\n",
        "    max_val1 = np.max(pred)\n",
        "    avg[1] = avg[1] + max_val1\n",
        "    count[1] = count[1] + 1\n",
        "  if lbl == 2:\n",
        "    logits = model_dict[2](img)\n",
        "    logits = tf.math.divide(logits, temp_val[2])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e2 = entropy(pred[0])\n",
        "    entropy_list[2] = entropy_list[2] + e2\n",
        "    max_val2 = np.max(pred)\n",
        "    avg[2] = avg[2] + max_val2\n",
        "    count[2] = count[2] + 1\n",
        "  if lbl == 3:\n",
        "    logits = model_dict[3](img)\n",
        "    logits = tf.math.divide(logits, temp_val[3])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e3 = entropy(pred[0])\n",
        "    entropy_list[3] = entropy_list[3] + e3\n",
        "    max_val3 = np.max(pred)  \n",
        "    avg[3] = avg[3] + max_val3\n",
        "    count[3] = count[3] + 1\n",
        "  if lbl == 4:\n",
        "    logits = model_dict[4](img)\n",
        "    logits = tf.math.divide(logits, temp_val[4])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e4 = entropy(pred[0])\n",
        "    entropy_list[4] = entropy_list[4] + e4\n",
        "    max_val4 = np.max(pred)\n",
        "    avg[4] = avg[4] + max_val4\n",
        "    count[4] = count[4] + 1\n",
        "  if lbl == 5:\n",
        "    logits = model_dict[5](img)\n",
        "    logits = tf.math.divide(logits, temp_val[5])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e5 = entropy(pred[0])\n",
        "    entropy_list[5] = entropy_list[5] + e5\n",
        "    max_val5 = np.max(pred)\n",
        "    avg[5] = avg[5] + max_val5\n",
        "    count[5] = count[5] + 1\n",
        "  if lbl == 6:\n",
        "    logits = model_dict[6](img)\n",
        "    logits = tf.math.divide(logits, temp_val[6])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e6 = entropy(pred[0])\n",
        "    entropy_list[6] = entropy_list[6] + e6\n",
        "    max_val6 = np.max(pred)\n",
        "    avg[6] = avg[6] + max_val6\n",
        "    count[6] = count[6] + 1\n",
        "  if lbl == 7:\n",
        "    logits = model_dict[7](img)\n",
        "    logits = tf.math.divide(logits, temp_val[7])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e7 = entropy(pred[0])\n",
        "    entropy_list[7] = entropy_list[7] + e7\n",
        "    max_val7 = np.max(pred)\n",
        "    avg[7] = avg[7] + max_val7\n",
        "    count[7] = count[7] + 1\n",
        "  if lbl == 8:\n",
        "    logits = model_dict[8](img)\n",
        "    logits = tf.math.divide(logits, temp_val[8])\n",
        "    pred = tf.nn.softmax(logits)\n",
        "    e8 = entropy(pred[0])\n",
        "    entropy_list[8] = entropy_list[8] + e8\n",
        "    max_val8 = np.max(pred)\n",
        "    avg[8] = avg[8] + max_val8\n",
        "    count[8] = count[8] + 1\n",
        "\n",
        "print(avg)\n",
        "print(count)\n",
        "print(entropy_list)\n",
        "\n",
        "entropy_avg_t = [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]\n",
        "for i in range(9):\n",
        "  entropy_avg_t[i] = entropy_list[i]/count[i]\n",
        "\n",
        "entropy_value_t = 0.0\n",
        "for i in range(9):\n",
        "  entropy_value_t = entropy_value_t + entropy_avg_t[i]\n",
        "\n",
        "entropy_t = entropy_value_t/len(entropy_avg_t)\n",
        "\n",
        "print('Entropy:', entropy_t)\n",
        "\n",
        "classifier_avg_t = [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]\n",
        "for i in range(9):\n",
        "  classifier_avg_t[i] = avg[i]/count[i]\n",
        "\n",
        "print('Each Classifier Average: ',classifier_avg_t)\n",
        "\n",
        "treshold_value = 0.0\n",
        "for i in range(9):\n",
        "  treshold_value = treshold_value + classifier_avg_t[i]\n",
        "\n",
        "treshold_t = treshold_value/len(classifier_avg_t)\n",
        "\n",
        "print('Threshold:', treshold_t)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10806it [01:32, 117.01it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[953.0528710186481, 707.4310759902, 915.7182317972183, 1054.7954660952091, 889.6830076575279, 905.4954099357128, 943.0036944448948, 967.1280114203691, 867.1922775655985]\n",
            "[1175, 1322, 1174, 1219, 1176, 1104, 1177, 1299, 1160]\n",
            "[568.9805146824801, 1590.943137747934, 676.4559725443905, 408.4250742853842, 723.1622181375569, 510.1251802155093, 608.5655140470835, 877.3564862636849, 777.0138058165458]\n",
            "Entropy: 0.615358066135967\n",
            "Each Classifier Average:  [0.8111088263988495, 0.5351218426552194, 0.7799984938647515, 0.8652957063947573, 0.7565331697768095, 0.820195117695392, 0.8011926036065377, 0.7445173298078285, 0.747579549625516]\n",
            "Threshold: 0.7623936266472957\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oiTuD4753sd2",
        "outputId": "efd42e69-153c-4762-92a1-7518a171c0e6"
      },
      "source": [
        "ref_vect_out_9an = []\n",
        "ref_vect_out_9an.append(classifier_avg_t)\n",
        "\n",
        "threshold_out_9an = []\n",
        "threshold_out_9an.append(treshold_t)\n",
        "\n",
        "entropy_out_9an = []\n",
        "entropy_out_9an.append(entropy_t)\n",
        "\n",
        "print(entropy_out_9an)\n",
        "print(ref_vect_out_9an)\n",
        "print(threshold_out_9an)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.615358066135967]\n",
            "[[0.8111088263988495, 0.5351218426552194, 0.7799984938647515, 0.8652957063947573, 0.7565331697768095, 0.820195117695392, 0.8011926036065377, 0.7445173298078285, 0.747579549625516]]\n",
            "[0.7623936266472957]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cASop2EnYD0i"
      },
      "source": [
        "entropy_out_9an = [0.615358066135967]\n",
        "ref_vect_out_9an = [[0.8111088263988495, 0.5351218426552194, 0.7799984938647515, 0.8652957063947573, 0.7565331697768095, 0.820195117695392, 0.8011926036065377, 0.7445173298078285, 0.747579549625516]]\n",
        "threshold_out_9an = [0.7623936266472957]"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAUXmSSb3sd2"
      },
      "source": [
        "def get_max_pred_value(model, img, temp):\n",
        "  logits = model(img)\n",
        "  logits = tf.math.divide(logits, temp)\n",
        "  pred = tf.nn.softmax(logits)\n",
        "  e = entropy(pred[0])\n",
        "\n",
        "  return np.max(pred), tf.argmax(pred[0]).numpy(), e"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9xuSDG43sd2"
      },
      "source": [
        "def get_mapping(leave_out_class, anomaly_class):\n",
        "  mapping = {}\n",
        "\n",
        "  labels = set(train_labels)\n",
        "  labels.remove(anomaly_class)\n",
        "  labels.remove(leave_out_class)\n",
        "  labels = sorted(labels)\n",
        "\n",
        "  for i,j in enumerate(labels):\n",
        "    mapping[i] = j\n",
        "\n",
        "  return mapping\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUdrg5Rk3sd3"
      },
      "source": [
        "ood = 0\n",
        "ind = 1"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kwLfkY7a3sd3",
        "outputId": "a8cc2f4c-8beb-432c-8c73-548afb6168b8"
      },
      "source": [
        "max_sm_all_wt_9an = []\n",
        "for data, label in tqdm(zip(test_imgs, test_lbls)):\n",
        "  img = data.reshape([-1, 28, 28, 1])\n",
        "  ref_value = []\n",
        "  \n",
        "  if label == 9:\n",
        "    lbl = ood\n",
        "  else:\n",
        "    lbl = ind\n",
        "\n",
        "\n",
        "  max0, pred_0, e0 = get_max_pred_value(model_dict[0], img, temp=temp_val[0])\n",
        "  map0 = get_mapping(0, 9)\n",
        "  pred_0 = map0[pred_0]\n",
        "\n",
        "  max1, pred_1, e1 = get_max_pred_value(model_dict[1], img, temp=temp_val[1])\n",
        "  map1 = get_mapping(1, 9)\n",
        "  pred_1 = map1[pred_1]\n",
        "\n",
        "  max2, pred_2, e2 = get_max_pred_value(model_dict[2], img, temp=temp_val[2])\n",
        "  map2 = get_mapping(2, 9)\n",
        "  pred_2 = map2[pred_2]\n",
        "\n",
        "  max3, pred_3, e3 = get_max_pred_value(model_dict[3], img, temp=temp_val[3])\n",
        "  map3 = get_mapping(3, 9)\n",
        "  pred_3 = map3[pred_3]\n",
        "\n",
        "  max4, pred_4, e4 = get_max_pred_value(model_dict[4], img, temp=temp_val[4])\n",
        "  map4 = get_mapping(4, 9)\n",
        "  pred_4 = map4[pred_4]\n",
        "\n",
        "  max5, pred_5, e5 = get_max_pred_value(model_dict[5], img, temp=temp_val[5])\n",
        "  map5 = get_mapping(5, 9)\n",
        "  pred_5 = map5[pred_5]\n",
        "\n",
        "  max6, pred_6, e6 = get_max_pred_value(model_dict[6], img, temp=temp_val[6])\n",
        "  map6 = get_mapping(6, 9)\n",
        "  pred_6 = map6[pred_6]\n",
        "\n",
        "  max7, pred_7, e7 = get_max_pred_value(model_dict[7], img, temp=temp_val[7])\n",
        "  map7 = get_mapping(7, 9)\n",
        "  pred_7 = map7[pred_7]\n",
        "\n",
        "  max8, pred_8, e8 = get_max_pred_value(model_dict[8], img, temp=temp_val[8])\n",
        "  map8 = get_mapping(8, 9)\n",
        "  pred_8 = map8[pred_8]\n",
        "\n",
        "  ref_value =[max0, max1, max2, max3, max4, max5, max6, max7, max8]\n",
        "  pred_value = [pred_0, pred_1, pred_2, pred_3, pred_4, pred_5, pred_6, pred_7, pred_8]\n",
        "  e_value = [e0, e1, e2, e3, e4, e5, e6, e7, e8]\n",
        "  e_ = 0.0\n",
        "  for  e in e_value:\n",
        "    e_ = e_ + e\n",
        "  e_ = e_/len(e_value)\n",
        "  max_sm_all_wt_9an.append([ref_value, lbl, pred_value, label, e_])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000it [20:15,  8.23it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eab30WPY3sd3"
      },
      "source": [
        "pickle_out = open(\"sm_all_wt_9an.pickle\",\"wb\")\n",
        "pickle.dump(max_sm_all_wt_9an, pickle_out)\n",
        "pickle_out.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_9TBOBc3sd4"
      },
      "source": [
        "pickle_in = open(\"sm_all_wt_9an.pickle\",\"rb\")\n",
        "max_sm_all_wt_9an = pickle.load(pickle_in)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Se5v_cX_3sd5",
        "outputId": "b38a8b63-ad88-4590-e995-63cd2d901cb0"
      },
      "source": [
        "for data, lbl, p, a_l, e_ in max_sm_all_wt_9an:\n",
        "  print(p, lbl, a_l)\n",
        "  break"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[7, 7, 7, 7, 7, 7, 7, 3, 7] 1 7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ymQeIOz3sd5",
        "outputId": "d2765216-cc95-469e-ca17-ac7bbc9f84f0"
      },
      "source": [
        "accuracy = 0.0\n",
        "count_in = 0\n",
        "count_ood = 0\n",
        "acc_in = 0.0\n",
        "acc_ood = 0.0\n",
        "tp = 0.0\n",
        "tn = 0.0\n",
        "fp = 0.0\n",
        "fn = 0.0\n",
        "y_true = []\n",
        "y_pred = []\n",
        "sim_score = []\n",
        "sim_score_ = []\n",
        "\n",
        "for data, lbl, p, a_l, e_ in max_sm_all_wt_9an:\n",
        "\n",
        "  score = 0.0\n",
        "  for d in data:\n",
        "    score = score + d\n",
        "  score = score / len(data)\n",
        "  sim_score.append(score)\n",
        "\n",
        "  dist_ood = np.linalg.norm(np.array(data) - np.array(ref_vect_out_9an[0])) \n",
        "  dist_in = np.linalg.norm(np.array(data) - np.array(ref_vect_in_9an[0]))\n",
        "\n",
        "  dist_ood2 = np.linalg.norm(np.array(e_) - np.array(entropy_out_9an[0])) \n",
        "  dist_in2 = np.linalg.norm(np.array(e_) - np.array(entropy_in_9an[0]))\n",
        "\n",
        "  dist_in = dist_in / (dist_in + dist_ood)\n",
        "  dist_ood = dist_ood / (dist_in + dist_ood)\n",
        "\n",
        "  dist_in2 = dist_in2 / (dist_in2 + dist_ood2)\n",
        "  dist_ood2 = dist_ood2 / (dist_in2 + dist_ood2)\n",
        "\n",
        "  sim_in = 1 / (1 + dist_in)\n",
        "  sim_ood = 1 / (1 + dist_ood)\n",
        "\n",
        "  sim_in2 = 1 / (1 + dist_in2)\n",
        "  sim_ood2 = 1 / (1 + dist_ood2)\n",
        "\n",
        "  sim_in = sim_in + sim_in2\n",
        "#  sim_ood = sim_ood + sim_ood2\n",
        "\n",
        "  sim_score_.append(sim_ood)\n",
        "\n",
        "  values, counts = np.unique(p, return_counts=True)\n",
        "#  print(values, counts)\n",
        "  #print(sim_in, sim_ood, lbl, e_)\n",
        "\n",
        "\n",
        "  if sim_in >= sim_ood:\n",
        "    y_ = ind\n",
        "    if np.max(counts) >= 8:\n",
        "      y_ = ind\n",
        "    else:\n",
        "      y_ = ood\n",
        "  else:\n",
        "    y_ = ood\n",
        "\n",
        "\n",
        "  y_pred.append(y_)\n",
        "  if lbl == 1:\n",
        "    y_true.append(0)\n",
        "  else:\n",
        "    y_true.append(1)\n",
        "#  y_true.append(lbl)\n",
        "\n",
        "\n",
        "  if lbl == ind:\n",
        "    count_in = count_in + 1\n",
        "  else:\n",
        "    count_ood = count_ood + 1\n",
        "\n",
        "  if y_ == lbl:\n",
        "    #sim_score_.append(1)\n",
        "    accuracy = accuracy + 1\n",
        "    if y_ == ind:\n",
        "      acc_in = acc_in + 1\n",
        "      tp = tp + 1\n",
        "    else:\n",
        "      acc_ood = acc_ood + 1\n",
        "      tn = tn + 1\n",
        "  else:\n",
        "    #sim_score_.append(0)\n",
        "    if y_ == ind:\n",
        "      fp = fp + 1\n",
        "    else:\n",
        "      fn = fn + 1\n",
        "\n",
        "\n",
        "print(\"Total Accuracy: \", accuracy/len(max_sm_all_wt_9an)) \n",
        "print(\"Accuracy of determining ID data: \", acc_in/count_in)\n",
        "print(\"Accuracy of determining OOD data: \", acc_ood/count_ood)\n"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Accuracy:  0.9279\n",
            "Accuracy of determining ID data:  0.9470581692803915\n",
            "Accuracy of determining OOD data:  0.757185332011893\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VR-JSW8t3sd5",
        "outputId": "378a43a4-1f3f-4a8c-9ee5-13ca69c46eb1"
      },
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "roc_auc_score(y_true, sim_score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9466390738277095"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HUIT0acQ3sd5",
        "outputId": "fbc9ceea-5df2-4f6c-8623-7b352aa5d244"
      },
      "source": [
        "roc_auc_score(y_true, y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8824382140096267"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0i3ZZXZ3sd6",
        "outputId": "c7216625-e2fb-4436-8a11-fd4d70a089f0"
      },
      "source": [
        "roc_auc_score(y_true, sim_score_)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9166690090597148"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYihoJzmcnZ_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}